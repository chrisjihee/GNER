<component name="ProjectRunConfigurationManager">
  <configuration default="false" name="run (train_llama3-1b-s)" type="PythonConfigurationType" factoryName="Python">
    <module name="GNER" />
    <option name="ENV_FILES" value="" />
    <option name="INTERPRETER_OPTIONS" value="" />
    <option name="PARENT_ENVS" value="true" />
    <envs>
      <env name="PYTHONUNBUFFERED" value="1" />
    </envs>
    <option name="SDK_HOME" value="" />
    <option name="WORKING_DIRECTORY" value="$PROJECT_DIR$" />
    <option name="IS_MODULE_SDK" value="true" />
    <option name="ADD_CONTENT_ROOTS" value="true" />
    <option name="ADD_SOURCE_ROOTS" value="true" />
    <EXTENSION ID="PythonCoverageRunConfigurationExtension" runner="coverage.py" />
    <option name="SCRIPT_NAME" value="$PROJECT_DIR$/src/run.py" />
    <option name="PARAMETERS" value="--do_train --do_eval --predict_with_generate --train_json_dir data/zero-shot-train.jsonl --valid_json_dir data/zero-shot-test.jsonl --no_load_gner_customized_datasets --model_name_or_path meta-llama/Llama-3.2-1B --output_dir output/train_llama3_1b_supervised-base --run_name train_llama3_1b_supervised-base --preprocessing_num_workers 4 --per_device_eval_batch_size 32 --per_device_train_batch_size 8 --gradient_accumulation_steps 4 --gradient_checkpointing True --bf16 True --tf32 True --lr_scheduler_type cosine --learning_rate 2e-05 --warmup_ratio 0.04 --weight_decay 0. --num_train_epochs 6 --max_source_length 640 --max_target_length 640 --generation_max_length 1280 --logging_strategy steps --logging_steps 10 --eval_strategy epoch --save_strategy no --overwrite_output_dir --overwrite_cache --seed 1234" />
    <option name="SHOW_COMMAND_LINE" value="false" />
    <option name="EMULATE_TERMINAL" value="false" />
    <option name="MODULE_MODE" value="false" />
    <option name="REDIRECT_INPUT" value="false" />
    <option name="INPUT_FILE" value="" />
    <method v="2" />
  </configuration>
</component>