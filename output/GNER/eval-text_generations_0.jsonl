{"id":"7","dataset":"crossner_ai","split":"dev","instance":{"id":"7","prompt_labels":"Since(O) the(O) Google(B-organization) acquisition(O) ,(O) the(O) company(O) has(O) notched(O) up(O) a(O) number(O) of(O) significant(O) achievements(O) ,(O) perhaps(O) the(O) most(O) notable(O) being(O) the(O) creation(O) of(O) AlphaGo(B-product) ,(O) a(O) program(O) that(O) defeated(O) world(O) champion(O) Lee(B-person) Sedol(I-person) at(O) the(O) complex(O) game(O) of(O) Go(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, researcher, location, organization, metric, conference, field, person, algorithm, product, country, task, university and O.\nSentence: Since the Google acquisition , the company has notched up a number of significant achievements , perhaps the most notable being the creation of AlphaGo , a program that defeated world champion Lee Sedol at the complex game of Go .","prediction_output":"Since(O) the(O) Google(B-organization) acquisition(O),(O) the(O) company(O) has(O) notched(O) up(O) a(O) number(O) of(O) significant(O) achievements(O),(O) perhaps(O) the(O) most(O) notable(O) being(O) the(O) creation(O) of(O) AlphaGo(B-product),(O) a(O) program(O) that(O) defeated(O) world(O) champion(O) Lee(B-person) Sedol(I-person) at(O) the(O) complex(O) game(O) of(O) Go(B-task).(O)","group":null,"words":["Since","the","Google","acquisition",",","the","company","has","notched","up","a","number","of","significant","achievements",",","perhaps","the","most","notable","being","the","creation","of","AlphaGo",",","a","program","that","defeated","world","champion","Lee","Sedol","at","the","complex","game","of","Go","."],"labels":["O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["programming language","researcher","location","organization","metric","conference","field","person","algorithm","product","country","task","university"]}
{"id":"31","dataset":"crossner_ai","split":"dev","instance":{"id":"31","prompt_labels":"The(O) Arduino(B-product) integrated(O) development(O) environment(O) ((O) IDE(O) )(O) is(O) a(O) cross-platform(O) application(O) ((O) for(O) Windows(B-product) ,(O) macOS(B-product) ,(O) and(O) Linux(B-product) )(O) that(O) is(O) written(O) in(O) the(O) programming(O) language(O) Java(B-programming language) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, product, metric, programming language, task, researcher, organization, conference, university, field, country, location, algorithm and O.\nSentence: The Arduino integrated development environment ( IDE ) is a cross-platform application ( for Windows , macOS , and Linux ) that is written in the programming language Java .","prediction_output":"The(O) Arduino(B-product) integrated(I-product) development(I-product) environment(I-product) ((O) IDE(O) )(O) is(O) a(O) cross-platform(O) application(O) ((O) for(O) Windows(B-product),(O) macOS(B-product),(O) and(O) Linux(B-product) )(O) that(O) is(O) written(O) in(O) the(O) programming(O) language(O) Java(B-programming language).(O)","group":null,"words":["The","Arduino","integrated","development","environment","(","IDE",")","is","a","cross-platform","application","(","for","Windows",",","macOS",",","and","Linux",")","that","is","written","in","the","programming","language","Java","."],"labels":["O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","O","B-product","O","O","O","O","O","O","O","O","B-programming language","O"],"target_index":null,"target_label":null},"label_list":["person","product","metric","programming language","task","researcher","organization","conference","university","field","country","location","algorithm"]}
{"id":"41","dataset":"crossner_ai","split":"dev","instance":{"id":"41","prompt_labels":"A(O) Java(B-programming language) implementation(O) using(O) zero(O) based(O) array(O) indexes(O) along(O) with(O) a(O) convenience(O) method(O) for(O) printing(O) the(O) solved(O) order(O) of(O) operations(O) :(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, location, metric, conference, country, product, researcher, task, university, person, programming language, organization, field and O.\nSentence: A Java implementation using zero based array indexes along with a convenience method for printing the solved order of operations :","prediction_output":"A(O) Java(B-programming language) implementation(O) using(O) zero(O) based(O) array(O) indexes(O) along(O) with(O) a(O) convenience(O) method(O) for(O) printing(O) the(O) solved(O) order(O) of(O) operations(O) :(O)","group":null,"words":["A","Java","implementation","using","zero","based","array","indexes","along","with","a","convenience","method","for","printing","the","solved","order","of","operations",":"],"labels":["O","B-programming language","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["algorithm","location","metric","conference","country","product","researcher","task","university","person","programming language","organization","field"]}
{"id":"139","dataset":"crossner_ai","split":"dev","instance":{"id":"139","prompt_labels":"One(O) of(O) the(O) first(O) versions(O) of(O) the(O) theorem(O) was(O) proved(O) by(O) George(B-researcher) Cybenko(I-researcher) in(O) 1989(O) for(O) sigmoid(B-algorithm) function(I-algorithm) activation(O) functions.(O) Cybenko(B-researcher) G.(I-researcher) ((O) 1989(O) )(O) ,(O) 2(O) ((O) 4(O) )(O) ,(O) 303-314(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, conference, organization, programming language, field, product, researcher, country, location, task, university, person, metric and O.\nSentence: One of the first versions of the theorem was proved by George Cybenko in 1989 for sigmoid function activation functions. Cybenko G. ( 1989 ) , 2 ( 4 ) , 303-314 .","prediction_output":"One(O) of(O) the(O) first(O) versions(O) of(O) the(O) theorem(O) was(O) proved(O) by(O) George(B-person) Cybenko(I-person) in(O) 1989(O) for(O) sigmoid(B-algorithm) function(I-algorithm) activation(I-algorithm) functions.(I-algorithm) Cybenko(O) G.(O) ((O) 1989(O) )(O),(O) 2(O) ((O) 4(O) )(O),(O) 303-314(O).(O)","group":null,"words":["One","of","the","first","versions","of","the","theorem","was","proved","by","George","Cybenko","in","1989","for","sigmoid","function","activation","functions.","Cybenko","G.","(","1989",")",",","2","(","4",")",",","303-314","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-researcher","I-researcher","O","O","O","B-algorithm","I-algorithm","O","O","B-researcher","I-researcher","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["algorithm","conference","organization","programming language","field","product","researcher","country","location","task","university","person","metric"]}
{"id":"161","dataset":"crossner_ai","split":"dev","instance":{"id":"161","prompt_labels":"Popular(O) loss(O) functions(O) include(O) the(O) hinge(B-metric) loss(I-metric) ((O) for(O) linear(B-algorithm) SVMs(I-algorithm) )(O) and(O) the(O) log(B-metric) loss(I-metric) ((O) for(O) logistic(B-algorithm) regression(I-algorithm) )(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, university, person, task, algorithm, product, researcher, field, programming language, organization, country, conference, location and O.\nSentence: Popular loss functions include the hinge loss ( for linear SVMs ) and the log loss ( for logistic regression ) .","prediction_output":"Popular(O) loss(O) functions(O) include(O) the(O) hinge(B-algorithm) loss(I-algorithm) ((O) for(O) linear(B-algorithm) SVMs(I-algorithm) )(O) and(O) the(O) log(B-algorithm) loss(I-algorithm) ((O) for(O) logistic(B-algorithm) regression(I-algorithm) )(O).(O)","group":null,"words":["Popular","loss","functions","include","the","hinge","loss","(","for","linear","SVMs",")","and","the","log","loss","(","for","logistic","regression",")","."],"labels":["O","O","O","O","O","B-metric","I-metric","O","O","B-algorithm","I-algorithm","O","O","O","B-metric","I-metric","O","O","B-algorithm","I-algorithm","O","O"],"target_index":null,"target_label":null},"label_list":["metric","university","person","task","algorithm","product","researcher","field","programming language","organization","country","conference","location"]}
{"id":"172","dataset":"crossner_ai","split":"dev","instance":{"id":"172","prompt_labels":"The(O) Apple(B-product) iOS(I-product) operating(I-product) system(I-product) used(O) on(O) the(O) iPhone(B-product) ,(O) iPad(B-product) and(O) iPod(B-product) Touch(I-product) uses(O) VoiceOver(B-product) speech(I-product) synthesis(I-product) accessibility(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, conference, researcher, programming language, metric, field, algorithm, university, task, product, organization, location, country and O.\nSentence: The Apple iOS operating system used on the iPhone , iPad and iPod Touch uses VoiceOver speech synthesis accessibility .","prediction_output":"The(O) Apple(B-product) iOS(I-product) operating(O) system(O) used(O) on(O) the(O) iPhone(B-product),(O) iPad(B-product) and(O) iPod(B-product) Touch(I-product) uses(O) VoiceOver(B-product) speech(O) synthesis(O) accessibility(O).(O)","group":null,"words":["The","Apple","iOS","operating","system","used","on","the","iPhone",",","iPad","and","iPod","Touch","uses","VoiceOver","speech","synthesis","accessibility","."],"labels":["O","B-product","I-product","I-product","I-product","O","O","O","B-product","O","B-product","O","B-product","I-product","O","B-product","I-product","I-product","O","O"],"target_index":null,"target_label":null},"label_list":["person","conference","researcher","programming language","metric","field","algorithm","university","task","product","organization","location","country"]}
{"id":"247","dataset":"crossner_ai","split":"dev","instance":{"id":"247","prompt_labels":"With(O) David(B-researcher) E.(I-researcher) Rumelhart(I-researcher) and(O) Ronald(B-researcher) J.(I-researcher) Williams(I-researcher) ,(O) Hinton(B-researcher) was(O) co-author(O) of(O) a(O) highly(O) cited(O) paper(O) published(O) in(O) 1986(O) that(O) popularized(O) the(O) backpropagation(B-algorithm) algorithm(I-algorithm) for(O) training(O) multi-layer(B-algorithm) neural(I-algorithm) networks(I-algorithm) ,(O) The(O) dramatic(O) image-recognition(B-task) milestone(O) of(O) the(O) AlexNet(B-algorithm) designed(O) by(O) his(O) student(O) Alex(B-researcher) Krizhevsky(I-researcher) {(O) {(O) cite(O) web(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, researcher, location, country, conference, university, organization, product, task, algorithm, person, programming language, metric and O.\nSentence: With David E. Rumelhart and Ronald J. Williams , Hinton was co-author of a highly cited paper published in 1986 that popularized the backpropagation algorithm for training multi-layer neural networks , The dramatic image-recognition milestone of the AlexNet designed by his student Alex Krizhevsky { { cite web","prediction_output":"With(O) David(B-person) E.(I-person) Rumelhart(I-person) and(O) Ronald(B-person) J.(I-person) Williams(I-person),(O) Hinton(O) was(O) co-author(O) of(O) a(O) highly(O) cited(O) paper(O) published(O) in(O) 1986(O) that(O) popularized(O) the(O) backpropagation(B-algorithm) algorithm(I-algorithm) for(O) training(O) multi-layer(B-algorithm) neural(I-algorithm) networks(I-algorithm),(O) The(O) dramatic(O) image-recognition(O) milestone(O) of(O) the(O) AlexNet(B-product) designed(O) by(O) his(O) student(O) Alex(B-person) Krizhevsky(I-person) (O) (O) cite(O) web(O)","group":null,"words":["With","David","E.","Rumelhart","and","Ronald","J.","Williams",",","Hinton","was","co-author","of","a","highly","cited","paper","published","in","1986","that","popularized","the","backpropagation","algorithm","for","training","multi-layer","neural","networks",",","The","dramatic","image-recognition","milestone","of","the","AlexNet","designed","by","his","student","Alex","Krizhevsky","{","{","cite","web"],"labels":["O","B-researcher","I-researcher","I-researcher","O","B-researcher","I-researcher","I-researcher","O","B-researcher","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","B-task","O","O","O","B-algorithm","O","O","O","O","B-researcher","I-researcher","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","researcher","location","country","conference","university","organization","product","task","algorithm","person","programming language","metric"]}
{"id":"292","dataset":"crossner_ai","split":"dev","instance":{"id":"292","prompt_labels":"The(O) manipulator(O) is(O) what(O) makes(O) the(O) robot(O) move(O) ,(O) and(O) the(O) design(O) of(O) these(O) systems(O) can(O) be(O) categorized(O) into(O) several(O) common(O) types(O) ,(O) such(O) as(O) SCARA(O) and(O) cartesian(O) coordinate(O) robot(O) ,(O) which(O) use(O) different(O) coordinate(O) systems(O) to(O) direct(O) the(O) arms(O) of(O) the(O) machine(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, product, task, university, metric, person, programming language, location, conference, country, organization, researcher, field and O.\nSentence: The manipulator is what makes the robot move , and the design of these systems can be categorized into several common types , such as SCARA and cartesian coordinate robot , which use different coordinate systems to direct the arms of the machine .","prediction_output":"The(O) manipulator(O) is(O) what(O) makes(O) the(O) robot(O) move(O),(O) and(O) the(O) design(O) of(O) these(O) systems(O) can(O) be(O) categorized(O) into(O) several(O) common(O) types(O),(O) such(O) as(O) SCARA(B-algorithm) and(O) cartesian(B-product) coordinate(I-product) robot(I-product),(O) which(O) use(O) different(O) coordinate(O) systems(O) to(O) direct(O) the(O) arms(O) of(O) the(O) machine(O).(O)","group":null,"words":["The","manipulator","is","what","makes","the","robot","move",",","and","the","design","of","these","systems","can","be","categorized","into","several","common","types",",","such","as","SCARA","and","cartesian","coordinate","robot",",","which","use","different","coordinate","systems","to","direct","the","arms","of","the","machine","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["algorithm","product","task","university","metric","person","programming language","location","conference","country","organization","researcher","field"]}
{"id":"319","dataset":"crossner_ai","split":"dev","instance":{"id":"319","prompt_labels":"The(O) method(O) is(O) based(O) on(O) estimating(O) the(O) conditional(O) probabilities(O) using(O) the(O) nonparametric(B-metric) maximum(I-metric) likelihood(I-metric) method(O) which(O) leads(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, university, organization, conference, task, algorithm, metric, country, location, researcher, programming language, product, person and O.\nSentence: The method is based on estimating the conditional probabilities using the nonparametric maximum likelihood method which leads","prediction_output":"The(O) method(O) is(O) based(O) on(O) estimating(O) the(O) conditional(O) probabilities(O) using(O) the(O) nonparametric(B-algorithm) maximum(I-algorithm) likelihood(I-algorithm) method(I-algorithm) which(O) leads(O)","group":null,"words":["The","method","is","based","on","estimating","the","conditional","probabilities","using","the","nonparametric","maximum","likelihood","method","which","leads"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","university","organization","conference","task","algorithm","metric","country","location","researcher","programming language","product","person"]}
{"id":"330","dataset":"crossner_ai","split":"dev","instance":{"id":"330","prompt_labels":"In(O) addition(O) to(O) the(O) standard(O) hinge(B-metric) loss(I-metric) math(O) ((O) 1-yf(O) ((O) x(O) )(O) )(O) _(O) +(O) /(O) math(O) for(O) labeled(O) data(O) ,(O) a(O) loss(O) function(O) math(O) ((O) -1(O) |(O) f(O) ((O) x(O) )(O) |(O) )(O) _(O) +(O) /(O) math(O) is(O) introduced(O) over(O) the(O) unlabeled(O) data(O) by(O) letting(O) mathy(O) =(O) \\(O) operatorname(O) {(O) sign(O) }(O) {(O) f(O) ((O) x(O) )(O) }(O) /(O) math(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, researcher, metric, conference, university, location, person, product, programming language, algorithm, organization, task, field and O.\nSentence: In addition to the standard hinge loss math ( 1-yf ( x ) ) _ + / math for labeled data , a loss function math ( -1 | f ( x ) | ) _ + / math is introduced over the unlabeled data by letting mathy = \\ operatorname { sign } { f ( x ) } / math .","prediction_output":"In(O) addition(O) to(O) the(O) standard(O) hinge(B-algorithm) loss(I-algorithm) math(O) ((O) 1-yf(O) ((O) x(O) )(O) )(O) _(O) +(O) /(O) math(O) for(O) labeled(O) data(O),(O) a(O) loss(B-algorithm) function(I-algorithm) math(O) ((O) -1(O) |(O) f(O) ((O) x(O) )(O) |(O) )(O) _(O) +(O) /(O) math(O) is(O) introduced(O) over(O) the(O) unlabeled(O) data(O) by(O) letting(O) mathy(O) =(O) (O) operatorname(O) (O) sign(O) (O) (O) f(O) ((O) x(O) )(O) (O) /(O) math(O).(O)","group":null,"words":["In","addition","to","the","standard","hinge","loss","math","(","1-yf","(","x",")",")","_","+","/","math","for","labeled","data",",","a","loss","function","math","(","-1","|","f","(","x",")","|",")","_","+","/","math","is","introduced","over","the","unlabeled","data","by","letting","mathy","=","\\","operatorname","{","sign","}","{","f","(","x",")","}","/","math","."],"labels":["O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","researcher","metric","conference","university","location","person","product","programming language","algorithm","organization","task","field"]}
{"id":"12","dataset":"crossner_literature","split":"dev","instance":{"id":"12","prompt_labels":"Later(O) in(O) his(O) life(O) ,(O) Ginsberg(B-writer) formed(O) a(O) bridge(O) between(O) the(O) beat(O) movement(O) of(O) the(O) 1950s(O) and(O) the(O) hippie(O) s(O) of(O) the(O) 1960s(O) ,(O) befriending(O) ,(O) among(O) others(O) ,(O) Timothy(B-writer) Leary(I-writer) ,(O) Ken(B-writer) Kesey(I-writer) ,(O) Hunter(B-writer) S.(I-writer) Thompson(I-writer) ,(O) and(O) Bob(B-writer) Dylan(I-writer) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, award, organization, event, location, country, writer, literary genre, poem, book, magazine and O.\nSentence: Later in his life , Ginsberg formed a bridge between the beat movement of the 1950s and the hippie s of the 1960s , befriending , among others , Timothy Leary , Ken Kesey , Hunter S. Thompson , and Bob Dylan .","prediction_output":"Later(O) in(O) his(O) life(O),(O) Ginsberg(O) formed(O) a(O) bridge(O) between(O) the(O) beat(B-event) movement(I-event) of(O) the(O) 1950s(O) and(O) the(O) hippie(B-event) s(I-event) of(O) the(O) 1960s(O),(O) befriending(O),(O) among(O) others(O),(O) Timothy(B-person) Leary(I-person),(O) Ken(B-person) Kesey(I-person),(O) Hunter(B-person) S.(I-person) Thompson(I-person),(O) and(O) Bob(B-person) Dylan(I-person).(O)","group":null,"words":["Later","in","his","life",",","Ginsberg","formed","a","bridge","between","the","beat","movement","of","the","1950s","and","the","hippie","s","of","the","1960s",",","befriending",",","among","others",",","Timothy","Leary",",","Ken","Kesey",",","Hunter","S.","Thompson",",","and","Bob","Dylan","."],"labels":["O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["person","award","organization","event","location","country","writer","literary genre","poem","book","magazine"]}
{"id":"93","dataset":"crossner_literature","split":"dev","instance":{"id":"93","prompt_labels":"The(O) crowds(O) were(O) delighted(O) with(O) the(O) stories(O) of(O) romances(O) ,(O) the(O) wickedness(O) of(O) Macaire(B-poem) ,(O) and(O) the(O) misfortunes(O) of(O) Blanziflor(B-poem) ,(O) the(O) terrors(O) of(O) the(O) Babilonia(B-poem) Infernale(I-poem) and(O) the(O) blessedness(O) of(O) the(O) Gerusalemme(B-poem) celeste(I-poem) ,(O) and(O) the(O) singers(O) of(O) religious(O) poetry(B-literary genre) vied(O) with(O) those(O) of(O) the(O) chansons(B-poem) de(I-poem) geste(I-poem) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, writer, literary genre, location, award, poem, event, country, organization, book, person and O.\nSentence: The crowds were delighted with the stories of romances , the wickedness of Macaire , and the misfortunes of Blanziflor , the terrors of the Babilonia Infernale and the blessedness of the Gerusalemme celeste , and the singers of religious poetry vied with those of the chansons de geste .","prediction_output":"the(O) her(O) to(O) the(O) stories(O) of(O) romances(O),(O) the(O) wickedness(O) of(O) Macaire(B-person),(O) and(O) the(O) misfortunes(O) of(O) Blanziflor(B-person),(O) the(O) terrors(O) of(O) the(O) Babilonia(B-book) Infernale(I-book) and(O) the(O) blessedness(O) of(O) the(O) Gerusalemme(B-book) celeste(I-book),(O) and(O) the(O) singers(O) of(O) religious(B-literary genre) poetry(I-literary genre) vied(O) with(O) those(O) of(O) the(O) chansons(B-poem) de(I-poem) geste(I-poem).(O)","group":null,"words":["The","crowds","were","delighted","with","the","stories","of","romances",",","the","wickedness","of","Macaire",",","and","the","misfortunes","of","Blanziflor",",","the","terrors","of","the","Babilonia","Infernale","and","the","blessedness","of","the","Gerusalemme","celeste",",","and","the","singers","of","religious","poetry","vied","with","those","of","the","chansons","de","geste","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-poem","O","O","O","O","O","B-poem","O","O","O","O","O","B-poem","I-poem","O","O","O","O","O","B-poem","I-poem","O","O","O","O","O","O","B-literary genre","O","O","O","O","O","B-poem","I-poem","I-poem","O"],"target_index":null,"target_label":null},"label_list":["magazine","writer","literary genre","location","award","poem","event","country","organization","book","person"]}
{"id":"110","dataset":"crossner_literature","split":"dev","instance":{"id":"110","prompt_labels":"Nominated(O) for(O) Academy(B-award) Awards(I-award) in(O) nine(O) categories(O) ,(O) it(O) won(O) an(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Screenplay(I-award) by(O) Herman(B-writer) J.(I-writer) Mankiewicz(I-writer) and(O) Welles(B-writer) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, writer, literary genre, poem, book, magazine, person, event, award, country, organization and O.\nSentence: Nominated for Academy Awards in nine categories , it won an Academy Award for Best Original Screenplay by Herman J. Mankiewicz and Welles .","prediction_output":"Nominated(O) for(O) Academy(B-event) Awards(I-event) in(O) nine(O) categories(O),(O) it(O) won(O) an(O) Academy(B-award) Award(I-award) for(O) Best(O) Original(O) Screenplay(O) by(O) Herman(B-writer) J.(I-writer) Mankiewicz(I-writer) and(O) Welles(O).(O)","group":null,"words":["Nominated","for","Academy","Awards","in","nine","categories",",","it","won","an","Academy","Award","for","Best","Original","Screenplay","by","Herman","J.","Mankiewicz","and","Welles","."],"labels":["O","O","B-award","I-award","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-writer","I-writer","I-writer","O","B-writer","O"],"target_index":null,"target_label":null},"label_list":["location","writer","literary genre","poem","book","magazine","person","event","award","country","organization"]}
{"id":"138","dataset":"crossner_literature","split":"dev","instance":{"id":"138","prompt_labels":"The(B-organization) Letterman(I-organization) Foundation(I-organization) for(I-organization) Courtesy(I-organization) and(I-organization) Grooming(I-organization) is(O) a(O) private(O) foundation(O) through(O) which(O) Letterman(B-writer) has(O) donated(O) millions(O) of(O) dollars(O) to(O) charities(O) and(O) other(O) non-profits(O) in(O) Indiana(B-location) and(O) Montana(B-location) ,(O) celebrity-affiliated(O) organizations(O) such(O) as(O) Paul(B-person) Newman(I-person) '(O) s(O) Hole(B-organization) in(I-organization) the(I-organization) Wall(I-organization) Gang(I-organization) Camp(I-organization) ,(O) Ball(B-organization) State(I-organization) University(I-organization) ,(O) the(O) American(B-organization) Cancer(I-organization) Society(I-organization) ,(O) the(O) Salvation(B-organization) Army(I-organization) ,(O) and(O) Médecins(B-organization) Sans(I-organization) Frontières(I-organization) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: writer, book, country, literary genre, award, person, magazine, location, organization, event, poem and O.\nSentence: The Letterman Foundation for Courtesy and Grooming is a private foundation through which Letterman has donated millions of dollars to charities and other non-profits in Indiana and Montana , celebrity-affiliated organizations such as Paul Newman ' s Hole in the Wall Gang Camp , Ball State University , the American Cancer Society , the Salvation Army , and Médecins Sans Frontières .","prediction_output":"The(O) Letterman(B-organization) Foundation(I-organization) for(I-organization) Courtesy(I-organization) and(I-organization) Grooming(I-organization) is(O) a(O) private(O) foundation(O) through(O) which(O) Letterman(O) has(O) donated(O) millions(O) of(O) dollars(O) to(O) charities(O) and(O) other(O) non-profits(O) in(O) Indiana(B-location) and(O) Montana(B-location),(O) celebrity-affiliated(O) organizations(O) such(O) as(O) Paul(B-person) Newman(I-person) '(O) s(O) Hole(B-organization) in(I-organization) the(I-organization) Wall(I-organization) Gang(I-organization) Camp(I-organization),(O) Ball(B-organization) State(I-organization) University(I-organization),(O) the(O) American(B-organization) Cancer(I-organization) Society(I-organization),(O) the(O) Salvation(B-organization) Army(I-organization),(O) and(O) Médecins(B-organization) Sans(I-organization) Frontières(I-organization).(O)","group":null,"words":["The","Letterman","Foundation","for","Courtesy","and","Grooming","is","a","private","foundation","through","which","Letterman","has","donated","millions","of","dollars","to","charities","and","other","non-profits","in","Indiana","and","Montana",",","celebrity-affiliated","organizations","such","as","Paul","Newman","'","s","Hole","in","the","Wall","Gang","Camp",",","Ball","State","University",",","the","American","Cancer","Society",",","the","Salvation","Army",",","and","Médecins","Sans","Frontières","."],"labels":["B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-location","O","O","O","O","O","B-person","I-person","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["writer","book","country","literary genre","award","person","magazine","location","organization","event","poem"]}
{"id":"177","dataset":"crossner_literature","split":"dev","instance":{"id":"177","prompt_labels":"The(O) main(O) facts(O) of(O) his(O) life(O) are(O) stated(O) in(O) his(O) long(B-literary genre) poem(I-literary genre) De(B-poem) triumphis(I-poem) ecclesiae(I-poem) ((O) On(B-poem) the(I-poem) triumphs(I-poem) of(I-poem) the(I-poem) Church(I-poem) )(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, magazine, award, book, country, person, literary genre, writer, poem, event, location and O.\nSentence: The main facts of his life are stated in his long poem De triumphis ecclesiae ( On the triumphs of the Church ) .","prediction_output":"The(O) main(O) facts(O) of(O) his(O) life(O) are(O) stated(O) in(O) his(O) long(O) poem(O) De(B-poem) triumphis(I-poem) ecclesiae(I-poem) ((O) On(O) the(O) triumphs(O) of(O) the(O) Church(B-organization) )(O).(O)","group":null,"words":["The","main","facts","of","his","life","are","stated","in","his","long","poem","De","triumphis","ecclesiae","(","On","the","triumphs","of","the","Church",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-literary genre","I-literary genre","B-poem","I-poem","I-poem","O","B-poem","I-poem","I-poem","I-poem","I-poem","I-poem","O","O"],"target_index":null,"target_label":null},"label_list":["organization","magazine","award","book","country","person","literary genre","writer","poem","event","location"]}
{"id":"262","dataset":"crossner_literature","split":"dev","instance":{"id":"262","prompt_labels":"Famous(O) Hopwood(B-award) award(I-award) winners(O) include(O) Robert(B-writer) Hayden(I-writer) ,(O) Marge(B-writer) Piercy(I-writer) ,(O) Arthur(B-writer) Miller(I-writer) ,(O) Betty(B-writer) Smith(I-writer) ,(O) Lawrence(B-writer) Kasdan(I-writer) ,(O) John(B-writer) Ciardi(I-writer) ,(O) Mary(B-writer) Gaitskill(I-writer) ,(O) Edmund(B-writer) White(I-writer) ,(O) Nancy(B-writer) Willard(I-writer) ,(O) Frank(B-writer) O(I-writer) 'Hara(I-writer) ,(O) and(O) I-writer(B-writer) I-writer(I-writer) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, country, book, event, literary genre, magazine, organization, person, writer, poem and O.\nSentence: Famous Hopwood award winners include Robert Hayden , Marge Piercy , Arthur Miller , Betty Smith , Lawrence Kasdan , John Ciardi , Mary Gaitskill , Edmund White , Nancy Willard , Frank O 'Hara , and I-writer I-writer .","prediction_output":"Famous(O) Hopwood(B-award) award(I-award) winners(O) include(O) Robert(B-writer) Hayden(I-writer),(O) Marge(B-writer) Piercy(I-writer),(O) Arthur(B-writer) Miller(I-writer),(O) Betty(B-writer) Smith(I-writer),(O) Lawrence(B-writer) Kasdan(I-writer),(O) John(B-writer) Ciardi(I-writer),(O) Mary(B-writer) Gaitskill(I-writer),(O) Edmund(B-writer) White(I-writer),(O) Nancy(B-writer) Willard(I-writer),(O) Frank(B-writer) O(I-writer) 'Hara(I-writer),(O) and(O) I-writer(B-poem) I-writer(I-poem).(O)","group":null,"words":["Famous","Hopwood","award","winners","include","Robert","Hayden",",","Marge","Piercy",",","Arthur","Miller",",","Betty","Smith",",","Lawrence","Kasdan",",","John","Ciardi",",","Mary","Gaitskill",",","Edmund","White",",","Nancy","Willard",",","Frank","O","'Hara",",","and","I-writer","I-writer","."],"labels":["O","B-award","I-award","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["award","location","country","book","event","literary genre","magazine","organization","person","writer","poem"]}
{"id":"294","dataset":"crossner_literature","split":"dev","instance":{"id":"294","prompt_labels":"Master(B-book) Humphrey(I-book) 's(I-book) Clock(I-book) was(O) shut(O) down(O) ,(O) though(O) Dickens(B-writer) was(O) still(O) keen(O) on(O) the(O) idea(O) of(O) the(O) weekly(O) magazine(O) ,(O) a(O) form(O) he(O) liked(O) ,(O) a(O) liking(O) that(O) had(O) begun(O) with(O) his(O) childhood(O) reading(O) of(O) the(O) eighteenth-century(O) magazines(O) Tatler(B-magazine) and(O) The(B-magazine) Spectator(I-magazine) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, book, award, country, event, writer, organization, poem, literary genre, magazine, location and O.\nSentence: Master Humphrey 's Clock was shut down , though Dickens was still keen on the idea of the weekly magazine , a form he liked , a liking that had begun with his childhood reading of the eighteenth-century magazines Tatler and The Spectator .","prediction_output":"Master(O) Humphrey(O)'s(O) Clock(O) was(O) shut(O) down(O),(O) though(O) Dickens(O) was(O) still(O) keen(O) on(O) the(O) idea(O) of(O) the(O) weekly(O) magazine(O),(O) a(O) form(O) he(O) liked(O),(O) a(O) liking(O) that(O) had(O) begun(O) with(O) his(O) childhood(O) reading(O) of(O) the(O) eighteenth-century(O) magazines(O) Tatler(B-magazine) and(O) The(B-magazine) Spectator(I-magazine).(O)","group":null,"words":["Master","Humphrey","'s","Clock","was","shut","down",",","though","Dickens","was","still","keen","on","the","idea","of","the","weekly","magazine",",","a","form","he","liked",",","a","liking","that","had","begun","with","his","childhood","reading","of","the","eighteenth-century","magazines","Tatler","and","The","Spectator","."],"labels":["B-book","I-book","I-book","I-book","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-magazine","O","B-magazine","I-magazine","O"],"target_index":null,"target_label":null},"label_list":["person","book","award","country","event","writer","organization","poem","literary genre","magazine","location"]}
{"id":"318","dataset":"crossner_literature","split":"dev","instance":{"id":"318","prompt_labels":"Elizabeth(B-writer) Gaskell(I-writer) '(O) s(O) biography(B-literary genre) The(B-book) Life(I-book) of(I-book) Charlotte(I-book) Brontë(I-book) was(O) published(O) in(O) 1857(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, location, literary genre, organization, person, award, event, book, magazine, writer, poem and O.\nSentence: Elizabeth Gaskell ' s biography The Life of Charlotte Brontë was published in 1857 .","prediction_output":"Elizabeth(B-person) Gaskell(I-person) '(O) s(O) biography(O) The(B-book) Life(I-book) of(I-book) Charlotte(I-book) Bront(I-book) was(O) published(O) in(O) 1857(O).(O)","group":null,"words":["Elizabeth","Gaskell","'","s","biography","The","Life","of","Charlotte","Brontë","was","published","in","1857","."],"labels":["B-writer","I-writer","O","O","B-literary genre","B-book","I-book","I-book","I-book","I-book","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","location","literary genre","organization","person","award","event","book","magazine","writer","poem"]}
{"id":"336","dataset":"crossner_literature","split":"dev","instance":{"id":"336","prompt_labels":"In(O) 1909(O) ,(O) Strindberg(B-writer) thought(O) he(O) might(O) get(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) ,(O) but(O) instead(O) lost(O) to(O) Selma(B-writer) Lagerlöf(I-writer) ,(O) the(O) first(O) woman(O) and(O) first(O) Swede(O) to(O) win(O) the(O) award(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, magazine, country, literary genre, event, location, poem, person, award, writer, book and O.\nSentence: In 1909 , Strindberg thought he might get the Nobel Prize in Literature , but instead lost to Selma Lagerlöf , the first woman and first Swede to win the award .","prediction_output":"In(O) 1909(O),(O) Strindberg(O) thought(O) he(O) might(O) get(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award),(O) but(O) instead(O) lost(O) to(O) Selma(B-person) Lagerlöf(I-person),(O) the(O) first(O) woman(O) and(O) first(O) Swede(O) to(O) win(O) the(O) award(O).(O)","group":null,"words":["In","1909",",","Strindberg","thought","he","might","get","the","Nobel","Prize","in","Literature",",","but","instead","lost","to","Selma","Lagerlöf",",","the","first","woman","and","first","Swede","to","win","the","award","."],"labels":["O","O","O","B-writer","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","magazine","country","literary genre","event","location","poem","person","award","writer","book"]}
{"id":"391","dataset":"crossner_literature","split":"dev","instance":{"id":"391","prompt_labels":"In(O) 1946(O) the(O) Society(B-organization) of(I-organization) Jesus(I-organization) was(O) banned(O) and(O) the(O) Franciscans(B-organization) were(O) banned(O) in(O) 1947(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, location, country, literary genre, event, organization, magazine, book, poem, person, writer and O.\nSentence: In 1946 the Society of Jesus was banned and the Franciscans were banned in 1947 .","prediction_output":"In(O) 1946(O) the(O) Society(B-organization) of(I-organization) Jesus(I-organization) was(O) banned(O) and(O) the(O) Franciscans(B-organization) were(O) banned(O) in(O) 1947(O).(O)","group":null,"words":["In","1946","the","Society","of","Jesus","was","banned","and","the","Franciscans","were","banned","in","1947","."],"labels":["O","O","O","B-organization","I-organization","I-organization","O","O","O","O","B-organization","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","location","country","literary genre","event","organization","magazine","book","poem","person","writer"]}
{"id":"80","dataset":"crossner_music","split":"dev","instance":{"id":"80","prompt_labels":"This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization) ,(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization) ,(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, person, location, musical instrument, country, band, event, album, musical artist, award, song, organization and O.\nSentence: This is the method used by Bands of America , the Indiana State School Music Association , Kentucky Music Educators Association and the University Interscholastic League .","prediction_output":"This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization),(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization),(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization).(O)","group":null,"words":["This","is","the","method","used","by","Bands","of","America",",","the","Indiana","State","School","Music","Association",",","Kentucky","Music","Educators","Association","and","the","University","Interscholastic","League","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["music genre","person","location","musical instrument","country","band","event","album","musical artist","award","song","organization"]}
{"id":"84","dataset":"crossner_music","split":"dev","instance":{"id":"84","prompt_labels":"Other(O) acts(O) who(O) became(O) prominent(O) in(O) the(O) alt-country(B-music genre) genre(I-music genre) during(O) the(O) 1990s(O) and(O) 2000s(O) included(O) The(B-band) Bottle(I-band) Rockets(I-band) ,(O) The(B-band) Handsome(I-band) Family(I-band) ,(O) Blue(B-band) Mountain(I-band) ,(O) Robbie(B-band) Fulks(I-band) ,(O) Blood(B-band) Oranges(I-band) ,(O) Bright(B-band) Eyes(I-band) ,(O) Drive-By(B-band) Truckers(I-band) ,(O) Old(B-band) 97(I-band) 's(I-band) ,(O) Old(B-band) Crow(I-band) Medicine(I-band) Show(I-band) ,(O) Nickel(B-band) Creek(I-band) ,(O) Neko(B-musical artist) Case(I-musical artist) ,(O) and(O) Whiskeytown(B-band) ,(O) whose(O) lead(O) singer(O) Ryan(B-musical artist) Adams(I-musical artist) later(O) had(O) a(O) successful(O) solo-career(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, organization, person, location, music genre, song, musical instrument, album, musical artist, award, event, band and O.\nSentence: Other acts who became prominent in the alt-country genre during the 1990s and 2000s included The Bottle Rockets , The Handsome Family , Blue Mountain , Robbie Fulks , Blood Oranges , Bright Eyes , Drive-By Truckers , Old 97 's , Old Crow Medicine Show , Nickel Creek , Neko Case , and Whiskeytown , whose lead singer Ryan Adams later had a successful solo-career .","prediction_output":"Other(O) acts(O) who(O) became(O) prominent(O) in(O) the(O) alt-country(B-music genre) genre(O) during(O) the(O) 1990s(O) and(O) 2000s(O) included(O) The(B-band) Bottle(I-band) Rockets(I-band),(O) The(B-band) Handsome(I-band) Family(I-band),(O) Blue(B-band) Mountain(I-band),(O) Robbie(B-musical artist) Fulks(I-musical artist),(O) Blood(B-band) Oranges(I-band),(O) Bright(B-band) Eyes(I-band),(O) Drive-By(B-band) Truckers(I-band),(O) Old(B-band) 97(I-band)'s(I-band),(O) Old(B-band) Crow(I-band) Medicine(I-band) Show(I-band),(O) Nickel(B-band) Creek(I-band),(O) Neko(B-musical artist) Case(I-musical artist),(O) and(O) Whiskeytown(B-band),(O) whose(O) lead(O) singer(O) Ryan(B-musical artist) Adams(I-musical artist) later(O) had(O) a(O) successful(O) solo-career(O).(O)","group":null,"words":["Other","acts","who","became","prominent","in","the","alt-country","genre","during","the","1990s","and","2000s","included","The","Bottle","Rockets",",","The","Handsome","Family",",","Blue","Mountain",",","Robbie","Fulks",",","Blood","Oranges",",","Bright","Eyes",",","Drive-By","Truckers",",","Old","97","'s",",","Old","Crow","Medicine","Show",",","Nickel","Creek",",","Neko","Case",",","and","Whiskeytown",",","whose","lead","singer","Ryan","Adams","later","had","a","successful","solo-career","."],"labels":["O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","B-band","I-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","O","B-musical artist","I-musical artist","O","O","B-band","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","organization","person","location","music genre","song","musical instrument","album","musical artist","award","event","band"]}
{"id":"160","dataset":"crossner_music","split":"dev","instance":{"id":"160","prompt_labels":"The(O) album(O) also(O) features(O) appearances(O) by(O) Damian(B-musical artist) Marley(I-musical artist) ,(O) son(O) of(O) Bob(B-person) Marley(I-person) ,(O) Prodigy(B-musical artist) of(O) Mobb(B-band) Deep(I-band) and(O) producers(O) the(B-musical artist) Alchemist(I-musical artist) and(O) Fredwreck(B-musical artist) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, musical artist, country, award, musical instrument, event, band, person, organization, music genre, location, album and O.\nSentence: The album also features appearances by Damian Marley , son of Bob Marley , Prodigy of Mobb Deep and producers the Alchemist and Fredwreck .","prediction_output":"The(O) album(O) also(O) features(O) appearances(O) by(O) Damian(B-musical artist) Marley(I-musical artist),(O) son(O) of(O) Bob(B-musical artist) Marley(I-musical artist),(O) Prodigy(B-musical artist) of(O) Mobb(B-band) Deep(I-band) and(O) producers(O) the(O) Alchemist(B-musical artist) and(O) Fredwreck(B-musical artist).(O)","group":null,"words":["The","album","also","features","appearances","by","Damian","Marley",",","son","of","Bob","Marley",",","Prodigy","of","Mobb","Deep","and","producers","the","Alchemist","and","Fredwreck","."],"labels":["O","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","B-person","I-person","O","B-musical artist","O","B-band","I-band","O","O","B-musical artist","I-musical artist","O","B-musical artist","O"],"target_index":null,"target_label":null},"label_list":["song","musical artist","country","award","musical instrument","event","band","person","organization","music genre","location","album"]}
{"id":"162","dataset":"crossner_music","split":"dev","instance":{"id":"162","prompt_labels":"Rebana(B-musical instrument) is(O) a(O) Malay(B-musical instrument) tambourine(I-musical instrument) that(O) is(O) used(O) in(O) Islamic(B-music genre) devotional(I-music genre) music(I-music genre) in(O) Southeast(B-location) Asia(B-location) ,(O) particularly(O) in(O) Indonesia(B-country) ,(O) Malaysia(B-country) ,(O) Brunei(B-country) ,(O) and(O) Singapore(B-country) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, song, organization, event, person, album, musical instrument, award, location, band, music genre, musical artist and O.\nSentence: Rebana is a Malay tambourine that is used in Islamic devotional music in Southeast Asia , particularly in Indonesia , Malaysia , Brunei , and Singapore .","prediction_output":"Rebana(B-musical instrument) is(O) a(O) Malay(O) tambourine(O) that(O) is(O) used(O) in(O) Islamic(B-music genre) devotional(I-music genre) music(I-music genre) in(O) Southeast(B-location) Asia(I-location),(O) particularly(O) in(O) Indonesia(B-country),(O) Malaysia(B-country),(O) Brunei(B-country),(O) and(O) Singapore(B-country).(O)","group":null,"words":["Rebana","is","a","Malay","tambourine","that","is","used","in","Islamic","devotional","music","in","Southeast","Asia",",","particularly","in","Indonesia",",","Malaysia",",","Brunei",",","and","Singapore","."],"labels":["B-musical instrument","O","O","B-musical instrument","I-musical instrument","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-location","B-location","O","O","O","B-country","O","B-country","O","B-country","O","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["country","song","organization","event","person","album","musical instrument","award","location","band","music genre","musical artist"]}
{"id":"167","dataset":"crossner_music","split":"dev","instance":{"id":"167","prompt_labels":"It(O) is(O) generally(O) divided(O) into(O) two(O) major(O) subgenres(O) ,(O) with(O) the(O) jazz(B-music genre) -influenced(O) New(B-music genre) Orleans(I-music genre) blues(I-music genre) based(O) on(O) the(O) musical(O) traditions(O) of(O) that(O) city(O) and(O) the(O) slower(O) tempo(O) swamp(B-music genre) blues(I-music genre) incorporating(O) influences(O) from(O) zydeco(B-music genre) and(O) Cajun(B-music genre) music(I-music genre) from(O) around(O) Baton(B-location) Rouge(I-location) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, organization, country, music genre, award, location, band, song, musical instrument, musical artist, event, person and O.\nSentence: It is generally divided into two major subgenres , with the jazz -influenced New Orleans blues based on the musical traditions of that city and the slower tempo swamp blues incorporating influences from zydeco and Cajun music from around Baton Rouge .","prediction_output":"It(O) is(O) generally(O) divided(O) into(O) two(O) major(O) subgenres(O),(O) with(O) the(O) jazz(O) -influenced(O) New(B-music genre) Orleans(I-music genre) blues(I-music genre) based(O) on(O) the(O) musical(O) traditions(O) of(O) that(O) city(O) and(O) the(O) slower(O) tempo(O) swamp(B-music genre) blues(I-music genre) incorporating(O) influences(O) from(O) zydeco(B-music genre) and(O) Cajun(B-music genre) music(I-music genre) from(O) around(O) Baton(B-location) Rouge(I-location).(O)","group":null,"words":["It","is","generally","divided","into","two","major","subgenres",",","with","the","jazz","-influenced","New","Orleans","blues","based","on","the","musical","traditions","of","that","city","and","the","slower","tempo","swamp","blues","incorporating","influences","from","zydeco","and","Cajun","music","from","around","Baton","Rouge","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-music genre","O","B-music genre","I-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","O","B-music genre","O","B-music genre","I-music genre","O","O","B-location","I-location","O"],"target_index":null,"target_label":null},"label_list":["album","organization","country","music genre","award","location","band","song","musical instrument","musical artist","event","person"]}
{"id":"207","dataset":"crossner_music","split":"dev","instance":{"id":"207","prompt_labels":"In(O) the(O) twentieth(O) century(O) ,(O) Christian(B-music genre) music(I-music genre) has(O) developed(O) to(O) reflect(O) the(O) emergence(O) of(O) a(O) diverse(O) array(O) of(O) musical(O) genres(O) including(O) Rock(B-music genre) music(I-music genre) ,(O) metal(B-music genre) ,(O) Pop(B-music genre) music(I-music genre) ,(O) jazz(B-music genre) ,(O) Contemporary(B-music genre) Christian(I-music genre) music(I-music genre) ,(O) rap(B-music genre) ,(O) spiritual(B-music genre) ,(O) Country(B-music genre) music(I-music genre) ,(O) blues(B-music genre) ,(O) and(O) Gospel(B-music genre) music(I-music genre) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, country, organization, album, musical instrument, band, song, person, award, event, musical artist, location and O.\nSentence: In the twentieth century , Christian music has developed to reflect the emergence of a diverse array of musical genres including Rock music , metal , Pop music , jazz , Contemporary Christian music , rap , spiritual , Country music , blues , and Gospel music .","prediction_output":"In(O) the(O) twentieth(O) century(O),(O) Christian(B-music genre) music(I-music genre) has(O) developed(O) to(O) reflect(O) the(O) emergence(O) of(O) a(O) diverse(O) array(O) of(O) musical(O) genres(O) including(O) Rock(B-music genre) music(I-music genre),(O) metal(B-music genre),(O) Pop(B-music genre) music(I-music genre),(O) jazz(B-music genre),(O) Contemporary(B-music genre) Christian(I-music genre) music(I-music genre),(O) rap(B-music genre),(O) spiritual(B-music genre),(O) Country(B-music genre) music(I-music genre),(O) blues(B-music genre),(O) and(O) Gospel(B-music genre) music(I-music genre).(O)","group":null,"words":["In","the","twentieth","century",",","Christian","music","has","developed","to","reflect","the","emergence","of","a","diverse","array","of","musical","genres","including","Rock","music",",","metal",",","Pop","music",",","jazz",",","Contemporary","Christian","music",",","rap",",","spiritual",",","Country","music",",","blues",",","and","Gospel","music","."],"labels":["O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","O","O","B-music genre","I-music genre","O"],"target_index":null,"target_label":null},"label_list":["music genre","country","organization","album","musical instrument","band","song","person","award","event","musical artist","location"]}
{"id":"219","dataset":"crossner_music","split":"dev","instance":{"id":"219","prompt_labels":"In(O) 1968(O) ,(O) three(O) of(O) the(O) genre(O) 's(O) most(O) famous(O) pioneers(O) ,(O) Led(B-band) Zeppelin(I-band) ,(O) Black(B-band) Sabbath(I-band) and(O) Deep(B-band) Purple(I-band) were(O) founded(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, musical artist, location, musical instrument, person, band, organization, country, event, song, award, music genre and O.\nSentence: In 1968 , three of the genre 's most famous pioneers , Led Zeppelin , Black Sabbath and Deep Purple were founded .","prediction_output":"In(O) 1968(O),(O) three(O) of(O) the(O) genre(O)'s(O) most(O) famous(O) pioneers(O),(O) Led(B-band) Zeppelin(I-band),(O) Black(B-band) Sabbath(I-band) and(O) Deep(B-band) Purple(I-band) were(O) founded(O).(O)","group":null,"words":["In","1968",",","three","of","the","genre","'s","most","famous","pioneers",",","Led","Zeppelin",",","Black","Sabbath","and","Deep","Purple","were","founded","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","O","O"],"target_index":null,"target_label":null},"label_list":["album","musical artist","location","musical instrument","person","band","organization","country","event","song","award","music genre"]}
{"id":"320","dataset":"crossner_music","split":"dev","instance":{"id":"320","prompt_labels":"Etta(B-musical artist) James(I-musical artist) ((O) born(O) Jamesetta(B-musical artist) Hawkins(I-musical artist) ;(O) January(O) 25(O) ,(O) 1938(O) -(O) January(O) 20(O) ,(O) 2012(O) )(O) was(O) an(O) American(O) singer(O) who(O) performed(O) in(O) various(O) genres(O) ,(O) including(O) blues(B-music genre) ,(O) Rhythm(B-music genre) and(I-music genre) blues(I-music genre) ,(O) Soul(B-music genre) music(I-music genre) ,(O) rock(B-music genre) and(I-music genre) roll(I-music genre) ,(O) jazz(B-music genre) and(O) Gospel(B-music genre) music(I-music genre) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, person, location, organization, award, music genre, musical artist, musical instrument, album, band, event and O.\nSentence: Etta James ( born Jamesetta Hawkins ; January 25 , 1938 - January 20 , 2012 ) was an American singer who performed in various genres , including blues , Rhythm and blues , Soul music , rock and roll , jazz and Gospel music .","prediction_output":"Etta(B-musical artist) James(I-musical artist) ((O) born(O) Jamesetta(B-person) Hawkins(I-person) ;(O) January(O) 25(O),(O) 1938(O) -(O) January(O) 20(O),(O) 2012(O) )(O) was(O) an(O) American(O) singer(O) who(O) performed(O) in(O) various(O) genres(O),(O) including(O) blues(B-music genre),(O) Rhythm(B-music genre) and(I-music genre) blues(I-music genre),(O) Soul(B-music genre) music(I-music genre),(O) rock(B-music genre) and(I-music genre) roll(I-music genre),(O) jazz(B-music genre) and(O) Gospel(B-music genre) music(I-music genre).(O)","group":null,"words":["Etta","James","(","born","Jamesetta","Hawkins",";","January","25",",","1938","-","January","20",",","2012",")","was","an","American","singer","who","performed","in","various","genres",",","including","blues",",","Rhythm","and","blues",",","Soul","music",",","rock","and","roll",",","jazz","and","Gospel","music","."],"labels":["B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O"],"target_index":null,"target_label":null},"label_list":["song","country","person","location","organization","award","music genre","musical artist","musical instrument","album","band","event"]}
{"id":"325","dataset":"crossner_music","split":"dev","instance":{"id":"325","prompt_labels":"Stock(B-band) Aitken(I-band) Waterman(I-band) ((O) SAW(B-band) )(O) expensively-produced(O) productions(O) for(O) Mel(B-band) and(I-band) Kim(I-band) ,(O) including(O) the(O) number-one(O) hit(O) Respectable(B-song) ,(O) added(O) elements(O) of(O) house(B-music genre) to(O) their(O) previous(O) Europop(B-music genre) sound(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, album, musical instrument, band, musical artist, song, organization, music genre, location, person, award and O.\nSentence: Stock Aitken Waterman ( SAW ) expensively-produced productions for Mel and Kim , including the number-one hit Respectable , added elements of house to their previous Europop sound .","prediction_output":"Stock(B-musical artist) Aitken(I-musical artist) Waterman(I-musical artist) ((O) SAW(O) )(O) expensively-produced(O) productions(O) for(O) Mel(B-band) and(I-band) Kim(I-band),(O) including(O) the(O) number-one(O) hit(O) Respectable(B-song),(O) added(O) elements(O) of(O) house(B-music genre) to(O) their(O) previous(O) Europop(B-music genre) sound(O).(O)","group":null,"words":["Stock","Aitken","Waterman","(","SAW",")","expensively-produced","productions","for","Mel","and","Kim",",","including","the","number-one","hit","Respectable",",","added","elements","of","house","to","their","previous","Europop","sound","."],"labels":["B-band","I-band","I-band","O","B-band","O","O","O","O","B-band","I-band","I-band","O","O","O","O","O","B-song","O","O","O","O","B-music genre","O","O","O","B-music genre","O","O"],"target_index":null,"target_label":null},"label_list":["country","event","album","musical instrument","band","musical artist","song","organization","music genre","location","person","award"]}
{"id":"337","dataset":"crossner_music","split":"dev","instance":{"id":"337","prompt_labels":"Other(O) groups(O) in(O) the(O) British(O) grindcore(B-music genre) scene(O) ,(O) such(O) as(O) Heresy(B-band) and(O) Unseen(B-band) Terror(I-band) ,(O) have(O) emphasized(O) the(O) influence(O) of(O) American(O) hardcore(B-music genre) punk(I-music genre) ,(O) including(O) Septic(B-band) Death(I-band) ,(O) as(O) well(O) as(O) Swedish(O) D-beat(B-music genre) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, musical instrument, organization, band, person, country, musical artist, album, music genre, song, event, award and O.\nSentence: Other groups in the British grindcore scene , such as Heresy and Unseen Terror , have emphasized the influence of American hardcore punk , including Septic Death , as well as Swedish D-beat .","prediction_output":"Other(O) groups(O) in(O) the(O) British(B-music genre) grindcore(I-music genre) scene(O),(O) such(O) as(O) Heresy(B-band) and(O) Unseen(B-band) Terror(I-band),(O) have(O) emphasized(O) the(O) influence(O) of(O) American(B-music genre) hardcore(I-music genre) punk(I-music genre),(O) including(O) Septic(B-band) Death(I-band),(O) as(O) well(O) as(O) Swedish(B-music genre) D-beat(I-music genre).(O)","group":null,"words":["Other","groups","in","the","British","grindcore","scene",",","such","as","Heresy","and","Unseen","Terror",",","have","emphasized","the","influence","of","American","hardcore","punk",",","including","Septic","Death",",","as","well","as","Swedish","D-beat","."],"labels":["O","O","O","O","O","B-music genre","O","O","O","O","B-band","O","B-band","I-band","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","B-band","I-band","O","O","O","O","O","B-music genre","O"],"target_index":null,"target_label":null},"label_list":["location","musical instrument","organization","band","person","country","musical artist","album","music genre","song","event","award"]}
{"id":"41","dataset":"crossner_politics","split":"dev","instance":{"id":"41","prompt_labels":"In(O) 1990(B-election) Australian(I-election) federal(I-election) election(I-election) Caldicott(O) unsuccessfully(O) contested(O) the(O) House(B-organization) of(I-organization) Representatives(I-organization) New(I-organization) South(I-organization) Wales(I-organization) seat(O) of(O) Richmond(B-location) ,(O) a(O) seat(O) held(O) since(O) the(O) inaugural(O) 1901(B-election) Australian(I-election) federal(I-election) election(I-election) by(O) conservatives(O) ,(O) and(O) by(O) the(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) since(O) it(O) first(O) contested(O) elections(O) at(O) the(O) 1922(B-election) Australian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, political party, organization, country, location, politician, person, event and O.\nSentence: In 1990 Australian federal election Caldicott unsuccessfully contested the House of Representatives New South Wales seat of Richmond , a seat held since the inaugural 1901 Australian federal election by conservatives , and by the National Party of Australia since it first contested elections at the 1922 Australian federal election .","prediction_output":"In(O) 1990(B-election) Australian(I-election) federal(I-election) election(I-election) Caldicott(O) unsuccessfully(O) contested(O) the(O) House(B-organization) of(I-organization) Representatives(I-organization) New(B-location) South(I-location) Wales(I-location) seat(O) of(O) Richmond(B-location),(O) a(O) seat(O) held(O) since(O) the(O) inaugural(O) 1901(B-election) Australian(I-election) federal(I-election) election(I-election) by(O) conservatives(B-political party),(O) and(O) by(O) the(O) National(B-political party) Party(I-political party) of(I-political party) Australia(I-political party) since(O) it(O) first(O) contested(O) elections(O) at(O) the(O) 1922(B-election) Australian(I-election) federal(I-election) election(I-election).(O)","group":null,"words":["In","1990","Australian","federal","election","Caldicott","unsuccessfully","contested","the","House","of","Representatives","New","South","Wales","seat","of","Richmond",",","a","seat","held","since","the","inaugural","1901","Australian","federal","election","by","conservatives",",","and","by","the","National","Party","of","Australia","since","it","first","contested","elections","at","the","1922","Australian","federal","election","."],"labels":["O","B-election","I-election","I-election","I-election","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["election","political party","organization","country","location","politician","person","event"]}
{"id":"61","dataset":"crossner_politics","split":"dev","instance":{"id":"61","prompt_labels":"The(O) UUP(B-political party) had(O) their(O) best(O) result(O) in(O) the(O) election(O) ,(O) in(O) part(O) due(O) to(O) no(O) candidate(O) from(O) either(O) the(O) UK(B-political party) Unionist(I-political party) Party(I-political party) or(O) Northern(B-political party) Ireland(I-political party) Unionist(I-political party) Party(I-political party) defending(O) one(O) of(O) the(O) seats(O) won(O) in(O) 1998(B-election) Northern(I-election) Ireland(I-election) Assembly(I-election) election(I-election) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, event, organization, person, election, political party, politician, country and O.\nSentence: The UUP had their best result in the election , in part due to no candidate from either the UK Unionist Party or Northern Ireland Unionist Party defending one of the seats won in 1998 Northern Ireland Assembly election .","prediction_output":"The(O) UUP(B-political party) had(O) their(O) best(O) result(O) in(O) the(O) election(O),(O) in(O) part(O) due(O) to(O) no(O) candidate(O) from(O) either(O) the(O) UK(B-political party) Unionist(I-political party) Party(I-political party) or(O) Northern(B-political party) Ireland(I-political party) Unionist(I-political party) Party(I-political party) defending(O) one(O) of(O) the(O) seats(O) won(O) in(O) 1998(B-election) Northern(I-election) Ireland(I-election) Assembly(I-election) election(I-election).(O)","group":null,"words":["The","UUP","had","their","best","result","in","the","election",",","in","part","due","to","no","candidate","from","either","the","UK","Unionist","Party","or","Northern","Ireland","Unionist","Party","defending","one","of","the","seats","won","in","1998","Northern","Ireland","Assembly","election","."],"labels":["O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["location","event","organization","person","election","political party","politician","country"]}
{"id":"64","dataset":"crossner_politics","split":"dev","instance":{"id":"64","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) to(O) be(O) the(O) leading(O) unionist(B-political party) party(I-political party) ,(O) between(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) and(O) Sinn(B-political party) Féin(I-political party) to(O) be(O) the(O) leading(O) nationalist(B-political party) party(I-political party) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(B-location) Down(I-location) is(O) different(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, organization, person, location, event, country, politician, election and O.\nSentence: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .","prediction_output":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(B-political party) Unionist(I-political party) Party(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) to(O) be(O) the(O) leading(O) unionist(O) party(O),(O) between(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) and(O) Sinn(B-political party) Féin(I-political party) to(O) be(O) the(O) leading(O) nationalist(O) party(O),(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O),(O) North(B-location) Down(I-location) is(O) different(O).(O)","group":null,"words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O","O","O","O","B-political party","I-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","I-political party","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":null},"label_list":["political party","organization","person","location","event","country","politician","election"]}
{"id":"69","dataset":"crossner_politics","split":"dev","instance":{"id":"69","prompt_labels":"However(O) ,(O) with(O) the(O) onset(O) of(O) the(B-event) Troubles(I-event) ,(O) new(O) parties(O) emerged(O) that(O) appealed(O) to(O) the(O) party(O) 's(O) support(O) base(O) ,(O) including(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ((O) SDLP(B-political party) )(O) ,(O) the(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, election, politician, political party, country, event, organization, person and O.\nSentence: However , with the onset of the Troubles , new parties emerged that appealed to the party 's support base , including the Social Democratic and Labour Party ( SDLP ) , the Alliance Party of Northern Ireland and the Democratic Unionist Party .","prediction_output":"However(O),(O) with(O) the(O) onset(O) of(O) the(O) Troubles(B-event),(O) new(O) parties(O) emerged(O) that(O) appealed(O) to(O) the(O) party's(O) support(O) base(O),(O) including(O) the(O) Social(B-political party) Democratic(I-political party) and(I-political party) Labour(I-political party) Party(I-political party) ((O) SDLP(O) )(O),(O) the(O) Alliance(B-political party) Party(I-political party) of(I-political party) Northern(I-political party) Ireland(I-political party) and(O) the(O) Democratic(B-political party) Unionist(I-political party) Party(I-political party).(O)","group":null,"words":["However",",","with","the","onset","of","the","Troubles",",","new","parties","emerged","that","appealed","to","the","party","'s","support","base",",","including","the","Social","Democratic","and","Labour","Party","(","SDLP",")",",","the","Alliance","Party","of","Northern","Ireland","and","the","Democratic","Unionist","Party","."],"labels":["O","O","O","O","O","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","B-political party","O","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","B-political party","I-political party","I-political party","O"],"target_index":null,"target_label":null},"label_list":["location","election","politician","political party","country","event","organization","person"]}
{"id":"113","dataset":"crossner_politics","split":"dev","instance":{"id":"113","prompt_labels":"During(O) this(O) period(O) ,(O) despite(O) no(O) longer(O) being(O) in(O) charge(O) of(O) external(O) affairs(O) ,(O) Ismail(B-person) expressed(O) strong(O) support(O) for(O) an(O) Association(B-organization) of(I-organization) Southeast(I-organization) Asia(I-organization) ,(O) telling(O) the(O) media(O) that(O) We(O) look(O) forward(O) to(O) a(O) regional(O) association(O) embracing(O) Thailand(B-country) ,(O) Burma(B-country) ,(O) Indonesia(B-country) ,(O) Singapore(B-country) ,(O) Malaysia(B-country) ,(O) Philippines(B-country) ,(O) Cambodia(B-country) ,(O) Laos(B-country) and(O) Vietnam(B-country) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, political party, event, country, person, organization, election, politician and O.\nSentence: During this period , despite no longer being in charge of external affairs , Ismail expressed strong support for an Association of Southeast Asia , telling the media that We look forward to a regional association embracing Thailand , Burma , Indonesia , Singapore , Malaysia , Philippines , Cambodia , Laos and Vietnam .","prediction_output":"During(O) this(O) period(O),(O) despite(O) no(O) longer(O) being(O) in(O) charge(O) of(O) external(O) affairs(O),(O) Ismail(O) expressed(O) strong(O) support(O) for(O) an(O) Association(B-organization) of(I-organization) Southeast(I-organization) Asia(I-organization),(O) telling(O) the(O) media(O) that(O) We(O) look(O) forward(O) to(O) a(O) regional(O) association(O) embracing(O) Thailand(B-country),(O) Burma(B-country),(O) Indonesia(B-country),(O) Singapore(B-country),(O) Malaysia(B-country),(O) Philippines(B-country),(O) Cambodia(B-country),(O) Laos(B-country) and(O) Vietnam(B-country).(O)","group":null,"words":["During","this","period",",","despite","no","longer","being","in","charge","of","external","affairs",",","Ismail","expressed","strong","support","for","an","Association","of","Southeast","Asia",",","telling","the","media","that","We","look","forward","to","a","regional","association","embracing","Thailand",",","Burma",",","Indonesia",",","Singapore",",","Malaysia",",","Philippines",",","Cambodia",",","Laos","and","Vietnam","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["location","political party","event","country","person","organization","election","politician"]}
{"id":"239","dataset":"crossner_politics","split":"dev","instance":{"id":"239","prompt_labels":"Wolman(B-politician) campaigned(O) for(O) the(O) Legislative(B-organization) Assembly(I-organization) of(I-organization) Ontario(I-organization) in(O) 1981(B-election) Ontario(I-election) general(I-election) election(I-election) and(O) 1985(B-election) Ontario(I-election) general(I-election) election(I-election) as(O) a(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Ontario(I-political party) candidate(O) ,(O) but(O) lost(O) both(O) times(O) to(O) New(B-political party) Democratic(I-political party) Party(I-political party) incumbent(O) Tony(B-politician) Grande(I-politician) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, location, country, organization, election, political party, person, politician and O.\nSentence: Wolman campaigned for the Legislative Assembly of Ontario in 1981 Ontario general election and 1985 Ontario general election as a Progressive Conservative Party of Ontario candidate , but lost both times to New Democratic Party incumbent Tony Grande .","prediction_output":"Wolman(O) campaigned(O) for(O) the(O) Legislative(B-organization) Assembly(I-organization) of(I-organization) Ontario(I-organization) in(O) 1981(B-election) Ontario(I-election) general(I-election) election(I-election) and(O) 1985(B-election) Ontario(I-election) general(I-election) election(I-election) as(O) a(O) Progressive(B-political party) Conservative(I-political party) Party(I-political party) of(I-political party) Ontario(I-political party) candidate(O),(O) but(O) lost(O) both(O) times(O) to(O) New(B-political party) Democratic(I-political party) Party(I-political party) incumbent(O) Tony(B-person) Grande(I-person).(O)","group":null,"words":["Wolman","campaigned","for","the","Legislative","Assembly","of","Ontario","in","1981","Ontario","general","election","and","1985","Ontario","general","election","as","a","Progressive","Conservative","Party","of","Ontario","candidate",",","but","lost","both","times","to","New","Democratic","Party","incumbent","Tony","Grande","."],"labels":["B-politician","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","B-political party","I-political party","I-political party","I-political party","I-political party","O","O","O","O","O","O","O","B-political party","I-political party","I-political party","O","B-politician","I-politician","O"],"target_index":null,"target_label":null},"label_list":["event","location","country","organization","election","political party","person","politician"]}
{"id":"320","dataset":"crossner_politics","split":"dev","instance":{"id":"320","prompt_labels":"After(O) the(O) electoral(O) defeat(O) of(O) Auzolan(B-political party) ,(O) EMK(B-political party) began(O) a(O) joint(O) campaign(O) with(O) the(O) trotskyist(O) formation(O) LKI(B-political party) ,(O) adopting(O) a(O) pro-(O) abertzale(O) speech(O) and(O) asking(O) several(O) times(O) to(O) vote(O) for(O) Herri(B-political party) Batasuna(I-political party) ,(O) which(O) has(O) led(O) some(O) historians(O) to(O) believe(O) that(O) the(O) party(O) became(O) a(O) satellite(O) of(O) Herri(B-political party) Batasuna(I-political party) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, country, politician, political party, election, person, location and O.\nSentence: After the electoral defeat of Auzolan , EMK began a joint campaign with the trotskyist formation LKI , adopting a pro- abertzale speech and asking several times to vote for Herri Batasuna , which has led some historians to believe that the party became a satellite of Herri Batasuna .","prediction_output":"After(O) the(O) electoral(O) defeat(O) of(O) Auzolan(B-person),(O) EMK(B-political party) began(O) a(O) joint(O) campaign(O) with(O) the(O) trotskyist(O) formation(O) LKI(B-organization),(O) adopting(O) a(O) pro-(O) abertzale(O) speech(O) and(O) asking(O) several(O) times(O) to(O) vote(O) for(O) Herri(B-person) Batasuna(I-person),(O) which(O) has(O) led(O) some(O) historians(O) to(O) believe(O) that(O) the(O) party(O) became(O) a(O) satellite(O) of(O) Herri(B-person) Batasuna(I-person).(O)","group":null,"words":["After","the","electoral","defeat","of","Auzolan",",","EMK","began","a","joint","campaign","with","the","trotskyist","formation","LKI",",","adopting","a","pro-","abertzale","speech","and","asking","several","times","to","vote","for","Herri","Batasuna",",","which","has","led","some","historians","to","believe","that","the","party","became","a","satellite","of","Herri","Batasuna","."],"labels":["O","O","O","O","O","B-political party","O","B-political party","O","O","O","O","O","O","O","O","B-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political party","I-political party","O"],"target_index":null,"target_label":null},"label_list":["organization","event","country","politician","political party","election","person","location"]}
{"id":"425","dataset":"crossner_politics","split":"dev","instance":{"id":"425","prompt_labels":"Members(O) of(O) the(O) 3(B-organization) Percenters(I-organization) ,(O) American(B-organization) Guard(I-organization) ,(O) Oath(B-organization) Keepers(I-organization) ,(O) and(O) Proud(B-organization) Boys(I-organization) were(O) present(O) ,(O) as(O) were(O) Antifa(B-organization) and(O) Black(B-organization) Lives(I-organization) Matter(I-organization) activists(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, person, country, election, organization, event, politician, location and O.\nSentence: Members of the 3 Percenters , American Guard , Oath Keepers , and Proud Boys were present , as were Antifa and Black Lives Matter activists .","prediction_output":"Members(O) of(O) the(O) 3(B-organization) Percenters(I-organization),(O) American(B-organization) Guard(I-organization),(O) Oath(B-organization) Keepers(I-organization),(O) and(O) Proud(B-organization) Boys(I-organization) were(O) present(O),(O) as(O) were(O) Antifa(B-organization) and(O) Black(B-organization) Lives(I-organization) Matter(I-organization) activists(O).(O)","group":null,"words":["Members","of","the","3","Percenters",",","American","Guard",",","Oath","Keepers",",","and","Proud","Boys","were","present",",","as","were","Antifa","and","Black","Lives","Matter","activists","."],"labels":["O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","B-organization","I-organization","O","O","B-organization","I-organization","O","O","O","O","O","B-organization","O","B-organization","I-organization","I-organization","O","O"],"target_index":null,"target_label":null},"label_list":["political party","person","country","election","organization","event","politician","location"]}
{"id":"486","dataset":"crossner_politics","split":"dev","instance":{"id":"486","prompt_labels":"The(O) national(B-organization) unity(I-organization) government(I-organization) ((O) War(B-organization) cabinet(I-organization) )(O) was(O) the(O) second(O) of(O) four(O) war(O) cabinets(O) of(O) the(O) Dutch(B-organization) government-in-exile(I-organization) in(O) London(B-location) during(O) World(B-event) War(I-event) II(I-event) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, election, organization, location, political party, event, country and O.\nSentence: The national unity government ( War cabinet ) was the second of four war cabinets of the Dutch government-in-exile in London during World War II .","prediction_output":"The(O) national(B-organization) unity(I-organization) government(I-organization) ((O) War(B-organization) cabinet(I-organization) )(O) was(O) the(O) second(O) of(O) four(O) war(O) cabinets(O) of(O) the(O) Dutch(B-organization) government-in-exile(I-organization) in(O) London(B-location) during(O) World(B-event) War(I-event) II(I-event).(O)","group":null,"words":["The","national","unity","government","(","War","cabinet",")","was","the","second","of","four","war","cabinets","of","the","Dutch","government-in-exile","in","London","during","World","War","II","."],"labels":["O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-location","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["person","politician","election","organization","location","political party","event","country"]}
{"id":"501","dataset":"crossner_politics","split":"dev","instance":{"id":"501","prompt_labels":"The(O) Persian(B-event) Campaign(I-event) or(O) Invasion(B-event) of(I-event) Iran(I-event) ((O) )(O) was(O) a(O) series(O) of(O) engagements(O) in(O) Iranian(B-location) Azerbaijan(I-location) region(O) involving(O) the(O) forces(O) of(O) the(O) Ottoman(B-country) Empire(I-country) against(O) those(O) of(O) the(O) British(B-country) Empire(I-country) and(O) Russian(B-country) Empire(I-country) ,(O) and(O) also(O) involving(O) local(O) Persian(O) population(O) elements(O) ,(O) beginning(O) in(O) December(O) 1914(O) and(O) ending(O) with(O) the(O) Armistice(B-event) of(I-event) Mudros(I-event) on(O) October(O) 30(O) ,(O) 1918(O) ,(O) as(O) part(O) of(O) Middle(B-event) Eastern(I-event) theatre(I-event) of(I-event) World(I-event) War(I-event) I(I-event) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, election, political party, organization, country, person, politician, event and O.\nSentence: The Persian Campaign or Invasion of Iran ( ) was a series of engagements in Iranian Azerbaijan region involving the forces of the Ottoman Empire against those of the British Empire and Russian Empire , and also involving local Persian population elements , beginning in December 1914 and ending with the Armistice of Mudros on October 30 , 1918 , as part of Middle Eastern theatre of World War I .","prediction_output":"The(O) Persian(B-event) Campaign(I-event) or(O) Invasion(B-event) of(I-event) Iran(I-event) ((O) )(O) was(O) a(O) series(O) of(O) engagements(O) in(O) Iranian(B-location) Azerbaijan(I-location) region(O) involving(O) the(O) forces(O) of(O) the(O) Ottoman(B-organization) Empire(I-organization) against(O) those(O) of(O) the(O) British(B-organization) Empire(I-organization) and(O) Russian(B-organization) Empire(I-organization),(O) and(O) also(O) involving(O) local(O) Persian(O) population(O) elements(O),(O) beginning(O) in(O) December(O) 1914(O) and(O) ending(O) with(O) the(O) Armistice(B-event) of(I-event) Mudros(I-event) on(O) October(O) 30(O),(O) 1918(O),(O) as(O) part(O) of(O) Middle(B-location) Eastern(I-location) theatre(O) of(O) World(B-event) War(I-event) I(I-event).(O)","group":null,"words":["The","Persian","Campaign","or","Invasion","of","Iran","(",")","was","a","series","of","engagements","in","Iranian","Azerbaijan","region","involving","the","forces","of","the","Ottoman","Empire","against","those","of","the","British","Empire","and","Russian","Empire",",","and","also","involving","local","Persian","population","elements",",","beginning","in","December","1914","and","ending","with","the","Armistice","of","Mudros","on","October","30",",","1918",",","as","part","of","Middle","Eastern","theatre","of","World","War","I","."],"labels":["O","B-event","I-event","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","B-country","I-country","O","O","O","O","B-country","I-country","O","B-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["location","election","political party","organization","country","person","politician","event"]}
{"id":"43","dataset":"crossner_science","split":"dev","instance":{"id":"43","prompt_labels":"Heartstone(B-event) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(B-event) Asian(I-event) Indoor(I-event) and(I-event) Martial(I-event) Arts(I-event) Games(I-event) and(O) 2018(B-event) Asian(I-event) Games(I-event) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, theory, discipline, academic journal, university, country, award, location, chemical element, protein, person, scientist, enzyme, event, organization, chemical compound and O.\nSentence: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .","prediction_output":"Heartstone(B-organization) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O),(O) such(O) as(O) the(O) 2017(B-event) Asian(I-event) Indoor(I-event) and(I-event) Martial(I-event) Arts(I-event) Games(I-event) and(O) 2018(B-event) Asian(I-event) Games(I-event).(O)","group":null,"words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["astronomical object","theory","discipline","academic journal","university","country","award","location","chemical element","protein","person","scientist","enzyme","event","organization","chemical compound"]}
{"id":"82","dataset":"crossner_science","split":"dev","instance":{"id":"82","prompt_labels":"They(O) are(O) made(O) up(O) of(O) monomers(O) called(O) nucleotide(B-chemical compound) s(O) which(O) consist(O) of(O) an(O) organic(O) base(O) :(O) Adenine(B-chemical compound) ,(O) Guanine(B-chemical compound) ,(O) Cytosine(B-chemical compound) and(O) Tyrosine(B-chemical compound) or(O) Uracil(B-chemical compound) ,(O) a(O) pentose(B-chemical compound) sugar(I-chemical compound) ,(O) and(O) a(O) Phosphate(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, academic journal, organization, university, event, theory, discipline, enzyme, country, person, protein, chemical element, chemical compound, location, scientist, award and O.\nSentence: They are made up of monomers called nucleotide s which consist of an organic base : Adenine , Guanine , Cytosine and Tyrosine or Uracil , a pentose sugar , and a Phosphate .","prediction_output":"They(O) are(O) made(O) up(O) of(O) monomers(O) called(O) nucleotide(B-chemical compound) s(I-chemical compound) which(O) consist(O) of(O) an(O) organic(B-chemical compound) base(I-chemical compound) :(O) Adenine(B-chemical element),(O) Guanine(B-chemical element),(O) Cytosine(B-chemical element) and(O) Tyrosine(B-chemical element) or(O) Uracil(B-chemical element),(O) a(O) pentose(B-chemical compound) sugar(I-chemical compound),(O) and(O) a(O) Phosphate(B-chemical compound).(O)","group":null,"words":["They","are","made","up","of","monomers","called","nucleotide","s","which","consist","of","an","organic","base",":","Adenine",",","Guanine",",","Cytosine","and","Tyrosine","or","Uracil",",","a","pentose","sugar",",","and","a","Phosphate","."],"labels":["O","O","O","O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","B-chemical compound","O","O","B-chemical compound","I-chemical compound","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["astronomical object","academic journal","organization","university","event","theory","discipline","enzyme","country","person","protein","chemical element","chemical compound","location","scientist","award"]}
{"id":"231","dataset":"crossner_science","split":"dev","instance":{"id":"231","prompt_labels":"Schweickart(B-scientist) is(O) a(O) Fellow(B-award) of(I-award) the(I-award) American(I-award) Astronautical(I-award) Society(I-award) ,(O) the(O) International(B-organization) Academy(I-organization) of(I-organization) Astronautics(I-organization) and(O) the(O) California(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) as(O) well(O) as(O) an(O) Associate(O) Fellow(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, location, university, theory, person, academic journal, discipline, organization, chemical compound, enzyme, astronomical object, award, chemical element, protein, country, event and O.\nSentence: Schweickart is a Fellow of the American Astronautical Society , the International Academy of Astronautics and the California Academy of Sciences , as well as an Associate Fellow of the American Institute of Aeronautics and Astronautics .","prediction_output":"Schweickart(O) is(O) a(O) Fellow(O) of(O) the(O) American(B-organization) Astronautical(I-organization) Society(I-organization),(O) the(O) International(B-organization) Academy(I-organization) of(I-organization) Astronautics(I-organization) and(O) the(O) California(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization),(O) as(O) well(O) as(O) an(O) Associate(O) Fellow(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization).(O)","group":null,"words":["Schweickart","is","a","Fellow","of","the","American","Astronautical","Society",",","the","International","Academy","of","Astronautics","and","the","California","Academy","of","Sciences",",","as","well","as","an","Associate","Fellow","of","the","American","Institute","of","Aeronautics","and","Astronautics","."],"labels":["B-scientist","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["scientist","location","university","theory","person","academic journal","discipline","organization","chemical compound","enzyme","astronomical object","award","chemical element","protein","country","event"]}
{"id":"306","dataset":"crossner_science","split":"dev","instance":{"id":"306","prompt_labels":"The(O) hydroxyl(B-chemical compound) radical(I-chemical compound) can(O) damage(O) virtually(O) all(O) types(O) of(O) macromolecules(O) :(O) carbohydrates(B-chemical compound) ,(O) nucleic(B-chemical compound) acids(I-chemical compound) ((O) mutation(O) s(O) )(O) ,(O) lipids(B-chemical compound) ((O) lipid(B-chemical compound) peroxidation(O) )(O) ,(O) and(O) amino(O) acids(O) ((O) e.g.(O) conversion(O) of(O) Phenylalanine(B-chemical compound) to(O) m(B-chemical compound) -(I-chemical compound) Tyrosine(B-chemical compound) and(O) o(B-chemical compound) -(I-chemical compound) Tyrosine(I-chemical compound) )(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, location, award, person, university, organization, discipline, event, astronomical object, theory, protein, chemical element, country, scientist, academic journal, chemical compound and O.\nSentence: The hydroxyl radical can damage virtually all types of macromolecules : carbohydrates , nucleic acids ( mutation s ) , lipids ( lipid peroxidation ) , and amino acids ( e.g. conversion of Phenylalanine to m - Tyrosine and o - Tyrosine ) .","prediction_output":"The(O) hydroxyl(B-chemical compound) radical(I-chemical compound) can(O) damage(O) virtually(O) all(O) types(O) of(O) macromolecules(B-chemical compound) :(O) carbohydrates(B-chemical compound),(O) nucleic(B-chemical compound) acids(I-chemical compound) ((O) mutation(B-chemical compound) s(I-chemical compound) )(O),(O) lipids(B-chemical compound) ((O) lipid(B-chemical compound) peroxidation(I-chemical compound) )(O),(O) and(O) amino(B-chemical compound) acids(I-chemical compound) ((O) e.g.(O) conversion(O) of(O) Phenylalanine(B-chemical compound) to(O) m(B-chemical compound) -(I-chemical compound) Tyrosine(I-chemical compound) and(O) o(B-chemical compound) -(I-chemical compound) Tyrosine(I-chemical compound) )(O).(O)","group":null,"words":["The","hydroxyl","radical","can","damage","virtually","all","types","of","macromolecules",":","carbohydrates",",","nucleic","acids","(","mutation","s",")",",","lipids","(","lipid","peroxidation",")",",","and","amino","acids","(","e.g.","conversion","of","Phenylalanine","to","m","-","Tyrosine","and","o","-","Tyrosine",")","."],"labels":["O","B-chemical compound","I-chemical compound","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","I-chemical compound","O","O","O","O","O","B-chemical compound","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","I-chemical compound","B-chemical compound","O","B-chemical compound","I-chemical compound","I-chemical compound","O","O"],"target_index":null,"target_label":null},"label_list":["enzyme","location","award","person","university","organization","discipline","event","astronomical object","theory","protein","chemical element","country","scientist","academic journal","chemical compound"]}
{"id":"329","dataset":"crossner_science","split":"dev","instance":{"id":"329","prompt_labels":"In(O) 2015(O) ,(O) Hill(B-scientist) was(O) a(O) Professor(O) at(O) the(O) Ontario(B-organization) Cancer(I-organization) Institute(I-organization) and(O) a(O) Senior(O) Scientist(O) at(O) the(O) Princess(B-organization) Margaret(I-organization) Cancer(I-organization) Centre(I-organization) within(O) the(O) University(B-university) Health(I-university) Network(I-university) ,(O) which(O) is(O) affiliated(O) with(O) the(O) University(B-organization) of(I-organization) Toronto(I-organization) Faculty(I-organization) of(I-organization) Medicine(I-organization) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, university, discipline, event, astronomical object, protein, country, location, chemical compound, chemical element, organization, person, academic journal, award, enzyme, scientist and O.\nSentence: In 2015 , Hill was a Professor at the Ontario Cancer Institute and a Senior Scientist at the Princess Margaret Cancer Centre within the University Health Network , which is affiliated with the University of Toronto Faculty of Medicine .","prediction_output":"In(O) 2015(O),(O) Hill(O) was(O) a(O) Professor(O) at(O) the(O) Ontario(B-organization) Cancer(I-organization) Institute(I-organization) and(O) a(O) Senior(O) Scientist(O) at(O) the(O) Princess(B-organization) Margaret(I-organization) Cancer(I-organization) Centre(I-organization) within(O) the(O) University(B-organization) Health(I-organization) Network(I-organization),(O) which(O) is(O) affiliated(O) with(O) the(O) University(B-university) of(I-university) Toronto(I-university) Faculty(I-university) of(I-university) Medicine(I-university).(O)","group":null,"words":["In","2015",",","Hill","was","a","Professor","at","the","Ontario","Cancer","Institute","and","a","Senior","Scientist","at","the","Princess","Margaret","Cancer","Centre","within","the","University","Health","Network",",","which","is","affiliated","with","the","University","of","Toronto","Faculty","of","Medicine","."],"labels":["O","O","O","B-scientist","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-university","I-university","I-university","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["theory","university","discipline","event","astronomical object","protein","country","location","chemical compound","chemical element","organization","person","academic journal","award","enzyme","scientist"]}
{"id":"343","dataset":"crossner_science","split":"dev","instance":{"id":"343","prompt_labels":"Ethylmercury(B-chemical compound) is(O) a(O) breakdown(O) product(O) of(O) the(O) antibacteriological(O) agent(O) ethylmercurithiosalicylate(B-chemical compound) ,(O) which(O) has(O) been(O) used(O) as(O) a(O) topical(O) antiseptic(O) and(O) a(O) vaccine(O) preservative(O) ((O) further(O) discussed(O) under(O) Thiomersal(B-chemical compound) below(O) )(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, event, country, university, chemical element, protein, enzyme, discipline, academic journal, scientist, person, organization, astronomical object, award, location, chemical compound and O.\nSentence: Ethylmercury is a breakdown product of the antibacteriological agent ethylmercurithiosalicylate , which has been used as a topical antiseptic and a vaccine preservative ( further discussed under Thiomersal below ) .","prediction_output":"Ethylmercury(B-chemical element) is(O) a(O) breakdown(O) product(O) of(O) the(O) antibacteriological(O) agent(O) ethylmercurithiosalicylate(B-chemical compound),(O) which(O) has(O) been(O) used(O) as(O) a(O) topical(O) antiseptic(O) and(O) a(O) vaccine(O) preservative(O) ((O) further(O) discussed(O) under(O) Thiomersal(O) below(O) )(O).(O)","group":null,"words":["Ethylmercury","is","a","breakdown","product","of","the","antibacteriological","agent","ethylmercurithiosalicylate",",","which","has","been","used","as","a","topical","antiseptic","and","a","vaccine","preservative","(","further","discussed","under","Thiomersal","below",")","."],"labels":["B-chemical compound","O","O","O","O","O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","O","O","O"],"target_index":null,"target_label":null},"label_list":["theory","event","country","university","chemical element","protein","enzyme","discipline","academic journal","scientist","person","organization","astronomical object","award","location","chemical compound"]}
{"id":"371","dataset":"crossner_science","split":"dev","instance":{"id":"371","prompt_labels":"In(O) 1978(O) ,(O) scientists(O) at(O) BMI-TNO(B-organization) ,(O) the(O) research(O) unit(O) of(O) Netherlands(B-organization) Organisation(I-organization) for(I-organization) Applied(I-organization) Scientific(I-organization) Research(I-organization) at(O) the(O) University(B-university) of(I-university) Amsterdam(I-university) ,(O) invented(O) and(O) patented(O) a(O) series(O) of(O) additional(O) key(O) elements(O) that(O) make(O) the(O) volume(O) clamp(O) work(O) in(O) clinical(O) practice(O) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, award, university, person, location, protein, event, theory, chemical element, organization, scientist, discipline, enzyme, country, academic journal, astronomical object and O.\nSentence: In 1978 , scientists at BMI-TNO , the research unit of Netherlands Organisation for Applied Scientific Research at the University of Amsterdam , invented and patented a series of additional key elements that make the volume clamp work in clinical practice .","prediction_output":"In(O) 1978(O),(O) scientists(O) at(O) BMI-TNO(B-organization),(O) the(O) research(O) unit(O) of(O) Netherlands(B-organization) Organisation(I-organization) for(I-organization) Applied(I-organization) Scientific(I-organization) Research(I-organization) at(O) the(O) University(B-university) of(I-university) Amsterdam(I-university),(O) invented(O) and(O) patented(O) a(O) series(O) of(O) additional(O) key(O) elements(O) that(O) make(O) the(O) volume(O) clamp(O) work(O) in(O) clinical(O) practice(O).(O)","group":null,"words":["In","1978",",","scientists","at","BMI-TNO",",","the","research","unit","of","Netherlands","Organisation","for","Applied","Scientific","Research","at","the","University","of","Amsterdam",",","invented","and","patented","a","series","of","additional","key","elements","that","make","the","volume","clamp","work","in","clinical","practice","."],"labels":["O","O","O","O","O","B-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["chemical compound","award","university","person","location","protein","event","theory","chemical element","organization","scientist","discipline","enzyme","country","academic journal","astronomical object"]}
{"id":"416","dataset":"crossner_science","split":"dev","instance":{"id":"416","prompt_labels":"H3K4me3(B-chemical compound) is(O) an(O) epigenetic(O) modification(O) to(O) the(O) DNA(O) packaging(O) protein(O) Histone(B-protein) H3(I-protein) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, discipline, theory, organization, award, event, university, location, chemical compound, protein, person, scientist, country, astronomical object, academic journal, enzyme and O.\nSentence: H3K4me3 is an epigenetic modification to the DNA packaging protein Histone H3 .","prediction_output":"H3K4me3(B-chemical compound) is(O) an(O) epigenetic(O) modification(O) to(O) the(O) DNA(B-protein) packaging(I-protein) protein(I-protein) Histone(I-protein) H3(I-protein).(O)","group":null,"words":["H3K4me3","is","an","epigenetic","modification","to","the","DNA","packaging","protein","Histone","H3","."],"labels":["B-chemical compound","O","O","O","O","O","O","O","O","O","B-protein","I-protein","O"],"target_index":null,"target_label":null},"label_list":["chemical element","discipline","theory","organization","award","event","university","location","chemical compound","protein","person","scientist","country","astronomical object","academic journal","enzyme"]}
{"id":"436","dataset":"crossner_science","split":"dev","instance":{"id":"436","prompt_labels":"The(O) film(O) was(O) also(O) nominated(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actor(I-award) ((O) Sam(B-person) Shepard(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) ((O) Art(B-person) Direction(I-person) :(O) Geoffrey(B-person) Kirkland(I-person) ,(O) Richard(B-person) Lawrence(I-person) ,(O) W.(B-person) Stewart(I-person) Campbell(I-person) and(O) Peter(B-person) R.(I-person) Romero(I-person) ;(O) Set(B-person) Decoration(I-person) :(O) George(B-person) R.(I-person) Nelson(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) ((O) Caleb(B-person) Deschanel(I-person) )(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, theory, astronomical object, chemical element, discipline, event, enzyme, protein, country, academic journal, location, award, person, chemical compound, organization, scientist and O.\nSentence: The film was also nominated for Academy Award for Best Supporting Actor ( Sam Shepard ) , Academy Award for Best Production Design ( Art Direction : Geoffrey Kirkland , Richard Lawrence , W. Stewart Campbell and Peter R. Romero ; Set Decoration : George R. Nelson ) , Academy Award for Best Cinematography ( Caleb Deschanel ) and Academy Award for Best Picture .","prediction_output":"The(O) film(O) was(O) also(O) nominated(O) for(O) Academy(B-award) Award(I-award) for(O) Best(O) Supporting(O) Actor(O) ((O) Sam(B-person) Shepard(I-person) )(O),(O) Academy(B-award) Award(I-award) for(O) Best(O) Production(O) Design(O) ((O) Art(O) Direction(O) :(O) Geoffrey(B-person) Kirkland(I-person),(O) Richard(B-person) Lawrence(I-person),(O) W.(B-person) Stewart(I-person) Campbell(I-person) and(O) Peter(B-person) R.(I-person) Romero(I-person) ;(O) Set(O) Decoration(O) :(O) George(B-person) R.(I-person) Nelson(I-person) )(O),(O) Academy(B-award) Award(I-award) for(O) Best(O) Cinematography(O) ((O) Caleb(B-person) Deschanel(I-person) )(O) and(O) Academy(B-award) Award(I-award) for(O) Best(O) Picture(O).(O)","group":null,"words":["The","film","was","also","nominated","for","Academy","Award","for","Best","Supporting","Actor","(","Sam","Shepard",")",",","Academy","Award","for","Best","Production","Design","(","Art","Direction",":","Geoffrey","Kirkland",",","Richard","Lawrence",",","W.","Stewart","Campbell","and","Peter","R.","Romero",";","Set","Decoration",":","George","R.","Nelson",")",",","Academy","Award","for","Best","Cinematography","(","Caleb","Deschanel",")","and","Academy","Award","for","Best","Picture","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","I-person","O","B-person","I-person","I-person","O","B-person","I-person","O","B-person","I-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["university","theory","astronomical object","chemical element","discipline","event","enzyme","protein","country","academic journal","location","award","person","chemical compound","organization","scientist"]}
{"id":"448","dataset":"crossner_science","split":"dev","instance":{"id":"448","prompt_labels":"She(O) is(O) a(O) member(O) of(O) the(O) Australian(B-organization) Antarctic(I-organization) Research(I-organization) Advisory(I-organization) Committee(I-organization) and(O) serves(O) on(O) the(O) Editorial(O) Boards(O) of(O) the(O) international(O) journals(O) :(O) Ecosystems(B-academic journal) ,(O) Global(B-academic journal) Change(I-academic journal) Biology(I-academic journal) ,(O) Oecologia(B-academic journal) ,(O) Plant(B-academic journal) ,(O) Cell(B-academic journal) ;(O) Environment(B-academic journal) ,(O) and(O) Tree(B-academic journal) Physiology(I-academic journal) .(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, chemical compound, astronomical object, location, chemical element, event, university, organization, theory, protein, academic journal, award, person, scientist, country, enzyme and O.\nSentence: She is a member of the Australian Antarctic Research Advisory Committee and serves on the Editorial Boards of the international journals : Ecosystems , Global Change Biology , Oecologia , Plant , Cell ; Environment , and Tree Physiology .","prediction_output":"She(O) is(O) a(O) member(O) of(O) the(O) Australian(B-organization) Antarctic(I-organization) Research(I-organization) Advisory(I-organization) Committee(I-organization) and(O) serves(O) on(O) the(O) Editorial(O) Boards(O) of(O) the(O) international(O) journals(O) :(O) Ecosystems(B-academic journal),(O) Global(B-academic journal) Change(I-academic journal) Biology(I-academic journal),(O) Oecologia(B-academic journal),(O) Plant(B-academic journal),(O) Cell(B-academic journal) ;(O) Environment(B-academic journal),(O) and(O) Tree(B-academic journal) Physiology(I-academic journal).(O)","group":null,"words":["She","is","a","member","of","the","Australian","Antarctic","Research","Advisory","Committee","and","serves","on","the","Editorial","Boards","of","the","international","journals",":","Ecosystems",",","Global","Change","Biology",",","Oecologia",",","Plant",",","Cell",";","Environment",",","and","Tree","Physiology","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","O","B-academic journal","O","B-academic journal","O","B-academic journal","O","O","B-academic journal","I-academic journal","O"],"target_index":null,"target_label":null},"label_list":["discipline","chemical compound","astronomical object","location","chemical element","event","university","organization","theory","protein","academic journal","award","person","scientist","country","enzyme"]}
{"id":"3","dataset":"mit-movie","split":"dev","instance":{"id":"3","prompt_labels":"what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(B-year)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, song, review, character, director, actor, plot, genre, rating, average ratings, title and O.\nSentence: what science fiction films have come out recently","prediction_output":"what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(O)","group":null,"words":["what","science","fiction","films","have","come","out","recently"],"labels":["O","B-genre","I-genre","O","O","O","O","B-year"],"target_index":null,"target_label":null},"label_list":["year","trailer","song","review","character","director","actor","plot","genre","rating","average ratings","title"]}
{"id":"525","dataset":"mit-movie","split":"dev","instance":{"id":"525","prompt_labels":"find(O) a(O) horror(B-genre) movie(O) with(O) creepy(B-plot) little(I-plot) girls(I-plot)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, trailer, year, average ratings, plot, actor, genre, director, song, rating, title, character and O.\nSentence: find a horror movie with creepy little girls","prediction_output":"find(O) a(O) horror(B-genre) movie(I-genre) with(O) creepy(B-character) little(I-character) girls(I-character)","group":null,"words":["find","a","horror","movie","with","creepy","little","girls"],"labels":["O","O","B-genre","O","O","B-plot","I-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["review","trailer","year","average ratings","plot","actor","genre","director","song","rating","title","character"]}
{"id":"535","dataset":"mit-movie","split":"dev","instance":{"id":"535","prompt_labels":"show(O) me(O) the(O) second(O) star(B-title) wars(I-title) film(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, director, trailer, rating, title, actor, average ratings, review, song, genre, plot, character and O.\nSentence: show me the second star wars film","prediction_output":"show(O) me(O) the(O) second(O) star(B-title) wars(I-title) film(I-title)","group":null,"words":["show","me","the","second","star","wars","film"],"labels":["O","O","O","O","B-title","I-title","O"],"target_index":null,"target_label":null},"label_list":["year","director","trailer","rating","title","actor","average ratings","review","song","genre","plot","character"]}
{"id":"880","dataset":"mit-movie","split":"dev","instance":{"id":"880","prompt_labels":"what(O) movies(O) from(O) the(O) 90s(B-year) did(O) jeremy(B-actor) irons(I-actor) star(O) in(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, trailer, average ratings, character, genre, title, director, plot, actor, song, year, rating and O.\nSentence: what movies from the 90s did jeremy irons star in","prediction_output":"what(O) movies(O) from(O) the(O) 90s(B-year) did(O) jeremy(B-actor) irons(I-actor) star(O) in(O)","group":null,"words":["what","movies","from","the","90s","did","jeremy","irons","star","in"],"labels":["O","O","O","O","B-year","O","B-actor","I-actor","O","O"],"target_index":null,"target_label":null},"label_list":["review","trailer","average ratings","character","genre","title","director","plot","actor","song","year","rating"]}
{"id":"997","dataset":"mit-movie","split":"dev","instance":{"id":"997","prompt_labels":"show(O) me(O) what(O) films(O) were(O) directed(O) by(O) the(O) wachowski(B-director) brothers(I-director)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, trailer, plot, director, song, title, rating, year, character, review, actor, genre and O.\nSentence: show me what films were directed by the wachowski brothers","prediction_output":"show(O) me(O) what(O) films(O) were(O) directed(O) by(O) the(O) wachowski(O) brothers(O)","group":null,"words":["show","me","what","films","were","directed","by","the","wachowski","brothers"],"labels":["O","O","O","O","O","O","O","O","B-director","I-director"],"target_index":null,"target_label":null},"label_list":["average ratings","trailer","plot","director","song","title","rating","year","character","review","actor","genre"]}
{"id":"1144","dataset":"mit-movie","split":"dev","instance":{"id":"1144","prompt_labels":"did(O) hal(B-director) mohr(I-director) direct(O) a(O) movie(O) about(O) gags(B-genre) in(O) the(O) 1950(B-year) s(I-year) that(O) was(O) given(O) six(B-average ratings) stars(I-average ratings)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, trailer, director, character, genre, actor, year, average ratings, plot, rating, review and O.\nSentence: did hal mohr direct a movie about gags in the 1950 s that was given six stars","prediction_output":"did(O) hal(B-director) mohr(I-director) direct(O) a(O) movie(O) about(O) gags(O) in(O) the(O) 1950(B-year) s(I-year) that(O) was(O) given(O) six(B-average ratings) stars(I-average ratings)","group":null,"words":["did","hal","mohr","direct","a","movie","about","gags","in","the","1950","s","that","was","given","six","stars"],"labels":["O","B-director","I-director","O","O","O","O","B-genre","O","O","B-year","I-year","O","O","O","B-average ratings","I-average ratings"],"target_index":null,"target_label":null},"label_list":["song","title","trailer","director","character","genre","actor","year","average ratings","plot","rating","review"]}
{"id":"1168","dataset":"mit-movie","split":"dev","instance":{"id":"1168","prompt_labels":"did(O) stanley(B-director) kubrick(I-director) ever(O) direct(O) any(O) romantic(B-genre) comedy(I-genre) films(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, actor, year, title, song, average ratings, plot, genre, director, character, trailer, rating and O.\nSentence: did stanley kubrick ever direct any romantic comedy films","prediction_output":"did(O) stanley(B-director) kubrick(I-director) ever(O) direct(O) any(O) romantic(B-genre) comedy(I-genre) films(O)","group":null,"words":["did","stanley","kubrick","ever","direct","any","romantic","comedy","films"],"labels":["O","B-director","I-director","O","O","O","B-genre","I-genre","O"],"target_index":null,"target_label":null},"label_list":["review","actor","year","title","song","average ratings","plot","genre","director","character","trailer","rating"]}
{"id":"1225","dataset":"mit-movie","split":"dev","instance":{"id":"1225","prompt_labels":"do(O) you(O) think(O) youd(O) be(O) able(O) to(O) help(O) me(O) find(O) the(B-title) penguins(I-title) of(I-title) madagascar(I-title) operation(I-title) dvd(I-title) premier(I-title)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, character, genre, rating, trailer, song, year, average ratings, plot, title, review, actor and O.\nSentence: do you think youd be able to help me find the penguins of madagascar operation dvd premier","prediction_output":"do(O) you(O) think(O) youd(O) be(O) able(O) to(O) help(O) me(O) find(O) the(O) penguins(O) of(O) madagascar(O) operation(O) dvd(O) premier(O)","group":null,"words":["do","you","think","youd","be","able","to","help","me","find","the","penguins","of","madagascar","operation","dvd","premier"],"labels":["O","O","O","O","O","O","O","O","O","O","B-title","I-title","I-title","I-title","I-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["director","character","genre","rating","trailer","song","year","average ratings","plot","title","review","actor"]}
{"id":"1655","dataset":"mit-movie","split":"dev","instance":{"id":"1655","prompt_labels":"list(O) all(O) g(B-rating) rated(O) movies(O) about(O) a(O) road(B-plot) trip(I-plot) that(O) received(O) an(O) average(B-average ratings) rating(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, song, plot, review, title, director, trailer, actor, genre, character, rating, year and O.\nSentence: list all g rated movies about a road trip that received an average rating","prediction_output":"list(O) all(O) g(B-rating) rated(I-rating) movies(I-rating) about(O) a(O) road(B-plot) trip(I-plot) that(O) received(O) an(O) average(B-rating) rating(I-rating)","group":null,"words":["list","all","g","rated","movies","about","a","road","trip","that","received","an","average","rating"],"labels":["O","O","B-rating","O","O","O","O","B-plot","I-plot","O","O","O","B-average ratings","O"],"target_index":null,"target_label":null},"label_list":["average ratings","song","plot","review","title","director","trailer","actor","genre","character","rating","year"]}
{"id":"2311","dataset":"mit-movie","split":"dev","instance":{"id":"2311","prompt_labels":"who(O) is(O) in(O) the(O) movie(O) spanglish(B-title)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, genre, review, title, year, average ratings, director, actor, character, plot, rating, trailer and O.\nSentence: who is in the movie spanglish","prediction_output":"who(O) is(O) in(O) the(O) movie(O) spanglish(O)","group":null,"words":["who","is","in","the","movie","spanglish"],"labels":["O","O","O","O","O","B-title"],"target_index":null,"target_label":null},"label_list":["song","genre","review","title","year","average ratings","director","actor","character","plot","rating","trailer"]}
{"id":"39","dataset":"mit-restaurant","split":"dev","instance":{"id":"39","prompt_labels":"are(O) there(O) any(O) fine(B-Amenity) dining(I-Amenity) options(O) within(B-Location) 5(I-Location) miles(I-Location) of(O) my(O) location(O)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Restaurant Name, Hours, Cuisine, Rating, Location, Dish and O.\nSentence: are there any fine dining options within 5 miles of my location","prediction_output":"are(O) there(O) any(O) fine(O) dining(O) options(O) within(O) 5(O) miles(O) of(O) my(O) location(O)","group":null,"words":["are","there","any","fine","dining","options","within","5","miles","of","my","location"],"labels":["O","O","O","B-Amenity","I-Amenity","O","B-Location","I-Location","I-Location","O","O","O"],"target_index":null,"target_label":null},"label_list":["Price","Amenity","Restaurant Name","Hours","Cuisine","Rating","Location","Dish"]}
{"id":"352","dataset":"mit-restaurant","split":"dev","instance":{"id":"352","prompt_labels":"find(O) an(O) inexpensive(B-Price) mexican(B-Cuisine) restaurant(O) in(B-Location) the(I-Location) area(I-Location)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Amenity, Hours, Price, Rating, Location, Dish, Cuisine and O.\nSentence: find an inexpensive mexican restaurant in the area","prediction_output":"find(O) an(O) inexpensive(O) mexican(B-Cuisine) restaurant(O) in(O) the(O) area(O)","group":null,"words":["find","an","inexpensive","mexican","restaurant","in","the","area"],"labels":["O","O","B-Price","B-Cuisine","O","B-Location","I-Location","I-Location"],"target_index":null,"target_label":null},"label_list":["Restaurant Name","Amenity","Hours","Price","Rating","Location","Dish","Cuisine"]}
{"id":"438","dataset":"mit-restaurant","split":"dev","instance":{"id":"438","prompt_labels":"find(O) me(O) the(O) phone(O) number(O) to(O) dominos(B-Restaurant Name) pizza(I-Restaurant Name)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Cuisine, Price, Amenity, Hours, Location, Dish and O.\nSentence: find me the phone number to dominos pizza","prediction_output":"find(O) me(O) the(O) phone(O) number(O) to(O) dominos(B-Restaurant Name) pizza(I-Restaurant Name)","group":null,"words":["find","me","the","phone","number","to","dominos","pizza"],"labels":["O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name"],"target_index":null,"target_label":null},"label_list":["Rating","Restaurant Name","Cuisine","Price","Amenity","Hours","Location","Dish"]}
{"id":"526","dataset":"mit-restaurant","split":"dev","instance":{"id":"526","prompt_labels":"how(O) many(O) burger(B-Restaurant Name) kings(I-Restaurant Name) are(O) around(B-Location)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Amenity, Dish, Restaurant Name, Location, Cuisine, Hours and O.\nSentence: how many burger kings are around","prediction_output":"how(O) many(O) burger(B-Restaurant Name) kings(I-Restaurant Name) are(O) around(O)","group":null,"words":["how","many","burger","kings","are","around"],"labels":["O","O","B-Restaurant Name","I-Restaurant Name","O","B-Location"],"target_index":null,"target_label":null},"label_list":["Rating","Price","Amenity","Dish","Restaurant Name","Location","Cuisine","Hours"]}
{"id":"837","dataset":"mit-restaurant","split":"dev","instance":{"id":"837","prompt_labels":"is(O) there(O) a(O) nicely(B-Amenity) decorated(I-Amenity) restaurant(O) in(O) sacramento(B-Location) with(O) a(O) fireplace(B-Amenity)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Restaurant Name, Rating, Price, Cuisine, Dish, Location, Hours and O.\nSentence: is there a nicely decorated restaurant in sacramento with a fireplace","prediction_output":"is(O) there(O) a(O) nicely(O) decorated(O) restaurant(O) in(O) sacramento(B-Location) with(O) a(O) fireplace(B-Amenity)","group":null,"words":["is","there","a","nicely","decorated","restaurant","in","sacramento","with","a","fireplace"],"labels":["O","O","O","B-Amenity","I-Amenity","O","O","B-Location","O","O","B-Amenity"],"target_index":null,"target_label":null},"label_list":["Amenity","Restaurant Name","Rating","Price","Cuisine","Dish","Location","Hours"]}
{"id":"1038","dataset":"mit-restaurant","split":"dev","instance":{"id":"1038","prompt_labels":"please(O) show(O) me(O) some(O) reviews(O) about(O) the(O) sushi(B-Cuisine) place(B-Location)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Restaurant Name, Rating, Dish, Cuisine, Hours, Amenity, Price and O.\nSentence: please show me some reviews about the sushi place","prediction_output":"please(O) show(O) me(O) some(O) reviews(O) about(O) the(O) sushi(B-Dish) place(O)","group":null,"words":["please","show","me","some","reviews","about","the","sushi","place"],"labels":["O","O","O","O","O","O","O","B-Cuisine","B-Location"],"target_index":null,"target_label":null},"label_list":["Location","Restaurant Name","Rating","Dish","Cuisine","Hours","Amenity","Price"]}
{"id":"1115","dataset":"mit-restaurant","split":"dev","instance":{"id":"1115","prompt_labels":"what(O) is(O) the(O) average(O) mealcost(O) for(O) townline(B-Restaurant Name) pizza(I-Restaurant Name) in(B-Location) my(I-Location) city(I-Location)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Restaurant Name, Location, Rating, Amenity, Hours, Dish, Cuisine and O.\nSentence: what is the average mealcost for townline pizza in my city","prediction_output":"what(O) is(O) the(O) average(O) mealcost(O) for(O) townline(B-Restaurant Name) pizza(B-Dish) in(O) my(O) city(B-Location)","group":null,"words":["what","is","the","average","mealcost","for","townline","pizza","in","my","city"],"labels":["O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name","B-Location","I-Location","I-Location"],"target_index":null,"target_label":null},"label_list":["Price","Restaurant Name","Location","Rating","Amenity","Hours","Dish","Cuisine"]}
{"id":"1145","dataset":"mit-restaurant","split":"dev","instance":{"id":"1145","prompt_labels":"what(O) is(O) the(O) phone(O) number(O) of(O) bills(B-Restaurant Name) pizza(I-Restaurant Name)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Dish, Price, Rating, Hours, Restaurant Name, Cuisine and O.\nSentence: what is the phone number of bills pizza","prediction_output":"what(O) is(O) the(O) phone(O) number(O) of(O) bills(B-Restaurant Name) pizza(I-Restaurant Name)","group":null,"words":["what","is","the","phone","number","of","bills","pizza"],"labels":["O","O","O","O","O","O","B-Restaurant Name","I-Restaurant Name"],"target_index":null,"target_label":null},"label_list":["Location","Amenity","Dish","Price","Rating","Hours","Restaurant Name","Cuisine"]}
{"id":"1464","dataset":"mit-restaurant","split":"dev","instance":{"id":"1464","prompt_labels":"wheres(O) a(O) kid(B-Amenity) friendly(I-Amenity) diner(B-Cuisine) thats(O) within(B-Location) an(O) hour(B-Location) of(I-Location) here(I-Location)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Dish, Price, Amenity, Restaurant Name, Location, Rating and O.\nSentence: wheres a kid friendly diner thats within an hour of here","prediction_output":"wheres(O) a(O) kid(B-Amenity) friendly(I-Amenity) diner(O) thats(O) within(O) an(O) hour(O) of(O) here(O)","group":null,"words":["wheres","a","kid","friendly","diner","thats","within","an","hour","of","here"],"labels":["O","O","B-Amenity","I-Amenity","B-Cuisine","O","B-Location","O","B-Location","I-Location","I-Location"],"target_index":null,"target_label":null},"label_list":["Cuisine","Hours","Dish","Price","Amenity","Restaurant Name","Location","Rating"]}
{"id":"1466","dataset":"mit-restaurant","split":"dev","instance":{"id":"1466","prompt_labels":"wheres(O) papa(B-Restaurant Name) johns(I-Restaurant Name)","instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Dish, Hours, Amenity, Restaurant Name, Cuisine, Price, Location and O.\nSentence: wheres papa johns","prediction_output":"wheres(O) papa(B-Restaurant Name) johns(I-Restaurant Name)","group":null,"words":["wheres","papa","johns"],"labels":["O","B-Restaurant Name","I-Restaurant Name"],"target_index":null,"target_label":null},"label_list":["Rating","Dish","Hours","Amenity","Restaurant Name","Cuisine","Price","Location"]}
