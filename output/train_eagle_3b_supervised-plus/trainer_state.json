{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.982412060301508,
  "eval_steps": 500,
  "global_step": 594,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10050251256281408,
      "grad_norm": 0.6086220858322579,
      "learning_rate": 1.449053550324508e-05,
      "loss": 0.5533,
      "step": 10
    },
    {
      "epoch": 0.20100502512562815,
      "grad_norm": 0.22816493357639217,
      "learning_rate": 1.885262134295571e-05,
      "loss": 0.1267,
      "step": 20
    },
    {
      "epoch": 0.3015075376884422,
      "grad_norm": 0.11688546358279882,
      "learning_rate": 1.9824561403508773e-05,
      "loss": 0.0709,
      "step": 30
    },
    {
      "epoch": 0.4020100502512563,
      "grad_norm": 0.0972021464522554,
      "learning_rate": 1.9473684210526318e-05,
      "loss": 0.0528,
      "step": 40
    },
    {
      "epoch": 0.5025125628140703,
      "grad_norm": 0.0802124745623052,
      "learning_rate": 1.912280701754386e-05,
      "loss": 0.0444,
      "step": 50
    },
    {
      "epoch": 0.6030150753768844,
      "grad_norm": 0.06838953170442844,
      "learning_rate": 1.8771929824561405e-05,
      "loss": 0.0394,
      "step": 60
    },
    {
      "epoch": 0.7035175879396985,
      "grad_norm": 0.09801467921626072,
      "learning_rate": 1.8421052631578947e-05,
      "loss": 0.0363,
      "step": 70
    },
    {
      "epoch": 0.8040201005025126,
      "grad_norm": 0.07588679507080834,
      "learning_rate": 1.8070175438596493e-05,
      "loss": 0.0332,
      "step": 80
    },
    {
      "epoch": 0.9045226130653267,
      "grad_norm": 0.10720799568508324,
      "learning_rate": 1.7719298245614035e-05,
      "loss": 0.0315,
      "step": 90
    },
    {
      "epoch": 0.9949748743718593,
      "eval_average_f1": 0.5491714401123039,
      "eval_crossner_ai_f1": 0.397421524614147,
      "eval_crossner_ai_precision": 0.3615502294747393,
      "eval_crossner_ai_recall": 0.441194772868672,
      "eval_crossner_literature_f1": 0.49138355484906937,
      "eval_crossner_literature_precision": 0.47980769230766923,
      "eval_crossner_literature_recall": 0.5035317860746467,
      "eval_crossner_music_f1": 0.5095503082672067,
      "eval_crossner_music_precision": 0.48056737588651116,
      "eval_crossner_music_recall": 0.5422535211267432,
      "eval_crossner_politics_f1": 0.5454100965153073,
      "eval_crossner_politics_precision": 0.5211399205792917,
      "eval_crossner_politics_recall": 0.5720512820512674,
      "eval_crossner_science_f1": 0.45620372037657814,
      "eval_crossner_science_precision": 0.42001995344195475,
      "eval_crossner_science_recall": 0.49920948616598815,
      "eval_mit-movie_f1": 0.767656646092743,
      "eval_mit-movie_precision": 0.7430324276949913,
      "eval_mit-movie_recall": 0.7939689080351977,
      "eval_mit-restaurant_f1": 0.6765742300710753,
      "eval_mit-restaurant_precision": 0.6538347645839309,
      "eval_mit-restaurant_recall": 0.7009523809523587,
      "eval_runtime": 237.545,
      "eval_samples_per_second": 27.237,
      "eval_steps_per_second": 0.109,
      "step": 99
    },
    {
      "epoch": 1.0075376884422111,
      "grad_norm": 0.26554911595403713,
      "learning_rate": 1.736842105263158e-05,
      "loss": 0.0329,
      "step": 100
    },
    {
      "epoch": 1.1080402010050252,
      "grad_norm": 0.06469611760686382,
      "learning_rate": 1.7017543859649125e-05,
      "loss": 0.0276,
      "step": 110
    },
    {
      "epoch": 1.2085427135678393,
      "grad_norm": 0.06344606694032581,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0276,
      "step": 120
    },
    {
      "epoch": 1.3090452261306533,
      "grad_norm": 0.06639435254835056,
      "learning_rate": 1.6315789473684213e-05,
      "loss": 0.0257,
      "step": 130
    },
    {
      "epoch": 1.4095477386934674,
      "grad_norm": 0.1021850059143667,
      "learning_rate": 1.5964912280701755e-05,
      "loss": 0.0254,
      "step": 140
    },
    {
      "epoch": 1.5100502512562815,
      "grad_norm": 0.11810334277049286,
      "learning_rate": 1.56140350877193e-05,
      "loss": 0.0254,
      "step": 150
    },
    {
      "epoch": 1.6105527638190955,
      "grad_norm": 0.08059464162175801,
      "learning_rate": 1.5263157894736846e-05,
      "loss": 0.0246,
      "step": 160
    },
    {
      "epoch": 1.7110552763819096,
      "grad_norm": 0.07302967394294059,
      "learning_rate": 1.4912280701754388e-05,
      "loss": 0.0235,
      "step": 170
    },
    {
      "epoch": 1.8115577889447236,
      "grad_norm": 0.07367721744049907,
      "learning_rate": 1.4561403508771931e-05,
      "loss": 0.0228,
      "step": 180
    },
    {
      "epoch": 1.9120603015075377,
      "grad_norm": 0.09383738934965306,
      "learning_rate": 1.4210526315789475e-05,
      "loss": 0.0228,
      "step": 190
    },
    {
      "epoch": 1.992462311557789,
      "eval_average_f1": 0.6452115305084287,
      "eval_crossner_ai_f1": 0.5273542600397312,
      "eval_crossner_ai_precision": 0.5074798619102124,
      "eval_crossner_ai_recall": 0.548848786558771,
      "eval_crossner_literature_f1": 0.5795877824183221,
      "eval_crossner_literature_precision": 0.5706601466992386,
      "eval_crossner_literature_recall": 0.5887991927345818,
      "eval_crossner_music_f1": 0.6278567016177388,
      "eval_crossner_music_precision": 0.6065035799522492,
      "eval_crossner_music_recall": 0.6507682458386476,
      "eval_crossner_politics_f1": 0.6544403968850624,
      "eval_crossner_politics_precision": 0.6414676188130845,
      "eval_crossner_politics_recall": 0.6679487179487008,
      "eval_crossner_science_f1": 0.5585893059796403,
      "eval_crossner_science_precision": 0.5368075801749076,
      "eval_crossner_science_recall": 0.5822134387351549,
      "eval_mit-movie_f1": 0.8242662179346548,
      "eval_mit-movie_precision": 0.8227281209180664,
      "eval_mit-movie_recall": 0.8258100767933916,
      "eval_mit-restaurant_f1": 0.7443860486838515,
      "eval_mit-restaurant_precision": 0.7468839884947028,
      "eval_mit-restaurant_recall": 0.7419047619047383,
      "eval_runtime": 250.6719,
      "eval_samples_per_second": 25.811,
      "eval_steps_per_second": 0.104,
      "step": 198
    },
    {
      "epoch": 2.0150753768844223,
      "grad_norm": 0.06305277649653211,
      "learning_rate": 1.385964912280702e-05,
      "loss": 0.0239,
      "step": 200
    },
    {
      "epoch": 2.1155778894472363,
      "grad_norm": 0.07083494414515173,
      "learning_rate": 1.3508771929824562e-05,
      "loss": 0.0202,
      "step": 210
    },
    {
      "epoch": 2.2160804020100504,
      "grad_norm": 0.07829848042278892,
      "learning_rate": 1.3157894736842108e-05,
      "loss": 0.0205,
      "step": 220
    },
    {
      "epoch": 2.3165829145728645,
      "grad_norm": 0.07682532539740222,
      "learning_rate": 1.280701754385965e-05,
      "loss": 0.019,
      "step": 230
    },
    {
      "epoch": 2.4170854271356785,
      "grad_norm": 0.08136362351859223,
      "learning_rate": 1.2456140350877195e-05,
      "loss": 0.0195,
      "step": 240
    },
    {
      "epoch": 2.5175879396984926,
      "grad_norm": 0.0886743675419365,
      "learning_rate": 1.2105263157894737e-05,
      "loss": 0.0194,
      "step": 250
    },
    {
      "epoch": 2.6180904522613067,
      "grad_norm": 0.07896634601217957,
      "learning_rate": 1.1754385964912282e-05,
      "loss": 0.019,
      "step": 260
    },
    {
      "epoch": 2.7185929648241207,
      "grad_norm": 0.06641400866903993,
      "learning_rate": 1.1403508771929826e-05,
      "loss": 0.0178,
      "step": 270
    },
    {
      "epoch": 2.819095477386935,
      "grad_norm": 0.06636391370062052,
      "learning_rate": 1.105263157894737e-05,
      "loss": 0.018,
      "step": 280
    },
    {
      "epoch": 2.919597989949749,
      "grad_norm": 0.06683062542885974,
      "learning_rate": 1.0701754385964913e-05,
      "loss": 0.0173,
      "step": 290
    },
    {
      "epoch": 2.9899497487437188,
      "eval_average_f1": 0.662002163422552,
      "eval_crossner_ai_f1": 0.5403200501539231,
      "eval_crossner_ai_precision": 0.544936708860725,
      "eval_crossner_ai_recall": 0.5357809583073717,
      "eval_crossner_literature_f1": 0.6071244191549516,
      "eval_crossner_literature_precision": 0.6215644820295655,
      "eval_crossner_literature_recall": 0.5933400605448742,
      "eval_crossner_music_f1": 0.6499352331106074,
      "eval_crossner_music_precision": 0.6576015727391659,
      "eval_crossner_music_recall": 0.642445582586407,
      "eval_crossner_politics_f1": 0.6416779431165776,
      "eval_crossner_politics_precision": 0.6793696275071438,
      "eval_crossner_politics_recall": 0.6079487179487023,
      "eval_crossner_science_f1": 0.5887775550602067,
      "eval_crossner_science_precision": 0.5971544715446911,
      "eval_crossner_science_recall": 0.5806324110671707,
      "eval_mit-movie_f1": 0.8541059166088129,
      "eval_mit-movie_precision": 0.857898715041556,
      "eval_mit-movie_recall": 0.8503465068364703,
      "eval_mit-restaurant_f1": 0.7520740267527852,
      "eval_mit-restaurant_precision": 0.7559332905708546,
      "eval_mit-restaurant_recall": 0.7482539682539445,
      "eval_runtime": 250.3406,
      "eval_samples_per_second": 25.845,
      "eval_steps_per_second": 0.104,
      "step": 297
    },
    {
      "epoch": 3.022613065326633,
      "grad_norm": 0.07497975490932791,
      "learning_rate": 1.0350877192982459e-05,
      "loss": 0.0195,
      "step": 300
    },
    {
      "epoch": 3.1231155778894473,
      "grad_norm": 0.07083974292391408,
      "learning_rate": 1e-05,
      "loss": 0.0157,
      "step": 310
    },
    {
      "epoch": 3.2236180904522613,
      "grad_norm": 0.0796498704166804,
      "learning_rate": 9.649122807017545e-06,
      "loss": 0.0159,
      "step": 320
    },
    {
      "epoch": 3.3241206030150754,
      "grad_norm": 0.07753611289979405,
      "learning_rate": 9.298245614035088e-06,
      "loss": 0.0157,
      "step": 330
    },
    {
      "epoch": 3.4246231155778895,
      "grad_norm": 0.08930760023833097,
      "learning_rate": 8.947368421052632e-06,
      "loss": 0.0154,
      "step": 340
    },
    {
      "epoch": 3.5251256281407035,
      "grad_norm": 0.06648953908594799,
      "learning_rate": 8.596491228070176e-06,
      "loss": 0.0149,
      "step": 350
    },
    {
      "epoch": 3.6256281407035176,
      "grad_norm": 0.07394716805086167,
      "learning_rate": 8.24561403508772e-06,
      "loss": 0.0149,
      "step": 360
    },
    {
      "epoch": 3.7261306532663316,
      "grad_norm": 0.07055914851288779,
      "learning_rate": 7.894736842105265e-06,
      "loss": 0.0157,
      "step": 370
    },
    {
      "epoch": 3.8266331658291457,
      "grad_norm": 0.06548279059192479,
      "learning_rate": 7.5438596491228074e-06,
      "loss": 0.016,
      "step": 380
    },
    {
      "epoch": 3.9271356783919598,
      "grad_norm": 0.07544218755908147,
      "learning_rate": 7.192982456140352e-06,
      "loss": 0.0157,
      "step": 390
    },
    {
      "epoch": 3.9974874371859297,
      "eval_average_f1": 0.6909874568864384,
      "eval_crossner_ai_f1": 0.5703200775446079,
      "eval_crossner_ai_precision": 0.5935397039030555,
      "eval_crossner_ai_recall": 0.548848786558771,
      "eval_crossner_literature_f1": 0.642384105910237,
      "eval_crossner_literature_precision": 0.6486625514402958,
      "eval_crossner_literature_recall": 0.6362260343087469,
      "eval_crossner_music_f1": 0.6635255889020613,
      "eval_crossner_music_precision": 0.6737050478389748,
      "eval_crossner_music_recall": 0.6536491677336539,
      "eval_crossner_politics_f1": 0.6868954550977788,
      "eval_crossner_politics_precision": 0.7107211406635396,
      "eval_crossner_politics_recall": 0.6646153846153676,
      "eval_crossner_science_f1": 0.6413236162588191,
      "eval_crossner_science_precision": 0.6391833529642466,
      "eval_crossner_science_recall": 0.6434782608695397,
      "eval_mit-movie_f1": 0.8630627236267607,
      "eval_mit-movie_precision": 0.8679674180715881,
      "eval_mit-movie_recall": 0.8582131485296711,
      "eval_mit-restaurant_f1": 0.7694006308648044,
      "eval_mit-restaurant_precision": 0.764576802507813,
      "eval_mit-restaurant_recall": 0.7742857142856897,
      "eval_runtime": 241.9578,
      "eval_samples_per_second": 26.74,
      "eval_steps_per_second": 0.107,
      "step": 397
    },
    {
      "epoch": 4.030150753768845,
      "grad_norm": 0.06954703633982401,
      "learning_rate": 6.842105263157896e-06,
      "loss": 0.0157,
      "step": 400
    },
    {
      "epoch": 4.130653266331659,
      "grad_norm": 0.08453525583079699,
      "learning_rate": 6.491228070175439e-06,
      "loss": 0.0136,
      "step": 410
    },
    {
      "epoch": 4.231155778894473,
      "grad_norm": 0.08493622332698371,
      "learning_rate": 6.140350877192983e-06,
      "loss": 0.0129,
      "step": 420
    },
    {
      "epoch": 4.331658291457287,
      "grad_norm": 0.08263776987228215,
      "learning_rate": 5.789473684210527e-06,
      "loss": 0.0128,
      "step": 430
    },
    {
      "epoch": 4.432160804020101,
      "grad_norm": 0.07783404052131969,
      "learning_rate": 5.438596491228071e-06,
      "loss": 0.013,
      "step": 440
    },
    {
      "epoch": 4.532663316582915,
      "grad_norm": 0.07879183613515012,
      "learning_rate": 5.087719298245615e-06,
      "loss": 0.013,
      "step": 450
    },
    {
      "epoch": 4.633165829145729,
      "grad_norm": 0.07672405009986824,
      "learning_rate": 4.736842105263158e-06,
      "loss": 0.0129,
      "step": 460
    },
    {
      "epoch": 4.733668341708543,
      "grad_norm": 0.07100658758968126,
      "learning_rate": 4.385964912280702e-06,
      "loss": 0.0124,
      "step": 470
    },
    {
      "epoch": 4.834170854271357,
      "grad_norm": 0.06318610568116514,
      "learning_rate": 4.035087719298246e-06,
      "loss": 0.0133,
      "step": 480
    },
    {
      "epoch": 4.934673366834171,
      "grad_norm": 0.06435796909366477,
      "learning_rate": 3.6842105263157896e-06,
      "loss": 0.0125,
      "step": 490
    },
    {
      "epoch": 4.994974874371859,
      "eval_average_f1": 0.7014499925454742,
      "eval_crossner_ai_f1": 0.5818759935906865,
      "eval_crossner_ai_precision": 0.5949284785435244,
      "eval_crossner_ai_recall": 0.5693839452395414,
      "eval_crossner_literature_f1": 0.6312074615078205,
      "eval_crossner_literature_precision": 0.6307304785893889,
      "eval_crossner_literature_recall": 0.6316851664984545,
      "eval_crossner_music_f1": 0.6813930989503033,
      "eval_crossner_music_precision": 0.6864847303443572,
      "eval_crossner_music_recall": 0.6763764404609258,
      "eval_crossner_politics_f1": 0.7164646069112783,
      "eval_crossner_politics_precision": 0.7287191726332345,
      "eval_crossner_politics_recall": 0.7046153846153665,
      "eval_crossner_science_f1": 0.6481191222070316,
      "eval_crossner_science_precision": 0.6425796425796176,
      "eval_crossner_science_recall": 0.6537549407114366,
      "eval_mit-movie_f1": 0.8673230191717372,
      "eval_mit-movie_precision": 0.8683815245963036,
      "eval_mit-movie_recall": 0.8662670912155672,
      "eval_mit-restaurant_f1": 0.7837666454794616,
      "eval_mit-restaurant_precision": 0.7827739075363906,
      "eval_mit-restaurant_recall": 0.7847619047618798,
      "eval_runtime": 236.0821,
      "eval_samples_per_second": 27.406,
      "eval_steps_per_second": 0.11,
      "step": 496
    },
    {
      "epoch": 5.0376884422110555,
      "grad_norm": 0.08490824709812095,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.014,
      "step": 500
    },
    {
      "epoch": 5.13819095477387,
      "grad_norm": 0.07385870222116535,
      "learning_rate": 2.9824561403508774e-06,
      "loss": 0.0112,
      "step": 510
    },
    {
      "epoch": 5.238693467336684,
      "grad_norm": 0.0784088907414782,
      "learning_rate": 2.631578947368421e-06,
      "loss": 0.0112,
      "step": 520
    },
    {
      "epoch": 5.339195979899498,
      "grad_norm": 0.08153382552733263,
      "learning_rate": 2.280701754385965e-06,
      "loss": 0.011,
      "step": 530
    },
    {
      "epoch": 5.439698492462312,
      "grad_norm": 0.0743720548060648,
      "learning_rate": 1.929824561403509e-06,
      "loss": 0.011,
      "step": 540
    },
    {
      "epoch": 5.540201005025126,
      "grad_norm": 0.09907097794479479,
      "learning_rate": 1.5789473684210526e-06,
      "loss": 0.0112,
      "step": 550
    },
    {
      "epoch": 5.64070351758794,
      "grad_norm": 0.07897807124420608,
      "learning_rate": 1.2280701754385965e-06,
      "loss": 0.0112,
      "step": 560
    },
    {
      "epoch": 5.741206030150754,
      "grad_norm": 0.07738487614475273,
      "learning_rate": 8.771929824561404e-07,
      "loss": 0.011,
      "step": 570
    },
    {
      "epoch": 5.841708542713568,
      "grad_norm": 0.08220873093428331,
      "learning_rate": 5.263157894736843e-07,
      "loss": 0.0109,
      "step": 580
    },
    {
      "epoch": 5.942211055276382,
      "grad_norm": 0.0689652500556552,
      "learning_rate": 1.7543859649122808e-07,
      "loss": 0.0107,
      "step": 590
    },
    {
      "epoch": 5.982412060301508,
      "eval_average_f1": 0.7043157471820208,
      "eval_crossner_ai_f1": 0.5763133353556218,
      "eval_crossner_ai_precision": 0.5757763975154921,
      "eval_crossner_ai_recall": 0.5768512756689125,
      "eval_crossner_literature_f1": 0.6381070983310472,
      "eval_crossner_literature_precision": 0.6301032956222021,
      "eval_crossner_literature_recall": 0.6463168516649522,
      "eval_crossner_music_f1": 0.6915319352789359,
      "eval_crossner_music_precision": 0.6916426512968078,
      "eval_crossner_music_recall": 0.6914212548015144,
      "eval_crossner_politics_f1": 0.714414996717923,
      "eval_crossner_politics_precision": 0.7204693611473084,
      "eval_crossner_politics_recall": 0.7084615384615203,
      "eval_crossner_science_f1": 0.6596450165288789,
      "eval_crossner_science_precision": 0.6511359260685156,
      "eval_crossner_science_recall": 0.6683794466402898,
      "eval_mit-movie_f1": 0.868849391905082,
      "eval_mit-movie_precision": 0.867875163520821,
      "eval_mit-movie_recall": 0.8698258100767771,
      "eval_mit-restaurant_f1": 0.7813484561566574,
      "eval_mit-restaurant_precision": 0.775484677923678,
      "eval_mit-restaurant_recall": 0.7873015873015623,
      "eval_runtime": 252.0357,
      "eval_samples_per_second": 25.671,
      "eval_steps_per_second": 0.103,
      "step": 594
    },
    {
      "epoch": 5.982412060301508,
      "step": 594,
      "total_flos": 2.2645297467107574e+18,
      "train_loss": 0.031174991405271118,
      "train_runtime": 4775.1133,
      "train_samples_per_second": 31.977,
      "train_steps_per_second": 0.124
    }
  ],
  "logging_steps": 10,
  "max_steps": 594,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.2645297467107574e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
