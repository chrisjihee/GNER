{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.975510204081632,
  "eval_steps": 500,
  "global_step": 732,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08163265306122448,
      "grad_norm": 1.3629188821125986,
      "learning_rate": 1.3539849850576912e-05,
      "loss": 0.2745,
      "step": 10
    },
    {
      "epoch": 0.16326530612244897,
      "grad_norm": 0.48599228504124803,
      "learning_rate": 1.7615750792387035e-05,
      "loss": 0.0948,
      "step": 20
    },
    {
      "epoch": 0.24489795918367346,
      "grad_norm": 0.1945298535706676,
      "learning_rate": 2e-05,
      "loss": 0.0512,
      "step": 30
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 0.08548058615292371,
      "learning_rate": 1.9743589743589745e-05,
      "loss": 0.039,
      "step": 40
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 0.08846411101616855,
      "learning_rate": 1.945868945868946e-05,
      "loss": 0.0345,
      "step": 50
    },
    {
      "epoch": 0.4897959183673469,
      "grad_norm": 0.2040465613912738,
      "learning_rate": 1.9173789173789174e-05,
      "loss": 0.0298,
      "step": 60
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.09658086909105028,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0272,
      "step": 70
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 0.09994177892964715,
      "learning_rate": 1.8603988603988604e-05,
      "loss": 0.0259,
      "step": 80
    },
    {
      "epoch": 0.7346938775510204,
      "grad_norm": 0.17008494631116766,
      "learning_rate": 1.8319088319088322e-05,
      "loss": 0.0251,
      "step": 90
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 0.08461268070698705,
      "learning_rate": 1.8034188034188037e-05,
      "loss": 0.0225,
      "step": 100
    },
    {
      "epoch": 0.8979591836734694,
      "grad_norm": 0.07080860423573435,
      "learning_rate": 1.774928774928775e-05,
      "loss": 0.0227,
      "step": 110
    },
    {
      "epoch": 0.9795918367346939,
      "grad_norm": 0.09262395661875805,
      "learning_rate": 1.7464387464387466e-05,
      "loss": 0.022,
      "step": 120
    },
    {
      "epoch": 0.9959183673469387,
      "eval_average_f1": 0.6670622836686532,
      "eval_crossner_ai_f1": 0.5540201004524822,
      "eval_crossner_ai_precision": 0.5592897907418796,
      "eval_crossner_ai_recall": 0.548848786558771,
      "eval_crossner_literature_f1": 0.5891514500038817,
      "eval_crossner_literature_precision": 0.6297359357060488,
      "eval_crossner_literature_recall": 0.5534813319878631,
      "eval_crossner_music_f1": 0.6765249537393809,
      "eval_crossner_music_precision": 0.7120622568093133,
      "eval_crossner_music_recall": 0.644366197183078,
      "eval_crossner_politics_f1": 0.6530776451157045,
      "eval_crossner_politics_precision": 0.6845656452066156,
      "eval_crossner_politics_recall": 0.6243589743589584,
      "eval_crossner_science_f1": 0.5649274224686154,
      "eval_crossner_science_precision": 0.5607476635513801,
      "eval_crossner_science_recall": 0.5691699604742858,
      "eval_mit-movie_f1": 0.8662092623856763,
      "eval_mit-movie_precision": 0.8816682832201574,
      "eval_mit-movie_recall": 0.8512830117999466,
      "eval_mit-restaurant_f1": 0.7655251515148312,
      "eval_mit-restaurant_precision": 0.7910599390450122,
      "eval_mit-restaurant_recall": 0.741587301587278,
      "eval_runtime": 158.6111,
      "eval_samples_per_second": 40.792,
      "eval_steps_per_second": 0.164,
      "step": 122
    },
    {
      "epoch": 1.0612244897959184,
      "grad_norm": 0.09478870791579024,
      "learning_rate": 1.717948717948718e-05,
      "loss": 0.0212,
      "step": 130
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.12037763427093058,
      "learning_rate": 1.6894586894586896e-05,
      "loss": 0.0182,
      "step": 140
    },
    {
      "epoch": 1.2244897959183674,
      "grad_norm": 0.09862988533737578,
      "learning_rate": 1.660968660968661e-05,
      "loss": 0.0178,
      "step": 150
    },
    {
      "epoch": 1.306122448979592,
      "grad_norm": 0.10544665423046444,
      "learning_rate": 1.6324786324786325e-05,
      "loss": 0.0163,
      "step": 160
    },
    {
      "epoch": 1.3877551020408163,
      "grad_norm": 0.05877278116747863,
      "learning_rate": 1.603988603988604e-05,
      "loss": 0.0175,
      "step": 170
    },
    {
      "epoch": 1.469387755102041,
      "grad_norm": 0.14221791267022793,
      "learning_rate": 1.5754985754985758e-05,
      "loss": 0.0171,
      "step": 180
    },
    {
      "epoch": 1.5510204081632653,
      "grad_norm": 0.08495831759567889,
      "learning_rate": 1.5470085470085473e-05,
      "loss": 0.0169,
      "step": 190
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 0.09932634872137237,
      "learning_rate": 1.5185185185185187e-05,
      "loss": 0.0173,
      "step": 200
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.0574561896427528,
      "learning_rate": 1.4900284900284902e-05,
      "loss": 0.016,
      "step": 210
    },
    {
      "epoch": 1.7959183673469388,
      "grad_norm": 0.06217272012861903,
      "learning_rate": 1.4615384615384615e-05,
      "loss": 0.0157,
      "step": 220
    },
    {
      "epoch": 1.8775510204081631,
      "grad_norm": 0.0722559136231816,
      "learning_rate": 1.4330484330484332e-05,
      "loss": 0.0156,
      "step": 230
    },
    {
      "epoch": 1.9591836734693877,
      "grad_norm": 0.10350165182847987,
      "learning_rate": 1.4045584045584046e-05,
      "loss": 0.0152,
      "step": 240
    },
    {
      "epoch": 2.0,
      "eval_average_f1": 0.7388863018840844,
      "eval_crossner_ai_f1": 0.6146586976536478,
      "eval_crossner_ai_precision": 0.6215012722645915,
      "eval_crossner_ai_recall": 0.6079651524579585,
      "eval_crossner_literature_f1": 0.6908033826139244,
      "eval_crossner_literature_precision": 0.7253052164261529,
      "eval_crossner_literature_recall": 0.6594349142280191,
      "eval_crossner_music_f1": 0.7847302904064739,
      "eval_crossner_music_precision": 0.8148914167528157,
      "eval_crossner_music_recall": 0.7567221510883241,
      "eval_crossner_politics_f1": 0.7361914781193984,
      "eval_crossner_politics_precision": 0.7556695464362647,
      "eval_crossner_politics_recall": 0.7176923076922893,
      "eval_crossner_science_f1": 0.6675933279881001,
      "eval_crossner_science_precision": 0.6707901037509708,
      "eval_crossner_science_recall": 0.6644268774703295,
      "eval_mit-movie_f1": 0.8781635148620177,
      "eval_mit-movie_precision": 0.8822306238185088,
      "eval_mit-movie_recall": 0.8741337329087681,
      "eval_mit-restaurant_f1": 0.8000634215450279,
      "eval_mit-restaurant_precision": 0.7991764333227495,
      "eval_mit-restaurant_recall": 0.8009523809523555,
      "eval_runtime": 87.3043,
      "eval_samples_per_second": 74.109,
      "eval_steps_per_second": 0.298,
      "step": 245
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.07107290391997827,
      "learning_rate": 1.3760683760683761e-05,
      "loss": 0.0139,
      "step": 250
    },
    {
      "epoch": 2.122448979591837,
      "grad_norm": 0.10881688140684333,
      "learning_rate": 1.3475783475783478e-05,
      "loss": 0.0109,
      "step": 260
    },
    {
      "epoch": 2.204081632653061,
      "grad_norm": 0.11572937603847724,
      "learning_rate": 1.3190883190883192e-05,
      "loss": 0.0105,
      "step": 270
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.05434911208244502,
      "learning_rate": 1.2905982905982907e-05,
      "loss": 0.0104,
      "step": 280
    },
    {
      "epoch": 2.36734693877551,
      "grad_norm": 0.06756804754938099,
      "learning_rate": 1.2621082621082624e-05,
      "loss": 0.0104,
      "step": 290
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 0.05841551334892549,
      "learning_rate": 1.2336182336182337e-05,
      "loss": 0.0101,
      "step": 300
    },
    {
      "epoch": 2.5306122448979593,
      "grad_norm": 0.06282813761833612,
      "learning_rate": 1.2051282051282051e-05,
      "loss": 0.0098,
      "step": 310
    },
    {
      "epoch": 2.612244897959184,
      "grad_norm": 0.06101194512569303,
      "learning_rate": 1.1766381766381768e-05,
      "loss": 0.0102,
      "step": 320
    },
    {
      "epoch": 2.693877551020408,
      "grad_norm": 0.06055468847249926,
      "learning_rate": 1.1481481481481482e-05,
      "loss": 0.0098,
      "step": 330
    },
    {
      "epoch": 2.7755102040816326,
      "grad_norm": 0.05912917400134921,
      "learning_rate": 1.1196581196581197e-05,
      "loss": 0.0103,
      "step": 340
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.05813453852735545,
      "learning_rate": 1.0911680911680914e-05,
      "loss": 0.0096,
      "step": 350
    },
    {
      "epoch": 2.938775510204082,
      "grad_norm": 0.058031265177003216,
      "learning_rate": 1.0626780626780628e-05,
      "loss": 0.0096,
      "step": 360
    },
    {
      "epoch": 2.9959183673469387,
      "eval_average_f1": 0.7594331378042971,
      "eval_crossner_ai_f1": 0.634940128902994,
      "eval_crossner_ai_precision": 0.6266666666666286,
      "eval_crossner_ai_recall": 0.6434349719974708,
      "eval_crossner_literature_f1": 0.7172867627948137,
      "eval_crossner_literature_precision": 0.7196546470289121,
      "eval_crossner_literature_recall": 0.7149344096871486,
      "eval_crossner_music_f1": 0.7907356058870336,
      "eval_crossner_music_precision": 0.8061190555370533,
      "eval_crossner_music_recall": 0.7759282970550327,
      "eval_crossner_politics_f1": 0.7691912047847498,
      "eval_crossner_politics_precision": 0.7714727882383087,
      "eval_crossner_politics_recall": 0.7669230769230573,
      "eval_crossner_science_f1": 0.7179684493536245,
      "eval_crossner_science_precision": 0.6994002998500487,
      "eval_crossner_science_recall": 0.7375494071145954,
      "eval_mit-movie_f1": 0.8836428104379939,
      "eval_mit-movie_precision": 0.8804388248419323,
      "eval_mit-movie_recall": 0.8868702004120456,
      "eval_mit-restaurant_f1": 0.8022670024688698,
      "eval_mit-restaurant_precision": 0.7957526545908559,
      "eval_mit-restaurant_recall": 0.8088888888888632,
      "eval_runtime": 89.1618,
      "eval_samples_per_second": 72.565,
      "eval_steps_per_second": 0.292,
      "step": 367
    },
    {
      "epoch": 3.020408163265306,
      "grad_norm": 0.08861914276687351,
      "learning_rate": 1.0341880341880343e-05,
      "loss": 0.0092,
      "step": 370
    },
    {
      "epoch": 3.1020408163265305,
      "grad_norm": 0.06647501918890003,
      "learning_rate": 1.0056980056980056e-05,
      "loss": 0.0059,
      "step": 380
    },
    {
      "epoch": 3.183673469387755,
      "grad_norm": 0.05806514799574869,
      "learning_rate": 9.772079772079773e-06,
      "loss": 0.0062,
      "step": 390
    },
    {
      "epoch": 3.2653061224489797,
      "grad_norm": 0.07011248365579029,
      "learning_rate": 9.487179487179487e-06,
      "loss": 0.0062,
      "step": 400
    },
    {
      "epoch": 3.3469387755102042,
      "grad_norm": 0.06390357176874358,
      "learning_rate": 9.202279202279202e-06,
      "loss": 0.0056,
      "step": 410
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.08303395869291508,
      "learning_rate": 8.917378917378919e-06,
      "loss": 0.0058,
      "step": 420
    },
    {
      "epoch": 3.510204081632653,
      "grad_norm": 0.05324902450004922,
      "learning_rate": 8.632478632478633e-06,
      "loss": 0.006,
      "step": 430
    },
    {
      "epoch": 3.5918367346938775,
      "grad_norm": 0.05445673055629407,
      "learning_rate": 8.347578347578348e-06,
      "loss": 0.0057,
      "step": 440
    },
    {
      "epoch": 3.673469387755102,
      "grad_norm": 0.06627664470523166,
      "learning_rate": 8.062678062678063e-06,
      "loss": 0.0061,
      "step": 450
    },
    {
      "epoch": 3.7551020408163263,
      "grad_norm": 0.0645785448038544,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.006,
      "step": 460
    },
    {
      "epoch": 3.836734693877551,
      "grad_norm": 0.06125249504522772,
      "learning_rate": 7.492877492877494e-06,
      "loss": 0.0054,
      "step": 470
    },
    {
      "epoch": 3.9183673469387754,
      "grad_norm": 0.05543883248902851,
      "learning_rate": 7.207977207977208e-06,
      "loss": 0.0052,
      "step": 480
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.07873722044626702,
      "learning_rate": 6.923076923076923e-06,
      "loss": 0.0064,
      "step": 490
    },
    {
      "epoch": 4.0,
      "eval_average_f1": 0.7478671581190375,
      "eval_crossner_ai_f1": 0.6524777636094469,
      "eval_crossner_ai_precision": 0.6664503569110535,
      "eval_crossner_ai_recall": 0.6390790292470044,
      "eval_crossner_literature_f1": 0.6849816849317182,
      "eval_crossner_literature_precision": 0.7114130434782222,
      "eval_crossner_literature_recall": 0.6604439959636397,
      "eval_crossner_music_f1": 0.7639854352363619,
      "eval_crossner_music_precision": 0.7909527073337631,
      "eval_crossner_music_recall": 0.7387964148527292,
      "eval_crossner_politics_f1": 0.7567922299014456,
      "eval_crossner_politics_precision": 0.7752083893519555,
      "eval_crossner_politics_recall": 0.7392307692307503,
      "eval_crossner_science_f1": 0.6869373874274755,
      "eval_crossner_science_precision": 0.6954232482786271,
      "eval_crossner_science_recall": 0.6786561264821867,
      "eval_mit-movie_f1": 0.8844239976966742,
      "eval_mit-movie_precision": 0.8866716867469713,
      "eval_mit-movie_recall": 0.8821876755946642,
      "eval_mit-restaurant_f1": 0.8054716080301398,
      "eval_mit-restaurant_precision": 0.8071405801721132,
      "eval_mit-restaurant_recall": 0.8038095238094983,
      "eval_runtime": 84.7039,
      "eval_samples_per_second": 76.384,
      "eval_steps_per_second": 0.307,
      "step": 490
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.030683644497754767,
      "learning_rate": 6.638176638176639e-06,
      "loss": 0.0033,
      "step": 500
    },
    {
      "epoch": 4.163265306122449,
      "grad_norm": 0.03672500015642872,
      "learning_rate": 6.3532763532763546e-06,
      "loss": 0.0031,
      "step": 510
    },
    {
      "epoch": 4.244897959183674,
      "grad_norm": 0.04101107776503187,
      "learning_rate": 6.0683760683760684e-06,
      "loss": 0.003,
      "step": 520
    },
    {
      "epoch": 4.326530612244898,
      "grad_norm": 0.06225768254920302,
      "learning_rate": 5.783475783475784e-06,
      "loss": 0.0034,
      "step": 530
    },
    {
      "epoch": 4.408163265306122,
      "grad_norm": 0.0355668347907395,
      "learning_rate": 5.498575498575499e-06,
      "loss": 0.0033,
      "step": 540
    },
    {
      "epoch": 4.489795918367347,
      "grad_norm": 0.043639819270760015,
      "learning_rate": 5.213675213675214e-06,
      "loss": 0.0034,
      "step": 550
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.08346912718198155,
      "learning_rate": 4.928774928774929e-06,
      "loss": 0.0028,
      "step": 560
    },
    {
      "epoch": 4.653061224489796,
      "grad_norm": 0.08871102498099323,
      "learning_rate": 4.643874643874644e-06,
      "loss": 0.0031,
      "step": 570
    },
    {
      "epoch": 4.73469387755102,
      "grad_norm": 0.03983517816376852,
      "learning_rate": 4.358974358974359e-06,
      "loss": 0.0033,
      "step": 580
    },
    {
      "epoch": 4.816326530612245,
      "grad_norm": 0.07598747037826441,
      "learning_rate": 4.074074074074074e-06,
      "loss": 0.0032,
      "step": 590
    },
    {
      "epoch": 4.8979591836734695,
      "grad_norm": 0.04735820536599182,
      "learning_rate": 3.7891737891737893e-06,
      "loss": 0.0032,
      "step": 600
    },
    {
      "epoch": 4.979591836734694,
      "grad_norm": 0.043793689570943956,
      "learning_rate": 3.5042735042735045e-06,
      "loss": 0.0031,
      "step": 610
    },
    {
      "epoch": 4.995918367346938,
      "eval_average_f1": 0.7545863252818359,
      "eval_crossner_ai_f1": 0.663098236725784,
      "eval_crossner_ai_precision": 0.671128107074527,
      "eval_crossner_ai_recall": 0.6552582451773084,
      "eval_crossner_literature_f1": 0.6937098844172458,
      "eval_crossner_literature_precision": 0.7062205959225977,
      "eval_crossner_literature_recall": 0.681634712411671,
      "eval_crossner_music_f1": 0.774951076270932,
      "eval_crossner_music_precision": 0.7898936170212503,
      "eval_crossner_music_recall": 0.7605633802816658,
      "eval_crossner_politics_f1": 0.7614030578967879,
      "eval_crossner_politics_precision": 0.7630697913983836,
      "eval_crossner_politics_recall": 0.7597435897435703,
      "eval_crossner_science_f1": 0.7042198233062062,
      "eval_crossner_science_precision": 0.6994152046783353,
      "eval_crossner_science_recall": 0.709090909090881,
      "eval_mit-movie_f1": 0.8874097683947195,
      "eval_mit-movie_precision": 0.8883258258258091,
      "eval_mit-movie_recall": 0.886495598426655,
      "eval_mit-restaurant_f1": 0.7973124299611758,
      "eval_mit-restaurant_precision": 0.8036117381489583,
      "eval_mit-restaurant_recall": 0.791111111111086,
      "eval_runtime": 87.2774,
      "eval_samples_per_second": 74.131,
      "eval_steps_per_second": 0.298,
      "step": 612
    },
    {
      "epoch": 5.061224489795919,
      "grad_norm": 0.029332739018176655,
      "learning_rate": 3.2193732193732196e-06,
      "loss": 0.0021,
      "step": 620
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.04151221500703876,
      "learning_rate": 2.9344729344729344e-06,
      "loss": 0.0016,
      "step": 630
    },
    {
      "epoch": 5.224489795918367,
      "grad_norm": 0.028437704102601165,
      "learning_rate": 2.64957264957265e-06,
      "loss": 0.0019,
      "step": 640
    },
    {
      "epoch": 5.3061224489795915,
      "grad_norm": 0.03356952493787793,
      "learning_rate": 2.3646723646723647e-06,
      "loss": 0.0017,
      "step": 650
    },
    {
      "epoch": 5.387755102040816,
      "grad_norm": 0.05961038070545261,
      "learning_rate": 2.07977207977208e-06,
      "loss": 0.0018,
      "step": 660
    },
    {
      "epoch": 5.469387755102041,
      "grad_norm": 0.03860182317666207,
      "learning_rate": 1.794871794871795e-06,
      "loss": 0.0016,
      "step": 670
    },
    {
      "epoch": 5.551020408163265,
      "grad_norm": 0.045155077975978744,
      "learning_rate": 1.5099715099715102e-06,
      "loss": 0.0019,
      "step": 680
    },
    {
      "epoch": 5.63265306122449,
      "grad_norm": 0.05150526439162092,
      "learning_rate": 1.2250712250712251e-06,
      "loss": 0.0019,
      "step": 690
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.026356208025290206,
      "learning_rate": 9.401709401709402e-07,
      "loss": 0.0015,
      "step": 700
    },
    {
      "epoch": 5.795918367346939,
      "grad_norm": 0.04721617219939725,
      "learning_rate": 6.552706552706554e-07,
      "loss": 0.0016,
      "step": 710
    },
    {
      "epoch": 5.877551020408164,
      "grad_norm": 0.032507928863414304,
      "learning_rate": 3.7037037037037036e-07,
      "loss": 0.0015,
      "step": 720
    },
    {
      "epoch": 5.959183673469388,
      "grad_norm": 0.039496813264072374,
      "learning_rate": 8.547008547008549e-08,
      "loss": 0.0017,
      "step": 730
    },
    {
      "epoch": 5.975510204081632,
      "eval_average_f1": 0.755318907104465,
      "eval_crossner_ai_f1": 0.6481423664813369,
      "eval_crossner_ai_precision": 0.6503759398495833,
      "eval_crossner_ai_recall": 0.6459240821405945,
      "eval_crossner_literature_f1": 0.7055837562951436,
      "eval_crossner_literature_precision": 0.709908069458595,
      "eval_crossner_literature_recall": 0.7013118062562713,
      "eval_crossner_music_f1": 0.7693801585516968,
      "eval_crossner_music_precision": 0.7780687397708419,
      "eval_crossner_music_recall": 0.7608834827144443,
      "eval_crossner_politics_f1": 0.7679671457405347,
      "eval_crossner_politics_precision": 0.7687564234326627,
      "eval_crossner_politics_recall": 0.7671794871794675,
      "eval_crossner_science_f1": 0.7118775430617916,
      "eval_crossner_science_precision": 0.698213606993512,
      "eval_crossner_science_recall": 0.7260869565217104,
      "eval_mit-movie_f1": 0.883899335715724,
      "eval_mit-movie_precision": 0.882990654205591,
      "eval_mit-movie_recall": 0.8848098894923977,
      "eval_mit-restaurant_f1": 0.8003820438850275,
      "eval_mit-restaurant_precision": 0.8026819923371391,
      "eval_mit-restaurant_recall": 0.7980952380952128,
      "eval_runtime": 110.121,
      "eval_samples_per_second": 58.754,
      "eval_steps_per_second": 0.236,
      "step": 732
    },
    {
      "epoch": 5.975510204081632,
      "step": 732,
      "total_flos": 7.714919378730353e+17,
      "train_loss": 0.01555290318614564,
      "train_runtime": 2224.4878,
      "train_samples_per_second": 84.548,
      "train_steps_per_second": 0.329
    }
  ],
  "logging_steps": 10,
  "max_steps": 732,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.714919378730353e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
