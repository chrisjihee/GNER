{
    "epoch": 5.975510204081632,
    "eval_average_f1": 0.7530100957413587,
    "eval_crossner_ai_f1": 0.6414157093569769,
    "eval_crossner_ai_precision": 0.6400247831474201,
    "eval_crossner_ai_recall": 0.6428126944616899,
    "eval_crossner_literature_f1": 0.6967316949081618,
    "eval_crossner_literature_precision": 0.6997455470737557,
    "eval_crossner_literature_recall": 0.6937436932391173,
    "eval_crossner_music_f1": 0.7732510955513483,
    "eval_crossner_music_precision": 0.7843266381297075,
    "eval_crossner_music_recall": 0.7624839948783366,
    "eval_crossner_politics_f1": 0.7618188844018686,
    "eval_crossner_politics_precision": 0.7654672534299569,
    "eval_crossner_politics_recall": 0.7582051282051088,
    "eval_crossner_science_f1": 0.708511465165688,
    "eval_crossner_science_precision": 0.6968654434250499,
    "eval_crossner_science_recall": 0.720553359683766,
    "eval_mit-movie_f1": 0.8854761681305247,
    "eval_mit-movie_precision": 0.8853932584269497,
    "eval_mit-movie_recall": 0.8855590934631787,
    "eval_mit-restaurant_f1": 0.8038656526749429,
    "eval_mit-restaurant_precision": 0.8023402909550663,
    "eval_mit-restaurant_recall": 0.8053968253967998,
    "eval_runtime": 85.5167,
    "eval_samples": 6470,
    "eval_samples_per_second": 75.658,
    "eval_steps_per_second": 0.304,
    "total_flos": 7.714919378730353e+17,
    "train_loss": 0.01555290318614564,
    "train_runtime": 2224.4878,
    "train_samples": 31346,
    "train_samples_per_second": 84.548,
    "train_steps_per_second": 0.329
}