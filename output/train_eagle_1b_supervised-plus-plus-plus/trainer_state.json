{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.986733001658375,
  "eval_steps": 500,
  "global_step": 900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06633499170812604,
      "grad_norm": 1.1560785321088503,
      "learning_rate": 1.2850972089384688e-05,
      "loss": 0.4178,
      "step": 10
    },
    {
      "epoch": 0.13266998341625208,
      "grad_norm": 1.3272220010137625,
      "learning_rate": 1.67195001617301e-05,
      "loss": 0.0964,
      "step": 20
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 0.91054778620651,
      "learning_rate": 1.898244401703927e-05,
      "loss": 0.0578,
      "step": 30
    },
    {
      "epoch": 0.26533996683250416,
      "grad_norm": 0.30899771072024224,
      "learning_rate": 1.9930555555555556e-05,
      "loss": 0.0413,
      "step": 40
    },
    {
      "epoch": 0.33167495854063017,
      "grad_norm": 0.2711448192589685,
      "learning_rate": 1.9699074074074076e-05,
      "loss": 0.0394,
      "step": 50
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 0.9165967387201105,
      "learning_rate": 1.9467592592592596e-05,
      "loss": 0.0347,
      "step": 60
    },
    {
      "epoch": 0.46434494195688225,
      "grad_norm": 0.7823740692693851,
      "learning_rate": 1.9236111111111113e-05,
      "loss": 0.0326,
      "step": 70
    },
    {
      "epoch": 0.5306799336650083,
      "grad_norm": 0.19507958829832797,
      "learning_rate": 1.9004629629629633e-05,
      "loss": 0.0283,
      "step": 80
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 0.22047810350146319,
      "learning_rate": 1.877314814814815e-05,
      "loss": 0.0245,
      "step": 90
    },
    {
      "epoch": 0.6633499170812603,
      "grad_norm": 0.14791222541033744,
      "learning_rate": 1.854166666666667e-05,
      "loss": 0.0234,
      "step": 100
    },
    {
      "epoch": 0.7296849087893864,
      "grad_norm": 0.11527935055568818,
      "learning_rate": 1.831018518518519e-05,
      "loss": 0.0218,
      "step": 110
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 0.13737632109203785,
      "learning_rate": 1.8078703703703705e-05,
      "loss": 0.0218,
      "step": 120
    },
    {
      "epoch": 0.8623548922056384,
      "grad_norm": 0.08876388959929078,
      "learning_rate": 1.7847222222222225e-05,
      "loss": 0.021,
      "step": 130
    },
    {
      "epoch": 0.9286898839137645,
      "grad_norm": 0.10421210926980602,
      "learning_rate": 1.7615740740740742e-05,
      "loss": 0.0204,
      "step": 140
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 0.12320231277764127,
      "learning_rate": 1.738425925925926e-05,
      "loss": 0.0197,
      "step": 150
    },
    {
      "epoch": 0.9950248756218906,
      "eval_average_f1": 0.5890658843612122,
      "eval_crossner_ai_f1": 0.4227548367968988,
      "eval_crossner_ai_precision": 0.3943965517241167,
      "eval_crossner_ai_recall": 0.4555071561916331,
      "eval_crossner_literature_f1": 0.5333990632973009,
      "eval_crossner_literature_precision": 0.521445783132505,
      "eval_crossner_literature_recall": 0.5459132189707091,
      "eval_crossner_music_f1": 0.5420531362493228,
      "eval_crossner_music_precision": 0.5325919060858655,
      "eval_crossner_music_recall": 0.5518565941100976,
      "eval_crossner_politics_f1": 0.554755400992996,
      "eval_crossner_politics_precision": 0.5377948964853024,
      "eval_crossner_politics_recall": 0.5728205128204982,
      "eval_crossner_science_f1": 0.49982007911555076,
      "eval_crossner_science_precision": 0.4587186261558633,
      "eval_crossner_science_recall": 0.5490118577074882,
      "eval_mit-movie_f1": 0.8267188372892817,
      "eval_mit-movie_precision": 0.8224281742353879,
      "eval_mit-movie_recall": 0.8310545045888588,
      "eval_mit-restaurant_f1": 0.7439598367871343,
      "eval_mit-restaurant_precision": 0.7354218362282651,
      "eval_mit-restaurant_recall": 0.7526984126983888,
      "eval_runtime": 223.8276,
      "eval_samples_per_second": 28.906,
      "eval_steps_per_second": 0.116,
      "step": 150
    },
    {
      "epoch": 1.064676616915423,
      "grad_norm": 0.18560714746611426,
      "learning_rate": 1.715277777777778e-05,
      "loss": 0.0175,
      "step": 160
    },
    {
      "epoch": 1.1310116086235489,
      "grad_norm": 0.26194249737686653,
      "learning_rate": 1.6921296296296298e-05,
      "loss": 0.0177,
      "step": 170
    },
    {
      "epoch": 1.197346600331675,
      "grad_norm": 0.27556188141789506,
      "learning_rate": 1.6689814814814815e-05,
      "loss": 0.0165,
      "step": 180
    },
    {
      "epoch": 1.263681592039801,
      "grad_norm": 0.4668720615759202,
      "learning_rate": 1.6458333333333335e-05,
      "loss": 0.0175,
      "step": 190
    },
    {
      "epoch": 1.330016583747927,
      "grad_norm": 0.27679643220190453,
      "learning_rate": 1.622685185185185e-05,
      "loss": 0.0174,
      "step": 200
    },
    {
      "epoch": 1.3963515754560532,
      "grad_norm": 0.10583541412432483,
      "learning_rate": 1.599537037037037e-05,
      "loss": 0.0157,
      "step": 210
    },
    {
      "epoch": 1.462686567164179,
      "grad_norm": 0.11799532294197622,
      "learning_rate": 1.576388888888889e-05,
      "loss": 0.0161,
      "step": 220
    },
    {
      "epoch": 1.529021558872305,
      "grad_norm": 0.12164150453321804,
      "learning_rate": 1.5532407407407408e-05,
      "loss": 0.0148,
      "step": 230
    },
    {
      "epoch": 1.5953565505804312,
      "grad_norm": 0.150980554061573,
      "learning_rate": 1.5300925925925928e-05,
      "loss": 0.0152,
      "step": 240
    },
    {
      "epoch": 1.6616915422885572,
      "grad_norm": 0.11542960375090529,
      "learning_rate": 1.5069444444444446e-05,
      "loss": 0.0154,
      "step": 250
    },
    {
      "epoch": 1.7280265339966832,
      "grad_norm": 0.13327176962583165,
      "learning_rate": 1.4837962962962964e-05,
      "loss": 0.0152,
      "step": 260
    },
    {
      "epoch": 1.7943615257048093,
      "grad_norm": 0.2866395752649224,
      "learning_rate": 1.4606481481481482e-05,
      "loss": 0.0149,
      "step": 270
    },
    {
      "epoch": 1.8606965174129353,
      "grad_norm": 0.09505197337766932,
      "learning_rate": 1.4375e-05,
      "loss": 0.0147,
      "step": 280
    },
    {
      "epoch": 1.9270315091210612,
      "grad_norm": 0.121143388572482,
      "learning_rate": 1.414351851851852e-05,
      "loss": 0.0141,
      "step": 290
    },
    {
      "epoch": 1.9933665008291874,
      "grad_norm": 0.12737093179016085,
      "learning_rate": 1.3912037037037039e-05,
      "loss": 0.0139,
      "step": 300
    },
    {
      "epoch": 1.9933665008291874,
      "eval_average_f1": 0.6514582580167965,
      "eval_crossner_ai_f1": 0.5010785823844883,
      "eval_crossner_ai_precision": 0.49633699633696604,
      "eval_crossner_ai_recall": 0.5059116365898876,
      "eval_crossner_literature_f1": 0.5704868153657938,
      "eval_crossner_literature_precision": 0.5733944954128148,
      "eval_crossner_literature_recall": 0.5676084762865505,
      "eval_crossner_music_f1": 0.6139580282564845,
      "eval_crossner_music_precision": 0.624214356599384,
      "eval_crossner_music_recall": 0.6040332906529896,
      "eval_crossner_politics_f1": 0.6397323725696444,
      "eval_crossner_politics_precision": 0.6420454545454379,
      "eval_crossner_politics_recall": 0.6374358974358811,
      "eval_crossner_science_f1": 0.602221789074913,
      "eval_crossner_science_precision": 0.5940023068050522,
      "eval_crossner_science_recall": 0.6106719367588691,
      "eval_mit-movie_f1": 0.8560740670967155,
      "eval_mit-movie_precision": 0.8548748599178024,
      "eval_mit-movie_recall": 0.8572766435661948,
      "eval_mit-restaurant_f1": 0.7766561513695358,
      "eval_mit-restaurant_precision": 0.7717868338557752,
      "eval_mit-restaurant_recall": 0.7815873015872767,
      "eval_runtime": 353.8542,
      "eval_samples_per_second": 18.284,
      "eval_steps_per_second": 0.073,
      "step": 300
    },
    {
      "epoch": 2.0630182421227197,
      "grad_norm": 0.10675963967270982,
      "learning_rate": 1.3680555555555557e-05,
      "loss": 0.0116,
      "step": 310
    },
    {
      "epoch": 2.129353233830846,
      "grad_norm": 0.1829265788740968,
      "learning_rate": 1.3449074074074075e-05,
      "loss": 0.0116,
      "step": 320
    },
    {
      "epoch": 2.195688225538972,
      "grad_norm": 0.25351652900522864,
      "learning_rate": 1.3217592592592593e-05,
      "loss": 0.0117,
      "step": 330
    },
    {
      "epoch": 2.2620232172470978,
      "grad_norm": 0.11131215399239089,
      "learning_rate": 1.2986111111111113e-05,
      "loss": 0.0113,
      "step": 340
    },
    {
      "epoch": 2.328358208955224,
      "grad_norm": 0.10566832503854207,
      "learning_rate": 1.2754629629629631e-05,
      "loss": 0.0113,
      "step": 350
    },
    {
      "epoch": 2.39469320066335,
      "grad_norm": 0.15140863281870862,
      "learning_rate": 1.252314814814815e-05,
      "loss": 0.0106,
      "step": 360
    },
    {
      "epoch": 2.461028192371476,
      "grad_norm": 0.0949027742783162,
      "learning_rate": 1.2291666666666668e-05,
      "loss": 0.0106,
      "step": 370
    },
    {
      "epoch": 2.527363184079602,
      "grad_norm": 0.19678803975684836,
      "learning_rate": 1.2060185185185188e-05,
      "loss": 0.0111,
      "step": 380
    },
    {
      "epoch": 2.593698175787728,
      "grad_norm": 0.1531826908075719,
      "learning_rate": 1.1828703703703706e-05,
      "loss": 0.0105,
      "step": 390
    },
    {
      "epoch": 2.660033167495854,
      "grad_norm": 0.2087962560600979,
      "learning_rate": 1.1597222222222224e-05,
      "loss": 0.0105,
      "step": 400
    },
    {
      "epoch": 2.72636815920398,
      "grad_norm": 0.11394934708230164,
      "learning_rate": 1.1365740740740742e-05,
      "loss": 0.0106,
      "step": 410
    },
    {
      "epoch": 2.7927031509121063,
      "grad_norm": 0.14125074798883872,
      "learning_rate": 1.1134259259259259e-05,
      "loss": 0.0105,
      "step": 420
    },
    {
      "epoch": 2.859038142620232,
      "grad_norm": 0.12743900925293083,
      "learning_rate": 1.0902777777777777e-05,
      "loss": 0.0096,
      "step": 430
    },
    {
      "epoch": 2.925373134328358,
      "grad_norm": 0.09913511130149066,
      "learning_rate": 1.0671296296296295e-05,
      "loss": 0.0103,
      "step": 440
    },
    {
      "epoch": 2.9917081260364844,
      "grad_norm": 0.09558573159654372,
      "learning_rate": 1.0439814814814815e-05,
      "loss": 0.0096,
      "step": 450
    },
    {
      "epoch": 2.9917081260364844,
      "eval_average_f1": 0.6856833521643795,
      "eval_crossner_ai_f1": 0.5645664378788485,
      "eval_crossner_ai_precision": 0.5659787367104087,
      "eval_crossner_ai_recall": 0.5631611698817323,
      "eval_crossner_literature_f1": 0.5734406438131506,
      "eval_crossner_literature_precision": 0.5717151454362802,
      "eval_crossner_literature_recall": 0.5751765893037045,
      "eval_crossner_music_f1": 0.655562742511433,
      "eval_crossner_music_precision": 0.6624183006535731,
      "eval_crossner_music_recall": 0.6488476312419766,
      "eval_crossner_politics_f1": 0.7152099454022264,
      "eval_crossner_politics_precision": 0.7077579713783403,
      "eval_crossner_politics_recall": 0.7228205128204943,
      "eval_crossner_science_f1": 0.6482652865131794,
      "eval_crossner_science_precision": 0.6293263863044053,
      "eval_crossner_science_recall": 0.6683794466402898,
      "eval_mit-movie_f1": 0.862518628862057,
      "eval_mit-movie_precision": 0.8578840096349665,
      "eval_mit-movie_recall": 0.8672035961790435,
      "eval_mit-restaurant_f1": 0.7802197801697618,
      "eval_mit-restaurant_precision": 0.7717391304347586,
      "eval_mit-restaurant_recall": 0.7888888888888639,
      "eval_runtime": 260.8924,
      "eval_samples_per_second": 24.799,
      "eval_steps_per_second": 0.1,
      "step": 450
    },
    {
      "epoch": 3.0613598673300166,
      "grad_norm": 0.1255247827425651,
      "learning_rate": 1.0208333333333334e-05,
      "loss": 0.0075,
      "step": 460
    },
    {
      "epoch": 3.127694859038143,
      "grad_norm": 0.1675931423634317,
      "learning_rate": 9.976851851851853e-06,
      "loss": 0.0071,
      "step": 470
    },
    {
      "epoch": 3.1940298507462686,
      "grad_norm": 0.10103657615839334,
      "learning_rate": 9.745370370370372e-06,
      "loss": 0.0071,
      "step": 480
    },
    {
      "epoch": 3.2603648424543947,
      "grad_norm": 0.1125563165982738,
      "learning_rate": 9.51388888888889e-06,
      "loss": 0.007,
      "step": 490
    },
    {
      "epoch": 3.326699834162521,
      "grad_norm": 0.12943910514779358,
      "learning_rate": 9.282407407407408e-06,
      "loss": 0.0067,
      "step": 500
    },
    {
      "epoch": 3.3930348258706466,
      "grad_norm": 0.12636751678989908,
      "learning_rate": 9.050925925925926e-06,
      "loss": 0.0071,
      "step": 510
    },
    {
      "epoch": 3.459369817578773,
      "grad_norm": 0.10896174664223267,
      "learning_rate": 8.819444444444445e-06,
      "loss": 0.0068,
      "step": 520
    },
    {
      "epoch": 3.525704809286899,
      "grad_norm": 0.09478972482351629,
      "learning_rate": 8.587962962962963e-06,
      "loss": 0.0065,
      "step": 530
    },
    {
      "epoch": 3.5920398009950247,
      "grad_norm": 0.10581819606113528,
      "learning_rate": 8.356481481481483e-06,
      "loss": 0.0071,
      "step": 540
    },
    {
      "epoch": 3.658374792703151,
      "grad_norm": 0.11318993176281444,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.0065,
      "step": 550
    },
    {
      "epoch": 3.724709784411277,
      "grad_norm": 0.12858785698042835,
      "learning_rate": 7.89351851851852e-06,
      "loss": 0.0067,
      "step": 560
    },
    {
      "epoch": 3.791044776119403,
      "grad_norm": 0.1645717777247636,
      "learning_rate": 7.662037037037037e-06,
      "loss": 0.0067,
      "step": 570
    },
    {
      "epoch": 3.857379767827529,
      "grad_norm": 0.1283419423910673,
      "learning_rate": 7.4305555555555565e-06,
      "loss": 0.0072,
      "step": 580
    },
    {
      "epoch": 3.923714759535655,
      "grad_norm": 0.2017152078407663,
      "learning_rate": 7.199074074074075e-06,
      "loss": 0.007,
      "step": 590
    },
    {
      "epoch": 3.990049751243781,
      "grad_norm": 0.1486595713705677,
      "learning_rate": 6.967592592592594e-06,
      "loss": 0.0073,
      "step": 600
    },
    {
      "epoch": 3.996683250414594,
      "eval_average_f1": 0.6899983085448549,
      "eval_crossner_ai_f1": 0.5753250871685042,
      "eval_crossner_ai_precision": 0.5866752910737008,
      "eval_crossner_ai_recall": 0.564405724953294,
      "eval_crossner_literature_f1": 0.6053834433222416,
      "eval_crossner_literature_precision": 0.609406952965204,
      "eval_crossner_literature_recall": 0.6014127144298385,
      "eval_crossner_music_f1": 0.6392559960341879,
      "eval_crossner_music_precision": 0.6519134775374159,
      "eval_crossner_music_recall": 0.6270806658130401,
      "eval_crossner_politics_f1": 0.7045483828903258,
      "eval_crossner_politics_precision": 0.7081067081066897,
      "eval_crossner_politics_recall": 0.701025641025623,
      "eval_crossner_science_f1": 0.6634279051190516,
      "eval_crossner_science_precision": 0.6525229357797916,
      "eval_crossner_science_recall": 0.6747035573122263,
      "eval_mit-movie_f1": 0.869598037315527,
      "eval_mit-movie_precision": 0.8762122076440221,
      "eval_mit-movie_recall": 0.8630829743397478,
      "eval_mit-restaurant_f1": 0.7724493079641462,
      "eval_mit-restaurant_precision": 0.7832898172323504,
      "eval_mit-restaurant_recall": 0.7619047619047377,
      "eval_runtime": 160.5935,
      "eval_samples_per_second": 40.288,
      "eval_steps_per_second": 0.162,
      "step": 601
    },
    {
      "epoch": 4.059701492537314,
      "grad_norm": 0.14941568311423237,
      "learning_rate": 6.736111111111112e-06,
      "loss": 0.0052,
      "step": 610
    },
    {
      "epoch": 4.126036484245439,
      "grad_norm": 0.1282895247221857,
      "learning_rate": 6.504629629629629e-06,
      "loss": 0.0044,
      "step": 620
    },
    {
      "epoch": 4.192371475953566,
      "grad_norm": 0.11831967692111596,
      "learning_rate": 6.2731481481481485e-06,
      "loss": 0.0048,
      "step": 630
    },
    {
      "epoch": 4.258706467661692,
      "grad_norm": 0.08707697205812986,
      "learning_rate": 6.041666666666667e-06,
      "loss": 0.0043,
      "step": 640
    },
    {
      "epoch": 4.325041459369817,
      "grad_norm": 0.08904575391238731,
      "learning_rate": 5.810185185185186e-06,
      "loss": 0.0041,
      "step": 650
    },
    {
      "epoch": 4.391376451077944,
      "grad_norm": 0.13058392871494967,
      "learning_rate": 5.578703703703704e-06,
      "loss": 0.0041,
      "step": 660
    },
    {
      "epoch": 4.45771144278607,
      "grad_norm": 0.1335776949599043,
      "learning_rate": 5.347222222222222e-06,
      "loss": 0.0046,
      "step": 670
    },
    {
      "epoch": 4.5240464344941955,
      "grad_norm": 0.09095298654067015,
      "learning_rate": 5.115740740740741e-06,
      "loss": 0.0045,
      "step": 680
    },
    {
      "epoch": 4.590381426202322,
      "grad_norm": 0.08650249104947433,
      "learning_rate": 4.8842592592592595e-06,
      "loss": 0.0046,
      "step": 690
    },
    {
      "epoch": 4.656716417910448,
      "grad_norm": 0.14009534244921434,
      "learning_rate": 4.652777777777779e-06,
      "loss": 0.0044,
      "step": 700
    },
    {
      "epoch": 4.723051409618574,
      "grad_norm": 0.17206483890691074,
      "learning_rate": 4.421296296296297e-06,
      "loss": 0.0039,
      "step": 710
    },
    {
      "epoch": 4.7893864013267,
      "grad_norm": 0.10315600492649961,
      "learning_rate": 4.189814814814815e-06,
      "loss": 0.0043,
      "step": 720
    },
    {
      "epoch": 4.855721393034826,
      "grad_norm": 0.1335417417604391,
      "learning_rate": 3.958333333333333e-06,
      "loss": 0.0041,
      "step": 730
    },
    {
      "epoch": 4.922056384742952,
      "grad_norm": 0.13162468833560398,
      "learning_rate": 3.726851851851852e-06,
      "loss": 0.0043,
      "step": 740
    },
    {
      "epoch": 4.988391376451078,
      "grad_norm": 0.10009241788229589,
      "learning_rate": 3.4953703703703706e-06,
      "loss": 0.0042,
      "step": 750
    },
    {
      "epoch": 4.9950248756218905,
      "eval_average_f1": 0.6974290062210164,
      "eval_crossner_ai_f1": 0.5916746106903727,
      "eval_crossner_ai_precision": 0.6045454545454153,
      "eval_crossner_ai_recall": 0.5793403858120361,
      "eval_crossner_literature_f1": 0.5975485188468105,
      "eval_crossner_literature_precision": 0.60496380558425,
      "eval_crossner_literature_recall": 0.5903128153380126,
      "eval_crossner_music_f1": 0.6591723687997828,
      "eval_crossner_music_precision": 0.6712010617119883,
      "eval_crossner_music_recall": 0.6475672215108628,
      "eval_crossner_politics_f1": 0.7289695398074078,
      "eval_crossner_politics_precision": 0.7370904325032572,
      "eval_crossner_politics_recall": 0.7210256410256225,
      "eval_crossner_science_f1": 0.6606512357287136,
      "eval_crossner_science_precision": 0.6557632398753639,
      "eval_crossner_science_recall": 0.6656126482213176,
      "eval_mit-movie_f1": 0.8643527204002655,
      "eval_mit-movie_precision": 0.8658146964856067,
      "eval_mit-movie_recall": 0.8628956733470525,
      "eval_mit-restaurant_f1": 0.7796340492737622,
      "eval_mit-restaurant_precision": 0.7814992025518092,
      "eval_mit-restaurant_recall": 0.777777777777753,
      "eval_runtime": 179.9043,
      "eval_samples_per_second": 35.964,
      "eval_steps_per_second": 0.145,
      "step": 751
    },
    {
      "epoch": 5.05804311774461,
      "grad_norm": 0.10529141617587165,
      "learning_rate": 3.2638888888888892e-06,
      "loss": 0.0026,
      "step": 760
    },
    {
      "epoch": 5.124378109452737,
      "grad_norm": 0.07088101871881777,
      "learning_rate": 3.032407407407408e-06,
      "loss": 0.0026,
      "step": 770
    },
    {
      "epoch": 5.1907131011608625,
      "grad_norm": 0.11576654913594306,
      "learning_rate": 2.8009259259259265e-06,
      "loss": 0.0025,
      "step": 780
    },
    {
      "epoch": 5.257048092868988,
      "grad_norm": 0.09987246140099272,
      "learning_rate": 2.5694444444444443e-06,
      "loss": 0.0025,
      "step": 790
    },
    {
      "epoch": 5.323383084577115,
      "grad_norm": 0.09901358030566872,
      "learning_rate": 2.3379629629629634e-06,
      "loss": 0.0026,
      "step": 800
    },
    {
      "epoch": 5.389718076285241,
      "grad_norm": 0.0870047401643793,
      "learning_rate": 2.1064814814814816e-06,
      "loss": 0.0024,
      "step": 810
    },
    {
      "epoch": 5.456053067993366,
      "grad_norm": 0.10257466470179888,
      "learning_rate": 1.8750000000000003e-06,
      "loss": 0.0023,
      "step": 820
    },
    {
      "epoch": 5.522388059701493,
      "grad_norm": 0.0798487110145721,
      "learning_rate": 1.6435185185185187e-06,
      "loss": 0.0023,
      "step": 830
    },
    {
      "epoch": 5.588723051409619,
      "grad_norm": 0.11123878675645282,
      "learning_rate": 1.4120370370370371e-06,
      "loss": 0.0026,
      "step": 840
    },
    {
      "epoch": 5.655058043117744,
      "grad_norm": 0.10110343289765715,
      "learning_rate": 1.1805555555555556e-06,
      "loss": 0.0026,
      "step": 850
    },
    {
      "epoch": 5.721393034825871,
      "grad_norm": 0.10630896348694466,
      "learning_rate": 9.490740740740742e-07,
      "loss": 0.0024,
      "step": 860
    },
    {
      "epoch": 5.787728026533997,
      "grad_norm": 0.06662755791676993,
      "learning_rate": 7.175925925925927e-07,
      "loss": 0.0023,
      "step": 870
    },
    {
      "epoch": 5.8540630182421225,
      "grad_norm": 0.14480801451169142,
      "learning_rate": 4.861111111111112e-07,
      "loss": 0.0021,
      "step": 880
    },
    {
      "epoch": 5.920398009950249,
      "grad_norm": 0.0789850283160862,
      "learning_rate": 2.5462962962962963e-07,
      "loss": 0.0023,
      "step": 890
    },
    {
      "epoch": 5.986733001658375,
      "grad_norm": 0.09231906853101086,
      "learning_rate": 2.3148148148148148e-08,
      "loss": 0.0023,
      "step": 900
    },
    {
      "epoch": 5.986733001658375,
      "eval_average_f1": 0.6975871865354939,
      "eval_crossner_ai_f1": 0.5674121405250795,
      "eval_crossner_ai_precision": 0.5830597504924108,
      "eval_crossner_ai_recall": 0.5525824517734566,
      "eval_crossner_literature_f1": 0.6135031846633494,
      "eval_crossner_literature_precision": 0.6196603190941523,
      "eval_crossner_literature_recall": 0.6074672048435616,
      "eval_crossner_music_f1": 0.6544920919115158,
      "eval_crossner_music_precision": 0.6669990029910048,
      "eval_crossner_music_recall": 0.642445582586407,
      "eval_crossner_politics_f1": 0.7324964410008462,
      "eval_crossner_politics_precision": 0.7394826234648356,
      "eval_crossner_politics_recall": 0.7256410256410071,
      "eval_crossner_science_f1": 0.6723186119373555,
      "eval_crossner_science_precision": 0.6707317073170468,
      "eval_crossner_science_recall": 0.6739130434782342,
      "eval_mit-movie_f1": 0.868847848454718,
      "eval_mit-movie_precision": 0.8697447447447284,
      "eval_mit-movie_recall": 0.8679528001498246,
      "eval_mit-restaurant_f1": 0.7740399872555926,
      "eval_mit-restaurant_precision": 0.7737944162436302,
      "eval_mit-restaurant_recall": 0.7742857142856897,
      "eval_runtime": 198.3927,
      "eval_samples_per_second": 32.612,
      "eval_steps_per_second": 0.131,
      "step": 900
    },
    {
      "epoch": 5.986733001658375,
      "step": 900,
      "total_flos": 1.6738738268463432e+18,
      "train_loss": 0.016723411132891972,
      "train_runtime": 3824.6033,
      "train_samples_per_second": 60.488,
      "train_steps_per_second": 0.235
    }
  ],
  "logging_steps": 10,
  "max_steps": 900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6738738268463432e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
