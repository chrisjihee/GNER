{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.982412060301508,
  "eval_steps": 500,
  "global_step": 594,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10050251256281408,
      "grad_norm": 1.1230068564541111,
      "learning_rate": 1.449053550324508e-05,
      "loss": 0.2115,
      "step": 10
    },
    {
      "epoch": 0.20100502512562815,
      "grad_norm": 0.31236159120549845,
      "learning_rate": 1.885262134295571e-05,
      "loss": 0.0599,
      "step": 20
    },
    {
      "epoch": 0.3015075376884422,
      "grad_norm": 0.2309454739604476,
      "learning_rate": 1.9824561403508773e-05,
      "loss": 0.0354,
      "step": 30
    },
    {
      "epoch": 0.4020100502512563,
      "grad_norm": 0.22290478604882977,
      "learning_rate": 1.9473684210526318e-05,
      "loss": 0.0289,
      "step": 40
    },
    {
      "epoch": 0.5025125628140703,
      "grad_norm": 0.15816795876627246,
      "learning_rate": 1.912280701754386e-05,
      "loss": 0.027,
      "step": 50
    },
    {
      "epoch": 0.6030150753768844,
      "grad_norm": 0.1658930606568021,
      "learning_rate": 1.8771929824561405e-05,
      "loss": 0.0241,
      "step": 60
    },
    {
      "epoch": 0.7035175879396985,
      "grad_norm": 0.19137029894082305,
      "learning_rate": 1.8421052631578947e-05,
      "loss": 0.0237,
      "step": 70
    },
    {
      "epoch": 0.8040201005025126,
      "grad_norm": 0.12188267974010039,
      "learning_rate": 1.8070175438596493e-05,
      "loss": 0.0225,
      "step": 80
    },
    {
      "epoch": 0.9045226130653267,
      "grad_norm": 0.13111157809849974,
      "learning_rate": 1.7719298245614035e-05,
      "loss": 0.0206,
      "step": 90
    },
    {
      "epoch": 0.9949748743718593,
      "eval_average_f1": 0.7376323709292631,
      "eval_crossner_ai_f1": 0.5956709956212237,
      "eval_crossner_ai_precision": 0.5554359526372145,
      "eval_crossner_ai_recall": 0.642190416925909,
      "eval_crossner_literature_f1": 0.6725750861144469,
      "eval_crossner_literature_precision": 0.6567307692307376,
      "eval_crossner_literature_recall": 0.6892028254288249,
      "eval_crossner_music_f1": 0.7920637399906225,
      "eval_crossner_music_precision": 0.7735733902959788,
      "eval_crossner_music_recall": 0.811459667093444,
      "eval_crossner_politics_f1": 0.7399877525526537,
      "eval_crossner_politics_precision": 0.7083235638921288,
      "eval_crossner_politics_recall": 0.7746153846153647,
      "eval_crossner_science_f1": 0.6927037102292074,
      "eval_crossner_science_precision": 0.628746374476293,
      "eval_crossner_science_recall": 0.771146245059258,
      "eval_mit-movie_f1": 0.8743179505649921,
      "eval_mit-movie_precision": 0.8635367190354245,
      "eval_mit-movie_recall": 0.8853717924704835,
      "eval_mit-restaurant_f1": 0.7961073614316952,
      "eval_mit-restaurant_precision": 0.7873331263582494,
      "eval_mit-restaurant_recall": 0.8050793650793395,
      "eval_runtime": 162.1773,
      "eval_samples_per_second": 39.895,
      "eval_steps_per_second": 0.16,
      "step": 99
    },
    {
      "epoch": 1.0075376884422111,
      "grad_norm": 0.30064581013860203,
      "learning_rate": 1.736842105263158e-05,
      "loss": 0.0222,
      "step": 100
    },
    {
      "epoch": 1.1080402010050252,
      "grad_norm": 0.12079178939326012,
      "learning_rate": 1.7017543859649125e-05,
      "loss": 0.0174,
      "step": 110
    },
    {
      "epoch": 1.2085427135678393,
      "grad_norm": 0.09993163506306461,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0165,
      "step": 120
    },
    {
      "epoch": 1.3090452261306533,
      "grad_norm": 0.14190975719235036,
      "learning_rate": 1.6315789473684213e-05,
      "loss": 0.0164,
      "step": 130
    },
    {
      "epoch": 1.4095477386934674,
      "grad_norm": 0.08691620020434153,
      "learning_rate": 1.5964912280701755e-05,
      "loss": 0.0162,
      "step": 140
    },
    {
      "epoch": 1.5100502512562815,
      "grad_norm": 0.11048514796145646,
      "learning_rate": 1.56140350877193e-05,
      "loss": 0.0161,
      "step": 150
    },
    {
      "epoch": 1.6105527638190955,
      "grad_norm": 0.12694925889217307,
      "learning_rate": 1.5263157894736846e-05,
      "loss": 0.0161,
      "step": 160
    },
    {
      "epoch": 1.7110552763819096,
      "grad_norm": 0.10261035892839106,
      "learning_rate": 1.4912280701754388e-05,
      "loss": 0.016,
      "step": 170
    },
    {
      "epoch": 1.8115577889447236,
      "grad_norm": 0.1108074771156358,
      "learning_rate": 1.4561403508771931e-05,
      "loss": 0.0162,
      "step": 180
    },
    {
      "epoch": 1.9120603015075377,
      "grad_norm": 0.1284337269792684,
      "learning_rate": 1.4210526315789475e-05,
      "loss": 0.0168,
      "step": 190
    },
    {
      "epoch": 1.992462311557789,
      "eval_average_f1": 0.7801277601799862,
      "eval_crossner_ai_f1": 0.6774397971616343,
      "eval_crossner_ai_precision": 0.690122659780459,
      "eval_crossner_ai_recall": 0.665214685749803,
      "eval_crossner_literature_f1": 0.7275064266851993,
      "eval_crossner_literature_precision": 0.7416142557651603,
      "eval_crossner_literature_recall": 0.7139253279515281,
      "eval_crossner_music_f1": 0.8233015974971771,
      "eval_crossner_music_precision": 0.8301334201106141,
      "eval_crossner_music_recall": 0.8165813060178996,
      "eval_crossner_politics_f1": 0.8002045250682209,
      "eval_crossner_politics_precision": 0.7978587815447158,
      "eval_crossner_politics_recall": 0.802564102564082,
      "eval_crossner_science_f1": 0.7312037397240372,
      "eval_crossner_science_precision": 0.720814132104427,
      "eval_crossner_science_recall": 0.7418972332015517,
      "eval_mit-movie_f1": 0.8926934230952729,
      "eval_mit-movie_precision": 0.8917757009345627,
      "eval_mit-movie_recall": 0.8936130361490748,
      "eval_mit-restaurant_f1": 0.808544812028362,
      "eval_mit-restaurant_precision": 0.8182704811443167,
      "eval_mit-restaurant_recall": 0.7990476190475937,
      "eval_runtime": 200.7258,
      "eval_samples_per_second": 32.233,
      "eval_steps_per_second": 0.13,
      "step": 198
    },
    {
      "epoch": 2.0150753768844223,
      "grad_norm": 0.09643282343241973,
      "learning_rate": 1.385964912280702e-05,
      "loss": 0.0168,
      "step": 200
    },
    {
      "epoch": 2.1155778894472363,
      "grad_norm": 0.14885296526687217,
      "learning_rate": 1.3508771929824562e-05,
      "loss": 0.012,
      "step": 210
    },
    {
      "epoch": 2.2160804020100504,
      "grad_norm": 0.12780846246623834,
      "learning_rate": 1.3157894736842108e-05,
      "loss": 0.0121,
      "step": 220
    },
    {
      "epoch": 2.3165829145728645,
      "grad_norm": 0.13917823138721258,
      "learning_rate": 1.280701754385965e-05,
      "loss": 0.0107,
      "step": 230
    },
    {
      "epoch": 2.4170854271356785,
      "grad_norm": 0.1319553258519227,
      "learning_rate": 1.2456140350877195e-05,
      "loss": 0.0112,
      "step": 240
    },
    {
      "epoch": 2.5175879396984926,
      "grad_norm": 0.13032755321125258,
      "learning_rate": 1.2105263157894737e-05,
      "loss": 0.0109,
      "step": 250
    },
    {
      "epoch": 2.6180904522613067,
      "grad_norm": 0.11330981552123398,
      "learning_rate": 1.1754385964912282e-05,
      "loss": 0.0108,
      "step": 260
    },
    {
      "epoch": 2.7185929648241207,
      "grad_norm": 0.1290854667636983,
      "learning_rate": 1.1403508771929826e-05,
      "loss": 0.0111,
      "step": 270
    },
    {
      "epoch": 2.819095477386935,
      "grad_norm": 0.12553115587276076,
      "learning_rate": 1.105263157894737e-05,
      "loss": 0.0116,
      "step": 280
    },
    {
      "epoch": 2.919597989949749,
      "grad_norm": 0.14840545433868957,
      "learning_rate": 1.0701754385964913e-05,
      "loss": 0.0109,
      "step": 290
    },
    {
      "epoch": 2.9899497487437188,
      "eval_average_f1": 0.7882119472930361,
      "eval_crossner_ai_f1": 0.7095565271204748,
      "eval_crossner_ai_precision": 0.7122257053291089,
      "eval_crossner_ai_recall": 0.7069072806471246,
      "eval_crossner_literature_f1": 0.7325400930694975,
      "eval_crossner_literature_precision": 0.7515923566878582,
      "eval_crossner_literature_recall": 0.7144298688193383,
      "eval_crossner_music_f1": 0.8040770101425053,
      "eval_crossner_music_precision": 0.8128884527314094,
      "eval_crossner_music_recall": 0.79545454545452,
      "eval_crossner_politics_f1": 0.8149489201620608,
      "eval_crossner_politics_precision": 0.8220714844768896,
      "eval_crossner_politics_recall": 0.8079487179486973,
      "eval_crossner_science_f1": 0.7493631196834643,
      "eval_crossner_science_precision": 0.743101438010076,
      "eval_crossner_science_recall": 0.7557312252964128,
      "eval_mit-movie_f1": 0.8998969940505543,
      "eval_mit-movie_precision": 0.8998127340823802,
      "eval_mit-movie_recall": 0.8999812699007136,
      "eval_mit-restaurant_f1": 0.8071009668226959,
      "eval_mit-restaurant_precision": 0.8059512503956693,
      "eval_mit-restaurant_recall": 0.8082539682539426,
      "eval_runtime": 164.2573,
      "eval_samples_per_second": 39.389,
      "eval_steps_per_second": 0.158,
      "step": 297
    },
    {
      "epoch": 3.022613065326633,
      "grad_norm": 0.11772192845561173,
      "learning_rate": 1.0350877192982459e-05,
      "loss": 0.0115,
      "step": 300
    },
    {
      "epoch": 3.1231155778894473,
      "grad_norm": 0.121492164981485,
      "learning_rate": 1e-05,
      "loss": 0.0081,
      "step": 310
    },
    {
      "epoch": 3.2236180904522613,
      "grad_norm": 0.12865431325843196,
      "learning_rate": 9.649122807017545e-06,
      "loss": 0.0081,
      "step": 320
    },
    {
      "epoch": 3.3241206030150754,
      "grad_norm": 0.17844733094225837,
      "learning_rate": 9.298245614035088e-06,
      "loss": 0.0072,
      "step": 330
    },
    {
      "epoch": 3.4246231155778895,
      "grad_norm": 0.1433349666553224,
      "learning_rate": 8.947368421052632e-06,
      "loss": 0.0077,
      "step": 340
    },
    {
      "epoch": 3.5251256281407035,
      "grad_norm": 0.141049255048863,
      "learning_rate": 8.596491228070176e-06,
      "loss": 0.0065,
      "step": 350
    },
    {
      "epoch": 3.6256281407035176,
      "grad_norm": 0.1167567003809117,
      "learning_rate": 8.24561403508772e-06,
      "loss": 0.0071,
      "step": 360
    },
    {
      "epoch": 3.7261306532663316,
      "grad_norm": 0.10353524993708023,
      "learning_rate": 7.894736842105265e-06,
      "loss": 0.0074,
      "step": 370
    },
    {
      "epoch": 3.8266331658291457,
      "grad_norm": 0.11952402616625557,
      "learning_rate": 7.5438596491228074e-06,
      "loss": 0.0075,
      "step": 380
    },
    {
      "epoch": 3.9271356783919598,
      "grad_norm": 0.125197381405689,
      "learning_rate": 7.192982456140352e-06,
      "loss": 0.0072,
      "step": 390
    },
    {
      "epoch": 3.9974874371859297,
      "eval_average_f1": 0.7996586487109869,
      "eval_crossner_ai_f1": 0.7134609540672735,
      "eval_crossner_ai_precision": 0.6971496437054218,
      "eval_crossner_ai_recall": 0.7305538270067996,
      "eval_crossner_literature_f1": 0.7623318385149921,
      "eval_crossner_literature_precision": 0.7529527559054747,
      "eval_crossner_literature_recall": 0.7719475277497088,
      "eval_crossner_music_f1": 0.8311189370397765,
      "eval_crossner_music_precision": 0.8312520012807931,
      "eval_crossner_music_recall": 0.8309859154929311,
      "eval_crossner_politics_f1": 0.8151379088659509,
      "eval_crossner_politics_precision": 0.8156611039794399,
      "eval_crossner_politics_recall": 0.8146153846153638,
      "eval_crossner_science_f1": 0.7725701113599212,
      "eval_crossner_science_precision": 0.7514947683108837,
      "eval_crossner_science_recall": 0.7948616600790199,
      "eval_mit-movie_f1": 0.8970822778372148,
      "eval_mit-movie_precision": 0.8986842105262989,
      "eval_mit-movie_recall": 0.8954860460760274,
      "eval_mit-restaurant_f1": 0.8059085132917788,
      "eval_mit-restaurant_precision": 0.8064208518753717,
      "eval_mit-restaurant_recall": 0.8053968253967998,
      "eval_runtime": 162.4828,
      "eval_samples_per_second": 39.82,
      "eval_steps_per_second": 0.16,
      "step": 397
    },
    {
      "epoch": 4.030150753768845,
      "grad_norm": 0.07739963258667941,
      "learning_rate": 6.842105263157896e-06,
      "loss": 0.0071,
      "step": 400
    },
    {
      "epoch": 4.130653266331659,
      "grad_norm": 0.11087156673650783,
      "learning_rate": 6.491228070175439e-06,
      "loss": 0.0053,
      "step": 410
    },
    {
      "epoch": 4.231155778894473,
      "grad_norm": 0.09347844033082718,
      "learning_rate": 6.140350877192983e-06,
      "loss": 0.0044,
      "step": 420
    },
    {
      "epoch": 4.331658291457287,
      "grad_norm": 0.14532759085609243,
      "learning_rate": 5.789473684210527e-06,
      "loss": 0.0047,
      "step": 430
    },
    {
      "epoch": 4.432160804020101,
      "grad_norm": 0.12566865952336206,
      "learning_rate": 5.438596491228071e-06,
      "loss": 0.0046,
      "step": 440
    },
    {
      "epoch": 4.532663316582915,
      "grad_norm": 0.1518572472961877,
      "learning_rate": 5.087719298245615e-06,
      "loss": 0.0049,
      "step": 450
    },
    {
      "epoch": 4.633165829145729,
      "grad_norm": 0.14093859462778158,
      "learning_rate": 4.736842105263158e-06,
      "loss": 0.0045,
      "step": 460
    },
    {
      "epoch": 4.733668341708543,
      "grad_norm": 0.13393686998293008,
      "learning_rate": 4.385964912280702e-06,
      "loss": 0.0044,
      "step": 470
    },
    {
      "epoch": 4.834170854271357,
      "grad_norm": 0.09454827884324687,
      "learning_rate": 4.035087719298246e-06,
      "loss": 0.0054,
      "step": 480
    },
    {
      "epoch": 4.934673366834171,
      "grad_norm": 0.0655370479112228,
      "learning_rate": 3.6842105263157896e-06,
      "loss": 0.0045,
      "step": 490
    },
    {
      "epoch": 4.994974874371859,
      "eval_average_f1": 0.7949767707977227,
      "eval_crossner_ai_f1": 0.7202416917928989,
      "eval_crossner_ai_precision": 0.6999412800939108,
      "eval_crossner_ai_recall": 0.7417548226508561,
      "eval_crossner_literature_f1": 0.7453819270593043,
      "eval_crossner_literature_precision": 0.737648221343837,
      "eval_crossner_literature_recall": 0.7532795156407289,
      "eval_crossner_music_f1": 0.8156925539932084,
      "eval_crossner_music_precision": 0.8160845882729633,
      "eval_crossner_music_recall": 0.8153008962867857,
      "eval_crossner_politics_f1": 0.8133762057377608,
      "eval_crossner_politics_precision": 0.815999999999979,
      "eval_crossner_politics_recall": 0.8107692307692099,
      "eval_crossner_science_f1": 0.763092269276697,
      "eval_crossner_science_precision": 0.7413343272455929,
      "eval_crossner_science_recall": 0.7861660079051073,
      "eval_mit-movie_f1": 0.8979287179943951,
      "eval_mit-movie_precision": 0.8945900725041663,
      "eval_mit-movie_recall": 0.9012923768495804,
      "eval_mit-restaurant_f1": 0.809124029729794,
      "eval_mit-restaurant_precision": 0.8074612709452795,
      "eval_mit-restaurant_recall": 0.8107936507936251,
      "eval_runtime": 160.0101,
      "eval_samples_per_second": 40.435,
      "eval_steps_per_second": 0.162,
      "step": 496
    },
    {
      "epoch": 5.0376884422110555,
      "grad_norm": 0.10765633139448037,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0048,
      "step": 500
    },
    {
      "epoch": 5.13819095477387,
      "grad_norm": 0.07231179901548204,
      "learning_rate": 2.9824561403508774e-06,
      "loss": 0.0033,
      "step": 510
    },
    {
      "epoch": 5.238693467336684,
      "grad_norm": 0.09560511397080645,
      "learning_rate": 2.631578947368421e-06,
      "loss": 0.0035,
      "step": 520
    },
    {
      "epoch": 5.339195979899498,
      "grad_norm": 0.09846868645427788,
      "learning_rate": 2.280701754385965e-06,
      "loss": 0.003,
      "step": 530
    },
    {
      "epoch": 5.439698492462312,
      "grad_norm": 0.07450085594518405,
      "learning_rate": 1.929824561403509e-06,
      "loss": 0.0028,
      "step": 540
    },
    {
      "epoch": 5.540201005025126,
      "grad_norm": 0.11290845284713735,
      "learning_rate": 1.5789473684210526e-06,
      "loss": 0.0033,
      "step": 550
    },
    {
      "epoch": 5.64070351758794,
      "grad_norm": 0.1903140572858464,
      "learning_rate": 1.2280701754385965e-06,
      "loss": 0.0033,
      "step": 560
    },
    {
      "epoch": 5.741206030150754,
      "grad_norm": 0.09355396397894218,
      "learning_rate": 8.771929824561404e-07,
      "loss": 0.0028,
      "step": 570
    },
    {
      "epoch": 5.841708542713568,
      "grad_norm": 0.06882502136420664,
      "learning_rate": 5.263157894736843e-07,
      "loss": 0.0029,
      "step": 580
    },
    {
      "epoch": 5.942211055276382,
      "grad_norm": 0.07284518730454909,
      "learning_rate": 1.7543859649122808e-07,
      "loss": 0.0031,
      "step": 590
    },
    {
      "epoch": 5.982412060301508,
      "eval_average_f1": 0.7982887013234743,
      "eval_crossner_ai_f1": 0.7221046264997388,
      "eval_crossner_ai_precision": 0.7023529411764292,
      "eval_crossner_ai_recall": 0.742999377722418,
      "eval_crossner_literature_f1": 0.750189059692841,
      "eval_crossner_literature_precision": 0.7496221662468137,
      "eval_crossner_literature_recall": 0.7507568113016776,
      "eval_crossner_music_f1": 0.8362704260954394,
      "eval_crossner_music_precision": 0.8370750481077345,
      "eval_crossner_music_recall": 0.8354673495518299,
      "eval_crossner_politics_f1": 0.8140458797398036,
      "eval_crossner_politics_precision": 0.8137330258775093,
      "eval_crossner_politics_recall": 0.8143589743589534,
      "eval_crossner_science_f1": 0.7548773420400099,
      "eval_crossner_science_precision": 0.7381941820929075,
      "eval_crossner_science_recall": 0.7723320158102461,
      "eval_mit-movie_f1": 0.8964807187818814,
      "eval_mit-movie_precision": 0.8959775491113022,
      "eval_mit-movie_recall": 0.8969844540175895,
      "eval_mit-restaurant_f1": 0.8140528564146052,
      "eval_mit-restaurant_precision": 0.8116124960555124,
      "eval_mit-restaurant_recall": 0.8165079365079105,
      "eval_runtime": 159.4309,
      "eval_samples_per_second": 40.582,
      "eval_steps_per_second": 0.163,
      "step": 594
    },
    {
      "epoch": 5.982412060301508,
      "step": 594,
      "total_flos": 1.64837975030707e+18,
      "train_loss": 0.015216336917972525,
      "train_runtime": 4242.602,
      "train_samples_per_second": 35.991,
      "train_steps_per_second": 0.14
    }
  ],
  "logging_steps": 10,
  "max_steps": 594,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.64837975030707e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
