{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.982412060301508,
  "eval_steps": 500,
  "global_step": 594,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.10050251256281408,
      "grad_norm": 6.434909039901546,
      "learning_rate": 1.449053550324508e-05,
      "loss": 0.5354,
      "step": 10
    },
    {
      "epoch": 0.20100502512562815,
      "grad_norm": 3.30087067070999,
      "learning_rate": 1.885262134295571e-05,
      "loss": 0.1201,
      "step": 20
    },
    {
      "epoch": 0.3015075376884422,
      "grad_norm": 0.9584652802950331,
      "learning_rate": 1.9824561403508773e-05,
      "loss": 0.0935,
      "step": 30
    },
    {
      "epoch": 0.4020100502512563,
      "grad_norm": 0.44991540378554173,
      "learning_rate": 1.9473684210526318e-05,
      "loss": 0.0574,
      "step": 40
    },
    {
      "epoch": 0.5025125628140703,
      "grad_norm": 0.27436333998667495,
      "learning_rate": 1.912280701754386e-05,
      "loss": 0.0439,
      "step": 50
    },
    {
      "epoch": 0.6030150753768844,
      "grad_norm": 0.28957934182432715,
      "learning_rate": 1.8771929824561405e-05,
      "loss": 0.0385,
      "step": 60
    },
    {
      "epoch": 0.7035175879396985,
      "grad_norm": 0.193449307729952,
      "learning_rate": 1.8421052631578947e-05,
      "loss": 0.0345,
      "step": 70
    },
    {
      "epoch": 0.8040201005025126,
      "grad_norm": 0.304212236202433,
      "learning_rate": 1.8070175438596493e-05,
      "loss": 0.031,
      "step": 80
    },
    {
      "epoch": 0.9045226130653267,
      "grad_norm": 0.3743515965465517,
      "learning_rate": 1.7719298245614035e-05,
      "loss": 0.0301,
      "step": 90
    },
    {
      "epoch": 0.9949748743718593,
      "eval_average_f1": 0.5703896807048353,
      "eval_crossner_ai_f1": 0.4765300058918443,
      "eval_crossner_ai_precision": 0.4559408754974158,
      "eval_crossner_ai_recall": 0.49906658369629747,
      "eval_crossner_literature_f1": 0.48712967454936634,
      "eval_crossner_literature_precision": 0.46956928838949114,
      "eval_crossner_literature_recall": 0.506054490413698,
      "eval_crossner_music_f1": 0.47093565428636536,
      "eval_crossner_music_precision": 0.45770392749243327,
      "eval_crossner_music_recall": 0.4849551856593955,
      "eval_crossner_politics_f1": 0.5451286646536092,
      "eval_crossner_politics_precision": 0.544362055740206,
      "eval_crossner_politics_recall": 0.5458974358974219,
      "eval_crossner_science_f1": 0.4880646345444308,
      "eval_crossner_science_precision": 0.45576131687241234,
      "eval_crossner_science_recall": 0.5252964426877262,
      "eval_mit-movie_f1": 0.8173041217472407,
      "eval_mit-movie_precision": 0.8102337566721736,
      "eval_mit-movie_recall": 0.8244989698445248,
      "eval_mit-restaurant_f1": 0.70763500926099,
      "eval_mit-restaurant_precision": 0.692167577413458,
      "eval_mit-restaurant_recall": 0.7238095238095008,
      "eval_runtime": 366.9468,
      "eval_samples_per_second": 17.632,
      "eval_steps_per_second": 0.071,
      "step": 99
    },
    {
      "epoch": 1.0075376884422111,
      "grad_norm": 0.1310308670704307,
      "learning_rate": 1.736842105263158e-05,
      "loss": 0.0283,
      "step": 100
    },
    {
      "epoch": 1.1080402010050252,
      "grad_norm": 0.1089212379992372,
      "learning_rate": 1.7017543859649125e-05,
      "loss": 0.0252,
      "step": 110
    },
    {
      "epoch": 1.2085427135678393,
      "grad_norm": 0.13823987940025326,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 0.0248,
      "step": 120
    },
    {
      "epoch": 1.3090452261306533,
      "grad_norm": 0.13875306130374251,
      "learning_rate": 1.6315789473684213e-05,
      "loss": 0.0236,
      "step": 130
    },
    {
      "epoch": 1.4095477386934674,
      "grad_norm": 0.16484456762680563,
      "learning_rate": 1.5964912280701755e-05,
      "loss": 0.023,
      "step": 140
    },
    {
      "epoch": 1.5100502512562815,
      "grad_norm": 0.156411992976555,
      "learning_rate": 1.56140350877193e-05,
      "loss": 0.0224,
      "step": 150
    },
    {
      "epoch": 1.6105527638190955,
      "grad_norm": 0.4500996783909033,
      "learning_rate": 1.5263157894736846e-05,
      "loss": 0.0231,
      "step": 160
    },
    {
      "epoch": 1.7110552763819096,
      "grad_norm": 0.36588441660824694,
      "learning_rate": 1.4912280701754388e-05,
      "loss": 0.0234,
      "step": 170
    },
    {
      "epoch": 1.8115577889447236,
      "grad_norm": 0.19035455248523864,
      "learning_rate": 1.4561403508771931e-05,
      "loss": 0.024,
      "step": 180
    },
    {
      "epoch": 1.9120603015075377,
      "grad_norm": 0.5577076906958853,
      "learning_rate": 1.4210526315789475e-05,
      "loss": 0.0243,
      "step": 190
    },
    {
      "epoch": 1.992462311557789,
      "eval_average_f1": 0.6261349048582263,
      "eval_crossner_ai_f1": 0.5058414903194138,
      "eval_crossner_ai_precision": 0.5134615384615056,
      "eval_crossner_ai_recall": 0.49844430616051655,
      "eval_crossner_literature_f1": 0.5417201539936336,
      "eval_crossner_literature_precision": 0.5514898065864845,
      "eval_crossner_literature_recall": 0.5322906155398318,
      "eval_crossner_music_f1": 0.5975252360294483,
      "eval_crossner_music_precision": 0.6080185553346386,
      "eval_crossner_music_recall": 0.5873879641485087,
      "eval_crossner_politics_f1": 0.6099120702937855,
      "eval_crossner_politics_precision": 0.6347753743760223,
      "eval_crossner_politics_recall": 0.5869230769230619,
      "eval_crossner_science_f1": 0.5123805809599326,
      "eval_crossner_science_precision": 0.5055790688726238,
      "eval_crossner_science_recall": 0.5193675889327858,
      "eval_mit-movie_f1": 0.8532300717293604,
      "eval_mit-movie_precision": 0.8605448656886862,
      "eval_mit-movie_recall": 0.8460385840044794,
      "eval_mit-restaurant_f1": 0.7623347306820097,
      "eval_mit-restaurant_precision": 0.7745740498033822,
      "eval_mit-restaurant_recall": 0.7504761904761666,
      "eval_runtime": 170.2747,
      "eval_samples_per_second": 37.997,
      "eval_steps_per_second": 0.153,
      "step": 198
    },
    {
      "epoch": 2.0150753768844223,
      "grad_norm": 0.24312940603348182,
      "learning_rate": 1.385964912280702e-05,
      "loss": 0.0217,
      "step": 200
    },
    {
      "epoch": 2.1155778894472363,
      "grad_norm": 0.15036711570986572,
      "learning_rate": 1.3508771929824562e-05,
      "loss": 0.019,
      "step": 210
    },
    {
      "epoch": 2.2160804020100504,
      "grad_norm": 0.27734354851943743,
      "learning_rate": 1.3157894736842108e-05,
      "loss": 0.019,
      "step": 220
    },
    {
      "epoch": 2.3165829145728645,
      "grad_norm": 0.16802123270048422,
      "learning_rate": 1.280701754385965e-05,
      "loss": 0.0182,
      "step": 230
    },
    {
      "epoch": 2.4170854271356785,
      "grad_norm": 0.1458064413537001,
      "learning_rate": 1.2456140350877195e-05,
      "loss": 0.0181,
      "step": 240
    },
    {
      "epoch": 2.5175879396984926,
      "grad_norm": 0.1464065154102733,
      "learning_rate": 1.2105263157894737e-05,
      "loss": 0.0176,
      "step": 250
    },
    {
      "epoch": 2.6180904522613067,
      "grad_norm": 0.17363424418559661,
      "learning_rate": 1.1754385964912282e-05,
      "loss": 0.0182,
      "step": 260
    },
    {
      "epoch": 2.7185929648241207,
      "grad_norm": 0.23539171628195799,
      "learning_rate": 1.1403508771929826e-05,
      "loss": 0.0168,
      "step": 270
    },
    {
      "epoch": 2.819095477386935,
      "grad_norm": 0.19189510393906573,
      "learning_rate": 1.105263157894737e-05,
      "loss": 0.0167,
      "step": 280
    },
    {
      "epoch": 2.919597989949749,
      "grad_norm": 0.12258867069513711,
      "learning_rate": 1.0701754385964913e-05,
      "loss": 0.0159,
      "step": 290
    },
    {
      "epoch": 2.9899497487437188,
      "eval_average_f1": 0.6753026332897137,
      "eval_crossner_ai_f1": 0.59425113459448,
      "eval_crossner_ai_precision": 0.5783274440517916,
      "eval_crossner_ai_recall": 0.611076540136863,
      "eval_crossner_literature_f1": 0.6029411764205589,
      "eval_crossner_literature_precision": 0.6060142711518549,
      "eval_crossner_literature_recall": 0.5998990918264077,
      "eval_crossner_music_f1": 0.5808015513397726,
      "eval_crossner_music_precision": 0.5864882506527224,
      "eval_crossner_music_recall": 0.5752240717029266,
      "eval_crossner_politics_f1": 0.6811145510335757,
      "eval_crossner_politics_precision": 0.6853582554516956,
      "eval_crossner_politics_recall": 0.6769230769230595,
      "eval_crossner_science_f1": 0.6274287869713964,
      "eval_crossner_science_precision": 0.6001443522193937,
      "eval_crossner_science_recall": 0.6573122529644009,
      "eval_mit-movie_f1": 0.8594640021910901,
      "eval_mit-movie_precision": 0.8569832402234477,
      "eval_mit-movie_recall": 0.8619591683835763,
      "eval_mit-restaurant_f1": 0.7811172304771231,
      "eval_mit-restaurant_precision": 0.7744149765990398,
      "eval_mit-restaurant_recall": 0.787936507936483,
      "eval_runtime": 163.0548,
      "eval_samples_per_second": 39.68,
      "eval_steps_per_second": 0.159,
      "step": 297
    },
    {
      "epoch": 3.022613065326633,
      "grad_norm": 0.18463295171371905,
      "learning_rate": 1.0350877192982459e-05,
      "loss": 0.0162,
      "step": 300
    },
    {
      "epoch": 3.1231155778894473,
      "grad_norm": 0.17018426717902108,
      "learning_rate": 1e-05,
      "loss": 0.0142,
      "step": 310
    },
    {
      "epoch": 3.2236180904522613,
      "grad_norm": 0.1257735842388711,
      "learning_rate": 9.649122807017545e-06,
      "loss": 0.0139,
      "step": 320
    },
    {
      "epoch": 3.3241206030150754,
      "grad_norm": 0.12764351264133228,
      "learning_rate": 9.298245614035088e-06,
      "loss": 0.0139,
      "step": 330
    },
    {
      "epoch": 3.4246231155778895,
      "grad_norm": 0.13248627933501692,
      "learning_rate": 8.947368421052632e-06,
      "loss": 0.0134,
      "step": 340
    },
    {
      "epoch": 3.5251256281407035,
      "grad_norm": 0.13458034660678517,
      "learning_rate": 8.596491228070176e-06,
      "loss": 0.0125,
      "step": 350
    },
    {
      "epoch": 3.6256281407035176,
      "grad_norm": 0.1456780493893697,
      "learning_rate": 8.24561403508772e-06,
      "loss": 0.0126,
      "step": 360
    },
    {
      "epoch": 3.7261306532663316,
      "grad_norm": 0.15538640381424323,
      "learning_rate": 7.894736842105265e-06,
      "loss": 0.0137,
      "step": 370
    },
    {
      "epoch": 3.8266331658291457,
      "grad_norm": 0.17431595746150869,
      "learning_rate": 7.5438596491228074e-06,
      "loss": 0.0137,
      "step": 380
    },
    {
      "epoch": 3.9271356783919598,
      "grad_norm": 0.13371147216948523,
      "learning_rate": 7.192982456140352e-06,
      "loss": 0.0139,
      "step": 390
    },
    {
      "epoch": 3.9974874371859297,
      "eval_average_f1": 0.6868047845638673,
      "eval_crossner_ai_f1": 0.5831842575529146,
      "eval_crossner_ai_precision": 0.5598168288494242,
      "eval_crossner_ai_recall": 0.6085874299937394,
      "eval_crossner_literature_f1": 0.5981308410714974,
      "eval_crossner_literature_precision": 0.5834932821496841,
      "eval_crossner_literature_recall": 0.6135216952572848,
      "eval_crossner_music_f1": 0.6069763703084446,
      "eval_crossner_music_precision": 0.6096222150467998,
      "eval_crossner_music_recall": 0.6043533930857681,
      "eval_crossner_politics_f1": 0.7040466826849869,
      "eval_crossner_politics_precision": 0.6967110218428145,
      "eval_crossner_politics_recall": 0.7115384615384432,
      "eval_crossner_science_f1": 0.6619900313328768,
      "eval_crossner_science_precision": 0.6210599237963068,
      "eval_crossner_science_recall": 0.708695652173885,
      "eval_mit-movie_f1": 0.8664561663690067,
      "eval_mit-movie_precision": 0.8592742678209456,
      "eval_mit-movie_recall": 0.8737591309233775,
      "eval_mit-restaurant_f1": 0.7868491426273427,
      "eval_mit-restaurant_precision": 0.7798565637667358,
      "eval_mit-restaurant_recall": 0.7939682539682288,
      "eval_runtime": 183.1434,
      "eval_samples_per_second": 35.328,
      "eval_steps_per_second": 0.142,
      "step": 397
    },
    {
      "epoch": 4.030150753768845,
      "grad_norm": 0.10717877711177695,
      "learning_rate": 6.842105263157896e-06,
      "loss": 0.0127,
      "step": 400
    },
    {
      "epoch": 4.130653266331659,
      "grad_norm": 0.13065243485379394,
      "learning_rate": 6.491228070175439e-06,
      "loss": 0.011,
      "step": 410
    },
    {
      "epoch": 4.231155778894473,
      "grad_norm": 0.13863521413692526,
      "learning_rate": 6.140350877192983e-06,
      "loss": 0.0107,
      "step": 420
    },
    {
      "epoch": 4.331658291457287,
      "grad_norm": 0.15427468538680303,
      "learning_rate": 5.789473684210527e-06,
      "loss": 0.0104,
      "step": 430
    },
    {
      "epoch": 4.432160804020101,
      "grad_norm": 0.15276628365832634,
      "learning_rate": 5.438596491228071e-06,
      "loss": 0.0108,
      "step": 440
    },
    {
      "epoch": 4.532663316582915,
      "grad_norm": 0.11623221691434217,
      "learning_rate": 5.087719298245615e-06,
      "loss": 0.0102,
      "step": 450
    },
    {
      "epoch": 4.633165829145729,
      "grad_norm": 0.1371258804515576,
      "learning_rate": 4.736842105263158e-06,
      "loss": 0.0111,
      "step": 460
    },
    {
      "epoch": 4.733668341708543,
      "grad_norm": 0.15081458587958793,
      "learning_rate": 4.385964912280702e-06,
      "loss": 0.0099,
      "step": 470
    },
    {
      "epoch": 4.834170854271357,
      "grad_norm": 0.1178231049186449,
      "learning_rate": 4.035087719298246e-06,
      "loss": 0.0112,
      "step": 480
    },
    {
      "epoch": 4.934673366834171,
      "grad_norm": 0.11518914741428846,
      "learning_rate": 3.6842105263157896e-06,
      "loss": 0.0102,
      "step": 490
    },
    {
      "epoch": 4.994974874371859,
      "eval_average_f1": 0.707520844004873,
      "eval_crossner_ai_f1": 0.6026388462218352,
      "eval_crossner_ai_precision": 0.5944309927360415,
      "eval_crossner_ai_recall": 0.611076540136863,
      "eval_crossner_literature_f1": 0.6317887393620341,
      "eval_crossner_literature_precision": 0.6240157480314653,
      "eval_crossner_literature_recall": 0.6397578203834188,
      "eval_crossner_music_f1": 0.6534846028673288,
      "eval_crossner_music_precision": 0.6618516086670827,
      "eval_crossner_music_recall": 0.6453265044814134,
      "eval_crossner_politics_f1": 0.7397330594982356,
      "eval_crossner_politics_precision": 0.7404933196299912,
      "eval_crossner_politics_recall": 0.73897435897434,
      "eval_crossner_science_f1": 0.6723549487555176,
      "eval_crossner_science_precision": 0.6461370262390435,
      "eval_crossner_science_recall": 0.7007905138339644,
      "eval_mit-movie_f1": 0.8691177845883972,
      "eval_mit-movie_precision": 0.8682242990654043,
      "eval_mit-movie_recall": 0.8700131110694723,
      "eval_mit-restaurant_f1": 0.7835279267407628,
      "eval_mit-restaurant_precision": 0.7788582183186706,
      "eval_mit-restaurant_recall": 0.7882539682539432,
      "eval_runtime": 180.008,
      "eval_samples_per_second": 35.943,
      "eval_steps_per_second": 0.144,
      "step": 496
    },
    {
      "epoch": 5.0376884422110555,
      "grad_norm": 0.12722040796897927,
      "learning_rate": 3.3333333333333333e-06,
      "loss": 0.0096,
      "step": 500
    },
    {
      "epoch": 5.13819095477387,
      "grad_norm": 0.16111107303892522,
      "learning_rate": 2.9824561403508774e-06,
      "loss": 0.0077,
      "step": 510
    },
    {
      "epoch": 5.238693467336684,
      "grad_norm": 0.12763648613205883,
      "learning_rate": 2.631578947368421e-06,
      "loss": 0.008,
      "step": 520
    },
    {
      "epoch": 5.339195979899498,
      "grad_norm": 0.1396904862061209,
      "learning_rate": 2.280701754385965e-06,
      "loss": 0.0079,
      "step": 530
    },
    {
      "epoch": 5.439698492462312,
      "grad_norm": 0.14122747137164796,
      "learning_rate": 1.929824561403509e-06,
      "loss": 0.0081,
      "step": 540
    },
    {
      "epoch": 5.540201005025126,
      "grad_norm": 0.1253257990912449,
      "learning_rate": 1.5789473684210526e-06,
      "loss": 0.0078,
      "step": 550
    },
    {
      "epoch": 5.64070351758794,
      "grad_norm": 0.1344502255106617,
      "learning_rate": 1.2280701754385965e-06,
      "loss": 0.0086,
      "step": 560
    },
    {
      "epoch": 5.741206030150754,
      "grad_norm": 0.12509609790221488,
      "learning_rate": 8.771929824561404e-07,
      "loss": 0.0081,
      "step": 570
    },
    {
      "epoch": 5.841708542713568,
      "grad_norm": 0.1452789490944861,
      "learning_rate": 5.263157894736843e-07,
      "loss": 0.0078,
      "step": 580
    },
    {
      "epoch": 5.942211055276382,
      "grad_norm": 0.1307172501656041,
      "learning_rate": 1.7543859649122808e-07,
      "loss": 0.0078,
      "step": 590
    },
    {
      "epoch": 5.982412060301508,
      "eval_average_f1": 0.7113724514703501,
      "eval_crossner_ai_f1": 0.6208384709733938,
      "eval_crossner_ai_precision": 0.6151496640195103,
      "eval_crossner_ai_recall": 0.626633478531386,
      "eval_crossner_literature_f1": 0.6321867938239337,
      "eval_crossner_literature_precision": 0.6291854072963203,
      "eval_crossner_literature_recall": 0.6352169525731264,
      "eval_crossner_music_f1": 0.6629923812111311,
      "eval_crossner_music_precision": 0.6715927750410289,
      "eval_crossner_music_recall": 0.6546094750319893,
      "eval_crossner_politics_f1": 0.7468549421836138,
      "eval_crossner_politics_precision": 0.7478149100256877,
      "eval_crossner_politics_recall": 0.7458974358974167,
      "eval_crossner_science_f1": 0.6667943316237108,
      "eval_crossner_science_precision": 0.6467310549776877,
      "eval_crossner_science_recall": 0.6881422924900914,
      "eval_mit-movie_f1": 0.8683891427538275,
      "eval_mit-movie_precision": 0.8649201040505228,
      "eval_mit-movie_recall": 0.8718861209964249,
      "eval_mit-restaurant_f1": 0.7815510977228401,
      "eval_mit-restaurant_precision": 0.7777428481609312,
      "eval_mit-restaurant_recall": 0.7853968253968004,
      "eval_runtime": 179.0578,
      "eval_samples_per_second": 36.134,
      "eval_steps_per_second": 0.145,
      "step": 594
    },
    {
      "epoch": 5.982412060301508,
      "step": 594,
      "total_flos": 9.574820951464346e+17,
      "train_loss": 0.02927124179172195,
      "train_runtime": 2739.4702,
      "train_samples_per_second": 55.739,
      "train_steps_per_second": 0.217
    }
  ],
  "logging_steps": 10,
  "max_steps": 594,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 9.574820951464346e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
