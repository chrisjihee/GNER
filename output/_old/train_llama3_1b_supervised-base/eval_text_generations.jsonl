{"id": "510", "dataset": "mit-restaurant", "split": "test", "label_list": ["Hours", "Rating", "Location", "Dish", "Restaurant Name", "Cuisine", "Amenity", "Price"], "instance": {"id": "510", "words": ["how", "far", "away", "is", "the", "closest", "burger", "king"], "labels": ["O", "O", "O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Location, Dish, Restaurant Name, Cuisine, Amenity, Price and O.\nSentence: how far away is the closest burger king", "prompt_labels": "how(O) far(O) away(O) is(O) the(O) closest(B-Location) burger(B-Restaurant Name) king(I-Restaurant Name)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 10067, 11, 49268, 11, 26568, 4076, 11, 81961, 11, 3383, 56685, 11, 8650, 323, 507, 627, 85664, 25, 1268, 3117, 3201, 374, 279, 18585, 45723, 11734, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "how(O) far(O) away(O) is(O) the(O) closest(B-Location) burger(B-Restaurant Name) king(I-Restaurant Name)"}
{"id": "135", "dataset": "crossner_music", "split": "test", "label_list": ["song", "country", "band", "location", "musical artist", "music genre", "person", "album", "organization", "musical instrument", "award", "event"], "instance": {"id": "135", "words": ["Shoegazing", ",", "Stoner", "rock", "and", "noise", "pop", "genres", "emerged", "into", "the", "mainstream", "with", "the", "explosion", "of", "bands", "such", "as", "Kyuss", ",", "Monster", "Magnet", ",", "the", "Desert", "Sessions", ",", "Slowdive", ",", "the", "Verve", ",", "My", "Bloody", "Valentine", ",", "Flying", "Saucer", "Attack", ",", "Loop", ",", "Ride", ",", "Shiner", ",", "the", "Flaming", "Lips", ",", "Failure", ",", "Year", "of", "the", "Rabbit", ",", "Cave", "In", ",", "Sun", "Dial", ",", "Hum", ",", "Orange", "Goblin", ",", "Porcupine", "Tree", ",", "Spacemen", "3", ",", "Spiritualized", ",", "and", "Mercury", "Rev", "."], "labels": ["B-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-band", "O", "B-band", "I-band", "O", "B-band", "I-band", "I-band", "O", "B-band", "O", "B-band", "I-band", "O", "B-band", "I-band", "I-band", "O", "B-band", "I-band", "I-band", "O", "B-band", "O", "B-band", "O", "B-band", "O", "B-band", "I-band", "I-band", "O", "B-band", "O", "B-band", "I-band", "I-band", "I-band", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "B-band", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "B-band", "I-band", "O", "B-band", "O", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, country, band, location, musical artist, music genre, person, album, organization, musical instrument, award, event and O.\nSentence: Shoegazing , Stoner rock and noise pop genres emerged into the mainstream with the explosion of bands such as Kyuss , Monster Magnet , the Desert Sessions , Slowdive , the Verve , My Bloody Valentine , Flying Saucer Attack , Loop , Ride , Shiner , the Flaming Lips , Failure , Year of the Rabbit , Cave In , Sun Dial , Hum , Orange Goblin , Porcupine Tree , Spacemen 3 , Spiritualized , and Mercury Rev .", "prompt_labels": "Shoegazing(B-music genre) ,(O) Stoner(B-music genre) rock(I-music genre) and(O) noise(B-music genre) pop(I-music genre) genres(O) emerged(O) into(O) the(O) mainstream(O) with(O) the(O) explosion(O) of(O) bands(O) such(O) as(O) Kyuss(B-band) ,(O) Monster(B-band) Magnet(I-band) ,(O) the(B-band) Desert(I-band) Sessions(I-band) ,(O) Slowdive(B-band) ,(O) the(B-band) Verve(I-band) ,(O) My(B-band) Bloody(I-band) Valentine(I-band) ,(O) Flying(B-band) Saucer(I-band) Attack(I-band) ,(O) Loop(B-band) ,(O) Ride(B-band) ,(O) Shiner(B-band) ,(O) the(B-band) Flaming(I-band) Lips(I-band) ,(O) Failure(B-band) ,(O) Year(B-band) of(I-band) the(I-band) Rabbit(I-band) ,(O) Cave(B-band) In(I-band) ,(O) Sun(B-band) Dial(I-band) ,(O) Hum(B-band) ,(O) Orange(B-band) Goblin(I-band) ,(O) Porcupine(B-band) Tree(I-band) ,(O) Spacemen(B-band) 3(I-band) ,(O) Spiritualized(B-band) ,(O) and(O) Mercury(B-band) Rev(I-band) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3224, 11, 7200, 11, 3813, 11, 18273, 10255, 11, 4731, 17779, 11, 1732, 11, 8176, 11, 7471, 11, 18273, 14473, 11, 10292, 11, 1567, 323, 507, 627, 85664, 25, 64040, 797, 6795, 1174, 36219, 261, 7091, 323, 12248, 2477, 36744, 22763, 1139, 279, 21391, 449, 279, 25176, 315, 21562, 1778, 439, 23727, 1892, 1174, 29073, 82328, 1174, 279, 43286, 31900, 1174, 39247, 67, 535, 1174, 279, 650, 5976, 1174, 3092, 94672, 39869, 1174, 47152, 16233, 60496, 21453, 1174, 22070, 1174, 42013, 1174, 1443, 10670, 1174, 279, 3061, 6605, 96363, 1174, 33360, 1174, 9941, 315, 279, 49431, 1174, 50492, 763, 1174, 8219, 67255, 1174, 20449, 1174, 22725, 81264, 1174, 20388, 37765, 483, 9119, 1174, 3165, 582, 16737, 220, 18, 1174, 63849, 1534, 1174, 323, 44662, 10315, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Shoegazing(B-music genre),(O) Stoner(B-music genre) rock(I-music genre) and(O) noise(B-music genre) pop(I-music genre) genres(O) emerged(O) into(O) the(O) mainstream(O) with(O) the(O) explosion(O) of(O) bands(O) such(O) as(O) Kyuss(B-band),(O) Monster(B-band) Magnet(I-band),(O) the(O) Desert(B-band) Sessions(I-band),(O) Slowdive(B-band),(O) the(B-band) Verve(I-band),(O) My(B-band) Bloody(I-band) Valentine(I-band),(O) Flying(B-band) Saucer(I-band) Attack(I-band),(O) Loop(B-band),(O) Ride(B-band),(O) Shiner(B-band),(O) the(B-band) Flaming(I-band) Lips(I-band),(O) Failure(B-band),(O) Year(B-band) of(I-band) the(I-band) Rabbit(I-band),(O) Cave(B-band) In(I-band),(O) Sun(B-band) Dial(I-band),(O) Hum(B-band),(O) Orange(B-band) Goblin(I-band),(O) Porcupine(B-band) Tree(I-band),(O) Spacemen(B-band) 3(I-band),(O) Spiritualized(B-band),(O) and(O) Mercury(B-band) Rev(I-band).(O)"}
{"id": "1134", "dataset": "mit-restaurant", "split": "test", "label_list": ["Price", "Cuisine", "Restaurant Name", "Dish", "Rating", "Location", "Amenity", "Hours"], "instance": {"id": "1134", "words": ["what", "is", "the", "favorite", "type", "of", "food", "people", "eat", "out", "here", "and", "where", "can", "i", "get", "it"], "labels": ["O", "O", "O", "B-Rating", "O", "O", "O", "O", "O", "B-Location", "I-Location", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Cuisine, Restaurant Name, Dish, Rating, Location, Amenity, Hours and O.\nSentence: what is the favorite type of food people eat out here and where can i get it", "prompt_labels": "what(O) is(O) the(O) favorite(B-Rating) type(O) of(O) food(O) people(O) eat(O) out(B-Location) here(I-Location) and(O) where(O) can(O) i(O) get(O) it(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 81961, 11, 26568, 4076, 11, 49268, 11, 19767, 11, 10067, 11, 3383, 56685, 11, 30192, 323, 507, 627, 85664, 25, 1148, 374, 279, 7075, 955, 315, 3691, 1274, 8343, 704, 1618, 323, 1405, 649, 602, 636, 433, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) the(O) favorite(O) type(O) of(O) food(O) people(O) eat(O) out(O) here(O) and(O) where(O) can(O) i(O) get(O) it(O)"}
{"id": "503", "dataset": "mit-restaurant", "split": "test", "label_list": ["Price", "Dish", "Location", "Hours", "Restaurant Name", "Rating", "Cuisine", "Amenity"], "instance": {"id": "503", "words": ["how", "do", "i", "get", "to", "the", "nearest", "taco", "bell"], "labels": ["O", "O", "O", "O", "O", "O", "B-Location", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Dish, Location, Hours, Restaurant Name, Rating, Cuisine, Amenity and O.\nSentence: how do i get to the nearest taco bell", "prompt_labels": "how(O) do(O) i(O) get(O) to(O) the(O) nearest(B-Location) taco(B-Restaurant Name) bell(I-Restaurant Name)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 49268, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 1268, 656, 602, 636, 311, 279, 24379, 91941, 29519, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "how(O) do(O) i(O) get(O) to(O) the(O) nearest(B-Location) taco(B-Restaurant Name) bell(I-Restaurant Name)"}
{"id": "83", "dataset": "crossner_literature", "split": "test", "label_list": ["organization", "event", "person", "poem", "book", "writer", "location", "literary genre", "magazine", "country", "award"], "instance": {"id": "83", "words": ["122", "The", "Public", "Square", "illustrates", "this", "quality", "."], "labels": ["O", "B-poem", "I-poem", "I-poem", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, person, poem, book, writer, location, literary genre, magazine, country, award and O.\nSentence: 122 The Public Square illustrates this quality .", "prompt_labels": "122(O) The(B-poem) Public(I-poem) Square(I-poem) illustrates(O) this(O) quality(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 1732, 11, 33894, 11, 2363, 11, 7061, 11, 3813, 11, 32465, 17779, 11, 14756, 11, 3224, 11, 10292, 323, 507, 627, 85664, 25, 220, 8259, 578, 3142, 15992, 46480, 420, 4367, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "122(O) The(B-magazine) Public(I-magazine) Square(I-magazine) illustrates(O) this(O) quality(O).(O)"}
{"id": "1004", "dataset": "mit-movie", "split": "test", "label_list": ["song", "character", "year", "rating", "genre", "review", "title", "director", "trailer", "actor", "average ratings", "plot"], "instance": {"id": "1004", "words": ["did", "marilyn", "monroe", "star", "in", "any", "drama", "films"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, character, year, rating, genre, review, title, director, trailer, actor, average ratings, plot and O.\nSentence: did marilyn monroe star in any drama films", "prompt_labels": "did(O) marilyn(B-actor) monroe(I-actor) star(O) in(O) any(O) drama(B-genre) films(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3752, 11, 1060, 11, 10959, 11, 17779, 11, 3477, 11, 2316, 11, 7690, 11, 19809, 11, 12360, 11, 5578, 18594, 11, 7234, 323, 507, 627, 85664, 25, 1550, 3678, 69582, 1647, 35804, 6917, 304, 904, 20156, 12631, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "did(O) marilyn(B-actor) monroe(I-actor) star(O) in(O) any(O) drama(B-genre) films(O)"}
{"id": "551", "dataset": "mit-movie", "split": "test", "label_list": ["character", "song", "year", "plot", "rating", "genre", "director", "average ratings", "actor", "trailer", "review", "title"], "instance": {"id": "551", "words": ["show", "me", "a", "movie", "with", "arnold", "schwarzenegger", "that", "is", "directed", "by", "james", "cameron"], "labels": ["O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, song, year, plot, rating, genre, director, average ratings, actor, trailer, review, title and O.\nSentence: show me a movie with arnold schwarzenegger that is directed by james cameron", "prompt_labels": "show(O) me(O) a(O) movie(O) with(O) arnold(B-actor) schwarzenegger(I-actor) that(O) is(O) directed(O) by(O) james(B-director) cameron(I-director)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5609, 11, 1060, 11, 7234, 11, 10959, 11, 17779, 11, 7690, 11, 5578, 18594, 11, 12360, 11, 19809, 11, 3477, 11, 2316, 323, 507, 627, 85664, 25, 1501, 757, 264, 5818, 449, 802, 77, 820, 82928, 5797, 797, 1414, 430, 374, 15910, 555, 86046, 6730, 20110, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) a(O) movie(O) with(O) arnold(B-actor) schwarzenegger(I-actor) that(O) is(O) directed(O) by(O) james(B-director) cameron(I-director)"}
{"id": "88", "dataset": "crossner_ai", "split": "test", "label_list": ["organization", "university", "person", "task", "field", "researcher", "conference", "location", "algorithm", "country", "product", "programming language", "metric"], "instance": {"id": "88", "words": ["WordNet", ",", "a", "freely", "available", "database", "originally", "designed", "as", "a", "semantic", "network", "based", "on", "psycholinguistic", "principles", ",", "was", "expanded", "by", "addition", "of", "definitions", "and", "is", "now", "also", "viewed", "as", "a", "dictionary", "."], "labels": ["B-product", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, university, person, task, field, researcher, conference, location, algorithm, country, product, programming language, metric and O.\nSentence: WordNet , a freely available database originally designed as a semantic network based on psycholinguistic principles , was expanded by addition of definitions and is now also viewed as a dictionary .", "prompt_labels": "WordNet(B-product) ,(O) a(O) freely(O) available(O) database(O) originally(O) designed(O) as(O) a(O) semantic(O) network(O) based(O) on(O) psycholinguistic(O) principles(O) ,(O) was(O) expanded(O) by(O) addition(O) of(O) definitions(O) and(O) is(O) now(O) also(O) viewed(O) as(O) a(O) dictionary(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 12374, 11, 1732, 11, 3465, 11, 2115, 11, 32185, 11, 10017, 11, 3813, 11, 12384, 11, 3224, 11, 2027, 11, 15840, 4221, 11, 18767, 323, 507, 627, 85664, 25, 9506, 7099, 1174, 264, 26662, 2561, 4729, 13517, 6319, 439, 264, 42833, 4009, 3196, 389, 8841, 337, 13102, 4633, 16565, 1174, 574, 17626, 555, 5369, 315, 17931, 323, 374, 1457, 1101, 19894, 439, 264, 11240, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "WordNet(B-product),(O) a(O) freely(O) available(O) database(O) originally(O) designed(O) as(O) a(O) semantic(B-algorithm) network(I-algorithm) based(O) on(O) psycholinguistic(O) principles(O),(O) was(O) expanded(O) by(O) addition(O) of(O) definitions(O) and(O) is(O) now(O) also(O) viewed(O) as(O) a(O) dictionary(O).(O)"}
{"id": "335", "dataset": "crossner_music", "split": "test", "label_list": ["location", "person", "event", "musical instrument", "band", "music genre", "album", "song", "musical artist", "organization", "award", "country"], "instance": {"id": "335", "words": ["The", "band", "released", "four", "albums", ":", "Styx", "I", "(", "1972", ")", ",", "Styx", "II", "(", "1973", ")", ",", "The", "Serpent", "Is", "Rising", "(", "1973", ")", ",", "and", "Man", "of", "Miracles", "(", "1974", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, person, event, musical instrument, band, music genre, album, song, musical artist, organization, award, country and O.\nSentence: The band released four albums : Styx I ( 1972 ) , Styx II ( 1973 ) , The Serpent Is Rising ( 1973 ) , and Man of Miracles ( 1974 ) .", "prompt_labels": "The(O) band(O) released(O) four(O) albums(O) :(O) Styx(B-album) I(I-album) ((O) 1972(O) )(O) ,(O) Styx(B-album) II(I-album) ((O) 1973(O) )(O) ,(O) The(B-album) Serpent(I-album) Is(I-album) Rising(I-album) ((O) 1973(O) )(O) ,(O) and(O) Man(B-album) of(I-album) Miracles(I-album) ((O) 1974(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 1732, 11, 1567, 11, 18273, 14473, 11, 7200, 11, 4731, 17779, 11, 8176, 11, 5609, 11, 18273, 10255, 11, 7471, 11, 10292, 11, 3224, 323, 507, 627, 85664, 25, 578, 7200, 6004, 3116, 28785, 551, 47665, 87, 358, 320, 220, 4468, 17, 883, 1174, 47665, 87, 8105, 320, 220, 4468, 18, 883, 1174, 578, 8409, 46225, 2209, 49987, 320, 220, 4468, 18, 883, 1174, 323, 2418, 315, 14603, 18709, 320, 220, 4468, 19, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) band(O) released(O) four(O) albums(O) :(O) Styx(B-album) I(I-album) ((O) 1972(O) )(O),(O) Styx(B-album) II(I-album) ((O) 1973(O) )(O),(O) The(B-album) Serpent(I-album) Is(I-album) Rising(I-album) ((O) 1973(O) )(O),(O) and(O) Man(B-album) of(I-album) Miracles(I-album) ((O) 1974(O) )(O).(O)"}
{"id": "315", "dataset": "crossner_science", "split": "test", "label_list": ["astronomical object", "organization", "academic journal", "chemical element", "award", "protein", "country", "chemical compound", "enzyme", "university", "scientist", "person", "location", "discipline", "event", "theory"], "instance": {"id": "315", "words": ["Several", "TLR", "immunodeficiencies", "have", "been", "described", "in", "which", "cellular", "proteins", "that", "should", "transmit", "the", "message", "from", "the", "Toll-like", "receptor", "to", "the", "nucleus", "are", "abnormal", "."], "labels": ["O", "B-protein", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-protein", "I-protein", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, organization, academic journal, chemical element, award, protein, country, chemical compound, enzyme, university, scientist, person, location, discipline, event, theory and O.\nSentence: Several TLR immunodeficiencies have been described in which cellular proteins that should transmit the message from the Toll-like receptor to the nucleus are abnormal .", "prompt_labels": "Several(O) TLR(B-protein) immunodeficiencies(O) have(O) been(O) described(O) in(O) which(O) cellular(O) proteins(O) that(O) should(O) transmit(O) the(O) message(O) from(O) the(O) Toll-like(B-protein) receptor(I-protein) to(O) the(O) nucleus(O) are(O) abnormal(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 87283, 1665, 11, 7471, 11, 14584, 8486, 11, 11742, 2449, 11, 10292, 11, 13128, 11, 3224, 11, 11742, 24549, 11, 49242, 11, 12374, 11, 28568, 11, 1732, 11, 3813, 11, 26434, 11, 1567, 11, 10334, 323, 507, 627, 85664, 25, 26778, 350, 20721, 33119, 98677, 43690, 617, 1027, 7633, 304, 902, 35693, 28896, 430, 1288, 30382, 279, 1984, 505, 279, 86394, 12970, 35268, 311, 279, 62607, 527, 35663, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Several(O) TLR(B-protein) immunodeficiencies(O) have(O) been(O) described(O) in(O) which(O) cellular(O) proteins(O) that(O) should(O) transmit(O) the(O) message(O) from(O) the(O) Toll-like(B-protein) receptor(I-protein) to(O) the(O) nucleus(B-location) are(O) abnormal(O).(O)"}
{"id": "267", "dataset": "crossner_politics", "split": "test", "label_list": ["political party", "politician", "country", "event", "election", "organization", "location", "person"], "instance": {"id": "267", "words": ["He", "went", "from", "place", "to", "place", ",", "in", "danger", "of", "his", "life", ",", "denouncing", "the", "errors", "of", "the", "Papacy", "and", "the", "abuses", "in", "the", "churches", "of", "Montrose", ",", "Dundee", "(", "where", "he", "escaped", "an", "attempt", "on", "his", "life", ")", ",", "Ayr", ",", "Perth", ",", "Edinburgh", ",", "Leith", ",", "Haddington", "(", "where", "Knox", "accompanied", "him", ")", "and", "elsewhere", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-location", "O", "B-location", "O", "B-location", "O", "B-location", "O", "O", "B-person", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: political party, politician, country, event, election, organization, location, person and O.\nSentence: He went from place to place , in danger of his life , denouncing the errors of the Papacy and the abuses in the churches of Montrose , Dundee ( where he escaped an attempt on his life ) , Ayr , Perth , Edinburgh , Leith , Haddington ( where Knox accompanied him ) and elsewhere .", "prompt_labels": "He(O) went(O) from(O) place(O) to(O) place(O) ,(O) in(O) danger(O) of(O) his(O) life(O) ,(O) denouncing(O) the(O) errors(O) of(O) the(O) Papacy(O) and(O) the(O) abuses(O) in(O) the(O) churches(O) of(O) Montrose(B-location) ,(O) Dundee(B-location) ((O) where(O) he(O) escaped(O) an(O) attempt(O) on(O) his(O) life(O) )(O) ,(O) Ayr(B-location) ,(O) Perth(B-location) ,(O) Edinburgh(B-location) ,(O) Leith(B-location) ,(O) Haddington(B-location) ((O) where(O) Knox(B-person) accompanied(O) him(O) )(O) and(O) elsewhere(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5054, 4717, 11, 37038, 11, 3224, 11, 1567, 11, 6355, 11, 7471, 11, 3813, 11, 1732, 323, 507, 627, 85664, 25, 1283, 4024, 505, 2035, 311, 2035, 1174, 304, 8137, 315, 813, 2324, 1174, 3453, 37857, 279, 6103, 315, 279, 32743, 2826, 323, 279, 50162, 304, 279, 31012, 315, 9995, 25888, 1174, 75015, 2176, 320, 1405, 568, 28883, 459, 4879, 389, 813, 2324, 883, 1174, 362, 11160, 1174, 50544, 1174, 41406, 1174, 2009, 411, 1174, 473, 3071, 783, 320, 1405, 54450, 24895, 1461, 883, 323, 18403, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "He(O) went(O) from(O) place(O) to(O) place(O),(O) in(O) danger(O) of(O) his(O) life(O),(O) denouncing(O) the(O) errors(O) of(O) the(O) Papacy(O) and(O) the(O) abuses(O) in(O) the(O) churches(O) of(O) Montrose(B-location),(O) Dundee(B-location) ((O) where(O) he(O) escaped(O) an(O) attempt(O) on(O) his(O) life(O) )(O),(O) Ayr(B-location),(O) Perth(B-location),(O) Edinburgh(B-location),(O) Leith(B-location),(O) Haddington(B-location) ((O) where(O) Knox(B-person) accompanied(O) him(O) )(O) and(O) elsewhere(O).(O)"}
{"id": "612", "dataset": "crossner_politics", "split": "test", "label_list": ["person", "politician", "election", "event", "country", "location", "organization", "political party"], "instance": {"id": "612", "words": ["The", "film", "was", "screened", "at", "various", "film", "festivals", ",", "including", ":", "the", "Toronto", "International", "Film", "Festival", ",", "Canada", ";", "the", "Huelva", "Latin", "American", "Film", "Festival", ",", "Spain", ";", "the", "Norwegian", "International", "Film", "Festival", ",", "Norway", ";", "the", "Human", "Rights", "Watch", "Film", "Festival", ",", "New", "York", "City", ";", "the", "Amnesty", "International", "Film", "Festival", ",", "Netherlands", ";", "and", "others", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O", "B-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-country", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O", "B-location", "I-location", "I-location", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "B-country", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, election, event, country, location, organization, political party and O.\nSentence: The film was screened at various film festivals , including : the Toronto International Film Festival , Canada ; the Huelva Latin American Film Festival , Spain ; the Norwegian International Film Festival , Norway ; the Human Rights Watch Film Festival , New York City ; the Amnesty International Film Festival , Netherlands ; and others .", "prompt_labels": "The(O) film(O) was(O) screened(O) at(O) various(O) film(O) festivals(O) ,(O) including(O) :(O) the(O) Toronto(B-event) International(I-event) Film(I-event) Festival(I-event) ,(O) Canada(B-country) ;(O) the(O) Huelva(B-event) Latin(I-event) American(I-event) Film(I-event) Festival(I-event) ,(O) Spain(B-country) ;(O) the(O) Norwegian(B-event) International(I-event) Film(I-event) Festival(I-event) ,(O) Norway(B-country) ;(O) the(O) Human(B-event) Rights(I-event) Watch(I-event) Film(I-event) Festival(I-event) ,(O) New(B-location) York(I-location) City(I-location) ;(O) the(O) Amnesty(B-event) International(I-event) Film(I-event) Festival(I-event) ,(O) Netherlands(B-country) ;(O) and(O) others(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 37038, 11, 6355, 11, 1567, 11, 3224, 11, 3813, 11, 7471, 11, 5054, 4717, 323, 507, 627, 85664, 25, 578, 4632, 574, 58677, 520, 5370, 4632, 45517, 1174, 2737, 551, 279, 14974, 7327, 17042, 17772, 1174, 7008, 2652, 279, 473, 4088, 6723, 20023, 3778, 17042, 17772, 1174, 18157, 2652, 279, 45721, 7327, 17042, 17772, 1174, 32603, 2652, 279, 11344, 10734, 10573, 17042, 17772, 1174, 1561, 4356, 4409, 2652, 279, 78796, 7327, 17042, 17772, 1174, 26746, 2652, 323, 3885, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) film(O) was(O) screened(O) at(O) various(O) film(O) festivals(O),(O) including(O) :(O) the(O) Toronto(B-event) International(I-event) Film(I-event) Festival(I-event),(O) Canada(B-country) ;(O) the(O) Huelva(B-event) Latin(I-event) American(I-event) Film(I-event) Festival(I-event),(O) Spain(B-country) ;(O) the(O) Norwegian(B-event) International(I-event) Film(I-event) Festival(I-event),(O) Norway(B-country) ;(O) the(O) Human(B-event) Rights(I-event) Watch(I-event) Film(I-event) Festival(I-event),(O) New(B-location) York(I-location) City(I-location) ;(O) the(O) Amnesty(B-event) International(I-event) Film(I-event) Festival(I-event),(O) Netherlands(B-country) ;(O) and(O) others(O).(O)"}
{"id": "1996", "dataset": "mit-movie", "split": "test", "label_list": ["character", "average ratings", "title", "actor", "year", "plot", "genre", "review", "trailer", "song", "director", "rating"], "instance": {"id": "1996", "words": ["what", "is", "a", "pg", "thriller", "rated", "seven", "stars", "directed", "by", "hironobu", "sakaguchi"], "labels": ["O", "O", "O", "B-rating", "B-genre", "O", "B-average ratings", "I-average ratings", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, title, actor, year, plot, genre, review, trailer, song, director, rating and O.\nSentence: what is a pg thriller rated seven stars directed by hironobu sakaguchi", "prompt_labels": "what(O) is(O) a(O) pg(B-rating) thriller(B-genre) rated(O) seven(B-average ratings) stars(I-average ratings) directed(O) by(O) hironobu(B-director) sakaguchi(I-director)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 2316, 11, 12360, 11, 1060, 11, 7234, 11, 17779, 11, 3477, 11, 19809, 11, 5609, 11, 7690, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 264, 17953, 54461, 22359, 8254, 9958, 15910, 555, 305, 2534, 677, 84, 78410, 351, 56017, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) a(O) pg(B-rating) thriller(B-genre) rated(O) seven(B-average ratings) stars(I-average ratings) directed(O) by(O) hironobu(B-director) sakaguchi(I-director)"}
{"id": "813", "dataset": "mit-restaurant", "split": "test", "label_list": ["Dish", "Cuisine", "Hours", "Amenity", "Restaurant Name", "Rating", "Price", "Location"], "instance": {"id": "813", "words": ["is", "there", "a", "diner", "with", "a", "patio", "in", "boxford"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "B-Amenity", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Hours, Amenity, Restaurant Name, Rating, Price, Location and O.\nSentence: is there a diner with a patio in boxford", "prompt_labels": "is(O) there(O) a(O) diner(B-Cuisine) with(O) a(O) patio(B-Amenity) in(O) boxford(B-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 81961, 11, 30192, 11, 3383, 56685, 11, 26568, 4076, 11, 19767, 11, 8650, 11, 10067, 323, 507, 627, 85664, 25, 374, 1070, 264, 89206, 449, 264, 32278, 304, 3830, 8350, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) a(O) diner(B-Cuisine) with(O) a(O) patio(B-Amenity) in(O) boxford(B-Location)"}
{"id": "485", "dataset": "mit-restaurant", "split": "test", "label_list": ["Location", "Dish", "Price", "Hours", "Restaurant Name", "Rating", "Cuisine", "Amenity"], "instance": {"id": "485", "words": ["hey", "could", "you", "look", "up", "a", "restaurant", "with", "the", "best", "meatballs", "in", "town"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Rating", "B-Dish", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Dish, Price, Hours, Restaurant Name, Rating, Cuisine, Amenity and O.\nSentence: hey could you look up a restaurant with the best meatballs in town", "prompt_labels": "hey(O) could(O) you(O) look(O) up(O) a(O) restaurant(O) with(O) the(O) best(B-Rating) meatballs(B-Dish) in(B-Location) town(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 49268, 11, 8650, 11, 30192, 11, 26568, 4076, 11, 19767, 11, 81961, 11, 3383, 56685, 323, 507, 627, 85664, 25, 35309, 1436, 499, 1427, 709, 264, 10960, 449, 279, 1888, 13339, 46618, 304, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "hey(O) could(O) you(O) look(O) up(O) a(O) restaurant(O) with(O) the(O) best(B-Rating) meatballs(B-Dish) in(B-Location) town(I-Location)"}
{"id": "263", "dataset": "crossner_music", "split": "test", "label_list": ["musical instrument", "award", "event", "album", "location", "music genre", "song", "band", "organization", "musical artist", "person", "country"], "instance": {"id": "263", "words": ["The", "Elephant", "Man", "was", "a", "huge", "critical", "and", "commercial", "success", ",", "and", "earned", "eight", "Academy", "Awards", "nominations", ",", "including", "Academy", "Award", "for", "Best", "Director", "and", "Academy", "Award", "for", "Best", "Adapted", "Screenplay", "for", "Lynch", "personally", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "I-award", "O", "B-musical artist", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, award, event, album, location, music genre, song, band, organization, musical artist, person, country and O.\nSentence: The Elephant Man was a huge critical and commercial success , and earned eight Academy Awards nominations , including Academy Award for Best Director and Academy Award for Best Adapted Screenplay for Lynch personally .", "prompt_labels": "The(O) Elephant(O) Man(O) was(O) a(O) huge(O) critical(O) and(O) commercial(O) success(O) ,(O) and(O) earned(O) eight(O) Academy(B-award) Awards(I-award) nominations(O) ,(O) including(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Adapted(I-award) Screenplay(I-award) for(O) Lynch(B-musical artist) personally(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 18273, 14473, 11, 10292, 11, 1567, 11, 8176, 11, 3813, 11, 4731, 17779, 11, 5609, 11, 7200, 11, 7471, 11, 18273, 10255, 11, 1732, 11, 3224, 323, 507, 627, 85664, 25, 578, 79189, 2418, 574, 264, 6908, 9200, 323, 8518, 2450, 1174, 323, 15662, 8223, 16192, 23488, 60698, 1174, 2737, 16192, 17768, 369, 7252, 10783, 323, 16192, 17768, 369, 7252, 59531, 291, 14275, 1387, 369, 38206, 16102, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(B-album) Elephant(I-album) Man(I-album) was(O) a(O) huge(O) critical(O) and(O) commercial(O) success(O),(O) and(O) earned(O) eight(O) Academy(B-award) Awards(I-award) nominations(O),(O) including(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Adapted(I-award) Screenplay(I-award) for(O) Lynch(B-musical artist) personally(O).(O)"}
{"id": "10", "dataset": "crossner_music", "split": "test", "label_list": ["person", "band", "event", "location", "award", "song", "musical artist", "country", "music genre", "album", "organization", "musical instrument"], "instance": {"id": "10", "words": ["With", "Fredriksson", "'s", "continued", "treatment", "and", "recuperation", "he", "made", "three", "more", "albums", ",", "Son", "of", "a", "Plumber", "(", "2005", ")", ",", "En", "h\u00e4ndig", "man", "(", "A", "handy", "man", ",", "2007", ")", "and", "Party", "Crasher", "(", "2008", ")", "."], "labels": ["O", "B-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "I-album", "O", "B-album", "I-album", "I-album", "O", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, band, event, location, award, song, musical artist, country, music genre, album, organization, musical instrument and O.\nSentence: With Fredriksson 's continued treatment and recuperation he made three more albums , Son of a Plumber ( 2005 ) , En h\u00e4ndig man ( A handy man , 2007 ) and Party Crasher ( 2008 ) .", "prompt_labels": "With(O) Fredriksson(B-musical artist) 's(O) continued(O) treatment(O) and(O) recuperation(O) he(O) made(O) three(O) more(O) albums(O) ,(O) Son(B-album) of(I-album) a(I-album) Plumber(I-album) ((O) 2005(O) )(O) ,(O) En(B-album) h\u00e4ndig(I-album) man(I-album) ((O) A(B-album) handy(I-album) man(I-album) ,(O) 2007(O) )(O) and(O) Party(B-album) Crasher(I-album) ((O) 2008(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 7200, 11, 1567, 11, 3813, 11, 10292, 11, 5609, 11, 18273, 10255, 11, 3224, 11, 4731, 17779, 11, 8176, 11, 7471, 11, 18273, 14473, 323, 507, 627, 85664, 25, 3161, 28588, 21042, 31031, 364, 82, 8738, 6514, 323, 52621, 367, 568, 1903, 2380, 810, 28785, 1174, 12103, 315, 264, 1856, 900, 320, 220, 1049, 20, 883, 1174, 2998, 305, 22270, 343, 893, 320, 362, 26222, 893, 1174, 220, 1049, 22, 883, 323, 8722, 4656, 34867, 320, 220, 1049, 23, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "With(O) Fredriksson(B-musical artist)'s(O) continued(O) treatment(O) and(O) recuperation(O) he(O) made(O) three(O) more(O) albums(O),(O) Son(B-album) of(I-album) a(I-album) Plumber(I-album) ((O) 2005(O) )(O),(O) En(B-album) h\u00e4ndig(I-album) man(I-album) ((O) A(B-album) handy(I-album) man(I-album),(O) 2007(O) )(O) and(O) Party(B-album) Crasher(I-album) ((O) 2008(O) )(O).(O)"}
{"id": "718", "dataset": "mit-movie", "split": "test", "label_list": ["year", "genre", "actor", "review", "plot", "rating", "song", "director", "title", "character", "average ratings", "trailer"], "instance": {"id": "718", "words": ["find", "a", "movie", "with", "the", "song", "for", "hes", "a", "jolly", "good", "fellow"], "labels": ["O", "O", "O", "O", "O", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, genre, actor, review, plot, rating, song, director, title, character, average ratings, trailer and O.\nSentence: find a movie with the song for hes a jolly good fellow", "prompt_labels": "find(O) a(O) movie(O) with(O) the(O) song(O) for(B-song) hes(I-song) a(I-song) jolly(I-song) good(I-song) fellow(I-song)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 17779, 11, 12360, 11, 3477, 11, 7234, 11, 10959, 11, 5609, 11, 7690, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 19809, 323, 507, 627, 85664, 25, 1505, 264, 5818, 449, 279, 5609, 369, 20365, 264, 503, 8788, 1695, 12637, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) a(O) movie(O) with(O) the(O) song(O) for(O) hes(B-song) a(I-song) jolly(I-song) good(I-song) fellow(I-song)"}
{"id": "987", "dataset": "mit-restaurant", "split": "test", "label_list": ["Location", "Rating", "Hours", "Cuisine", "Price", "Amenity", "Dish", "Restaurant Name"], "instance": {"id": "987", "words": ["looking", "for", "tom", "yum", "cafe", "around", "here", "with", "excellent", "prices"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "B-Location", "I-Location", "O", "B-Price", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Rating, Hours, Cuisine, Price, Amenity, Dish, Restaurant Name and O.\nSentence: looking for tom yum cafe around here with excellent prices", "prompt_labels": "looking(O) for(O) tom(B-Restaurant Name) yum(I-Restaurant Name) cafe(I-Restaurant Name) around(B-Location) here(I-Location) with(O) excellent(B-Price) prices(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 19767, 11, 30192, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 49268, 11, 26568, 4076, 323, 507, 627, 85664, 25, 3411, 369, 10390, 69970, 42030, 2212, 1618, 449, 9250, 7729, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "looking(O) for(O) tom(B-Restaurant Name) yum(I-Restaurant Name) cafe(I-Restaurant Name) around(B-Location) here(I-Location) with(O) excellent(B-Price) prices(O)"}
{"id": "1442", "dataset": "mit-movie", "split": "test", "label_list": ["average ratings", "title", "plot", "actor", "year", "review", "character", "trailer", "genre", "song", "rating", "director"], "instance": {"id": "1442", "words": ["is", "robert", "de", "niro", "in", "any", "disaster", "movies"], "labels": ["O", "B-actor", "I-actor", "I-actor", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, title, plot, actor, year, review, character, trailer, genre, song, rating, director and O.\nSentence: is robert de niro in any disaster movies", "prompt_labels": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 2316, 11, 7234, 11, 12360, 11, 1060, 11, 3477, 11, 3752, 11, 19809, 11, 17779, 11, 5609, 11, 10959, 11, 7690, 323, 507, 627, 85664, 25, 374, 89993, 409, 308, 8869, 304, 904, 21426, 9698, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) robert(B-actor) de(I-actor) niro(I-actor) in(O) any(O) disaster(B-genre) movies(O)"}
{"id": "156", "dataset": "crossner_literature", "split": "test", "label_list": ["magazine", "poem", "writer", "organization", "award", "person", "literary genre", "country", "location", "event", "book"], "instance": {"id": "156", "words": ["Two", "other", "early", "works", "were", "Anelida", "and", "Arcite", "and", "The", "House", "of", "Fame", "."], "labels": ["O", "O", "O", "O", "O", "B-poem", "I-poem", "I-poem", "O", "B-poem", "I-poem", "I-poem", "I-poem", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: magazine, poem, writer, organization, award, person, literary genre, country, location, event, book and O.\nSentence: Two other early works were Anelida and Arcite and The House of Fame .", "prompt_labels": "Two(O) other(O) early(O) works(O) were(O) Anelida(B-poem) and(I-poem) Arcite(I-poem) and(O) The(B-poem) House(I-poem) of(I-poem) Fame(I-poem) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14756, 11, 33894, 11, 7061, 11, 7471, 11, 10292, 11, 1732, 11, 32465, 17779, 11, 3224, 11, 3813, 11, 1567, 11, 2363, 323, 507, 627, 85664, 25, 9220, 1023, 4216, 4375, 1051, 1556, 301, 4849, 323, 20267, 635, 323, 578, 4783, 315, 39627, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Two(O) other(O) early(O) works(O) were(O) Anelida(B-poem) and(I-poem) Arcite(I-poem) and(O) The(B-poem) House(I-poem) of(I-poem) Fame(I-poem).(O)"}
{"id": "28", "dataset": "crossner_science", "split": "test", "label_list": ["location", "award", "university", "academic journal", "enzyme", "chemical compound", "scientist", "theory", "country", "chemical element", "organization", "discipline", "person", "astronomical object", "event", "protein"], "instance": {"id": "28", "words": ["Alferov", "and", "colleagues", "worked", "on", "Gallium", "arsenide", "and", "Aluminium", "arsenide", "III-V", "heterojunctions", "."], "labels": ["B-scientist", "O", "O", "O", "O", "B-chemical compound", "I-chemical compound", "O", "B-chemical compound", "I-chemical compound", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, award, university, academic journal, enzyme, chemical compound, scientist, theory, country, chemical element, organization, discipline, person, astronomical object, event, protein and O.\nSentence: Alferov and colleagues worked on Gallium arsenide and Aluminium arsenide III-V heterojunctions .", "prompt_labels": "Alferov(B-scientist) and(O) colleagues(O) worked(O) on(O) Gallium(B-chemical compound) arsenide(I-chemical compound) and(O) Aluminium(B-chemical compound) arsenide(I-chemical compound) III-V(O) heterojunctions(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 10292, 11, 12374, 11, 14584, 8486, 11, 49242, 11, 11742, 24549, 11, 28568, 11, 10334, 11, 3224, 11, 11742, 2449, 11, 7471, 11, 26434, 11, 1732, 11, 87283, 1665, 11, 1567, 11, 13128, 323, 507, 627, 85664, 25, 1708, 809, 869, 323, 18105, 6575, 389, 25919, 2411, 87364, 579, 323, 89582, 87364, 579, 14767, 20198, 30548, 21963, 600, 82, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Alferov(B-scientist) and(O) colleagues(O) worked(O) on(O) Gallium(B-chemical compound) arsenide(I-chemical compound) and(O) Aluminium(B-chemical compound) arsenide(I-chemical compound) III-V(I-chemical compound) heterojunctions(I-chemical compound).(O)"}
{"id": "200", "dataset": "crossner_literature", "split": "test", "label_list": ["event", "organization", "country", "magazine", "person", "poem", "literary genre", "location", "book", "writer", "award"], "instance": {"id": "200", "words": ["In", "1930", ",", "an", "American", "film", "of", "the", "novel", "was", "made", ",", "directed", "by", "Lewis", "Milestone", ";", "with", "a", "screenplay", "by", "Maxwell", "Anderson", ",", "George", "Abbott", ",", "Del", "Andrews", ",", "C.", "Gardner", "Sullivan", ";", "and", "with", "uncredited", "work", "by", "Walter", "Anthony", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-literary genre", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "O", "B-writer", "I-writer", "I-writer", "O", "O", "O", "O", "O", "O", "B-writer", "I-writer", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, organization, country, magazine, person, poem, literary genre, location, book, writer, award and O.\nSentence: In 1930 , an American film of the novel was made , directed by Lewis Milestone ; with a screenplay by Maxwell Anderson , George Abbott , Del Andrews , C. Gardner Sullivan ; and with uncredited work by Walter Anthony .", "prompt_labels": "In(O) 1930(O) ,(O) an(O) American(O) film(O) of(O) the(O) novel(B-literary genre) was(O) made(O) ,(O) directed(O) by(O) Lewis(B-person) Milestone(I-person) ;(O) with(O) a(O) screenplay(O) by(O) Maxwell(B-writer) Anderson(I-writer) ,(O) George(B-writer) Abbott(I-writer) ,(O) Del(B-writer) Andrews(I-writer) ,(O) C.(B-writer) Gardner(I-writer) Sullivan(I-writer) ;(O) and(O) with(O) uncredited(O) work(O) by(O) Walter(B-writer) Anthony(I-writer) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 7471, 11, 3224, 11, 14756, 11, 1732, 11, 33894, 11, 32465, 17779, 11, 3813, 11, 2363, 11, 7061, 11, 10292, 323, 507, 627, 85664, 25, 763, 220, 7285, 15, 1174, 459, 3778, 4632, 315, 279, 11775, 574, 1903, 1174, 15910, 555, 21256, 39697, 11046, 2652, 449, 264, 85875, 555, 59497, 21293, 1174, 10058, 43227, 1174, 7462, 52951, 1174, 356, 13, 57729, 43089, 2652, 323, 449, 653, 67309, 990, 555, 33305, 21353, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) 1930(O),(O) an(O) American(O) film(O) of(O) the(O) novel(B-literary genre) was(O) made(O),(O) directed(O) by(O) Lewis(B-director) Milestone(I-director) ;(O) with(O) a(O) screenplay(O) by(O) Maxwell(B-writer) Anderson(I-writer),(O) George(B-writer) Abbott(I-writer),(O) Del(B-writer) Andrews(I-writer),(O) C.(B-writer) Gardner(I-writer) Sullivan(I-writer) ;(O) and(O) with(O) uncredited(O) work(O) by(O) Walter(B-writer) Anthony(I-writer).(O)"}
{"id": "2285", "dataset": "mit-movie", "split": "test", "label_list": ["genre", "title", "trailer", "rating", "review", "average ratings", "character", "director", "year", "actor", "plot", "song"], "instance": {"id": "2285", "words": ["where", "there", "any", "derek", "jacobi", "fantasy", "movies", "made", "in", "the", "last", "eight", "decades"], "labels": ["O", "O", "O", "B-actor", "I-actor", "B-genre", "O", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, title, trailer, rating, review, average ratings, character, director, year, actor, plot, song and O.\nSentence: where there any derek jacobi fantasy movies made in the last eight decades", "prompt_labels": "where(O) there(O) any(O) derek(B-actor) jacobi(I-actor) fantasy(B-genre) movies(O) made(O) in(O) the(O) last(B-year) eight(I-year) decades(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 2316, 11, 19809, 11, 10959, 11, 3477, 11, 5578, 18594, 11, 3752, 11, 7690, 11, 1060, 11, 12360, 11, 7234, 11, 5609, 323, 507, 627, 85664, 25, 1405, 1070, 904, 26344, 74, 60943, 18843, 18884, 9698, 1903, 304, 279, 1566, 8223, 11026, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) there(O) any(O) derek(B-actor) jacobi(I-actor) fantasy(B-genre) movies(O) made(O) in(O) the(O) last(B-year) eight(I-year) decades(I-year)"}
{"id": "251", "dataset": "crossner_ai", "split": "test", "label_list": ["programming language", "university", "algorithm", "product", "field", "country", "researcher", "person", "task", "location", "organization", "conference", "metric"], "instance": {"id": "251", "words": ["SHRDLU", "was", "an", "early", "natural", "language", "understanding", "computer", "program", ",", "developed", "by", "Terry", "Winograd", "at", "MIT", "in", "1968-1970"], "labels": ["B-product", "O", "O", "O", "B-task", "I-task", "I-task", "O", "O", "O", "O", "O", "B-researcher", "I-researcher", "O", "B-university", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, university, algorithm, product, field, country, researcher, person, task, location, organization, conference, metric and O.\nSentence: SHRDLU was an early natural language understanding computer program , developed by Terry Winograd at MIT in 1968-1970", "prompt_labels": "SHRDLU(B-product) was(O) an(O) early(O) natural(B-task) language(I-task) understanding(I-task) computer(O) program(O) ,(O) developed(O) by(O) Terry(B-researcher) Winograd(I-researcher) at(O) MIT(B-university) in(O) 1968-1970(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 15840, 4221, 11, 12374, 11, 12384, 11, 2027, 11, 2115, 11, 3224, 11, 32185, 11, 1732, 11, 3465, 11, 3813, 11, 7471, 11, 10017, 11, 18767, 323, 507, 627, 85664, 25, 78148, 16931, 52, 574, 459, 4216, 5933, 4221, 8830, 6500, 2068, 1174, 8040, 555, 32618, 12468, 68011, 520, 15210, 304, 220, 5162, 23, 12, 4468, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "SHRDLU(B-product) was(O) an(O) early(O) natural(B-field) language(I-field) understanding(I-field) computer(O) program(O),(O) developed(O) by(O) Terry(B-researcher) Winograd(I-researcher) at(O) MIT(B-university) in(O) 1968-1970(O)"}
{"id": "876", "dataset": "mit-movie", "split": "test", "label_list": ["actor", "director", "year", "average ratings", "song", "review", "plot", "rating", "character", "trailer", "title", "genre"], "instance": {"id": "876", "words": ["show", "me", "a", "list", "of", "r", "rated", "movies", "about", "aliens"], "labels": ["O", "O", "O", "O", "O", "B-rating", "I-rating", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, director, year, average ratings, song, review, plot, rating, character, trailer, title, genre and O.\nSentence: show me a list of r rated movies about aliens", "prompt_labels": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(I-rating) movies(O) about(O) aliens(B-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 7690, 11, 1060, 11, 5578, 18594, 11, 5609, 11, 3477, 11, 7234, 11, 10959, 11, 3752, 11, 19809, 11, 2316, 11, 17779, 323, 507, 627, 85664, 25, 1501, 757, 264, 1160, 315, 436, 22359, 9698, 922, 37219, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) a(O) list(O) of(O) r(B-rating) rated(I-rating) movies(O) about(O) aliens(B-plot)"}
{"id": "908", "dataset": "mit-restaurant", "split": "test", "label_list": ["Dish", "Location", "Amenity", "Cuisine", "Hours", "Rating", "Price", "Restaurant Name"], "instance": {"id": "908", "words": ["is", "there", "any", "place", "open", "after", "9", "pm"], "labels": ["O", "O", "O", "O", "B-Hours", "I-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Location, Amenity, Cuisine, Hours, Rating, Price, Restaurant Name and O.\nSentence: is there any place open after 9 pm", "prompt_labels": "is(O) there(O) any(O) place(O) open(B-Hours) after(I-Hours) 9(I-Hours) pm(I-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 10067, 11, 3383, 56685, 11, 81961, 11, 30192, 11, 19767, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 374, 1070, 904, 2035, 1825, 1306, 220, 24, 9012, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) any(O) place(O) open(B-Hours) after(I-Hours) 9(I-Hours) pm(I-Hours)"}
{"id": "360", "dataset": "mit-restaurant", "split": "test", "label_list": ["Restaurant Name", "Dish", "Hours", "Amenity", "Price", "Rating", "Location", "Cuisine"], "instance": {"id": "360", "words": ["find", "me", "a", "cheaply", "priced", "thai", "restaurant"], "labels": ["O", "O", "O", "B-Price", "O", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Dish, Hours, Amenity, Price, Rating, Location, Cuisine and O.\nSentence: find me a cheaply priced thai restaurant", "prompt_labels": "find(O) me(O) a(O) cheaply(B-Price) priced(O) thai(B-Cuisine) restaurant(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 49268, 11, 30192, 11, 3383, 56685, 11, 8650, 11, 19767, 11, 10067, 11, 81961, 323, 507, 627, 85664, 25, 1505, 757, 264, 12136, 398, 33705, 18420, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) cheaply(B-Price) priced(O) thai(B-Cuisine) restaurant(O)"}
{"id": "692", "dataset": "mit-movie", "split": "test", "label_list": ["character", "actor", "rating", "review", "director", "title", "average ratings", "plot", "year", "song", "genre", "trailer"], "instance": {"id": "692", "words": ["who", "provided", "the", "voice", "talent", "for", "the", "tiger", "in", "kung", "fu", "panda"], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-character", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, actor, rating, review, director, title, average ratings, plot, year, song, genre, trailer and O.\nSentence: who provided the voice talent for the tiger in kung fu panda", "prompt_labels": "who(O) provided(O) the(O) voice(O) talent(O) for(O) the(O) tiger(B-character) in(O) kung(B-title) fu(I-title) panda(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 12360, 11, 10959, 11, 3477, 11, 7690, 11, 2316, 11, 5578, 18594, 11, 7234, 11, 1060, 11, 5609, 11, 17779, 11, 19809, 323, 507, 627, 85664, 25, 889, 3984, 279, 7899, 11005, 369, 279, 52835, 304, 597, 2234, 18922, 89322, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "who(O) provided(O) the(O) voice(O) talent(O) for(O) the(O) tiger(B-character) in(O) kung(B-title) fu(I-title) panda(I-title)"}
{"id": "1137", "dataset": "mit-movie", "split": "test", "label_list": ["average ratings", "director", "genre", "title", "trailer", "rating", "actor", "year", "review", "song", "character", "plot"], "instance": {"id": "1137", "words": ["did", "dylan", "neal", "do", "a", "movie", "child", "movie"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, director, genre, title, trailer, rating, actor, year, review, song, character, plot and O.\nSentence: did dylan neal do a movie child movie", "prompt_labels": "did(O) dylan(B-actor) neal(I-actor) do(O) a(O) movie(O) child(B-genre) movie(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 7690, 11, 17779, 11, 2316, 11, 19809, 11, 10959, 11, 12360, 11, 1060, 11, 3477, 11, 5609, 11, 3752, 11, 7234, 323, 507, 627, 85664, 25, 1550, 294, 37578, 841, 278, 656, 264, 5818, 1716, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "did(O) dylan(B-actor) neal(I-actor) do(O) a(O) movie(O) child(B-genre) movie(O)"}
{"id": "882", "dataset": "mit-movie", "split": "test", "label_list": ["title", "year", "plot", "character", "trailer", "average ratings", "song", "actor", "genre", "review", "rating", "director"], "instance": {"id": "882", "words": ["whats", "a", "rock", "hudson", "flick", "from", "the", "1960s"], "labels": ["O", "O", "B-actor", "I-actor", "O", "O", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, year, plot, character, trailer, average ratings, song, actor, genre, review, rating, director and O.\nSentence: whats a rock hudson flick from the 1960s", "prompt_labels": "whats(O) a(O) rock(B-actor) hudson(I-actor) flick(O) from(O) the(O) 1960s(B-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 1060, 11, 7234, 11, 3752, 11, 19809, 11, 5578, 18594, 11, 5609, 11, 12360, 11, 17779, 11, 3477, 11, 10959, 11, 7690, 323, 507, 627, 85664, 25, 41209, 264, 7091, 305, 32778, 29447, 505, 279, 220, 5162, 15, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "whats(O) a(O) rock(B-actor) hudson(I-actor) flick(O) from(O) the(O) 1960s(B-year)"}
{"id": "2196", "dataset": "mit-movie", "split": "test", "label_list": ["review", "song", "title", "director", "trailer", "actor", "plot", "average ratings", "year", "rating", "genre", "character"], "instance": {"id": "2196", "words": ["what", "unrated", "movie", "came", "out", "in", "2000", "and", "stars", "james", "van", "der", "beek"], "labels": ["O", "B-rating", "O", "O", "O", "O", "B-year", "O", "O", "B-actor", "I-actor", "I-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, song, title, director, trailer, actor, plot, average ratings, year, rating, genre, character and O.\nSentence: what unrated movie came out in 2000 and stars james van der beek", "prompt_labels": "what(O) unrated(B-rating) movie(O) came(O) out(O) in(O) 2000(B-year) and(O) stars(O) james(B-actor) van(I-actor) der(I-actor) beek(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 5609, 11, 2316, 11, 7690, 11, 19809, 11, 12360, 11, 7234, 11, 5578, 18594, 11, 1060, 11, 10959, 11, 17779, 11, 3752, 323, 507, 627, 85664, 25, 1148, 41480, 660, 5818, 3782, 704, 304, 220, 1049, 15, 323, 9958, 86046, 5355, 2761, 387, 1247, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) unrated(B-rating) movie(O) came(O) out(O) in(O) 2000(B-year) and(O) stars(O) james(B-actor) van(I-actor) der(I-actor) beek(I-actor)"}
{"id": "47", "dataset": "crossner_music", "split": "test", "label_list": ["music genre", "award", "song", "musical artist", "person", "organization", "country", "event", "band", "album", "musical instrument", "location"], "instance": {"id": "47", "words": ["The", "success", "and", "popularity", "of", "the", "Commonwealth", "Games", "resulted", "in", "Edmonton", "bidding", "for", "and", "being", "selected", "to", "host", "the", "1983", "Summer", "Universiade", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-event", "I-event", "O", "O", "B-location", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, award, song, musical artist, person, organization, country, event, band, album, musical instrument, location and O.\nSentence: The success and popularity of the Commonwealth Games resulted in Edmonton bidding for and being selected to host the 1983 Summer Universiade .", "prompt_labels": "The(O) success(O) and(O) popularity(O) of(O) the(O) Commonwealth(B-event) Games(I-event) resulted(O) in(O) Edmonton(B-location) bidding(O) for(O) and(O) being(O) selected(O) to(O) host(O) the(O) 1983(B-event) Summer(I-event) Universiade(I-event) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 10292, 11, 5609, 11, 18273, 10255, 11, 1732, 11, 7471, 11, 3224, 11, 1567, 11, 7200, 11, 8176, 11, 18273, 14473, 11, 3813, 323, 507, 627, 85664, 25, 578, 2450, 323, 23354, 315, 279, 38298, 11871, 19543, 304, 46387, 49500, 369, 323, 1694, 4183, 311, 3552, 279, 220, 3753, 18, 19367, 15915, 72, 1037, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) success(O) and(O) popularity(O) of(O) the(O) Commonwealth(B-event) Games(I-event) resulted(O) in(O) Edmonton(B-location) bidding(O) for(O) and(O) being(O) selected(O) to(O) host(O) the(O) 1983(B-event) Summer(I-event) Universiade(I-event).(O)"}
{"id": "1485", "dataset": "mit-movie", "split": "test", "label_list": ["genre", "trailer", "song", "rating", "average ratings", "plot", "character", "actor", "director", "review", "year", "title"], "instance": {"id": "1485", "words": ["is", "there", "a", "good", "action", "movie", "based", "on", "a", "mission", "that", "came", "out", "in", "2011"], "labels": ["O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "B-plot", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, trailer, song, rating, average ratings, plot, character, actor, director, review, year, title and O.\nSentence: is there a good action movie based on a mission that came out in 2011", "prompt_labels": "is(O) there(O) a(O) good(O) action(B-genre) movie(O) based(O) on(O) a(O) mission(B-plot) that(O) came(O) out(O) in(O) 2011(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 19809, 11, 5609, 11, 10959, 11, 5578, 18594, 11, 7234, 11, 3752, 11, 12360, 11, 7690, 11, 3477, 11, 1060, 11, 2316, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 1957, 5818, 3196, 389, 264, 9131, 430, 3782, 704, 304, 220, 679, 16, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) a(O) good(O) action(B-genre) movie(O) based(O) on(O) a(O) mission(B-plot) that(O) came(O) out(O) in(O) 2011(O)"}
{"id": "148", "dataset": "mit-restaurant", "split": "test", "label_list": ["Dish", "Location", "Hours", "Restaurant Name", "Price", "Cuisine", "Amenity", "Rating"], "instance": {"id": "148", "words": ["can", "you", "find", "an", "italian", "restaurant", "that", "serves", "brunch", "on", "sunday"], "labels": ["O", "O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Hours", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Location, Hours, Restaurant Name, Price, Cuisine, Amenity, Rating and O.\nSentence: can you find an italian restaurant that serves brunch on sunday", "prompt_labels": "can(O) you(O) find(O) an(O) italian(B-Cuisine) restaurant(O) that(O) serves(O) brunch(B-Hours) on(O) sunday(B-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 10067, 11, 30192, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 649, 499, 1505, 459, 29048, 10960, 430, 17482, 70917, 389, 93463, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "can(O) you(O) find(O) an(O) italian(B-Cuisine) restaurant(O) that(O) serves(O) brunch(B-Hours) on(I-Hours) sunday(I-Hours)"}
{"id": "74", "dataset": "mit-movie", "split": "test", "label_list": ["genre", "title", "year", "review", "character", "plot", "average ratings", "trailer", "rating", "actor", "song", "director"], "instance": {"id": "74", "words": ["who", "was", "the", "actress", "in", "the", "goodbye", "girl", "with", "richard", "dreyfuss"], "labels": ["O", "O", "O", "O", "O", "B-title", "I-title", "I-title", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, title, year, review, character, plot, average ratings, trailer, rating, actor, song, director and O.\nSentence: who was the actress in the goodbye girl with richard dreyfuss", "prompt_labels": "who(O) was(O) the(O) actress(O) in(O) the(B-title) goodbye(I-title) girl(I-title) with(O) richard(B-actor) dreyfuss(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 2316, 11, 1060, 11, 3477, 11, 3752, 11, 7234, 11, 5578, 18594, 11, 19809, 11, 10959, 11, 12360, 11, 5609, 11, 7690, 323, 507, 627, 85664, 25, 889, 574, 279, 24577, 304, 279, 47555, 3828, 449, 9257, 569, 294, 8233, 69, 1892, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "who(O) was(O) the(O) actress(O) in(O) the(B-title) goodbye(I-title) girl(I-title) with(O) richard(B-actor) dreyfuss(I-actor)"}
{"id": "403", "dataset": "mit-movie", "split": "test", "label_list": ["year", "genre", "actor", "average ratings", "character", "rating", "trailer", "plot", "review", "song", "director", "title"], "instance": {"id": "403", "words": ["what", "is", "a", "good", "r", "rated", "mystery"], "labels": ["O", "O", "O", "B-review", "B-rating", "O", "B-genre"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, genre, actor, average ratings, character, rating, trailer, plot, review, song, director, title and O.\nSentence: what is a good r rated mystery", "prompt_labels": "what(O) is(O) a(O) good(B-review) r(B-rating) rated(O) mystery(B-genre)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 17779, 11, 12360, 11, 5578, 18594, 11, 3752, 11, 10959, 11, 19809, 11, 7234, 11, 3477, 11, 5609, 11, 7690, 11, 2316, 323, 507, 627, 85664, 25, 1148, 374, 264, 1695, 436, 22359, 23347, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) a(O) good(O) r(B-rating) rated(O) mystery(B-genre)"}
{"id": "153", "dataset": "crossner_politics", "split": "test", "label_list": ["person", "country", "politician", "location", "political party", "event", "organization", "election"], "instance": {"id": "153", "words": ["During", "the", "Eurozone", "crisis", ",", "the", "two", "main", "parties", ",", "The", "People", "of", "Freedom", "and", "the", "Democratic", "Party", ",", "along", "with", "other", "minor", "political", "forces", ",", "supported", "the", "Monti", "cabinet", ",", "and", "eventually", ",", "after", "the", "2013", "Italian", "general", "election", ",", "formed", "a", "grand", "coalition", "in", "support", "of", "the", "Letta", "Cabinet", ",", "which", ",", "however", ",", "was", "opposed", "by", "a", "new", "major", "political", "force", "in", "parliament", ",", "the", "anti-establishment", "Five", "Star", "Movement", "."], "labels": ["O", "O", "B-event", "I-event", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-political party", "I-political party", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, country, politician, location, political party, event, organization, election and O.\nSentence: During the Eurozone crisis , the two main parties , The People of Freedom and the Democratic Party , along with other minor political forces , supported the Monti cabinet , and eventually , after the 2013 Italian general election , formed a grand coalition in support of the Letta Cabinet , which , however , was opposed by a new major political force in parliament , the anti-establishment Five Star Movement .", "prompt_labels": "During(O) the(O) Eurozone(B-event) crisis(I-event) ,(O) the(O) two(O) main(O) parties(O) ,(O) The(B-political party) People(I-political party) of(I-political party) Freedom(I-political party) and(O) the(O) Democratic(B-political party) Party(I-political party) ,(O) along(O) with(O) other(O) minor(O) political(O) forces(O) ,(O) supported(O) the(O) Monti(B-organization) cabinet(I-organization) ,(O) and(O) eventually(O) ,(O) after(O) the(O) 2013(B-election) Italian(I-election) general(I-election) election(I-election) ,(O) formed(O) a(O) grand(O) coalition(O) in(O) support(O) of(O) the(O) Letta(B-organization) Cabinet(I-organization) ,(O) which(O) ,(O) however(O) ,(O) was(O) opposed(O) by(O) a(O) new(O) major(O) political(O) force(O) in(O) parliament(O) ,(O) the(O) anti-establishment(O) Five(B-political party) Star(I-political party) Movement(I-political party) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 3224, 11, 37038, 11, 3813, 11, 5054, 4717, 11, 1567, 11, 7471, 11, 6355, 323, 507, 627, 85664, 25, 12220, 279, 20026, 8855, 11501, 1174, 279, 1403, 1925, 9875, 1174, 578, 9029, 315, 25320, 323, 279, 11650, 8722, 1174, 3235, 449, 1023, 9099, 5054, 8603, 1174, 7396, 279, 9995, 72, 22685, 1174, 323, 9778, 1174, 1306, 279, 220, 679, 18, 15155, 4689, 6355, 1174, 14454, 264, 6800, 26283, 304, 1862, 315, 279, 6914, 2629, 34046, 1174, 902, 1174, 4869, 1174, 574, 16475, 555, 264, 502, 3682, 5054, 5457, 304, 21814, 1174, 279, 7294, 48587, 479, 21594, 7834, 29098, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "During(O) the(O) Eurozone(B-event) crisis(I-event),(O) the(O) two(O) main(O) parties(O),(O) The(B-political party) People(I-political party) of(I-political party) Freedom(I-political party) and(O) the(O) Democratic(B-political party) Party(I-political party),(O) along(O) with(O) other(O) minor(O) political(O) forces(O),(O) supported(O) the(O) Monti(B-politician) cabinet(O),(O) and(O) eventually(O),(O) after(O) the(O) 2013(B-election) Italian(I-election) general(I-election) election(I-election),(O) formed(O) a(O) grand(O) coalition(O) in(O) support(O) of(O) the(O) Letta(B-politician) Cabinet(O),(O) which(O),(O) however(O),(O) was(O) opposed(O) by(O) a(O) new(O) major(O) political(O) force(O) in(O) parliament(O),(O) the(O) anti-establishment(B-political party) Five(I-political party) Star(I-political party) Movement(I-political party).(O)"}
{"id": "590", "dataset": "crossner_politics", "split": "test", "label_list": ["country", "election", "organization", "event", "politician", "location", "person", "political party"], "instance": {"id": "590", "words": ["The", "air", "raid", "was", "part", "of", "the", "Allies", "of", "World", "War", "II", "'", "aerial", "campaign", "against", "the", "Home", "Islands", "of", "the", "Empire", "of", "Japan", "during", "World", "War", "II", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-country", "O", "B-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "I-country", "I-country", "O", "B-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, election, organization, event, politician, location, person, political party and O.\nSentence: The air raid was part of the Allies of World War II ' aerial campaign against the Home Islands of the Empire of Japan during World War II .", "prompt_labels": "The(O) air(O) raid(O) was(O) part(O) of(O) the(O) Allies(B-country) of(O) World(B-event) War(I-event) II(I-event) '(O) aerial(O) campaign(O) against(O) the(O) Home(O) Islands(O) of(O) the(O) Empire(B-country) of(I-country) Japan(I-country) during(O) World(B-event) War(I-event) II(I-event) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 6355, 11, 7471, 11, 1567, 11, 37038, 11, 3813, 11, 1732, 11, 5054, 4717, 323, 507, 627, 85664, 25, 578, 3805, 25834, 574, 961, 315, 279, 81774, 315, 4435, 5111, 8105, 364, 41884, 4901, 2403, 279, 5492, 23028, 315, 279, 21080, 315, 6457, 2391, 4435, 5111, 8105, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) air(O) raid(O) was(O) part(O) of(O) the(O) Allies(B-organization) of(I-organization) World(I-organization) War(I-organization) II(I-organization) '(O) aerial(O) campaign(O) against(O) the(O) Home(O) Islands(O) of(O) the(O) Empire(B-country) of(I-country) Japan(I-country) during(O) World(B-event) War(I-event) II(I-event).(O)"}
{"id": "271", "dataset": "mit-restaurant", "split": "test", "label_list": ["Price", "Rating", "Restaurant Name", "Amenity", "Location", "Cuisine", "Hours", "Dish"], "instance": {"id": "271", "words": ["do", "you", "think", "the", "noodle", "bar", "is", "open"], "labels": ["O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Rating, Restaurant Name, Amenity, Location, Cuisine, Hours, Dish and O.\nSentence: do you think the noodle bar is open", "prompt_labels": "do(O) you(O) think(O) the(O) noodle(B-Restaurant Name) bar(I-Restaurant Name) is(O) open(B-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 19767, 11, 26568, 4076, 11, 3383, 56685, 11, 10067, 11, 81961, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 656, 499, 1781, 279, 46895, 273, 3703, 374, 1825, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "do(O) you(O) think(O) the(O) noodle(B-Restaurant Name) bar(I-Restaurant Name) is(O) open(B-Hours)"}
{"id": "265", "dataset": "crossner_science", "split": "test", "label_list": ["university", "chemical compound", "protein", "theory", "event", "academic journal", "discipline", "enzyme", "award", "person", "organization", "scientist", "astronomical object", "chemical element", "country", "location"], "instance": {"id": "265", "words": ["There", "is", "some", "information", "about", "earthquakes", "in", "Aristotle", "'", "s", "Meteorology", ",", "in", "Naturalis", "Historia", "by", "Pliny", "the", "Elder", ",", "and", "in", "Strabo", "'", "s", "Geographica", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-scientist", "O", "O", "B-discipline", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "B-scientist", "O", "O", "B-discipline", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical compound, protein, theory, event, academic journal, discipline, enzyme, award, person, organization, scientist, astronomical object, chemical element, country, location and O.\nSentence: There is some information about earthquakes in Aristotle ' s Meteorology , in Naturalis Historia by Pliny the Elder , and in Strabo ' s Geographica .", "prompt_labels": "There(O) is(O) some(O) information(O) about(O) earthquakes(O) in(O) Aristotle(B-scientist) '(O) s(O) Meteorology(B-discipline) ,(O) in(O) Naturalis(O) Historia(O) by(O) Pliny(B-person) the(I-person) Elder(I-person) ,(O) and(O) in(O) Strabo(B-scientist) '(O) s(O) Geographica(B-discipline) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 24549, 11, 13128, 11, 10334, 11, 1567, 11, 14584, 8486, 11, 26434, 11, 49242, 11, 10292, 11, 1732, 11, 7471, 11, 28568, 11, 87283, 1665, 11, 11742, 2449, 11, 3224, 11, 3813, 323, 507, 627, 85664, 25, 2684, 374, 1063, 2038, 922, 66579, 304, 79001, 364, 274, 40732, 2508, 1174, 304, 18955, 285, 22425, 689, 555, 1856, 6577, 279, 39669, 1174, 323, 304, 4610, 48521, 364, 274, 4323, 3257, 3074, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "There(O) is(O) some(O) information(O) about(O) earthquakes(O) in(O) Aristotle(B-person) '(O) s(O) Meteorology(B-book),(O) in(O) Naturalis(B-book) Historia(I-book) by(O) Pliny(B-scientist) the(I-scientist) Elder(I-scientist),(O) and(O) in(O) Strabo(B-person) '(O) s(O) Geographica(B-book).(O)"}
{"id": "1240", "dataset": "mit-restaurant", "split": "test", "label_list": ["Location", "Amenity", "Cuisine", "Hours", "Price", "Dish", "Restaurant Name", "Rating"], "instance": {"id": "1240", "words": ["whats", "the", "most", "popular", "steak", "house", "around", "here"], "labels": ["O", "O", "O", "B-Rating", "B-Cuisine", "I-Cuisine", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Cuisine, Hours, Price, Dish, Restaurant Name, Rating and O.\nSentence: whats the most popular steak house around here", "prompt_labels": "whats(O) the(O) most(O) popular(B-Rating) steak(B-Cuisine) house(I-Cuisine) around(B-Location) here(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 81961, 11, 30192, 11, 8650, 11, 49268, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 41209, 279, 1455, 5526, 50059, 3838, 2212, 1618, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "whats(O) the(O) most(B-Rating) popular(I-Rating) steak(B-Cuisine) house(I-Cuisine) around(B-Location) here(I-Location)"}
{"id": "169", "dataset": "crossner_politics", "split": "test", "label_list": ["organization", "political party", "politician", "location", "event", "election", "person", "country"], "instance": {"id": "169", "words": ["Personal", "exhibitions", "include", "such", "as", "Janos", "Gallery", "in", "New", "York", "City", "(", "1993", ")", ";", "Place", "de", "M\u00e9diath\u00e8que", "in", "France", "(", "1995", ")", ";", "Acud", "in", "Berlin", "(", "1993", ")", ";", "S\u00e3o", "Paulo", "in", "Brazil", "(", "1994", ")", ";", "Israel", "(", "1995", ")", ";", "National", "Art", "Gallery", "in", "Tirana", ",", "Albania", "(", "1992", ")", ";", "and", "Gallery", "XXI", "in", "Albania", "(", "1999", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "I-location", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O", "B-location", "I-location", "O", "B-country", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, political party, politician, location, event, election, person, country and O.\nSentence: Personal exhibitions include such as Janos Gallery in New York City ( 1993 ) ; Place de M\u00e9diath\u00e8que in France ( 1995 ) ; Acud in Berlin ( 1993 ) ; S\u00e3o Paulo in Brazil ( 1994 ) ; Israel ( 1995 ) ; National Art Gallery in Tirana , Albania ( 1992 ) ; and Gallery XXI in Albania ( 1999 ) .", "prompt_labels": "Personal(O) exhibitions(O) include(O) such(O) as(O) Janos(O) Gallery(O) in(O) New(B-location) York(I-location) City(I-location) ((O) 1993(O) )(O) ;(O) Place(O) de(O) M\u00e9diath\u00e8que(O) in(O) France(B-country) ((O) 1995(O) )(O) ;(O) Acud(O) in(O) Berlin(B-location) ((O) 1993(O) )(O) ;(O) S\u00e3o(B-location) Paulo(I-location) in(O) Brazil(B-country) ((O) 1994(O) )(O) ;(O) Israel(B-country) ((O) 1995(O) )(O) ;(O) National(O) Art(O) Gallery(O) in(O) Tirana(B-location) ,(O) Albania(B-country) ((O) 1992(O) )(O) ;(O) and(O) Gallery(O) XXI(O) in(O) Albania(B-location) ((O) 1999(O) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 5054, 4717, 11, 37038, 11, 3813, 11, 1567, 11, 6355, 11, 1732, 11, 3224, 323, 507, 627, 85664, 25, 19758, 70864, 2997, 1778, 439, 4448, 437, 19853, 304, 1561, 4356, 4409, 320, 220, 2550, 18, 883, 2652, 11004, 409, 44031, 8747, 589, 4558, 593, 304, 9822, 320, 220, 2550, 20, 883, 2652, 6515, 664, 304, 20437, 320, 220, 2550, 18, 883, 2652, 48790, 38026, 304, 16327, 320, 220, 2550, 19, 883, 2652, 6921, 320, 220, 2550, 20, 883, 2652, 5165, 5277, 19853, 304, 83655, 3444, 1174, 95733, 320, 220, 2550, 17, 883, 2652, 323, 19853, 30388, 40, 304, 95733, 320, 220, 2550, 24, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Personal exhibitions(O) include(O) such(O) as(O) Janos(B-gallery) Gallery(I-gallery) in(O) New(B-location) York(I-location) City(I-location) ((O) 1993(O) )(O) ;(O) Place(B-location) de(I-location) M\u00e9diath\u00e8que(I-location) in(O) France(B-country) ((O) 1995(O) )(O) ;(O) Acud(B-location) in(O) Berlin(B-location) ((O) 1993(O) )(O) ;(O) S\u00e3o(B-location) Paulo(I-location) in(O) Brazil(B-country) ((O) 1994(O) )(O) ;(O) Israel(B-country) ((O) 1995(O) )(O) ;(O) National(B-location) Art(I-location) Gallery(I-location) in(O) Tirana(B-location),(O) Albania(B-country) ((O) 1992(O) )(O) ;(O) and(O) Gallery(B-location) XXI(I-location) in(O) Albania(B-country) ((O) 1999(O) )(O).(O)"}
{"id": "468", "dataset": "mit-restaurant", "split": "test", "label_list": ["Dish", "Rating", "Restaurant Name", "Price", "Cuisine", "Hours", "Location", "Amenity"], "instance": {"id": "468", "words": ["give", "me", "the", "closest", "place", "that", "does", "sushi"], "labels": ["O", "O", "O", "B-Location", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Rating, Restaurant Name, Price, Cuisine, Hours, Location, Amenity and O.\nSentence: give me the closest place that does sushi", "prompt_labels": "give(O) me(O) the(O) closest(B-Location) place(O) that(O) does(O) sushi(B-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 19767, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 30192, 11, 10067, 11, 3383, 56685, 323, 507, 627, 85664, 25, 3041, 757, 279, 18585, 2035, 430, 1587, 67322, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "give(O) me(O) the(O) closest(B-Location) place(O) that(O) does(O) sushi(B-Cuisine)"}
{"id": "1590", "dataset": "mit-movie", "split": "test", "label_list": ["title", "trailer", "average ratings", "character", "actor", "rating", "plot", "year", "song", "director", "genre", "review"], "instance": {"id": "1590", "words": ["list", "a", "christopher", "lloyd", "animation", "movie", "from", "the", "past", "nine", "years"], "labels": ["O", "O", "B-actor", "I-actor", "B-genre", "O", "O", "O", "B-year", "I-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, trailer, average ratings, character, actor, rating, plot, year, song, director, genre, review and O.\nSentence: list a christopher lloyd animation movie from the past nine years", "prompt_labels": "list(O) a(O) christopher(B-actor) lloyd(I-actor) animation(B-genre) movie(O) from(O) the(O) past(B-year) nine(I-year) years(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 19809, 11, 5578, 18594, 11, 3752, 11, 12360, 11, 10959, 11, 7234, 11, 1060, 11, 5609, 11, 7690, 11, 17779, 11, 3477, 323, 507, 627, 85664, 25, 1160, 264, 26853, 17370, 326, 26881, 10571, 5818, 505, 279, 3347, 11888, 1667, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "list(O) a(O) christopher(B-actor) lloyd(I-actor) animation(B-genre) movie(O) from(O) the(O) past(B-year) nine(I-year) years(I-year)"}
{"id": "104", "dataset": "crossner_science", "split": "test", "label_list": ["university", "chemical element", "theory", "chemical compound", "discipline", "astronomical object", "protein", "country", "scientist", "event", "award", "organization", "enzyme", "academic journal", "person", "location"], "instance": {"id": "104", "words": ["It", "is", "probably", "the", "fifth-", "most-massive", "asteroid", "after", "Ceres", ",", "4", "Vesta", ",", "2", "Pallas", ",", "and", "10", "Hygiea", ",", "with", "a", "mass", "estimated", "to", "be", "1.2", "%", "of", "the", "mass", "of", "the", "entire", "asteroid", "belt", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O", "B-astronomical object", "I-astronomical object", "O", "O", "B-astronomical object", "I-astronomical object", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical element, theory, chemical compound, discipline, astronomical object, protein, country, scientist, event, award, organization, enzyme, academic journal, person, location and O.\nSentence: It is probably the fifth- most-massive asteroid after Ceres , 4 Vesta , 2 Pallas , and 10 Hygiea , with a mass estimated to be 1.2 % of the mass of the entire asteroid belt .", "prompt_labels": "It(O) is(O) probably(O) the(O) fifth-(O) most-massive(O) asteroid(O) after(O) Ceres(B-astronomical object) ,(O) 4(B-astronomical object) Vesta(I-astronomical object) ,(O) 2(B-astronomical object) Pallas(I-astronomical object) ,(O) and(O) 10(B-astronomical object) Hygiea(I-astronomical object) ,(O) with(O) a(O) mass(O) estimated(O) to(O) be(O) 1.2(O) %(O) of(O) the(O) mass(O) of(O) the(O) entire(O) asteroid(O) belt(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 11742, 2449, 11, 10334, 11, 11742, 24549, 11, 26434, 11, 87283, 1665, 11, 13128, 11, 3224, 11, 28568, 11, 1567, 11, 10292, 11, 7471, 11, 49242, 11, 14584, 8486, 11, 1732, 11, 3813, 323, 507, 627, 85664, 25, 1102, 374, 4762, 279, 18172, 12, 1455, 1474, 395, 535, 55479, 1306, 356, 13213, 1174, 220, 19, 650, 30279, 1174, 220, 17, 393, 16242, 1174, 323, 220, 605, 10320, 22235, 64, 1174, 449, 264, 3148, 13240, 311, 387, 220, 16, 13, 17, 1034, 315, 279, 3148, 315, 279, 4553, 55479, 19671, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "It(O) is(O) probably(O) the(O) fifth-(O) most-massive(O) asteroid(O) after(O) Ceres(B-astronomical object),(O) 4(B-astronomical object) Vesta(I-astronomical object),(O) 2(B-astronomical object) Pallas(I-astronomical object),(O) and(O) 10(B-astronomical object) Hygiea(I-astronomical object),(O) with(O) a(O) mass(O) estimated(O) to(O) be(O) 1.2(O) %(O) of(O) the(O) mass(O) of(O) the(O) entire(O) asteroid(O) belt(O).(O)"}
{"id": "399", "dataset": "crossner_ai", "split": "test", "label_list": ["task", "programming language", "university", "organization", "conference", "person", "algorithm", "country", "metric", "field", "researcher", "product", "location"], "instance": {"id": "399", "words": ["This", "is", "a", "particular", "way", "of", "implementing", "maximum", "likelihood", "estimation", "for", "this", "problem", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "B-metric", "I-metric", "I-metric", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, programming language, university, organization, conference, person, algorithm, country, metric, field, researcher, product, location and O.\nSentence: This is a particular way of implementing maximum likelihood estimation for this problem .", "prompt_labels": "This(O) is(O) a(O) particular(O) way(O) of(O) implementing(O) maximum(B-metric) likelihood(I-metric) estimation(I-metric) for(O) this(O) problem(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3465, 11, 15840, 4221, 11, 12374, 11, 7471, 11, 10017, 11, 1732, 11, 12384, 11, 3224, 11, 18767, 11, 2115, 11, 32185, 11, 2027, 11, 3813, 323, 507, 627, 85664, 25, 1115, 374, 264, 4040, 1648, 315, 25976, 7340, 29736, 42304, 369, 420, 3575, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "This(O) is(O) a(O) particular(O) way(O) of(O) implementing(O) maximum(B-metric) likelihood(I-metric) estimation(O) for(O) this(O) problem(O).(O)"}
{"id": "174", "dataset": "crossner_literature", "split": "test", "label_list": ["literary genre", "magazine", "person", "location", "poem", "event", "award", "book", "writer", "organization", "country"], "instance": {"id": "174", "words": ["In", "recognition", "of", "his", "work", "with", "electricity", ",", "Franklin", "received", "the", "Royal", "Society", "'", "s", "Copley", "Medal", "in", "1753", ",", "and", "in", "1756", ",", "he", "became", "one", "of", "the", "few", "18th-century", "Americans", "elected", "as", "a", "Fellow", "of", "the", "Society", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-person", "O", "O", "B-organization", "I-organization", "O", "O", "B-award", "I-award", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: literary genre, magazine, person, location, poem, event, award, book, writer, organization, country and O.\nSentence: In recognition of his work with electricity , Franklin received the Royal Society ' s Copley Medal in 1753 , and in 1756 , he became one of the few 18th-century Americans elected as a Fellow of the Society .", "prompt_labels": "In(O) recognition(O) of(O) his(O) work(O) with(O) electricity(O) ,(O) Franklin(B-person) received(O) the(O) Royal(B-organization) Society(I-organization) '(O) s(O) Copley(B-award) Medal(I-award) in(O) 1753(O) ,(O) and(O) in(O) 1756(O) ,(O) he(O) became(O) one(O) of(O) the(O) few(O) 18th-century(O) Americans(O) elected(O) as(O) a(O) Fellow(B-award) of(I-award) the(I-award) Society(I-award) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32465, 17779, 11, 14756, 11, 1732, 11, 3813, 11, 33894, 11, 1567, 11, 10292, 11, 2363, 11, 7061, 11, 7471, 11, 3224, 323, 507, 627, 85664, 25, 763, 18324, 315, 813, 990, 449, 18200, 1174, 19372, 4036, 279, 16591, 13581, 364, 274, 356, 1184, 88, 17867, 304, 220, 10005, 18, 1174, 323, 304, 220, 10005, 21, 1174, 568, 6244, 832, 315, 279, 2478, 220, 972, 339, 34457, 9053, 16689, 439, 264, 37946, 315, 279, 13581, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) recognition(O) of(O) his(O) work(O) with(O) electricity(B-organization),(O) Franklin(B-writer) received(O) the(O) Royal(B-award) Society(I-award) '(I-award) s(I-award) Copley(I-award) Medal(I-award) in(O) 1753(O),(O) and(O) in(O) 1756(O),(O) he(O) became(O) one(O) of(O) the(O) few(O) 18th-century(O) Americans(O) elected(O) as(O) a(O) Fellow(B-award) of(I-award) the(I-award) Society(I-award).(O)"}
{"id": "1054", "dataset": "mit-movie", "split": "test", "label_list": ["director", "title", "song", "rating", "review", "year", "trailer", "average ratings", "character", "plot", "actor", "genre"], "instance": {"id": "1054", "words": ["a", "1980", "well", "rated", "pg", "13", "that", "involves", "fighting", "of", "any", "kind"], "labels": ["O", "B-year", "B-average ratings", "I-average ratings", "B-rating", "I-rating", "O", "O", "B-plot", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, title, song, rating, review, year, trailer, average ratings, character, plot, actor, genre and O.\nSentence: a 1980 well rated pg 13 that involves fighting of any kind", "prompt_labels": "a(O) 1980(B-year) well(B-average ratings) rated(I-average ratings) pg(B-rating) 13(I-rating) that(O) involves(O) fighting(B-plot) of(O) any(O) kind(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 2316, 11, 5609, 11, 10959, 11, 3477, 11, 1060, 11, 19809, 11, 5578, 18594, 11, 3752, 11, 7234, 11, 12360, 11, 17779, 323, 507, 627, 85664, 25, 264, 220, 3753, 15, 1664, 22359, 17953, 220, 1032, 430, 18065, 11039, 315, 904, 3169, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "a(O) 1980(B-year) well(B-average ratings) rated(I-average ratings) pg(B-rating) 13(I-rating) that(O) involves(O) fighting(B-plot) of(O) any(O) kind(O)"}
{"id": "146", "dataset": "crossner_science", "split": "test", "label_list": ["academic journal", "award", "theory", "organization", "person", "country", "chemical element", "protein", "discipline", "chemical compound", "location", "astronomical object", "scientist", "university", "event", "enzyme"], "instance": {"id": "146", "words": ["Alessandra", "Becatti", "(", "born", "30", "April", "1965", ")", "is", "an", "Italy", "female", "retired", "heptathlete", ",", "which", "participated", "at", "the", "1987", "World", "Championships", "in", "Athletics", "."], "labels": ["B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, award, theory, organization, person, country, chemical element, protein, discipline, chemical compound, location, astronomical object, scientist, university, event, enzyme and O.\nSentence: Alessandra Becatti ( born 30 April 1965 ) is an Italy female retired heptathlete , which participated at the 1987 World Championships in Athletics .", "prompt_labels": "Alessandra(B-person) Becatti(I-person) ((O) born(O) 30(O) April(O) 1965(O) )(O) is(O) an(O) Italy(B-country) female(O) retired(O) heptathlete(O) ,(O) which(O) participated(O) at(O) the(O) 1987(B-event) World(I-event) Championships(I-event) in(I-event) Athletics(I-event) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 14584, 8486, 11, 10292, 11, 10334, 11, 7471, 11, 1732, 11, 3224, 11, 11742, 2449, 11, 13128, 11, 26434, 11, 11742, 24549, 11, 3813, 11, 87283, 1665, 11, 28568, 11, 12374, 11, 1567, 11, 49242, 323, 507, 627, 85664, 25, 70885, 24155, 32146, 32055, 320, 9405, 220, 966, 5936, 220, 5162, 20, 883, 374, 459, 15704, 8954, 22311, 568, 418, 91044, 1174, 902, 31408, 520, 279, 220, 3753, 22, 4435, 48854, 304, 70831, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Alessandra(B-person) Becatti(I-person) ((O) born(O) 30(O) April(O) 1965(O) )(O) is(O) an(O) Italy(B-country) female(O) retired(O) heptathlete(O),(O) which(O) participated(O) at(O) the(O) 1987(B-event) World(I-event) Championships(I-event) in(I-event) Athletics(I-event).(O)"}
{"id": "1624", "dataset": "mit-movie", "split": "test", "label_list": ["plot", "review", "genre", "rating", "director", "actor", "trailer", "character", "average ratings", "year", "song", "title"], "instance": {"id": "1624", "words": ["list", "a", "movie", "wall", "e"], "labels": ["O", "O", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, review, genre, rating, director, actor, trailer, character, average ratings, year, song, title and O.\nSentence: list a movie wall e", "prompt_labels": "list(O) a(O) movie(O) wall(B-title) e(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 3477, 11, 17779, 11, 10959, 11, 7690, 11, 12360, 11, 19809, 11, 3752, 11, 5578, 18594, 11, 1060, 11, 5609, 11, 2316, 323, 507, 627, 85664, 25, 1160, 264, 5818, 7147, 384, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "list(O) a(O) movie(O) wall(B-title) e(I-title)"}
{"id": "213", "dataset": "crossner_politics", "split": "test", "label_list": ["person", "politician", "country", "event", "political party", "location", "election", "organization"], "instance": {"id": "213", "words": ["He", "quickly", "became", "active", "in", "the", "party", ",", "making", "two", "sacrificial-lamb", "bids", "for", "Parliament", "against", "entrenched", "but", "vulnerable", "New", "Zealand", "Labour", "Party", "incumbents", "in", "1954", "New", "Zealand", "general", "election", "(", "Mount", "Albert", ")", "and", "1957", "New", "Zealand", "general", "election", "(", "Waitemata", ")", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-political party", "I-political party", "I-political party", "I-political party", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-location", "I-location", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "B-location", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, country, event, political party, location, election, organization and O.\nSentence: He quickly became active in the party , making two sacrificial-lamb bids for Parliament against entrenched but vulnerable New Zealand Labour Party incumbents in 1954 New Zealand general election ( Mount Albert ) and 1957 New Zealand general election ( Waitemata ) .", "prompt_labels": "He(O) quickly(O) became(O) active(O) in(O) the(O) party(O) ,(O) making(O) two(O) sacrificial-lamb(O) bids(O) for(O) Parliament(O) against(O) entrenched(O) but(O) vulnerable(O) New(B-political party) Zealand(I-political party) Labour(I-political party) Party(I-political party) incumbents(O) in(O) 1954(B-election) New(I-election) Zealand(I-election) general(I-election) election(I-election) ((O) Mount(B-location) Albert(I-location) )(O) and(O) 1957(B-election) New(I-election) Zealand(I-election) general(I-election) election(I-election) ((O) Waitemata(B-location) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 37038, 11, 3224, 11, 1567, 11, 5054, 4717, 11, 3813, 11, 6355, 11, 7471, 323, 507, 627, 85664, 25, 1283, 6288, 6244, 4642, 304, 279, 4717, 1174, 3339, 1403, 17475, 16895, 2922, 3042, 44599, 369, 20302, 2403, 82144, 719, 20134, 1561, 17340, 18993, 8722, 43850, 812, 304, 220, 6280, 19, 1561, 17340, 4689, 6355, 320, 10640, 17971, 883, 323, 220, 6280, 22, 1561, 17340, 4689, 6355, 320, 29614, 1224, 460, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "He(O) quickly(O) became(O) active(O) in(O) the(O) party(O),(O) making(O) two(O) sacrificial-lamb(O) bids(O) for(O) Parliament(O) against(O) entrenched(O) but(O) vulnerable(O) New(B-political party) Zealand(I-political party) Labour(I-political party) Party(I-political party) incumbents(O) in(O) 1954(B-election) New(I-election) Zealand(I-election) general(I-election) election(I-election) ((O) Mount(B-location) Albert(I-location) )(O) and(O) 1957(B-election) New(I-election) Zealand(I-election) general(I-election) election(I-election) ((O) Waitemata(B-location) )(O).(O)"}
{"id": "970", "dataset": "mit-movie", "split": "test", "label_list": ["character", "director", "review", "actor", "year", "average ratings", "genre", "trailer", "plot", "song", "title", "rating"], "instance": {"id": "970", "words": ["find", "all", "movies", "starring", "elvis", "presley"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, director, review, actor, year, average ratings, genre, trailer, plot, song, title, rating and O.\nSentence: find all movies starring elvis presley", "prompt_labels": "find(O) all(O) movies(O) starring(O) elvis(B-actor) presley(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 7690, 11, 3477, 11, 12360, 11, 1060, 11, 5578, 18594, 11, 17779, 11, 19809, 11, 7234, 11, 5609, 11, 2316, 11, 10959, 323, 507, 627, 85664, 25, 1505, 682, 9698, 40500, 658, 2749, 1685, 3258, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) all(O) movies(O) starring(O) elvis(B-actor) presley(I-actor)"}
{"id": "1179", "dataset": "mit-movie", "split": "test", "label_list": ["year", "character", "actor", "trailer", "song", "title", "rating", "review", "genre", "average ratings", "plot", "director"], "instance": {"id": "1179", "words": ["did", "vivien", "leigh", "act", "in", "any", "historical", "movies", "in", "the", "1950", "s"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "B-genre", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, character, actor, trailer, song, title, rating, review, genre, average ratings, plot, director and O.\nSentence: did vivien leigh act in any historical movies in the 1950 s", "prompt_labels": "did(O) vivien(B-actor) leigh(I-actor) act(O) in(O) any(O) historical(B-genre) movies(O) in(O) the(O) 1950(B-year) s(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3752, 11, 12360, 11, 19809, 11, 5609, 11, 2316, 11, 10959, 11, 3477, 11, 17779, 11, 5578, 18594, 11, 7234, 11, 7690, 323, 507, 627, 85664, 25, 1550, 18434, 3675, 514, 1108, 1180, 304, 904, 13970, 9698, 304, 279, 220, 6280, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "did(O) vivien(B-actor) leigh(I-actor) act(O) in(O) any(O) historical(B-genre) movies(O) in(O) the(O) 1950(B-year) s(I-year)"}
{"id": "1418", "dataset": "mit-restaurant", "split": "test", "label_list": ["Price", "Amenity", "Cuisine", "Location", "Dish", "Rating", "Hours", "Restaurant Name"], "instance": {"id": "1418", "words": ["where", "is", "the", "closest", "place", "to", "get", "pizza"], "labels": ["O", "O", "O", "B-Location", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Cuisine, Location, Dish, Rating, Hours, Restaurant Name and O.\nSentence: where is the closest place to get pizza", "prompt_labels": "where(O) is(O) the(O) closest(B-Location) place(O) to(O) get(O) pizza(B-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 3383, 56685, 11, 81961, 11, 10067, 11, 49268, 11, 19767, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1405, 374, 279, 18585, 2035, 311, 636, 23317, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) is(O) the(O) closest(B-Location) place(O) to(O) get(O) pizza(B-Dish)"}
{"id": "280", "dataset": "mit-restaurant", "split": "test", "label_list": ["Restaurant Name", "Hours", "Cuisine", "Price", "Dish", "Amenity", "Rating", "Location"], "instance": {"id": "280", "words": ["does", "chuck", "e", "cheeses", "have", "drive", "thru"], "labels": ["O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Hours, Cuisine, Price, Dish, Amenity, Rating, Location and O.\nSentence: does chuck e cheeses have drive thru", "prompt_labels": "does(O) chuck(B-Restaurant Name) e(I-Restaurant Name) cheeses(I-Restaurant Name) have(O) drive(B-Amenity) thru(I-Amenity)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 30192, 11, 81961, 11, 8650, 11, 49268, 11, 3383, 56685, 11, 19767, 11, 10067, 323, 507, 627, 85664, 25, 1587, 43560, 384, 98564, 617, 6678, 41178, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "does(O) chuck(B-Restaurant Name) e(I-Restaurant Name) cheeses(I-Restaurant Name) have(O) drive(B-Amenity) thru(I-Amenity)"}
{"id": "418", "dataset": "mit-movie", "split": "test", "label_list": ["actor", "song", "character", "average ratings", "year", "director", "review", "genre", "plot", "trailer", "rating", "title"], "instance": {"id": "418", "words": ["what", "movies", "did", "judy", "garland", "star", "in"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, song, character, average ratings, year, director, review, genre, plot, trailer, rating, title and O.\nSentence: what movies did judy garland star in", "prompt_labels": "what(O) movies(O) did(O) judy(B-actor) garland(I-actor) star(O) in(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 5609, 11, 3752, 11, 5578, 18594, 11, 1060, 11, 7690, 11, 3477, 11, 17779, 11, 7234, 11, 19809, 11, 10959, 11, 2316, 323, 507, 627, 85664, 25, 1148, 9698, 1550, 5860, 88, 7515, 1974, 6917, 304, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) movies(O) did(O) judy(B-actor) garland(I-actor) star(O) in(O)"}
{"id": "1220", "dataset": "mit-restaurant", "split": "test", "label_list": ["Restaurant Name", "Location", "Price", "Hours", "Dish", "Cuisine", "Amenity", "Rating"], "instance": {"id": "1220", "words": ["what", "vegetarian", "options", "does", "zaxbys", "offer"], "labels": ["O", "O", "O", "O", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Price, Hours, Dish, Cuisine, Amenity, Rating and O.\nSentence: what vegetarian options does zaxbys offer", "prompt_labels": "what(O) vegetarian(O) options(O) does(O) zaxbys(B-Restaurant Name) offer(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 8650, 11, 30192, 11, 49268, 11, 81961, 11, 3383, 56685, 11, 19767, 323, 507, 627, 85664, 25, 1148, 46482, 2671, 1587, 1167, 710, 65, 1065, 3085, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) vegetarian(B-Cuisine) options(O) does(O) zaxbys(B-Restaurant Name) offer(O)"}
{"id": "1499", "dataset": "mit-movie", "split": "test", "label_list": ["song", "trailer", "actor", "plot", "title", "director", "rating", "genre", "character", "review", "year", "average ratings"], "instance": {"id": "1499", "words": ["is", "there", "a", "highly", "rated", "drama", "film", "that", "stars", "julie", "andrews"], "labels": ["O", "O", "O", "B-average ratings", "I-average ratings", "B-genre", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, trailer, actor, plot, title, director, rating, genre, character, review, year, average ratings and O.\nSentence: is there a highly rated drama film that stars julie andrews", "prompt_labels": "is(O) there(O) a(O) highly(B-average ratings) rated(I-average ratings) drama(B-genre) film(O) that(O) stars(O) julie(B-actor) andrews(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 19809, 11, 12360, 11, 7234, 11, 2316, 11, 7690, 11, 10959, 11, 17779, 11, 3752, 11, 3477, 11, 1060, 11, 5578, 18594, 323, 507, 627, 85664, 25, 374, 1070, 264, 7701, 22359, 20156, 4632, 430, 9958, 41638, 648, 323, 4361, 82, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) a(O) highly(B-average ratings) rated(I-average ratings) drama(B-genre) film(O) that(O) stars(O) julie(B-actor) andrews(I-actor)"}
{"id": "1460", "dataset": "mit-restaurant", "split": "test", "label_list": ["Amenity", "Dish", "Location", "Cuisine", "Hours", "Price", "Restaurant Name", "Rating"], "instance": {"id": "1460", "words": ["where", "is", "wing", "stop"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Dish, Location, Cuisine, Hours, Price, Restaurant Name, Rating and O.\nSentence: where is wing stop", "prompt_labels": "where(O) is(O) wing(B-Restaurant Name) stop(I-Restaurant Name)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 49268, 11, 10067, 11, 81961, 11, 30192, 11, 8650, 11, 26568, 4076, 11, 19767, 323, 507, 627, 85664, 25, 1405, 374, 20611, 3009, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) is(O) wing(B-Restaurant Name) stop(I-Restaurant Name)"}
{"id": "482", "dataset": "mit-movie", "split": "test", "label_list": ["actor", "review", "plot", "genre", "director", "average ratings", "trailer", "song", "rating", "character", "title", "year"], "instance": {"id": "482", "words": ["show", "me", "a", "non", "peter", "sellers", "film", "where", "the", "lead", "actor", "plays", "just", "one", "role"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: actor, review, plot, genre, director, average ratings, trailer, song, rating, character, title, year and O.\nSentence: show me a non peter sellers film where the lead actor plays just one role", "prompt_labels": "show(O) me(O) a(O) non(O) peter(B-actor) sellers(I-actor) film(O) where(O) the(O) lead(O) actor(O) plays(O) just(O) one(O) role(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12360, 11, 3477, 11, 7234, 11, 17779, 11, 7690, 11, 5578, 18594, 11, 19809, 11, 5609, 11, 10959, 11, 3752, 11, 2316, 11, 1060, 323, 507, 627, 85664, 25, 1501, 757, 264, 2536, 95087, 37249, 4632, 1405, 279, 3063, 12360, 11335, 1120, 832, 3560, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) a(O) non(O) peter(B-actor) sellers(I-actor) film(O) where(O) the(O) lead(B-plot) actor(I-plot) plays(I-plot) just(I-plot) one(I-plot) role(I-plot)"}
{"id": "1395", "dataset": "mit-restaurant", "split": "test", "label_list": ["Price", "Amenity", "Restaurant Name", "Location", "Cuisine", "Hours", "Rating", "Dish"], "instance": {"id": "1395", "words": ["where", "is", "roosevelts", "restaurant", "and", "sin", "in", "framingham"], "labels": ["O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name", "O", "B-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Amenity, Restaurant Name, Location, Cuisine, Hours, Rating, Dish and O.\nSentence: where is roosevelts restaurant and sin in framingham", "prompt_labels": "where(O) is(O) roosevelts(B-Restaurant Name) restaurant(I-Restaurant Name) and(I-Restaurant Name) sin(I-Restaurant Name) in(O) framingham(B-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 3383, 56685, 11, 26568, 4076, 11, 10067, 11, 81961, 11, 30192, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 1405, 374, 938, 974, 899, 2641, 10960, 323, 7589, 304, 59049, 5721, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) is(O) roosevelts(B-Restaurant Name) restaurant(I-Restaurant Name) and(I-Restaurant Name) sin(I-Restaurant Name) in(O) framingham(B-Location)"}
{"id": "68", "dataset": "crossner_politics", "split": "test", "label_list": ["politician", "organization", "election", "event", "country", "person", "location", "political party"], "instance": {"id": "68", "words": ["In", "a", "nod", "to", "the", "deep", "US", "political", "divide", "between", "Republicans", "led", "by", "Mitt", "Romney", "and", "the", "Democrats", "of", "Barack", "Obama", "-", "then", "battling", "to", "win", "the", "2012", "United", "States", "presidential", "election", "-", "she", "stressed", ",", "Those", "of", "you", "who", "are", "familiar", "with", "American", "politics", "I", "'m", "sure", "understand", "the", "need", "for", "negotiated", "compromise", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-country", "O", "O", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "B-politician", "I-politician", "O", "O", "O", "O", "O", "O", "B-election", "I-election", "I-election", "I-election", "I-election", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, organization, election, event, country, person, location, political party and O.\nSentence: In a nod to the deep US political divide between Republicans led by Mitt Romney and the Democrats of Barack Obama - then battling to win the 2012 United States presidential election - she stressed , Those of you who are familiar with American politics I 'm sure understand the need for negotiated compromise .", "prompt_labels": "In(O) a(O) nod(O) to(O) the(O) deep(O) US(B-country) political(O) divide(O) between(O) Republicans(O) led(O) by(O) Mitt(B-politician) Romney(I-politician) and(O) the(O) Democrats(O) of(O) Barack(B-politician) Obama(I-politician) -(O) then(O) battling(O) to(O) win(O) the(O) 2012(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) -(O) she(O) stressed(O) ,(O) Those(O) of(O) you(O) who(O) are(O) familiar(O) with(O) American(O) politics(O) I(O) 'm(O) sure(O) understand(O) the(O) need(O) for(O) negotiated(O) compromise(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 7471, 11, 6355, 11, 1567, 11, 3224, 11, 1732, 11, 3813, 11, 5054, 4717, 323, 507, 627, 85664, 25, 763, 264, 16387, 311, 279, 5655, 2326, 5054, 22497, 1990, 13063, 6197, 555, 33718, 26386, 323, 279, 12643, 315, 24448, 7250, 482, 1243, 47336, 311, 3243, 279, 220, 679, 17, 3723, 4273, 13621, 6355, 482, 1364, 32647, 1174, 13266, 315, 499, 889, 527, 11537, 449, 3778, 11759, 358, 364, 76, 2771, 3619, 279, 1205, 369, 51578, 30485, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) a(O) nod(O) to(O) the(O) deep(O) US(O) political(O) divide(O) between(O) Republicans(O) led(O) by(O) Mitt(B-politician) Romney(I-politician) and(O) the(O) Democrats(O) of(O) Barack(B-politician) Obama(I-politician) -(O) then(O) battling(O) to(O) win(O) the(O) 2012(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) -(O) she(O) stressed(O),(O) Those(O) of(O) you(O) who(O) are(O) familiar(O) with(O) American(O) politics(O) I(O)'m(O) sure(O) understand(O) the(O) need(O) for(O) negotiated(O) compromise(O).(O)"}
{"id": "162", "dataset": "mit-movie", "split": "test", "label_list": ["character", "average ratings", "actor", "year", "trailer", "title", "rating", "song", "genre", "plot", "director", "review"], "instance": {"id": "162", "words": ["did", "gwyneth", "paltrow", "play", "a", "mathematician", "in", "a", "movie", "with", "anthony", "hopkins"], "labels": ["O", "B-actor", "I-actor", "O", "O", "B-plot", "O", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: character, average ratings, actor, year, trailer, title, rating, song, genre, plot, director, review and O.\nSentence: did gwyneth paltrow play a mathematician in a movie with anthony hopkins", "prompt_labels": "did(O) gwyneth(B-actor) paltrow(I-actor) play(O) a(O) mathematician(B-plot) in(O) a(O) movie(O) with(O) anthony(B-actor) hopkins(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3752, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 19809, 11, 2316, 11, 10959, 11, 5609, 11, 17779, 11, 7234, 11, 7690, 11, 3477, 323, 507, 627, 85664, 25, 1550, 342, 54756, 774, 281, 3223, 654, 1514, 264, 21651, 1122, 304, 264, 5818, 449, 23064, 3633, 7598, 11966, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "did(O) gwyneth(B-actor) paltrow(I-actor) play(O) a(O) mathematician(B-plot) in(O) a(O) movie(O) with(O) anthony(B-actor) hopkins(I-actor)"}
{"id": "637", "dataset": "mit-restaurant", "split": "test", "label_list": ["Rating", "Restaurant Name", "Dish", "Location", "Amenity", "Cuisine", "Hours", "Price"], "instance": {"id": "637", "words": ["i", "want", "some", "chips", "and", "salsa"], "labels": ["O", "O", "O", "B-Dish", "I-Dish", "I-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Restaurant Name, Dish, Location, Amenity, Cuisine, Hours, Price and O.\nSentence: i want some chips and salsa", "prompt_labels": "i(O) want(O) some(O) chips(B-Dish) and(I-Dish) salsa(I-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 26568, 4076, 11, 49268, 11, 10067, 11, 3383, 56685, 11, 81961, 11, 30192, 11, 8650, 323, 507, 627, 85664, 25, 602, 1390, 1063, 24512, 323, 74314, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "i(O) want(O) some(O) chips(B-Dish) and(I-Dish) salsa(I-Dish)"}
{"id": "1889", "dataset": "mit-movie", "split": "test", "label_list": ["review", "director", "year", "average ratings", "plot", "actor", "song", "title", "rating", "trailer", "character", "genre"], "instance": {"id": "1889", "words": ["what", "are", "some", "pg", "movies", "that", "came", "out", "last", "year", "and", "had", "something", "to", "do", "with", "the", "british"], "labels": ["O", "O", "O", "B-rating", "O", "O", "O", "O", "B-year", "I-year", "O", "O", "O", "O", "O", "O", "O", "B-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, year, average ratings, plot, actor, song, title, rating, trailer, character, genre and O.\nSentence: what are some pg movies that came out last year and had something to do with the british", "prompt_labels": "what(O) are(O) some(O) pg(B-rating) movies(O) that(O) came(O) out(O) last(B-year) year(I-year) and(O) had(O) something(O) to(O) do(O) with(O) the(O) british(B-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 1060, 11, 5578, 18594, 11, 7234, 11, 12360, 11, 5609, 11, 2316, 11, 10959, 11, 19809, 11, 3752, 11, 17779, 323, 507, 627, 85664, 25, 1148, 527, 1063, 17953, 9698, 430, 3782, 704, 1566, 1060, 323, 1047, 2555, 311, 656, 449, 279, 95027, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) are(O) some(O) pg(B-rating) movies(O) that(O) came(O) out(O) last(B-year) year(I-year) and(O) had(O) something(O) to(O) do(O) with(O) the(O) british(B-plot)"}
{"id": "1295", "dataset": "mit-movie", "split": "test", "label_list": ["year", "rating", "plot", "trailer", "character", "title", "average ratings", "song", "genre", "director", "review", "actor"], "instance": {"id": "1295", "words": ["have", "you", "seen", "my", "last", "five", "girlfriends"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, plot, trailer, character, title, average ratings, song, genre, director, review, actor and O.\nSentence: have you seen my last five girlfriends", "prompt_labels": "have(O) you(O) seen(O) my(B-title) last(I-title) five(I-title) girlfriends(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 7234, 11, 19809, 11, 3752, 11, 2316, 11, 5578, 18594, 11, 5609, 11, 17779, 11, 7690, 11, 3477, 11, 12360, 323, 507, 627, 85664, 25, 617, 499, 3970, 856, 1566, 4330, 85612, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "have(B-title) you(I-title) seen(I-title) my(I-title) last(I-title) five(I-title) girlfriends(I-title)"}
{"id": "310", "dataset": "crossner_science", "split": "test", "label_list": ["chemical compound", "academic journal", "protein", "award", "event", "discipline", "astronomical object", "university", "country", "chemical element", "location", "person", "enzyme", "scientist", "theory", "organization"], "instance": {"id": "310", "words": ["Red", "Mars", "won", "the", "BSFA", "Award", "in", "1992", "and", "Nebula", "Award", "for", "Best", "Novel", "in", "1993", "."], "labels": ["O", "O", "O", "O", "B-award", "I-award", "O", "O", "O", "B-award", "I-award", "I-award", "I-award", "I-award", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, academic journal, protein, award, event, discipline, astronomical object, university, country, chemical element, location, person, enzyme, scientist, theory, organization and O.\nSentence: Red Mars won the BSFA Award in 1992 and Nebula Award for Best Novel in 1993 .", "prompt_labels": "Red(O) Mars(O) won(O) the(O) BSFA(B-award) Award(I-award) in(O) 1992(O) and(O) Nebula(B-award) Award(I-award) for(I-award) Best(I-award) Novel(I-award) in(O) 1993(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 11742, 24549, 11, 14584, 8486, 11, 13128, 11, 10292, 11, 1567, 11, 26434, 11, 87283, 1665, 11, 12374, 11, 3224, 11, 11742, 2449, 11, 3813, 11, 1732, 11, 49242, 11, 28568, 11, 10334, 11, 7471, 323, 507, 627, 85664, 25, 3816, 21725, 2834, 279, 28718, 3711, 17768, 304, 220, 2550, 17, 323, 52809, 5724, 17768, 369, 7252, 53976, 304, 220, 2550, 18, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Red(B-book) Mars(I-book) won(O) the(O) BSFA(B-award) Award(I-award) in(O) 1992(O) and(O) Nebula(B-award) Award(I-award) for(I-award) Best(I-award) Novel(I-award) in(O) 1993(O).(O)"}
{"id": "562", "dataset": "crossner_politics", "split": "test", "label_list": ["country", "election", "politician", "person", "event", "organization", "political party", "location"], "instance": {"id": "562", "words": ["The", "series", "is", "set", "to", "be", "written", "by", "Oscar", "-nominated", "screenwriter", "Billy", "Ray", ",", "who", "will", "also", "executive", "produce", "the", "series", "alongside", "Alex", "Kurtzman", ",", "Heather", "Kadin", ",", "and", "Shane", "Salerno", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, election, politician, person, event, organization, political party, location and O.\nSentence: The series is set to be written by Oscar -nominated screenwriter Billy Ray , who will also executive produce the series alongside Alex Kurtzman , Heather Kadin , and Shane Salerno .", "prompt_labels": "The(O) series(O) is(O) set(O) to(O) be(O) written(O) by(O) Oscar(O) -nominated(O) screenwriter(O) Billy(B-person) Ray(I-person) ,(O) who(O) will(O) also(O) executive(O) produce(O) the(O) series(O) alongside(O) Alex(B-person) Kurtzman(I-person) ,(O) Heather(B-person) Kadin(I-person) ,(O) and(O) Shane(B-person) Salerno(I-person) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3224, 11, 6355, 11, 37038, 11, 1732, 11, 1567, 11, 7471, 11, 5054, 4717, 11, 3813, 323, 507, 627, 85664, 25, 578, 4101, 374, 743, 311, 387, 5439, 555, 31797, 482, 77, 50615, 4264, 18688, 33919, 13558, 1174, 889, 690, 1101, 11145, 8356, 279, 4101, 16662, 8683, 44023, 82016, 1174, 47363, 735, 32084, 1174, 323, 51075, 8375, 25980, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) series(O) is(O) set(O) to(O) be(O) written(O) by(O) Oscar(O)-nominated(O) screenwriter(O) Billy(B-actor) Ray(I-actor),(O) who(O) will(O) also(O) executive(O) produce(O) the(O) series(O) alongside(O) Alex(B-actor) Kurtzman(I-actor),(O) Heather(B-actor) Kadin(I-actor),(O) and(O) Shane(B-actor) Salerno(I-actor).(O)"}
{"id": "1447", "dataset": "mit-restaurant", "split": "test", "label_list": ["Cuisine", "Location", "Amenity", "Restaurant Name", "Dish", "Price", "Rating", "Hours"], "instance": {"id": "1447", "words": ["where", "is", "the", "nearest", "sushi", "bar"], "labels": ["O", "O", "O", "B-Location", "B-Cuisine", "I-Cuisine"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Location, Amenity, Restaurant Name, Dish, Price, Rating, Hours and O.\nSentence: where is the nearest sushi bar", "prompt_labels": "where(O) is(O) the(O) nearest(B-Location) sushi(B-Cuisine) bar(I-Cuisine)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 10067, 11, 3383, 56685, 11, 26568, 4076, 11, 49268, 11, 8650, 11, 19767, 11, 30192, 323, 507, 627, 85664, 25, 1405, 374, 279, 24379, 67322, 3703, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) is(O) the(O) nearest(B-Location) sushi(B-Cuisine) bar(I-Cuisine)"}
{"id": "2077", "dataset": "mit-movie", "split": "test", "label_list": ["trailer", "rating", "year", "character", "song", "director", "average ratings", "title", "actor", "genre", "review", "plot"], "instance": {"id": "2077", "words": ["what", "is", "the", "mockumentary", "by", "yann", "samuell"], "labels": ["O", "O", "O", "B-genre", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, rating, year, character, song, director, average ratings, title, actor, genre, review, plot and O.\nSentence: what is the mockumentary by yann samuell", "prompt_labels": "what(O) is(O) the(O) mockumentary(B-genre) by(O) yann(B-director) samuell(I-director)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 10959, 11, 1060, 11, 3752, 11, 5609, 11, 7690, 11, 5578, 18594, 11, 2316, 11, 12360, 11, 17779, 11, 3477, 11, 7234, 323, 507, 627, 85664, 25, 1148, 374, 279, 8018, 1143, 661, 555, 379, 1036, 10167, 42758, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) the(O) mockumentary(B-genre) by(O) yann(B-director) samuell(I-director)"}
{"id": "800", "dataset": "mit-movie", "split": "test", "label_list": ["director", "character", "trailer", "review", "actor", "genre", "title", "song", "plot", "year", "rating", "average ratings"], "instance": {"id": "800", "words": ["what", "was", "the", "plot", "of", "sudden", "death"], "labels": ["O", "O", "O", "B-plot", "O", "B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, character, trailer, review, actor, genre, title, song, plot, year, rating, average ratings and O.\nSentence: what was the plot of sudden death", "prompt_labels": "what(O) was(O) the(O) plot(B-plot) of(O) sudden(B-title) death(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 3752, 11, 19809, 11, 3477, 11, 12360, 11, 17779, 11, 2316, 11, 5609, 11, 7234, 11, 1060, 11, 10959, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1148, 574, 279, 7234, 315, 11210, 4648, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) was(O) the(O) plot(O) of(O) sudden(B-title) death(I-title)"}
{"id": "250", "dataset": "mit-movie", "split": "test", "label_list": ["plot", "average ratings", "year", "genre", "actor", "trailer", "song", "director", "review", "rating", "title", "character"], "instance": {"id": "250", "words": ["rainbow", "6"], "labels": ["B-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: plot, average ratings, year, genre, actor, trailer, song, director, review, rating, title, character and O.\nSentence: rainbow 6", "prompt_labels": "rainbow(B-title) 6(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7234, 11, 5578, 18594, 11, 1060, 11, 17779, 11, 12360, 11, 19809, 11, 5609, 11, 7690, 11, 3477, 11, 10959, 11, 2316, 11, 3752, 323, 507, 627, 85664, 25, 48713, 220, 21, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "rainbow(B-title) 6(I-title)"}
{"id": "199", "dataset": "crossner_politics", "split": "test", "label_list": ["person", "politician", "location", "election", "event", "country", "organization", "political party"], "instance": {"id": "199", "words": ["Later", ",", "the", "Rainbow", "Coalition", "was", "joined", "nationwide", "by", "Students", "for", "a", "Democratic", "Society", "(", "SDS", ")", ",", "the", "Brown", "Berets", ",", "American", "Indian", "Movement", ",", "and", "the", "Red", "Guard", "Party", "."], "labels": ["O", "O", "O", "B-event", "I-event", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "O", "B-organization", "I-organization", "O", "B-political party", "I-political party", "I-political party", "O", "O", "O", "B-political party", "I-political party", "I-political party", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, location, election, event, country, organization, political party and O.\nSentence: Later , the Rainbow Coalition was joined nationwide by Students for a Democratic Society ( SDS ) , the Brown Berets , American Indian Movement , and the Red Guard Party .", "prompt_labels": "Later(O) ,(O) the(O) Rainbow(B-event) Coalition(I-event) was(O) joined(O) nationwide(O) by(O) Students(B-organization) for(I-organization) a(I-organization) Democratic(I-organization) Society(I-organization) ((O) SDS(B-organization) )(O) ,(O) the(O) Brown(B-organization) Berets(I-organization) ,(O) American(B-political party) Indian(I-political party) Movement(I-political party) ,(O) and(O) the(O) Red(B-political party) Guard(I-political party) Party(I-political party) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 37038, 11, 3813, 11, 6355, 11, 1567, 11, 3224, 11, 7471, 11, 5054, 4717, 323, 507, 627, 85664, 25, 25929, 1174, 279, 47745, 36892, 574, 11096, 29054, 555, 20783, 369, 264, 11650, 13581, 320, 96712, 883, 1174, 279, 10690, 9084, 1441, 1174, 3778, 7904, 29098, 1174, 323, 279, 3816, 12542, 8722, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Later(O),(O) the(O) Rainbow(B-organization) Coalition(I-organization) was(O) joined(O) nationwide(O) by(O) Students(B-organization) for(I-organization) a(I-organization) Democratic(I-organization) Society(I-organization) ((O) SDS(B-organization) )(O),(O) the(O) Brown(B-organization) Berets(I-organization),(O) American(B-organization) Indian(I-organization) Movement(I-organization),(O) and(O) the(O) Red(B-organization) Guard(I-organization) Party(I-organization).(O)"}
{"id": "280", "dataset": "crossner_music", "split": "test", "label_list": ["organization", "event", "song", "band", "album", "location", "musical artist", "music genre", "person", "musical instrument", "country", "award"], "instance": {"id": "280", "words": ["With", "the", "release", "of", "chart-topping", "albums", "such", "as", "Heart", "Like", "a", "Wheel", ",", "Simple", "Dreams", ",", "and", "Living", "in", "the", "USA", ",", "Ronstadt", "became", "the", "first", "female", "arena", "class", "rock", "star", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-album", "I-album", "O", "O", "B-album", "I-album", "I-album", "I-album", "O", "B-musical artist", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, song, band, album, location, musical artist, music genre, person, musical instrument, country, award and O.\nSentence: With the release of chart-topping albums such as Heart Like a Wheel , Simple Dreams , and Living in the USA , Ronstadt became the first female arena class rock star .", "prompt_labels": "With(O) the(O) release(O) of(O) chart-topping(O) albums(O) such(O) as(O) Heart(B-album) Like(I-album) a(I-album) Wheel(I-album) ,(O) Simple(B-album) Dreams(I-album) ,(O) and(O) Living(B-album) in(I-album) the(I-album) USA(I-album) ,(O) Ronstadt(B-musical artist) became(O) the(O) first(O) female(O) arena(O) class(O) rock(O) star(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 5609, 11, 7200, 11, 8176, 11, 3813, 11, 18273, 10255, 11, 4731, 17779, 11, 1732, 11, 18273, 14473, 11, 3224, 11, 10292, 323, 507, 627, 85664, 25, 3161, 279, 4984, 315, 9676, 2442, 7153, 28785, 1778, 439, 18449, 9086, 264, 33442, 1174, 9170, 53718, 1174, 323, 19048, 304, 279, 7427, 1174, 14662, 45378, 6244, 279, 1176, 8954, 25946, 538, 7091, 6917, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "With(O) the(O) release(O) of(O) chart-topping(O) albums(O) such(O) as(O) Heart(B-album) Like(I-album) a(I-album) Wheel(I-album),(O) Simple(B-album) Dreams(I-album),(O) and(O) Living(B-album) in(I-album) the(I-album) USA(I-album),(O) Ronstadt(B-musical artist) became(O) the(O) first(O) female(O) arena(O) class(O) rock(O) star(O).(O)"}
{"id": "1170", "dataset": "mit-movie", "split": "test", "label_list": ["rating", "title", "plot", "trailer", "song", "genre", "review", "average ratings", "character", "actor", "year", "director"], "instance": {"id": "1170", "words": ["did", "steve", "barron", "direct", "any", "comedy", "movies", "that", "people", "thought", "was", "all", "right"], "labels": ["O", "B-director", "I-director", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-average ratings", "I-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, title, plot, trailer, song, genre, review, average ratings, character, actor, year, director and O.\nSentence: did steve barron direct any comedy movies that people thought was all right", "prompt_labels": "did(O) steve(B-director) barron(I-director) direct(O) any(O) comedy(B-genre) movies(O) that(O) people(O) thought(O) was(O) all(B-average ratings) right(I-average ratings)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 2316, 11, 7234, 11, 19809, 11, 5609, 11, 17779, 11, 3477, 11, 5578, 18594, 11, 3752, 11, 12360, 11, 1060, 11, 7690, 323, 507, 627, 85664, 25, 1550, 4179, 588, 32039, 263, 2167, 904, 23160, 9698, 430, 1274, 3463, 574, 682, 1314, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "did(O) steve(B-director) barron(I-director) direct(O) any(O) comedy(B-genre) movies(O) that(O) people(O) thought(O) was(O) all(B-average ratings) right(I-average ratings)"}
{"id": "145", "dataset": "crossner_music", "split": "test", "label_list": ["band", "musical instrument", "person", "country", "album", "award", "organization", "song", "location", "musical artist", "event", "music genre"], "instance": {"id": "145", "words": ["He", "also", "appeared", "with", "RBX", ",", "Nas", "and", "KRS-One", "on", "East", "Coast", "Killer", ",", "West", "Coast", "Killer", "from", "Dr.", "Dre", "'s", "Dr.", "Dre", "Presents", "the", "Aftermath", "album", ",", "and", "contributed", "to", "an", "album", "entitled", "The", "Psycho", "Realm", "with", "Psycho", "Realm", "."], "labels": ["O", "O", "O", "O", "B-musical artist", "O", "B-musical artist", "O", "B-musical artist", "O", "B-song", "I-song", "I-song", "I-song", "I-song", "I-song", "I-song", "O", "B-musical artist", "I-musical artist", "O", "B-album", "I-album", "I-album", "I-album", "I-album", "O", "O", "O", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "O", "B-band", "I-band", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, musical instrument, person, country, album, award, organization, song, location, musical artist, event, music genre and O.\nSentence: He also appeared with RBX , Nas and KRS-One on East Coast Killer , West Coast Killer from Dr. Dre 's Dr. Dre Presents the Aftermath album , and contributed to an album entitled The Psycho Realm with Psycho Realm .", "prompt_labels": "He(O) also(O) appeared(O) with(O) RBX(B-musical artist) ,(O) Nas(B-musical artist) and(O) KRS-One(B-musical artist) on(O) East(B-song) Coast(I-song) Killer(I-song) ,(I-song) West(I-song) Coast(I-song) Killer(I-song) from(O) Dr.(B-musical artist) Dre(I-musical artist) 's(O) Dr.(B-album) Dre(I-album) Presents(I-album) the(I-album) Aftermath(I-album) album(O) ,(O) and(O) contributed(O) to(O) an(O) album(O) entitled(O) The(B-album) Psycho(I-album) Realm(I-album) with(O) Psycho(B-band) Realm(I-band) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 18273, 14473, 11, 1732, 11, 3224, 11, 8176, 11, 10292, 11, 7471, 11, 5609, 11, 3813, 11, 18273, 10255, 11, 1567, 11, 4731, 17779, 323, 507, 627, 85664, 25, 1283, 1101, 9922, 449, 29074, 55, 1174, 39322, 323, 735, 11706, 91477, 389, 6460, 16377, 54053, 1174, 4410, 16377, 54053, 505, 2999, 13, 66110, 364, 82, 2999, 13, 66110, 83836, 279, 4740, 10590, 8176, 1174, 323, 20162, 311, 459, 8176, 20458, 578, 70276, 42206, 449, 70276, 42206, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "He(O) also(O) appeared(O) with(O) RBX(B-musical artist),(O) Nas(B-musical artist) and(O) KRS-One(B-musical artist) on(O) East(B-song) Coast(I-song) Killer(I-song),(O) West(B-song) Coast(I-song) Killer(I-song) from(O) Dr.(B-musical artist) Dre(I-musical artist)'s(O) Dr.(B-album) Dre(I-album) Presents(I-album) the(I-album) Aftermath(I-album) album(O),(O) and(O) contributed(O) to(O) an(O) album(O) entitled(O) The(B-album) Psycho(I-album) Realm(I-album) with(O) Psycho(B-band) Realm(I-band).(O)"}
{"id": "1476", "dataset": "mit-restaurant", "split": "test", "label_list": ["Restaurant Name", "Price", "Cuisine", "Location", "Rating", "Dish", "Hours", "Amenity"], "instance": {"id": "1476", "words": ["wheres", "the", "nearest", "italian", "restaurant"], "labels": ["O", "O", "B-Location", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Price, Cuisine, Location, Rating, Dish, Hours, Amenity and O.\nSentence: wheres the nearest italian restaurant", "prompt_labels": "wheres(O) the(O) nearest(B-Location) italian(B-Cuisine) restaurant(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 8650, 11, 81961, 11, 10067, 11, 19767, 11, 49268, 11, 30192, 11, 3383, 56685, 323, 507, 627, 85664, 25, 421, 13213, 279, 24379, 29048, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "wheres(O) the(O) nearest(B-Location) italian(B-Cuisine) restaurant(O)"}
{"id": "334", "dataset": "mit-restaurant", "split": "test", "label_list": ["Dish", "Cuisine", "Price", "Amenity", "Hours", "Rating", "Location", "Restaurant Name"], "instance": {"id": "334", "words": ["find", "a", "cheap", "brewpub", "that", "serves", "beef"], "labels": ["O", "O", "B-Price", "B-Cuisine", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Dish, Cuisine, Price, Amenity, Hours, Rating, Location, Restaurant Name and O.\nSentence: find a cheap brewpub that serves beef", "prompt_labels": "find(O) a(O) cheap(B-Price) brewpub(B-Cuisine) that(O) serves(O) beef(B-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 49268, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 30192, 11, 19767, 11, 10067, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1505, 264, 12136, 17109, 9780, 430, 17482, 25309, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) a(O) cheap(B-Price) brewpub(B-Cuisine) that(O) serves(O) beef(B-Dish)"}
{"id": "2335", "dataset": "mit-movie", "split": "test", "label_list": ["review", "year", "genre", "rating", "director", "character", "plot", "average ratings", "song", "actor", "title", "trailer"], "instance": {"id": "2335", "words": ["who", "stars", "in", "west", "is", "west"], "labels": ["O", "O", "O", "B-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, year, genre, rating, director, character, plot, average ratings, song, actor, title, trailer and O.\nSentence: who stars in west is west", "prompt_labels": "who(O) stars(O) in(O) west(B-title) is(I-title) west(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 1060, 11, 17779, 11, 10959, 11, 7690, 11, 3752, 11, 7234, 11, 5578, 18594, 11, 5609, 11, 12360, 11, 2316, 11, 19809, 323, 507, 627, 85664, 25, 889, 9958, 304, 9909, 374, 9909, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "who(O) stars(O) in(O) west(B-title) is(I-title) west(I-title)"}
{"id": "398", "dataset": "crossner_ai", "split": "test", "label_list": ["product", "programming language", "organization", "location", "researcher", "conference", "university", "country", "field", "person", "metric", "algorithm", "task"], "instance": {"id": "398", "words": ["In", "red-green", "anaglyph", ",", "the", "audience", "was", "presented", "three", "reels", "of", "tests", ",", "which", "included", "rural", "scenes", ",", "test", "shots", "of", "Marie", "Doro", ",", "a", "segment", "of", "John", "B.", "Mason", "playing", "a", "number", "of", "passages", "from", "Jim", "the", "Penman", "(", "a", "film", "released", "by", "Famous", "Players-Lasky", "that", "year", ",", "but", "not", "in", "3D", ")", ",", "Oriental", "dancers", ",", "and", "a", "reel", "of", "footage", "of", "Niagara", "Falls", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-location", "I-location", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, programming language, organization, location, researcher, conference, university, country, field, person, metric, algorithm, task and O.\nSentence: In red-green anaglyph , the audience was presented three reels of tests , which included rural scenes , test shots of Marie Doro , a segment of John B. Mason playing a number of passages from Jim the Penman ( a film released by Famous Players-Lasky that year , but not in 3D ) , Oriental dancers , and a reel of footage of Niagara Falls .", "prompt_labels": "In(O) red-green(O) anaglyph(O) ,(O) the(O) audience(O) was(O) presented(O) three(O) reels(O) of(O) tests(O) ,(O) which(O) included(O) rural(O) scenes(O) ,(O) test(O) shots(O) of(O) Marie(B-person) Doro(I-person) ,(O) a(O) segment(O) of(O) John(B-person) B.(I-person) Mason(I-person) playing(O) a(O) number(O) of(O) passages(O) from(O) Jim(B-person) the(I-person) Penman(I-person) ((O) a(O) film(O) released(O) by(O) Famous(B-organization) Players-Lasky(I-organization) that(O) year(O) ,(O) but(O) not(O) in(O) 3D(O) )(O) ,(O) Oriental(O) dancers(O) ,(O) and(O) a(O) reel(O) of(O) footage(O) of(O) Niagara(B-location) Falls(I-location) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2027, 11, 15840, 4221, 11, 7471, 11, 3813, 11, 32185, 11, 10017, 11, 12374, 11, 3224, 11, 2115, 11, 1732, 11, 18767, 11, 12384, 11, 3465, 323, 507, 627, 85664, 25, 763, 2579, 39368, 459, 351, 9717, 1174, 279, 10877, 574, 10666, 2380, 79600, 315, 7177, 1174, 902, 5343, 19624, 16451, 1174, 1296, 15300, 315, 33116, 423, 18812, 1174, 264, 10449, 315, 3842, 426, 13, 29927, 5737, 264, 1396, 315, 47869, 505, 11641, 279, 13597, 1543, 320, 264, 4632, 6004, 555, 67888, 25640, 8288, 1091, 88, 430, 1060, 1174, 719, 539, 304, 220, 18, 35, 883, 1174, 72051, 61583, 1174, 323, 264, 57382, 315, 22609, 315, 78977, 30743, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) red-green(B-product) anaglyph(I-product),(O) the(O) audience(O) was(O) presented(O) three(O) reels(O) of(O) tests(O),(O) which(O) included(O) rural(O) scenes(O),(O) test(O) shots(O) of(O) Marie(B-person) Doro(I-person),(O) a(O) segment(O) of(O) John(B-person) B.(I-person) Mason(I-person) playing(O) a(O) number(O) of(O) passages(O) from(O) Jim(B-book) the(I-book) Penman(I-book) ((O) a(O) film(O) released(O) by(O) Famous(B-organization) Players-Lasky(I-organization) that(O) year(O),(O) but(O) not(O) in(O) 3D(O) )(O),(O) Oriental(O) dancers(O),(O) and(O) a(O) reel(O) of(O) footage(O) of(O) Niagara(B-location) Falls(I-location).(O)"}
{"id": "316", "dataset": "mit-movie", "split": "test", "label_list": ["song", "character", "trailer", "rating", "director", "average ratings", "review", "plot", "year", "title", "genre", "actor"], "instance": {"id": "316", "words": ["what", "movies", "had", "the", "biggest", "explosions"], "labels": ["O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, character, trailer, rating, director, average ratings, review, plot, year, title, genre, actor and O.\nSentence: what movies had the biggest explosions", "prompt_labels": "what(O) movies(O) had(O) the(O) biggest(B-plot) explosions(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 3752, 11, 19809, 11, 10959, 11, 7690, 11, 5578, 18594, 11, 3477, 11, 7234, 11, 1060, 11, 2316, 11, 17779, 11, 12360, 323, 507, 627, 85664, 25, 1148, 9698, 1047, 279, 8706, 56506, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) movies(O) had(O) the(O) biggest(B-plot) explosions(I-plot)"}
{"id": "191", "dataset": "crossner_ai", "split": "test", "label_list": ["algorithm", "person", "metric", "researcher", "product", "field", "location", "university", "programming language", "organization", "country", "conference", "task"], "instance": {"id": "191", "words": ["The", "VOICEBOX", "speech", "processing", "toolbox", "for", "MATLAB", "implements", "the", "conversion", "and", "its", "inverse", "as", ":"], "labels": ["O", "B-product", "O", "O", "O", "O", "B-product", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, person, metric, researcher, product, field, location, university, programming language, organization, country, conference, task and O.\nSentence: The VOICEBOX speech processing toolbox for MATLAB implements the conversion and its inverse as :", "prompt_labels": "The(O) VOICEBOX(B-product) speech(O) processing(O) toolbox(O) for(O) MATLAB(B-product) implements(O) the(O) conversion(O) and(O) its(O) inverse(O) as(O) :(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12384, 11, 1732, 11, 18767, 11, 32185, 11, 2027, 11, 2115, 11, 3813, 11, 12374, 11, 15840, 4221, 11, 7471, 11, 3224, 11, 10017, 11, 3465, 323, 507, 627, 85664, 25, 578, 44752, 5604, 23892, 8982, 8863, 68970, 369, 50447, 5280, 279, 14747, 323, 1202, 29049, 439, 551, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) VOICEBOX(B-product) speech(I-product) processing(I-product) toolbox(I-product) for(I-product) MATLAB(I-product) implements(O) the(O) conversion(O) and(O) its(O) inverse(O) as(O) :(O)"}
{"id": "997", "dataset": "mit-movie", "split": "test", "label_list": ["year", "trailer", "review", "character", "rating", "average ratings", "genre", "director", "title", "actor", "plot", "song"], "instance": {"id": "997", "words": ["show", "me", "what", "films", "were", "directed", "by", "the", "wachowski", "brothers"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, review, character, rating, average ratings, genre, director, title, actor, plot, song and O.\nSentence: show me what films were directed by the wachowski brothers", "prompt_labels": "show(O) me(O) what(O) films(O) were(O) directed(O) by(O) the(O) wachowski(B-director) brothers(I-director)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 19809, 11, 3477, 11, 3752, 11, 10959, 11, 5578, 18594, 11, 17779, 11, 7690, 11, 2316, 11, 12360, 11, 7234, 11, 5609, 323, 507, 627, 85664, 25, 1501, 757, 1148, 12631, 1051, 15910, 555, 279, 289, 613, 29384, 20820, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) what(O) films(O) were(O) directed(O) by(O) the(O) wachowski(B-director) brothers(I-director)"}
{"id": "262", "dataset": "mit-movie", "split": "test", "label_list": ["trailer", "rating", "year", "average ratings", "genre", "title", "song", "director", "character", "review", "actor", "plot"], "instance": {"id": "262", "words": ["when", "did", "goodfellas", "come", "out"], "labels": ["O", "O", "B-title", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: trailer, rating, year, average ratings, genre, title, song, director, character, review, actor, plot and O.\nSentence: when did goodfellas come out", "prompt_labels": "when(O) did(O) goodfellas(B-title) come(O) out(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19809, 11, 10959, 11, 1060, 11, 5578, 18594, 11, 17779, 11, 2316, 11, 5609, 11, 7690, 11, 3752, 11, 3477, 11, 12360, 11, 7234, 323, 507, 627, 85664, 25, 994, 1550, 1695, 67643, 300, 2586, 704, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "when(O) did(O) goodfellas(B-title) come(O) out(O)"}
{"id": "772", "dataset": "mit-movie", "split": "test", "label_list": ["year", "character", "title", "trailer", "average ratings", "actor", "genre", "plot", "song", "director", "rating", "review"], "instance": {"id": "772", "words": ["what", "movie", "has", "liev", "shrieber", "and", "sean", "william", "scott", "in", "it", "as", "hockey", "players"], "labels": ["O", "O", "O", "B-actor", "I-actor", "O", "B-actor", "I-actor", "I-actor", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, character, title, trailer, average ratings, actor, genre, plot, song, director, rating, review and O.\nSentence: what movie has liev shrieber and sean william scott in it as hockey players", "prompt_labels": "what(O) movie(O) has(O) liev(B-actor) shrieber(I-actor) and(O) sean(B-actor) william(I-actor) scott(I-actor) in(O) it(O) as(O) hockey(B-plot) players(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 3752, 11, 2316, 11, 19809, 11, 5578, 18594, 11, 12360, 11, 17779, 11, 7234, 11, 5609, 11, 7690, 11, 10959, 11, 3477, 323, 507, 627, 85664, 25, 1148, 5818, 706, 10457, 85, 559, 7379, 655, 323, 85522, 690, 5038, 1156, 1751, 304, 433, 439, 28051, 4311, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) movie(O) has(O) liev(B-actor) shrieber(I-actor) and(O) sean(B-actor) william(I-actor) scott(I-actor) in(O) it(O) as(O) hockey(B-plot) players(I-plot)"}
{"id": "192", "dataset": "crossner_ai", "split": "test", "label_list": ["field", "researcher", "person", "university", "organization", "conference", "country", "metric", "product", "task", "location", "algorithm", "programming language"], "instance": {"id": "192", "words": ["Prolog", "is", "a", "logic", "programming", "language", "associated", "with", "artificial", "intelligence", "and", "computational", "linguistics", "."], "labels": ["B-programming language", "O", "O", "O", "O", "O", "O", "O", "B-field", "I-field", "O", "B-field", "I-field", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, researcher, person, university, organization, conference, country, metric, product, task, location, algorithm, programming language and O.\nSentence: Prolog is a logic programming language associated with artificial intelligence and computational linguistics .", "prompt_labels": "Prolog(B-programming language) is(O) a(O) logic(O) programming(O) language(O) associated(O) with(O) artificial(B-field) intelligence(I-field) and(O) computational(B-field) linguistics(I-field) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 32185, 11, 1732, 11, 12374, 11, 7471, 11, 10017, 11, 3224, 11, 18767, 11, 2027, 11, 3465, 11, 3813, 11, 12384, 11, 15840, 4221, 323, 507, 627, 85664, 25, 1322, 848, 374, 264, 12496, 15840, 4221, 5938, 449, 21075, 11478, 323, 55580, 39603, 5706, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Prolog(B-programming language) is(O) a(O) logic(B-programming language) programming(I-programming language) language(O) associated(O) with(O) artificial(B-field) intelligence(I-field) and(O) computational(B-field) linguistics(I-field).(O)"}
{"id": "614", "dataset": "crossner_politics", "split": "test", "label_list": ["politician", "election", "location", "event", "person", "political party", "organization", "country"], "instance": {"id": "614", "words": ["Operation", "Cascade", "gave", "the", "Allies", "of", "World", "War", "II", "valuable", "experience", "in", "planning", "deception", "operations", ",", "which", "was", "later", "used", "to", "good", "effect", "in", "the", "deception", "operations", "covering", "the", "invasion", "of", "Europe", "(", "D-Day", "landings", "in", "Normandy", ",", "and", "the", "invasion", "of", "Southern", "France", ")", "."], "labels": ["O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, election, location, event, person, political party, organization, country and O.\nSentence: Operation Cascade gave the Allies of World War II valuable experience in planning deception operations , which was later used to good effect in the deception operations covering the invasion of Europe ( D-Day landings in Normandy , and the invasion of Southern France ) .", "prompt_labels": "Operation(O) Cascade(O) gave(O) the(O) Allies(B-organization) of(I-organization) World(I-organization) War(I-organization) II(I-organization) valuable(O) experience(O) in(O) planning(O) deception(O) operations(O) ,(O) which(O) was(O) later(O) used(O) to(O) good(O) effect(O) in(O) the(O) deception(O) operations(O) covering(O) the(O) invasion(B-event) of(I-event) Europe(I-event) ((O) D-Day(B-event) landings(I-event) in(I-event) Normandy(I-event) ,(O) and(O) the(O) invasion(B-event) of(I-event) Southern(I-event) France(I-event) )(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 6355, 11, 3813, 11, 1567, 11, 1732, 11, 5054, 4717, 11, 7471, 11, 3224, 323, 507, 627, 85664, 25, 17145, 57870, 6688, 279, 81774, 315, 4435, 5111, 8105, 15525, 3217, 304, 9293, 64575, 7677, 1174, 902, 574, 3010, 1511, 311, 1695, 2515, 304, 279, 64575, 7677, 18702, 279, 30215, 315, 4606, 320, 423, 56012, 4363, 826, 304, 20935, 13634, 1174, 323, 279, 30215, 315, 16642, 9822, 883, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Operation(B-event) Cascade(I-event) gave(O) the(O) Allies(B-country) of(I-country) World(I-country) War(I-country) II(I-country) valuable(O) experience(O) in(O) planning(O) deception(O) operations(O),(O) which(O) was(O) later(O) used(O) to(O) good(O) effect(O) in(O) the(O) deception(O) operations(O) covering(O) the(O) invasion(O) of(O) Europe(B-location) ((O) D-Day(B-event) landings(I-event) in(O) Normandy(B-location),(O) and(O) the(O) invasion(O) of(O) Southern(B-location) France(I-location) )(O).(O)"}
{"id": "1623", "dataset": "mit-movie", "split": "test", "label_list": ["director", "song", "actor", "title", "average ratings", "character", "plot", "trailer", "year", "review", "rating", "genre"], "instance": {"id": "1623", "words": ["list", "a", "move", "of", "the", "gags", "genre", "that", "was", "directed", "by", "j", "s", "cardone", "and", "uses", "satire", "in", "its", "plot"], "labels": ["O", "O", "O", "O", "O", "B-genre", "O", "O", "O", "O", "O", "B-director", "I-director", "I-director", "O", "O", "B-plot", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, song, actor, title, average ratings, character, plot, trailer, year, review, rating, genre and O.\nSentence: list a move of the gags genre that was directed by j s cardone and uses satire in its plot", "prompt_labels": "list(O) a(O) move(O) of(O) the(O) gags(B-genre) genre(O) that(O) was(O) directed(O) by(O) j(B-director) s(I-director) cardone(I-director) and(O) uses(O) satire(B-plot) in(O) its(O) plot(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 5609, 11, 12360, 11, 2316, 11, 5578, 18594, 11, 3752, 11, 7234, 11, 19809, 11, 1060, 11, 3477, 11, 10959, 11, 17779, 323, 507, 627, 85664, 25, 1160, 264, 3351, 315, 279, 342, 2076, 17779, 430, 574, 15910, 555, 503, 274, 3786, 606, 323, 5829, 82495, 304, 1202, 7234, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "list(O) a(O) move(O) of(O) the(O) gags(B-genre) genre(O) that(O) was(O) directed(O) by(O) j(B-director) s(I-director) cardone(I-director) and(O) uses(O) satire(B-plot) in(O) its(O) plot(O)"}
{"id": "410", "dataset": "mit-restaurant", "split": "test", "label_list": ["Hours", "Rating", "Amenity", "Location", "Dish", "Price", "Cuisine", "Restaurant Name"], "instance": {"id": "410", "words": ["find", "me", "a", "take", "out", "chinese", "restaurant"], "labels": ["O", "O", "O", "B-Amenity", "I-Amenity", "B-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Amenity, Location, Dish, Price, Cuisine, Restaurant Name and O.\nSentence: find me a take out chinese restaurant", "prompt_labels": "find(O) me(O) a(O) take(B-Amenity) out(I-Amenity) chinese(B-Cuisine) restaurant(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 3383, 56685, 11, 10067, 11, 49268, 11, 8650, 11, 81961, 11, 26568, 4076, 323, 507, 627, 85664, 25, 1505, 757, 264, 1935, 704, 57487, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) take(B-Amenity) out(I-Amenity) chinese(B-Cuisine) restaurant(O)"}
{"id": "147", "dataset": "crossner_politics", "split": "test", "label_list": ["election", "location", "country", "politician", "organization", "person", "event", "political party"], "instance": {"id": "147", "words": ["Most", "famously", ",", "the", "Houses", "of", "House", "of", "York", "and", "House", "of", "Lancaster", ",", "whose", "feuding", "over", "the", "succession", "to", "the", "English", "throne", "after", "the", "end", "of", "the", "main", "line", "of", "the", "House", "of", "Plantagenet", "caused", "the", "Wars", "of", "the", "Roses", ",", "were", "both", "established", "when", "the", "Duchies", "of", "York", "and", "Lancaster", "were", "given", "as", "appanages", "for", "Edmund", "of", "Langley", "and", "John", "of", "Gaunt", ",", "the", "younger", "sons", "of", "King", "Edward", "III", "."], "labels": ["O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "I-person", "O", "B-person", "I-person", "I-person", "O", "O", "O", "O", "O", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: election, location, country, politician, organization, person, event, political party and O.\nSentence: Most famously , the Houses of House of York and House of Lancaster , whose feuding over the succession to the English throne after the end of the main line of the House of Plantagenet caused the Wars of the Roses , were both established when the Duchies of York and Lancaster were given as appanages for Edmund of Langley and John of Gaunt , the younger sons of King Edward III .", "prompt_labels": "Most(O) famously(O) ,(O) the(O) Houses(O) of(O) House(B-organization) of(I-organization) York(I-organization) and(O) House(B-organization) of(I-organization) Lancaster(I-organization) ,(O) whose(O) feuding(O) over(O) the(O) succession(O) to(O) the(O) English(O) throne(O) after(O) the(O) end(O) of(O) the(O) main(O) line(O) of(O) the(O) House(B-organization) of(I-organization) Plantagenet(I-organization) caused(O) the(O) Wars(B-event) of(I-event) the(I-event) Roses(I-event) ,(O) were(O) both(O) established(O) when(O) the(O) Duchies(O) of(O) York(O) and(O) Lancaster(O) were(O) given(O) as(O) appanages(O) for(O) Edmund(B-person) of(I-person) Langley(I-person) and(O) John(B-person) of(I-person) Gaunt(I-person) ,(O) the(O) younger(O) sons(O) of(O) King(O) Edward(B-person) III(I-person) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 6355, 11, 3813, 11, 3224, 11, 37038, 11, 7471, 11, 1732, 11, 1567, 11, 5054, 4717, 323, 507, 627, 85664, 25, 7648, 51287, 1174, 279, 58759, 315, 4783, 315, 4356, 323, 4783, 315, 66223, 1174, 6832, 1172, 51867, 927, 279, 50787, 311, 279, 6498, 44721, 1306, 279, 842, 315, 279, 1925, 1584, 315, 279, 4783, 315, 18317, 8703, 295, 9057, 279, 15317, 315, 279, 81470, 1174, 1051, 2225, 9749, 994, 279, 61122, 552, 315, 4356, 323, 66223, 1051, 2728, 439, 917, 276, 1154, 369, 71911, 315, 23272, 3258, 323, 3842, 315, 18879, 3935, 1174, 279, 14992, 26419, 315, 6342, 22653, 14767, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Most(O) famously(O),(O) the(O) Houses(B-location) of(I-location) House(I-location) of(I-location) York(I-location) and(I-location) House(I-location) of(I-location) Lancaster(I-location) were(O) given(O) as(O) appanages(O) for(O) Edmund(B-politician) of(I-politician) Langley(I-politician) and(O) John(B-politician) of(I-politician) Gaunt(I-politician),(O) the(O) younger(O) sons(O) of(O) King(O) Edward(B-politician) III(I-politician).(O)"}
{"id": "359", "dataset": "crossner_literature", "split": "test", "label_list": ["organization", "award", "country", "person", "writer", "location", "book", "magazine", "poem", "literary genre", "event"], "instance": {"id": "359", "words": ["Pauline", "Kael", ",", "who", "wrote", "a", "lengthy", "freelance", "essay", "in", "The", "New", "Yorker", "in", "praise", "of", "the", "film", ",", "was", "hired", "as", "the", "magazine", "'s", "new", "staff-critic", "."], "labels": ["B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "B-magazine", "I-magazine", "I-magazine", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, award, country, person, writer, location, book, magazine, poem, literary genre, event and O.\nSentence: Pauline Kael , who wrote a lengthy freelance essay in The New Yorker in praise of the film , was hired as the magazine 's new staff-critic .", "prompt_labels": "Pauline(B-writer) Kael(I-writer) ,(O) who(O) wrote(O) a(O) lengthy(O) freelance(O) essay(O) in(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) in(O) praise(O) of(O) the(O) film(O) ,(O) was(O) hired(O) as(O) the(O) magazine(O) 's(O) new(O) staff-critic(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 10292, 11, 3224, 11, 1732, 11, 7061, 11, 3813, 11, 2363, 11, 14756, 11, 33894, 11, 32465, 17779, 11, 1567, 323, 507, 627, 85664, 25, 7043, 483, 735, 6015, 1174, 889, 6267, 264, 35306, 46209, 9071, 304, 578, 1561, 64874, 304, 29488, 315, 279, 4632, 1174, 574, 22163, 439, 279, 14756, 364, 82, 502, 5687, 1824, 50308, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Pauline(B-writer) Kael(I-writer),(O) who(O) wrote(O) a(O) lengthy(O) freelance(O) essay(O) in(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) in(O) praise(O) of(O) the(O) film(O),(O) was(O) hired(O) as(O) the(O) magazine(O)'s(O) new(O) staff-critic(O).(O)"}
{"id": "2364", "dataset": "mit-movie", "split": "test", "label_list": ["genre", "review", "actor", "song", "title", "director", "year", "rating", "trailer", "average ratings", "character", "plot"], "instance": {"id": "2364", "words": ["list", "some", "films", "starring", "hugh", "jackman"], "labels": ["O", "O", "O", "O", "B-actor", "I-actor"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: genre, review, actor, song, title, director, year, rating, trailer, average ratings, character, plot and O.\nSentence: list some films starring hugh jackman", "prompt_labels": "list(O) some(O) films(O) starring(O) hugh(B-actor) jackman(I-actor)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 17779, 11, 3477, 11, 12360, 11, 5609, 11, 2316, 11, 7690, 11, 1060, 11, 10959, 11, 19809, 11, 5578, 18594, 11, 3752, 11, 7234, 323, 507, 627, 85664, 25, 1160, 1063, 12631, 40500, 305, 7595, 26128, 1543, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "list(O) some(O) films(O) starring(O) hugh(B-actor) jackman(I-actor)"}
{"id": "397", "dataset": "crossner_ai", "split": "test", "label_list": ["university", "field", "organization", "conference", "task", "algorithm", "country", "researcher", "programming language", "metric", "location", "person", "product"], "instance": {"id": "397", "words": ["Resources", "for", "affectivity", "of", "words", "and", "concepts", "have", "been", "made", "for", "WordNet", "{", "{", "cite", "journal"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-product", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, field, organization, conference, task, algorithm, country, researcher, programming language, metric, location, person, product and O.\nSentence: Resources for affectivity of words and concepts have been made for WordNet { { cite journal", "prompt_labels": "Resources(O) for(O) affectivity(O) of(O) words(O) and(O) concepts(O) have(O) been(O) made(O) for(O) WordNet(B-product) {(O) {(O) cite(O) journal(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12374, 11, 2115, 11, 7471, 11, 10017, 11, 3465, 11, 12384, 11, 3224, 11, 32185, 11, 15840, 4221, 11, 18767, 11, 3813, 11, 1732, 11, 2027, 323, 507, 627, 85664, 25, 16607, 369, 7958, 1968, 315, 4339, 323, 19476, 617, 1027, 1903, 369, 9506, 7099, 314, 314, 39396, 8486, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Resources(O) for(O) affectivity(O) of(O) words(O) and(O) concepts(O) have(O) been(O) made(O) for(O) WordNet(B-organization) {(O) {(O) cite(O) journal(O)"}
{"id": "1912", "dataset": "mit-movie", "split": "test", "label_list": ["average ratings", "actor", "review", "genre", "plot", "year", "title", "rating", "character", "director", "trailer", "song"], "instance": {"id": "1912", "words": ["what", "are", "some", "police", "themed", "movies", "from", "the", "1990", "s"], "labels": ["O", "O", "O", "B-genre", "O", "O", "O", "O", "B-year", "I-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, actor, review, genre, plot, year, title, rating, character, director, trailer, song and O.\nSentence: what are some police themed movies from the 1990 s", "prompt_labels": "what(O) are(O) some(O) police(B-genre) themed(O) movies(O) from(O) the(O) 1990(B-year) s(I-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 12360, 11, 3477, 11, 17779, 11, 7234, 11, 1060, 11, 2316, 11, 10959, 11, 3752, 11, 7690, 11, 19809, 11, 5609, 323, 507, 627, 85664, 25, 1148, 527, 1063, 4379, 49644, 9698, 505, 279, 220, 2550, 15, 274, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) are(O) some(O) police(B-plot) themed(O) movies(O) from(O) the(O) 1990(B-year) s(I-year)"}
{"id": "104", "dataset": "mit-restaurant", "split": "test", "label_list": ["Hours", "Rating", "Cuisine", "Location", "Dish", "Amenity", "Restaurant Name", "Price"], "instance": {"id": "104", "words": ["beer", "and", "hot", "wings", "in", "town"], "labels": ["B-Dish", "O", "B-Dish", "I-Dish", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Rating, Cuisine, Location, Dish, Amenity, Restaurant Name, Price and O.\nSentence: beer and hot wings in town", "prompt_labels": "beer(B-Dish) and(O) hot(B-Dish) wings(I-Dish) in(B-Location) town(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 19767, 11, 81961, 11, 10067, 11, 49268, 11, 3383, 56685, 11, 26568, 4076, 11, 8650, 323, 507, 627, 85664, 25, 13179, 323, 4106, 27296, 304, 6424, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "beer(B-Dish) and(I-Dish) hot(I-Dish) wings(I-Dish) in(B-Location) town(I-Location)"}
{"id": "405", "dataset": "mit-restaurant", "split": "test", "label_list": ["Rating", "Amenity", "Restaurant Name", "Price", "Cuisine", "Location", "Hours", "Dish"], "instance": {"id": "405", "words": ["find", "me", "a", "southwestern", "restaurant", "that", "serves", "breakfast", "and", "is", "located", "nearby"], "labels": ["O", "O", "O", "B-Cuisine", "O", "O", "O", "B-Hours", "O", "O", "B-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Amenity, Restaurant Name, Price, Cuisine, Location, Hours, Dish and O.\nSentence: find me a southwestern restaurant that serves breakfast and is located nearby", "prompt_labels": "find(O) me(O) a(O) southwestern(B-Cuisine) restaurant(O) that(O) serves(O) breakfast(B-Hours) and(O) is(O) located(B-Location) nearby(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 3383, 56685, 11, 26568, 4076, 11, 8650, 11, 81961, 11, 10067, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 1505, 757, 264, 99911, 10960, 430, 17482, 17954, 323, 374, 7559, 14373, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "find(O) me(O) a(O) southwestern(B-Cuisine) restaurant(O) that(O) serves(O) breakfast(B-Hours) and(O) is(O) located(B-Location) nearby(I-Location)"}
{"id": "252", "dataset": "mit-movie", "split": "test", "label_list": ["review", "director", "title", "trailer", "character", "actor", "genre", "rating", "song", "year", "plot", "average ratings"], "instance": {"id": "252", "words": ["show", "me", "action", "movies", "that", "deal", "with", "stealing", "cars"], "labels": ["O", "O", "B-genre", "O", "O", "O", "O", "B-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: review, director, title, trailer, character, actor, genre, rating, song, year, plot, average ratings and O.\nSentence: show me action movies that deal with stealing cars", "prompt_labels": "show(O) me(O) action(B-genre) movies(O) that(O) deal(O) with(O) stealing(B-plot) cars(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3477, 11, 7690, 11, 2316, 11, 19809, 11, 3752, 11, 12360, 11, 17779, 11, 10959, 11, 5609, 11, 1060, 11, 7234, 11, 5578, 18594, 323, 507, 627, 85664, 25, 1501, 757, 1957, 9698, 430, 3568, 449, 39098, 9515, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) action(B-genre) movies(O) that(O) deal(O) with(O) stealing(B-plot) cars(I-plot)"}
{"id": "1340", "dataset": "mit-restaurant", "split": "test", "label_list": ["Price", "Location", "Cuisine", "Hours", "Restaurant Name", "Amenity", "Rating", "Dish"], "instance": {"id": "1340", "words": ["where", "can", "i", "get", "some", "slushy"], "labels": ["O", "O", "O", "O", "O", "B-Dish"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Price, Location, Cuisine, Hours, Restaurant Name, Amenity, Rating, Dish and O.\nSentence: where can i get some slushy", "prompt_labels": "where(O) can(O) i(O) get(O) some(O) slushy(B-Dish)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 8650, 11, 10067, 11, 81961, 11, 30192, 11, 26568, 4076, 11, 3383, 56685, 11, 19767, 11, 49268, 323, 507, 627, 85664, 25, 1405, 649, 602, 636, 1063, 1776, 1136, 88, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "where(O) can(O) i(O) get(O) some(O) slushy(B-Dish)"}
{"id": "718", "dataset": "mit-restaurant", "split": "test", "label_list": ["Amenity", "Hours", "Cuisine", "Dish", "Price", "Restaurant Name", "Location", "Rating"], "instance": {"id": "718", "words": ["im", "feeling", "a", "little", "down", "so", "id", "like", "go", "somewhere", "thats", "really", "bright", "and", "fun", "for", "breakfast"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-Amenity", "I-Amenity", "I-Amenity", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Amenity, Hours, Cuisine, Dish, Price, Restaurant Name, Location, Rating and O.\nSentence: im feeling a little down so id like go somewhere thats really bright and fun for breakfast", "prompt_labels": "im(O) feeling(O) a(O) little(O) down(O) so(O) id(O) like(O) go(O) somewhere(O) thats(O) really(O) bright(B-Amenity) and(I-Amenity) fun(I-Amenity) for(O) breakfast(B-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3383, 56685, 11, 30192, 11, 81961, 11, 49268, 11, 8650, 11, 26568, 4076, 11, 10067, 11, 19767, 323, 507, 627, 85664, 25, 737, 8430, 264, 2697, 1523, 779, 887, 1093, 733, 15038, 41136, 2216, 10107, 323, 2523, 369, 17954, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "im(O) feeling(O) a(O) little(O) down(O) so(O) id(O) like(O) go(O) somewhere(O) thats(O) really(O) bright(B-Amenity) and(O) fun(B-Amenity) for(O) breakfast(B-Hours)"}
{"id": "1440", "dataset": "mit-movie", "split": "test", "label_list": ["average ratings", "actor", "rating", "plot", "genre", "title", "year", "character", "trailer", "review", "song", "director"], "instance": {"id": "1440", "words": ["is", "john", "travolta", "starring", "in", "any", "childrens", "movie"], "labels": ["O", "B-actor", "I-actor", "O", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, actor, rating, plot, genre, title, year, character, trailer, review, song, director and O.\nSentence: is john travolta starring in any childrens movie", "prompt_labels": "is(O) john(B-actor) travolta(I-actor) starring(O) in(O) any(O) childrens(B-genre) movie(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 12360, 11, 10959, 11, 7234, 11, 17779, 11, 2316, 11, 1060, 11, 3752, 11, 19809, 11, 3477, 11, 5609, 11, 7690, 323, 507, 627, 85664, 25, 374, 40742, 10346, 60954, 40500, 304, 904, 2911, 82, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) john(B-actor) travolta(I-actor) starring(O) in(O) any(O) childrens(B-genre) movie(O)"}
{"id": "583", "dataset": "crossner_politics", "split": "test", "label_list": ["politician", "person", "country", "election", "organization", "location", "event", "political party"], "instance": {"id": "583", "words": ["R\u00f6ttgen", ",", "in", "his", "capacity", "as", "environment", "minister", ",", "led", "the", "German", "delegations", "to", "the", "2009", "United", "Nations", "Climate", "Change", "Conference", "in", "Copenhagen", ",", "the", "2010", "United", "Nations", "Climate", "Change", "Conference", "in", "Canc\u00fan", "and", "the", "2011", "United", "Nations", "Climate", "Change", "Conference", "in", "Durban", ",", "respectively", "."], "labels": ["B-politician", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "B-location", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "B-location", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "I-event", "O", "B-location", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: politician, person, country, election, organization, location, event, political party and O.\nSentence: R\u00f6ttgen , in his capacity as environment minister , led the German delegations to the 2009 United Nations Climate Change Conference in Copenhagen , the 2010 United Nations Climate Change Conference in Canc\u00fan and the 2011 United Nations Climate Change Conference in Durban , respectively .", "prompt_labels": "R\u00f6ttgen(B-politician) ,(O) in(O) his(O) capacity(O) as(O) environment(O) minister(O) ,(O) led(O) the(O) German(O) delegations(O) to(O) the(O) 2009(B-event) United(I-event) Nations(I-event) Climate(I-event) Change(I-event) Conference(I-event) in(O) Copenhagen(B-location) ,(O) the(O) 2010(B-event) United(I-event) Nations(I-event) Climate(I-event) Change(I-event) Conference(I-event) in(O) Canc\u00fan(B-location) and(O) the(O) 2011(B-event) United(I-event) Nations(I-event) Climate(I-event) Change(I-event) Conference(I-event) in(O) Durban(B-location) ,(O) respectively(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 37038, 11, 1732, 11, 3224, 11, 6355, 11, 7471, 11, 3813, 11, 1567, 11, 5054, 4717, 323, 507, 627, 85664, 25, 432, 87864, 4469, 1174, 304, 813, 8824, 439, 4676, 13015, 1174, 6197, 279, 6063, 20445, 811, 311, 279, 220, 1049, 24, 3723, 19687, 31636, 10604, 15217, 304, 64161, 1174, 279, 220, 679, 15, 3723, 19687, 31636, 10604, 15217, 304, 81423, 25155, 323, 279, 220, 679, 16, 3723, 19687, 31636, 10604, 15217, 304, 20742, 6993, 1174, 15947, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "R\u00f6ttgen(B-politician),(O) in(O) his(O) capacity(O) as(O) environment(O) minister(O),(O) led(O) the(O) German(O) delegations(O) to(O) the(O) 2009(B-event) United(I-event) Nations(I-event) Climate(I-event) Change(I-event) Conference(I-event) in(O) Copenhagen(B-location),(O) the(O) 2010(B-event) United(I-event) Nations(I-event) Climate(I-event) Change(I-event) Conference(I-event) in(O) Canc\u00fan(B-location) and(O) the(O) 2011(B-event) United(I-event) Nations(I-event) Climate(I-event) Change(I-event) conference(I-event) in(O) Durban(B-location),(O) respectively(O).(O)"}
{"id": "194", "dataset": "mit-restaurant", "split": "test", "label_list": ["Restaurant Name", "Rating", "Dish", "Amenity", "Cuisine", "Price", "Hours", "Location"], "instance": {"id": "194", "words": ["can", "you", "make", "a", "reservation", "at", "pf", "changs", "for", "tonight"], "labels": ["O", "O", "O", "O", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "O", "B-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Rating, Dish, Amenity, Cuisine, Price, Hours, Location and O.\nSentence: can you make a reservation at pf changs for tonight", "prompt_labels": "can(O) you(O) make(O) a(O) reservation(O) at(O) pf(B-Restaurant Name) changs(I-Restaurant Name) for(O) tonight(B-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 19767, 11, 49268, 11, 3383, 56685, 11, 81961, 11, 8650, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 649, 499, 1304, 264, 28767, 520, 28518, 2609, 82, 369, 18396, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "can(O) you(O) make(O) a(O) reservation(O) at(O) pf(B-Restaurant Name) changs(I-Restaurant Name) for(O) tonight(B-Hours)"}
{"id": "2120", "dataset": "mit-movie", "split": "test", "label_list": ["average ratings", "review", "character", "plot", "song", "genre", "trailer", "title", "year", "director", "actor", "rating"], "instance": {"id": "2120", "words": ["what", "is", "the", "title", "of", "the", "jim", "byrnes", "film", "that", "received", "nine", "stars", "in", "1980"], "labels": ["O", "O", "O", "O", "O", "O", "B-actor", "I-actor", "O", "O", "O", "B-average ratings", "I-average ratings", "O", "B-year"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: average ratings, review, character, plot, song, genre, trailer, title, year, director, actor, rating and O.\nSentence: what is the title of the jim byrnes film that received nine stars in 1980", "prompt_labels": "what(O) is(O) the(O) title(O) of(O) the(O) jim(B-actor) byrnes(I-actor) film(O) that(O) received(O) nine(B-average ratings) stars(I-average ratings) in(O) 1980(B-year)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5578, 18594, 11, 3477, 11, 3752, 11, 7234, 11, 5609, 11, 17779, 11, 19809, 11, 2316, 11, 1060, 11, 7690, 11, 12360, 11, 10959, 323, 507, 627, 85664, 25, 1148, 374, 279, 2316, 315, 279, 96544, 555, 81, 4978, 4632, 430, 4036, 11888, 9958, 304, 220, 3753, 15, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "what(O) is(O) the(O) title(O) of(O) the(O) jim(B-director) byrnes(I-director) film(O) that(O) received(O) nine(B-average ratings) stars(I-average ratings) in(O) 1980(B-year)"}
{"id": "175", "dataset": "crossner_literature", "split": "test", "label_list": ["event", "book", "magazine", "writer", "poem", "literary genre", "person", "award", "organization", "country", "location"], "instance": {"id": "175", "words": ["The", "Dragons", "of", "Eden", ",", "which", "won", "a", "Pulitzer", "Prize", ";", "and", "Broca", "'s", "Brain", ":", "Reflections", "on", "the", "Romance", "of", "Science", "."], "labels": ["B-book", "I-book", "I-book", "I-book", "O", "O", "O", "O", "B-award", "I-award", "O", "O", "B-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "I-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, book, magazine, writer, poem, literary genre, person, award, organization, country, location and O.\nSentence: The Dragons of Eden , which won a Pulitzer Prize ; and Broca 's Brain : Reflections on the Romance of Science .", "prompt_labels": "The(B-book) Dragons(I-book) of(I-book) Eden(I-book) ,(O) which(O) won(O) a(O) Pulitzer(B-award) Prize(I-award) ;(O) and(O) Broca(B-book) 's(I-book) Brain(I-book) :(I-book) Reflections(I-book) on(I-book) the(I-book) Romance(I-book) of(I-book) Science(I-book) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1567, 11, 2363, 11, 14756, 11, 7061, 11, 33894, 11, 32465, 17779, 11, 1732, 11, 10292, 11, 7471, 11, 3224, 11, 3813, 323, 507, 627, 85664, 25, 578, 49109, 315, 51915, 1174, 902, 2834, 264, 96815, 32293, 2652, 323, 6031, 936, 364, 82, 31417, 551, 43976, 82, 389, 279, 52256, 315, 10170, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) Dragons(B-book) of(I-book) Eden(I-book),(O) which(O) won(O) a(O) Pulitzer(B-award) Prize(I-award) ;(O) and(O) Broca(B-book)'s(I-book) Brain(I-book) :(O) Reflections(O) on(O) the(O) Romance(O) of(O) Science(O).(O)"}
{"id": "1487", "dataset": "mit-movie", "split": "test", "label_list": ["song", "title", "character", "average ratings", "actor", "rating", "trailer", "director", "year", "plot", "genre", "review"], "instance": {"id": "1487", "words": ["is", "there", "a", "good", "fantasy", "movie"], "labels": ["O", "O", "O", "O", "B-genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: song, title, character, average ratings, actor, rating, trailer, director, year, plot, genre, review and O.\nSentence: is there a good fantasy movie", "prompt_labels": "is(O) there(O) a(O) good(O) fantasy(B-genre) movie(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 5609, 11, 2316, 11, 3752, 11, 5578, 18594, 11, 12360, 11, 10959, 11, 19809, 11, 7690, 11, 1060, 11, 7234, 11, 17779, 11, 3477, 323, 507, 627, 85664, 25, 374, 1070, 264, 1695, 18884, 5818, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "is(O) there(O) a(O) good(O) fantasy(B-genre) movie(O)"}
{"id": "221", "dataset": "crossner_music", "split": "test", "label_list": ["music genre", "band", "musical instrument", "song", "person", "award", "organization", "event", "album", "location", "musical artist", "country"], "instance": {"id": "221", "words": ["Many", "stations", "play", "primarily", "gospel", "music", ",", "including", "Urban", "contemporary", "gospel", "and", "Southern", "Gospel", ",", "or", "contemporary", "worship", "music", ",", "while", "others", "play", "all", "formats", "of", "contemporary", "Christian", "music", ",", "including", "Christian", "pop", ",", "Christian", "rock", ",", "Christian", "rap", ",", "Christian", "country", "music", ",", "and", "Christian", "alternative", "rock", "."], "labels": ["O", "O", "O", "O", "B-music genre", "I-music genre", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "O", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O", "O", "O", "O", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "O", "B-music genre", "I-music genre", "I-music genre", "O", "O", "B-music genre", "I-music genre", "I-music genre", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, band, musical instrument, song, person, award, organization, event, album, location, musical artist, country and O.\nSentence: Many stations play primarily gospel music , including Urban contemporary gospel and Southern Gospel , or contemporary worship music , while others play all formats of contemporary Christian music , including Christian pop , Christian rock , Christian rap , Christian country music , and Christian alternative rock .", "prompt_labels": "Many(O) stations(O) play(O) primarily(O) gospel(B-music genre) music(I-music genre) ,(O) including(O) Urban(B-music genre) contemporary(I-music genre) gospel(I-music genre) and(O) Southern(B-music genre) Gospel(I-music genre) ,(O) or(O) contemporary(B-music genre) worship(I-music genre) music(I-music genre) ,(O) while(O) others(O) play(O) all(O) formats(O) of(O) contemporary(B-music genre) Christian(I-music genre) music(I-music genre) ,(O) including(O) Christian(O) pop(O) ,(O) Christian(B-music genre) rock(I-music genre) ,(O) Christian(B-music genre) rap(I-music genre) ,(O) Christian(B-music genre) country(I-music genre) music(I-music genre) ,(O) and(O) Christian(B-music genre) alternative(I-music genre) rock(I-music genre) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 4731, 17779, 11, 7200, 11, 18273, 14473, 11, 5609, 11, 1732, 11, 10292, 11, 7471, 11, 1567, 11, 8176, 11, 3813, 11, 18273, 10255, 11, 3224, 323, 507, 627, 85664, 25, 9176, 17789, 1514, 15871, 42582, 4731, 1174, 2737, 29422, 19225, 42582, 323, 16642, 44468, 1174, 477, 19225, 24863, 4731, 1174, 1418, 3885, 1514, 682, 20447, 315, 19225, 9052, 4731, 1174, 2737, 9052, 2477, 1174, 9052, 7091, 1174, 9052, 7477, 1174, 9052, 3224, 4731, 1174, 323, 9052, 10778, 7091, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Many(O) stations(O) play(O) primarily(O) gospel(B-music genre) music(I-music genre),(O) including(O) Urban(B-music genre) contemporary(I-music genre) gospel(I-music genre) and(O) Southern(B-music genre) Gospel(I-music genre),(O) or(O) contemporary(B-music genre) worship(I-music genre) music(I-music genre),(O) while(O) others(O) play(O) all(O) formats(O) of(O) contemporary(B-music genre) Christian(I-music genre) music(I-music genre),(O) including(O) Christian(B-music genre) pop(I-music genre),(O) Christian(B-music genre) rock(I-music genre),(O) Christian(B-music genre) rap(I-music genre),(O) Christian(B-music genre) country(I-music genre) music(I-music genre),(O) and(O) Christian(B-music genre) alternative(I-music genre) rock(I-music genre).(O)"}
{"id": "413", "dataset": "crossner_ai", "split": "test", "label_list": ["algorithm", "conference", "person", "field", "location", "university", "country", "researcher", "task", "programming language", "organization", "metric", "product"], "instance": {"id": "413", "words": ["Delta", "robot", "s", "have", "base-mounted", "rotary", "actuator", "s", "that", "move", "a", "light", ",", "stiff", ",", "parallelogram", "arm", "."], "labels": ["B-product", "I-product", "O", "O", "O", "B-product", "I-product", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, conference, person, field, location, university, country, researcher, task, programming language, organization, metric, product and O.\nSentence: Delta robot s have base-mounted rotary actuator s that move a light , stiff , parallelogram arm .", "prompt_labels": "Delta(B-product) robot(I-product) s(O) have(O) base-mounted(O) rotary(B-product) actuator(I-product) s(O) that(O) move(O) a(O) light(O) ,(O) stiff(O) ,(O) parallelogram(O) arm(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 12384, 11, 10017, 11, 1732, 11, 2115, 11, 3813, 11, 12374, 11, 3224, 11, 32185, 11, 3465, 11, 15840, 4221, 11, 7471, 11, 18767, 11, 2027, 323, 507, 627, 85664, 25, 26002, 12585, 274, 617, 2385, 78830, 62917, 1180, 46262, 274, 430, 3351, 264, 3177, 1174, 31161, 1174, 58130, 848, 2453, 6916, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Delta(B-product) robot(I-product) s(O) have(O) base-mounted(O) rotary(O) actuator(O) s(O) that(O) move(O) a(O) light(B-product),(O) stiff(O),(O) parallelogram(O) arm(O).(O)"}
{"id": "374", "dataset": "crossner_literature", "split": "test", "label_list": ["organization", "event", "poem", "person", "literary genre", "award", "book", "country", "writer", "magazine", "location"], "instance": {"id": "374", "words": ["Adaptations", "of", "the", "novel", "include", "Fran\u00e7ois", "Truffaut", "'", "s", "1966", "film", "adaptation", "and", "a", "1982", "BBC", "Radio", "dramatization.Nov", "13", "1982", "Fahrenheit", "451", ",", "BBC", "Radio", "4", "Bradbury", "published", "a", "stage", "play", "version", "in", "1979", "and", "helped", "develop", "a", "1984", "interactive", "fiction", "computer", "game", "titled", "Fahrenheit", "451", ",", "as", "well", "as", "a", "collection", "of", "his", "short", "stories", "titled", "A", "Pleasure", "to", "Burn", "."], "labels": ["O", "O", "O", "B-literary genre", "O", "B-writer", "I-writer", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "O", "B-book", "I-book", "O", "B-organization", "I-organization", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-literary genre", "I-literary genre", "O", "B-book", "I-book", "I-book", "I-book", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, poem, person, literary genre, award, book, country, writer, magazine, location and O.\nSentence: Adaptations of the novel include Fran\u00e7ois Truffaut ' s 1966 film adaptation and a 1982 BBC Radio dramatization.Nov 13 1982 Fahrenheit 451 , BBC Radio 4 Bradbury published a stage play version in 1979 and helped develop a 1984 interactive fiction computer game titled Fahrenheit 451 , as well as a collection of his short stories titled A Pleasure to Burn .", "prompt_labels": "Adaptations(O) of(O) the(O) novel(B-literary genre) include(O) Fran\u00e7ois(B-writer) Truffaut(I-writer) '(O) s(O) 1966(O) film(O) adaptation(O) and(O) a(O) 1982(O) BBC(B-organization) Radio(I-organization) dramatization.Nov(O) 13(O) 1982(O) Fahrenheit(B-book) 451(I-book) ,(O) BBC(B-organization) Radio(I-organization) 4(O) Bradbury(B-organization) published(O) a(O) stage(O) play(O) version(O) in(O) 1979(O) and(O) helped(O) develop(O) a(O) 1984(O) interactive(B-literary genre) fiction(I-literary genre) computer(O) game(O) titled(O) Fahrenheit(O) 451(O) ,(O) as(O) well(O) as(O) a(O) collection(O) of(O) his(O) short(B-literary genre) stories(I-literary genre) titled(O) A(B-book) Pleasure(I-book) to(I-book) Burn(I-book) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7471, 11, 1567, 11, 33894, 11, 1732, 11, 32465, 17779, 11, 10292, 11, 2363, 11, 3224, 11, 7061, 11, 14756, 11, 3813, 323, 507, 627, 85664, 25, 59531, 811, 315, 279, 11775, 2997, 85807, 1183, 1386, 2784, 364, 274, 220, 5162, 21, 4632, 34185, 323, 264, 220, 3753, 17, 18588, 13792, 13859, 266, 2065, 2112, 869, 220, 1032, 220, 3753, 17, 69823, 220, 20360, 1174, 18588, 13792, 220, 19, 17478, 20176, 4756, 264, 6566, 1514, 2373, 304, 220, 4468, 24, 323, 9087, 2274, 264, 220, 3753, 19, 21416, 17422, 6500, 1847, 25891, 69823, 220, 20360, 1174, 439, 1664, 439, 264, 4526, 315, 813, 2875, 7493, 25891, 362, 33540, 4058, 311, 18530, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Adaptations(O) of(O) the(O) novel(B-literary genre) include(O) Fran\u00e7ois(B-writer) Truffaut(I-writer) '(O) s(O) 1966(O) film(O) adaptation(O) and(O) a(O) 1982(O) BBC(O) Radio(O) dramatization.Nov(O) 13(O) 1982(O) Fahrenheit(B-book) 451(I-book),(O) BBC(O) Radio(O) 4(O) Bradbury(B-writer) published(O) a(O) stage(O) play(O) version(O) in(O) 1979(O) and(O) helped(O) develop(O) a(O) 1984(O) interactive(O) fiction(O) computer(O) game(O) titled(O) Fahrenheit(B-book) 451(I-book),(O) as(O) well(O) as(O) a(O) collection(O) of(O) his(O) short(O) stories(O) titled(O) A(B-book) Pleasure(I-book) to(I-book) Burn(I-book).(O)"}
{"id": "1188", "dataset": "mit-movie", "split": "test", "label_list": ["rating", "song", "review", "actor", "director", "character", "trailer", "average ratings", "plot", "year", "genre", "title"], "instance": {"id": "1188", "words": ["do", "you", "happen", "to", "know", "where", "i", "might", "find", "the", "movie", "every", "which", "way", "but", "loose"], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-title", "I-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, song, review, actor, director, character, trailer, average ratings, plot, year, genre, title and O.\nSentence: do you happen to know where i might find the movie every which way but loose", "prompt_labels": "do(O) you(O) happen(O) to(O) know(O) where(O) i(O) might(O) find(O) the(O) movie(O) every(B-title) which(I-title) way(I-title) but(I-title) loose(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 5609, 11, 3477, 11, 12360, 11, 7690, 11, 3752, 11, 19809, 11, 5578, 18594, 11, 7234, 11, 1060, 11, 17779, 11, 2316, 323, 507, 627, 85664, 25, 656, 499, 3621, 311, 1440, 1405, 602, 2643, 1505, 279, 5818, 1475, 902, 1648, 719, 20784, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "do(O) you(O) happen(O) to(O) know(O) where(O) i(O) might(O) find(O) the(O) movie(O) every(B-title) which(I-title) way(I-title) but(I-title) loose(I-title)"}
{"id": "755", "dataset": "mit-restaurant", "split": "test", "label_list": ["Rating", "Cuisine", "Dish", "Amenity", "Price", "Hours", "Location", "Restaurant Name"], "instance": {"id": "755", "words": ["im", "starving", "tell", "me", "where", "the", "closest", "mcdonalds", "is"], "labels": ["O", "O", "O", "O", "O", "O", "B-Location", "B-Restaurant Name", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Cuisine, Dish, Amenity, Price, Hours, Location, Restaurant Name and O.\nSentence: im starving tell me where the closest mcdonalds is", "prompt_labels": "im(O) starving(O) tell(O) me(O) where(O) the(O) closest(B-Location) mcdonalds(B-Restaurant Name) is(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 81961, 11, 49268, 11, 3383, 56685, 11, 8650, 11, 30192, 11, 10067, 11, 26568, 4076, 323, 507, 627, 85664, 25, 737, 78501, 3371, 757, 1405, 279, 18585, 296, 4484, 80794, 82, 374, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "im(O) starving(O) tell(O) me(O) where(O) the(O) closest(B-Location) mcdonalds(B-Restaurant Name) is(O)"}
{"id": "565", "dataset": "crossner_politics", "split": "test", "label_list": ["person", "politician", "political party", "location", "event", "election", "country", "organization"], "instance": {"id": "565", "words": ["The", "speakers", "-", "all", "of", "whom", "were", "high", "schoolers", "or", "younger", "-", "included", "Marjory", "Stoneman", "Douglas", "students", "Cameron", "Kasky", ",", "David", "Hogg", ",", "Delaney", "Tarr", ",", "Sarah", "Chadwick", ",", "Alex", "Wind", ",", "Jaclyn", "Corin", ",", "Ryan", "Deitsch", ",", "Aalayah", "Eastmond", ",", "Samantha", "Fuentes", ",", "and", "Emma", "Gonz\u00e1lez", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "B-person", "I-person", "O", "O", "B-person", "I-person", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, politician, political party, location, event, election, country, organization and O.\nSentence: The speakers - all of whom were high schoolers or younger - included Marjory Stoneman Douglas students Cameron Kasky , David Hogg , Delaney Tarr , Sarah Chadwick , Alex Wind , Jaclyn Corin , Ryan Deitsch , Aalayah Eastmond , Samantha Fuentes , and Emma Gonz\u00e1lez .", "prompt_labels": "The(O) speakers(O) -(O) all(O) of(O) whom(O) were(O) high(O) schoolers(O) or(O) younger(O) -(O) included(O) Marjory(B-organization) Stoneman(I-organization) Douglas(I-organization) students(O) Cameron(B-person) Kasky(I-person) ,(O) David(B-person) Hogg(I-person) ,(O) Delaney(B-person) Tarr(I-person) ,(O) Sarah(B-person) Chadwick(I-person) ,(O) Alex(B-person) Wind(I-person) ,(O) Jaclyn(B-person) Corin(I-person) ,(O) Ryan(B-person) Deitsch(I-person) ,(O) Aalayah(B-person) Eastmond(I-person) ,(O) Samantha(B-person) Fuentes(I-person) ,(O) and(O) Emma(B-person) Gonz\u00e1lez(I-person) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1732, 11, 37038, 11, 5054, 4717, 11, 3813, 11, 1567, 11, 6355, 11, 3224, 11, 7471, 323, 507, 627, 85664, 25, 578, 22032, 482, 682, 315, 8884, 1051, 1579, 2978, 388, 477, 14992, 482, 5343, 2947, 73, 683, 36219, 16357, 31164, 4236, 27524, 735, 1091, 88, 1174, 6941, 473, 16499, 1174, 7462, 82286, 350, 1138, 1174, 21077, 43130, 21878, 1174, 8683, 22862, 1174, 15385, 18499, 4563, 258, 1174, 13960, 1611, 1220, 331, 1174, 362, 278, 85174, 6460, 12669, 1174, 63908, 435, 69837, 1174, 323, 36035, 33555, 97465, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) speakers(O) -(O) all(O) of(O) whom(O) were(O) high(O) schoolers(O) or(O) younger(O) -(O) included(O) Marjory(B-person) Stoneman(I-person) Douglas(I-person) students(O) Cameron(B-person) Kasky(I-person),(O) David(B-person) Hogg(I-person),(O) Delaney(B-person) Tarr(I-person),(O) Sarah(B-person) Chadwick(I-person),(O) Alex(B-person) Wind(I-person),(O) Jaclyn(B-person) Corin(I-person),(O) Ryan(B-person) Deitsch(I-person),(O) Aalayah(B-person) Eastmond(I-person),(O) Samantha(B-person) Fuentes(I-person),(O) and(O) Emma(B-person) Gonz\u00e1lez(I-person).(O)"}
{"id": "271", "dataset": "crossner_ai", "split": "test", "label_list": ["field", "country", "conference", "researcher", "algorithm", "task", "organization", "university", "location", "person", "metric", "product", "programming language"], "instance": {"id": "271", "words": ["Unimation", "later", "licensed", "their", "technology", "to", "Kawasaki", "Heavy", "Industries", "and", "GKN", ",", "manufacturing", "Unimate", "s", "in", "Japan", "and", "England", "respectively", "."], "labels": ["B-organization", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "O", "O", "B-product", "O", "O", "B-country", "O", "B-country", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, country, conference, researcher, algorithm, task, organization, university, location, person, metric, product, programming language and O.\nSentence: Unimation later licensed their technology to Kawasaki Heavy Industries and GKN , manufacturing Unimate s in Japan and England respectively .", "prompt_labels": "Unimation(B-organization) later(O) licensed(O) their(O) technology(O) to(O) Kawasaki(B-organization) Heavy(I-organization) Industries(I-organization) and(O) GKN(B-organization) ,(O) manufacturing(O) Unimate(B-product) s(O) in(O) Japan(B-country) and(O) England(B-country) respectively(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2115, 11, 3224, 11, 10017, 11, 32185, 11, 12384, 11, 3465, 11, 7471, 11, 12374, 11, 3813, 11, 1732, 11, 18767, 11, 2027, 11, 15840, 4221, 323, 507, 627, 85664, 25, 1252, 5582, 3010, 16383, 872, 5557, 311, 98538, 29201, 37528, 323, 480, 17596, 1174, 15266, 1252, 3509, 274, 304, 6457, 323, 9635, 15947, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "Unimation(B-organization) later(O) licensed(O) their(O) technology(O) to(O) Kawasaki(B-organization) Heavy(I-organization) Industries(I-organization) and(O) GKN(B-organization),(O) manufacturing(O) Unimate(B-product) s(O) in(O) Japan(B-country) and(O) England(B-country) respectively(O).(O)"}
{"id": "315", "dataset": "crossner_ai", "split": "test", "label_list": ["researcher", "country", "programming language", "conference", "person", "organization", "location", "algorithm", "metric", "university", "field", "product", "task"], "instance": {"id": "315", "words": ["The", "Sobel", "operator", ",", "sometimes", "called", "the", "Sobel-Feldman", "operator", "or", "Sobel", "filter", ",", "is", "used", "in", "image", "processing", "and", "computer", "vision", ",", "particularly", "within", "edge", "detection", "algorithms", "where", "it", "creates", "an", "image", "emphasising", "edges", "."], "labels": ["O", "B-algorithm", "I-algorithm", "O", "O", "O", "O", "B-algorithm", "I-algorithm", "O", "B-algorithm", "I-algorithm", "O", "O", "O", "O", "B-field", "I-field", "O", "B-field", "I-field", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, country, programming language, conference, person, organization, location, algorithm, metric, university, field, product, task and O.\nSentence: The Sobel operator , sometimes called the Sobel-Feldman operator or Sobel filter , is used in image processing and computer vision , particularly within edge detection algorithms where it creates an image emphasising edges .", "prompt_labels": "The(O) Sobel(B-algorithm) operator(I-algorithm) ,(O) sometimes(O) called(O) the(O) Sobel-Feldman(B-algorithm) operator(I-algorithm) or(O) Sobel(B-algorithm) filter(I-algorithm) ,(O) is(O) used(O) in(O) image(B-field) processing(I-field) and(O) computer(B-field) vision(I-field) ,(O) particularly(O) within(O) edge(O) detection(O) algorithms(O) where(O) it(O) creates(O) an(O) image(O) emphasising(O) edges(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 32185, 11, 3224, 11, 15840, 4221, 11, 10017, 11, 1732, 11, 7471, 11, 3813, 11, 12384, 11, 18767, 11, 12374, 11, 2115, 11, 2027, 11, 3465, 323, 507, 627, 85664, 25, 578, 67537, 301, 5793, 1174, 7170, 2663, 279, 67537, 301, 7424, 789, 1543, 5793, 477, 67537, 301, 4141, 1174, 374, 1511, 304, 2217, 8863, 323, 6500, 11376, 1174, 8104, 2949, 6964, 18468, 26249, 1405, 433, 11705, 459, 2217, 20654, 3876, 13116, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "The(O) Sobel(B-algorithm) operator(I-algorithm),(O) sometimes(O) called(O) the(O) Sobel-Feldman(O) operator(O) or(O) Sobel(O) filter(O),(O) is(O) used(O) in(O) image(B-field) processing(I-field) and(O) computer(B-field) vision(I-field),(O) particularly(O) within(O) edge(O) detection(O) algorithms(O) where(O) it(O) creates(O) an(O) image(O) emphasising(O) edges(O).(O)"}
{"id": "1415", "dataset": "mit-movie", "split": "test", "label_list": ["year", "rating", "character", "actor", "plot", "genre", "review", "trailer", "song", "average ratings", "title", "director"], "instance": {"id": "1415", "words": ["in", "the", "last", "seven", "years", "was", "there", "an", "r", "rated", "violence", "film", "that", "received", "an", "average", "rating", "of", "five"], "labels": ["O", "O", "B-year", "I-year", "I-year", "O", "O", "O", "B-rating", "O", "B-genre", "O", "O", "O", "O", "O", "O", "O", "B-average ratings"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, rating, character, actor, plot, genre, review, trailer, song, average ratings, title, director and O.\nSentence: in the last seven years was there an r rated violence film that received an average rating of five", "prompt_labels": "in(O) the(O) last(B-year) seven(I-year) years(I-year) was(O) there(O) an(O) r(B-rating) rated(O) violence(B-genre) film(O) that(O) received(O) an(O) average(O) rating(O) of(O) five(B-average ratings)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 10959, 11, 3752, 11, 12360, 11, 7234, 11, 17779, 11, 3477, 11, 19809, 11, 5609, 11, 5578, 18594, 11, 2316, 11, 7690, 323, 507, 627, 85664, 25, 304, 279, 1566, 8254, 1667, 574, 1070, 459, 436, 22359, 9349, 4632, 430, 4036, 459, 5578, 10959, 315, 4330, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "in(O) the(O) last(B-year) seven(I-year) years(I-year) was(O) there(O) an(O) r(B-rating) rated(O) violence(B-genre) film(O) that(O) received(O) an(O) average(O) rating(O) of(O) five(B-average ratings)"}
{"id": "172", "dataset": "mit-movie", "split": "test", "label_list": ["title", "song", "review", "trailer", "rating", "plot", "director", "average ratings", "actor", "year", "genre", "character"], "instance": {"id": "172", "words": ["kung", "fu", "panda", "2"], "labels": ["B-title", "I-title", "I-title", "I-title"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: title, song, review, trailer, rating, plot, director, average ratings, actor, year, genre, character and O.\nSentence: kung fu panda 2", "prompt_labels": "kung(B-title) fu(I-title) panda(I-title) 2(I-title)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 2316, 11, 5609, 11, 3477, 11, 19809, 11, 10959, 11, 7234, 11, 7690, 11, 5578, 18594, 11, 12360, 11, 1060, 11, 17779, 11, 3752, 323, 507, 627, 85664, 25, 597, 2234, 18922, 89322, 220, 17, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "kung(B-title) fu(I-title) panda(I-title) 2(I-title)"}
{"id": "494", "dataset": "mit-restaurant", "split": "test", "label_list": ["Cuisine", "Hours", "Restaurant Name", "Location", "Amenity", "Rating", "Dish", "Price"], "instance": {"id": "494", "words": ["how", "big", "are", "the", "portions", "at", "cheddars"], "labels": ["O", "O", "O", "O", "O", "O", "B-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Cuisine, Hours, Restaurant Name, Location, Amenity, Rating, Dish, Price and O.\nSentence: how big are the portions at cheddars", "prompt_labels": "how(O) big(O) are(O) the(O) portions(O) at(O) cheddars(B-Restaurant Name)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 81961, 11, 30192, 11, 26568, 4076, 11, 10067, 11, 3383, 56685, 11, 19767, 11, 49268, 11, 8650, 323, 507, 627, 85664, 25, 1268, 2466, 527, 279, 19885, 520, 523, 54637, 1590, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "how(O) big(O) are(O) the(O) portions(O) at(O) cheddars(B-Restaurant Name)"}
{"id": "63", "dataset": "mit-restaurant", "split": "test", "label_list": ["Hours", "Cuisine", "Dish", "Amenity", "Rating", "Location", "Price", "Restaurant Name"], "instance": {"id": "63", "words": ["are", "there", "any", "place", "close", "by", "that", "is", "open", "24", "hours"], "labels": ["O", "O", "O", "O", "B-Location", "O", "O", "O", "B-Hours", "I-Hours", "I-Hours"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Hours, Cuisine, Dish, Amenity, Rating, Location, Price, Restaurant Name and O.\nSentence: are there any place close by that is open 24 hours", "prompt_labels": "are(O) there(O) any(O) place(O) close(B-Location) by(O) that(O) is(O) open(B-Hours) 24(I-Hours) hours(I-Hours)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 30192, 11, 81961, 11, 49268, 11, 3383, 56685, 11, 19767, 11, 10067, 11, 8650, 11, 26568, 4076, 323, 507, 627, 85664, 25, 527, 1070, 904, 2035, 3345, 555, 430, 374, 1825, 220, 1187, 4207, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "are(O) there(O) any(O) place(O) close(B-Location) by(I-Location) that(O) is(O) open(B-Hours) 24(I-Hours) hours(I-Hours)"}
{"id": "1727", "dataset": "mit-movie", "split": "test", "label_list": ["year", "trailer", "song", "average ratings", "director", "title", "review", "character", "genre", "plot", "rating", "actor"], "instance": {"id": "1727", "words": ["name", "a", "film", "about", "a", "kung", "fu", "master"], "labels": ["O", "O", "O", "O", "O", "B-plot", "I-plot", "I-plot"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: year, trailer, song, average ratings, director, title, review, character, genre, plot, rating, actor and O.\nSentence: name a film about a kung fu master", "prompt_labels": "name(O) a(O) film(O) about(O) a(O) kung(B-plot) fu(I-plot) master(I-plot)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 1060, 11, 19809, 11, 5609, 11, 5578, 18594, 11, 7690, 11, 2316, 11, 3477, 11, 3752, 11, 17779, 11, 7234, 11, 10959, 11, 12360, 323, 507, 627, 85664, 25, 836, 264, 4632, 922, 264, 597, 2234, 18922, 7491, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "name(O) a(O) film(O) about(O) a(O) kung(B-plot) fu(I-plot) master(I-plot)"}
{"id": "6", "dataset": "crossner_science", "split": "test", "label_list": ["scientist", "organization", "chemical compound", "person", "award", "university", "country", "protein", "enzyme", "astronomical object", "event", "theory", "chemical element", "academic journal", "location", "discipline"], "instance": {"id": "6", "words": ["In", "February", "2016", ",", "he", "was", "one", "of", "the", "four", "scientists", "of", "LIGO", "Scientific", "Collaboration", "/", "Virgo", "interferometer", "collaboration", "presenting", "at", "the", "press", "conference", "for", "the", "announcement", "that", "the", "first", "direct", "gravitational", "wave", "observation", "had", "been", "made", "in", "September", "2015", "."], "labels": ["O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "I-organization", "O", "B-organization", "I-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-event", "I-event", "I-event", "I-event", "I-event", "O", "O", "O", "O", "O", "O", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, organization, chemical compound, person, award, university, country, protein, enzyme, astronomical object, event, theory, chemical element, academic journal, location, discipline and O.\nSentence: In February 2016 , he was one of the four scientists of LIGO Scientific Collaboration / Virgo interferometer collaboration presenting at the press conference for the announcement that the first direct gravitational wave observation had been made in September 2015 .", "prompt_labels": "In(O) February(O) 2016(O) ,(O) he(O) was(O) one(O) of(O) the(O) four(O) scientists(O) of(O) LIGO(B-organization) Scientific(I-organization) Collaboration(I-organization) /(O) Virgo(B-organization) interferometer(I-organization) collaboration(O) presenting(O) at(O) the(O) press(O) conference(O) for(O) the(O) announcement(O) that(O) the(O) first(B-event) direct(I-event) gravitational(I-event) wave(I-event) observation(I-event) had(O) been(O) made(O) in(O) September(O) 2015(O) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 28568, 11, 7471, 11, 11742, 24549, 11, 1732, 11, 10292, 11, 12374, 11, 3224, 11, 13128, 11, 49242, 11, 87283, 1665, 11, 1567, 11, 10334, 11, 11742, 2449, 11, 14584, 8486, 11, 3813, 11, 26434, 323, 507, 627, 85664, 25, 763, 7552, 220, 679, 21, 1174, 568, 574, 832, 315, 279, 3116, 14248, 315, 445, 61589, 38130, 87687, 611, 9734, 3427, 41305, 21037, 20632, 32644, 520, 279, 3577, 10017, 369, 279, 17480, 430, 279, 1176, 2167, 71019, 12330, 22695, 1047, 1027, 1903, 304, 6250, 220, 679, 20, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) February(O) 2016(O),(O) he(O) was(O) one(O) of(O) the(O) four(O) scientists(O) of(O) LIGO(B-organization) Scientific(I-organization) Collaboration(I-organization) /(O) Virgo(B-organization) interferometer(I-organization) collaboration(O) presenting(O) at(O) the(O) press(O) conference(O) for(O) the(O) announcement(O) that(O) the(O) first(O) direct(O) gravitational(O) wave(O) observation(O) had(O) been(O) made(O) in(O) September(O) 2015(O).(O)"}
{"id": "173", "dataset": "crossner_music", "split": "test", "label_list": ["location", "organization", "musical artist", "band", "person", "album", "event", "music genre", "award", "musical instrument", "song", "country"], "instance": {"id": "173", "words": ["In", "June", "2010", ",", "ASCAP", "sent", "letters", "to", "its", "members", "soliciting", "donations", "to", "fight", "entities", "that", "support", "weaker", "copyright", "restrictions", ",", "such", "as", "Public", "Knowledge", ",", "the", "Electronic", "Frontier", "Foundation", ",", "and", "Creative", "Commons", ","], "labels": ["O", "O", "O", "O", "B-organization", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "O", "B-organization", "I-organization", "O", "O", "B-organization", "I-organization", "I-organization", "O", "O", "B-organization", "I-organization", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, organization, musical artist, band, person, album, event, music genre, award, musical instrument, song, country and O.\nSentence: In June 2010 , ASCAP sent letters to its members soliciting donations to fight entities that support weaker copyright restrictions , such as Public Knowledge , the Electronic Frontier Foundation , and Creative Commons ,", "prompt_labels": "In(O) June(O) 2010(O) ,(O) ASCAP(B-organization) sent(O) letters(O) to(O) its(O) members(O) soliciting(O) donations(O) to(O) fight(O) entities(O) that(O) support(O) weaker(O) copyright(O) restrictions(O) ,(O) such(O) as(O) Public(B-organization) Knowledge(I-organization) ,(O) the(O) Electronic(B-organization) Frontier(I-organization) Foundation(I-organization) ,(O) and(O) Creative(B-organization) Commons(I-organization) ,(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 3813, 11, 7471, 11, 18273, 10255, 11, 7200, 11, 1732, 11, 8176, 11, 1567, 11, 4731, 17779, 11, 10292, 11, 18273, 14473, 11, 5609, 11, 3224, 323, 507, 627, 85664, 25, 763, 5651, 220, 679, 15, 1174, 20382, 2599, 3288, 12197, 311, 1202, 3697, 30844, 5977, 24910, 311, 4465, 15086, 430, 1862, 43383, 7065, 17294, 1174, 1778, 439, 3142, 33025, 1174, 279, 35269, 58418, 5114, 1174, 323, 25248, 26667, 1174, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) June(O) 2010(O),(O) ASCAP(B-organization) sent(O) letters(O) to(O) its(O) members(O) soliciting(O) donations(O) to(O) fight(O) entities(O) that(O) support(O) weaker(O) copyright(O) restrictions(O),(O) such(O) as(O) Public(B-organization) Knowledge(I-organization),(O) the(O) Electronic(B-organization) Frontier(I-organization) Foundation(I-organization),(O) and(O) Creative(B-organization) Commons(I-organization),(O)"}
{"id": "648", "dataset": "mit-restaurant", "split": "test", "label_list": ["Location", "Amenity", "Cuisine", "Dish", "Price", "Rating", "Hours", "Restaurant Name"], "instance": {"id": "648", "words": ["i", "want", "to", "eat", "in", "the", "best", "rated", "restaurant", "in", "the", "area"], "labels": ["O", "O", "O", "O", "O", "O", "B-Rating", "I-Rating", "O", "B-Location", "I-Location", "I-Location"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Location, Amenity, Cuisine, Dish, Price, Rating, Hours, Restaurant Name and O.\nSentence: i want to eat in the best rated restaurant in the area", "prompt_labels": "i(O) want(O) to(O) eat(O) in(O) the(O) best(B-Rating) rated(I-Rating) restaurant(O) in(B-Location) the(I-Location) area(I-Location)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10067, 11, 3383, 56685, 11, 81961, 11, 49268, 11, 8650, 11, 19767, 11, 30192, 11, 26568, 4076, 323, 507, 627, 85664, 25, 602, 1390, 311, 8343, 304, 279, 1888, 22359, 10960, 304, 279, 3158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "i(O) want(O) to(O) eat(O) in(O) the(O) best(B-Rating) rated(I-Rating) restaurant(O) in(B-Location) the(I-Location) area(I-Location)"}
{"id": "2256", "dataset": "mit-movie", "split": "test", "label_list": ["rating", "actor", "title", "trailer", "song", "plot", "average ratings", "review", "character", "year", "director", "genre"], "instance": {"id": "2256", "words": ["whats", "the", "science", "fiction", "movie", "in", "1990", "that", "was", "rated", "r", "averaged", "really", "good", "ratings", "directed", "by", "brett", "ratner"], "labels": ["O", "O", "B-genre", "I-genre", "O", "O", "B-year", "O", "O", "O", "B-rating", "O", "B-average ratings", "I-average ratings", "O", "O", "O", "B-director", "I-director"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: rating, actor, title, trailer, song, plot, average ratings, review, character, year, director, genre and O.\nSentence: whats the science fiction movie in 1990 that was rated r averaged really good ratings directed by brett ratner", "prompt_labels": "whats(O) the(O) science(B-genre) fiction(I-genre) movie(O) in(O) 1990(B-year) that(O) was(O) rated(O) r(B-rating) averaged(O) really(B-average ratings) good(I-average ratings) ratings(O) directed(O) by(O) brett(B-director) ratner(I-director)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 10959, 11, 12360, 11, 2316, 11, 19809, 11, 5609, 11, 7234, 11, 5578, 18594, 11, 3477, 11, 3752, 11, 1060, 11, 7690, 11, 17779, 323, 507, 627, 85664, 25, 41209, 279, 8198, 17422, 5818, 304, 220, 2550, 15, 430, 574, 22359, 436, 37956, 2216, 1695, 18594, 15910, 555, 293, 17708, 11494, 1215, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "whats(O) the(O) science(B-genre) fiction(I-genre) movie(O) in(O) 1990(B-year) that(O) was(O) rated(O) r(B-rating) averaged(O) really(B-average ratings) good(I-average ratings) ratings(O) directed(O) by(O) brett(B-director) ratner(I-director)"}
{"id": "130", "dataset": "mit-restaurant", "split": "test", "label_list": ["Rating", "Price", "Restaurant Name", "Cuisine", "Hours", "Amenity", "Location", "Dish"], "instance": {"id": "130", "words": ["can", "i", "valet", "park", "at", "the", "blue", "coyote", "grill"], "labels": ["O", "O", "B-Amenity", "I-Amenity", "O", "O", "B-Restaurant Name", "I-Restaurant Name", "I-Restaurant Name"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Price, Restaurant Name, Cuisine, Hours, Amenity, Location, Dish and O.\nSentence: can i valet park at the blue coyote grill", "prompt_labels": "can(O) i(O) valet(B-Amenity) park(I-Amenity) at(O) the(O) blue(B-Restaurant Name) coyote(I-Restaurant Name) grill(I-Restaurant Name)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 8650, 11, 26568, 4076, 11, 81961, 11, 30192, 11, 3383, 56685, 11, 10067, 11, 49268, 323, 507, 627, 85664, 25, 649, 602, 11412, 1169, 6246, 520, 279, 6437, 75709, 1295, 40158, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "can(O) i(O) valet(B-Amenity) park(I-Amenity) at(O) the(O) blue(B-Restaurant Name) coyote(I-Restaurant Name) grill(I-Restaurant Name)"}
{"id": "135", "dataset": "mit-restaurant", "split": "test", "label_list": ["Restaurant Name", "Location", "Cuisine", "Price", "Rating", "Amenity", "Hours", "Dish"], "instance": {"id": "135", "words": ["can", "you", "find", "a", "fast", "food", "restaurant"], "labels": ["O", "O", "O", "O", "B-Cuisine", "I-Cuisine", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Restaurant Name, Location, Cuisine, Price, Rating, Amenity, Hours, Dish and O.\nSentence: can you find a fast food restaurant", "prompt_labels": "can(O) you(O) find(O) a(O) fast(B-Cuisine) food(I-Cuisine) restaurant(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 26568, 4076, 11, 10067, 11, 81961, 11, 8650, 11, 19767, 11, 3383, 56685, 11, 30192, 11, 49268, 323, 507, 627, 85664, 25, 649, 499, 1505, 264, 5043, 3691, 10960, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "can(O) you(O) find(O) a(O) fast(B-Cuisine) food(I-Cuisine) restaurant(O)"}
{"id": "86", "dataset": "mit-restaurant", "split": "test", "label_list": ["Rating", "Cuisine", "Price", "Amenity", "Restaurant Name", "Dish", "Hours", "Location"], "instance": {"id": "86", "words": ["are", "there", "any", "restaurants", "within", "5", "miles", "that", "accept", "travelers", "checks"], "labels": ["O", "O", "O", "O", "B-Location", "I-Location", "I-Location", "O", "B-Amenity", "I-Amenity", "I-Amenity"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: Rating, Cuisine, Price, Amenity, Restaurant Name, Dish, Hours, Location and O.\nSentence: are there any restaurants within 5 miles that accept travelers checks", "prompt_labels": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 19767, 11, 81961, 11, 8650, 11, 3383, 56685, 11, 26568, 4076, 11, 49268, 11, 30192, 11, 10067, 323, 507, 627, 85664, 25, 527, 1070, 904, 15926, 2949, 220, 20, 8931, 430, 4287, 40386, 12621, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "are(O) there(O) any(O) restaurants(O) within(B-Location) 5(I-Location) miles(I-Location) that(O) accept(B-Amenity) travelers(I-Amenity) checks(I-Amenity)"}
{"id": "245", "dataset": "crossner_music", "split": "test", "label_list": ["band", "musical instrument", "location", "organization", "award", "song", "person", "album", "country", "event", "musical artist", "music genre"], "instance": {"id": "245", "words": ["In", "2004", ",", "Grohl", "drummed", "on", "several", "tracks", "for", "Nine", "Inch", "Nails", "'", "2005", "album", "With", "Teeth", ",", "later", "returning", "to", "play", "drums", "on", "'", "The", "Idea", "of", "You", "'", "from", "their", "2016", "EP", "Not", "the", "Actual", "Events", "."], "labels": ["O", "O", "O", "B-musical artist", "O", "O", "O", "O", "O", "B-band", "I-band", "I-band", "O", "O", "O", "B-album", "I-album", "O", "O", "O", "O", "O", "B-musical instrument", "O", "O", "B-song", "I-song", "I-song", "I-song", "O", "O", "O", "O", "O", "B-album", "I-album", "I-album", "I-album", "O"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, musical instrument, location, organization, award, song, person, album, country, event, musical artist, music genre and O.\nSentence: In 2004 , Grohl drummed on several tracks for Nine Inch Nails ' 2005 album With Teeth , later returning to play drums on ' The Idea of You ' from their 2016 EP Not the Actual Events .", "prompt_labels": "In(O) 2004(O) ,(O) Grohl(B-musical artist) drummed(O) on(O) several(O) tracks(O) for(O) Nine(B-band) Inch(I-band) Nails(I-band) '(O) 2005(O) album(O) With(B-album) Teeth(I-album) ,(O) later(O) returning(O) to(O) play(O) drums(B-musical instrument) on(O) '(O) The(B-song) Idea(I-song) of(I-song) You(I-song) '(O) from(O) their(O) 2016(O) EP(O) Not(B-album) the(I-album) Actual(I-album) Events(I-album) .(O)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7200, 11, 18273, 14473, 11, 3813, 11, 7471, 11, 10292, 11, 5609, 11, 1732, 11, 8176, 11, 3224, 11, 1567, 11, 18273, 10255, 11, 4731, 17779, 323, 507, 627, 85664, 25, 763, 220, 1049, 19, 1174, 18370, 18442, 24074, 2106, 389, 3892, 14242, 369, 38166, 55692, 452, 6341, 364, 220, 1049, 20, 8176, 3161, 98978, 1174, 3010, 13758, 311, 1514, 47389, 389, 364, 578, 52101, 315, 1472, 364, 505, 872, 220, 679, 21, 19613, 2876, 279, 34459, 18093, 662, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "In(O) 2004(O),(O) Grohl(B-musical artist) drummed(O) on(O) several(O) tracks(O) for(O) Nine(B-band) Inch(I-band) Nails(I-band) '(O) 2005(O) album(O) With(B-album) Teeth(I-album),(O) later(O) returning(O) to(O) play(O) drums(O) on(O) '(O) The(B-song) Idea(I-song) of(I-song) You(I-song) '(O) from(O) their(O) 2016(O) EP(O) Not(B-song) the(I-song) Actual(I-song) Events(I-song).(O)"}
{"id": "416", "dataset": "mit-movie", "split": "test", "label_list": ["director", "rating", "actor", "genre", "title", "average ratings", "character", "song", "year", "trailer", "plot", "review"], "instance": {"id": "416", "words": ["show", "me", "a", "shrek", "clip"], "labels": ["O", "O", "O", "B-title", "B-trailer"], "instruction_inputs": "Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: director, rating, actor, genre, title, average ratings, character, song, year, trailer, plot, review and O.\nSentence: show me a shrek clip", "prompt_labels": "show(O) me(O) a(O) shrek(B-title) clip(B-trailer)"}, "input_ids": [128000, 58, 65562, 60, 5321, 24564, 279, 11914, 3984, 11, 25607, 279, 955, 315, 5502, 369, 1855, 3492, 389, 264, 4037, 14656, 35941, 8197, 627, 5207, 3645, 374, 25, 3492, 62, 16, 13648, 62, 16, 705, 3492, 62, 17, 13648, 62, 17, 705, 12515, 1687, 3358, 1005, 279, 73166, 39480, 311, 2440, 279, 15086, 11, 1405, 512, 16, 13, 426, 12, 320, 11382, 8, 15151, 279, 1212, 315, 264, 7086, 5502, 627, 17, 13, 358, 12, 320, 25488, 8, 374, 1511, 369, 4339, 2949, 264, 7086, 5502, 719, 527, 539, 279, 1176, 3492, 627, 18, 13, 507, 320, 42465, 8, 72214, 4339, 430, 527, 539, 961, 315, 264, 7086, 5502, 382, 10464, 279, 3230, 5502, 9681, 25, 7690, 11, 10959, 11, 12360, 11, 17779, 11, 2316, 11, 5578, 18594, 11, 3752, 11, 5609, 11, 1060, 11, 19809, 11, 7234, 11, 3477, 323, 507, 627, 85664, 25, 1501, 757, 264, 559, 42961, 12607, 66028, 65562, 60], "attention_mask": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], "prediction": "show(O) me(O) a(O) shrek(B-title) clip(B-trailer)"}
