{
  "best_metric": 0.5954685290654329,
  "best_model_checkpoint": "output-lfs/GNER-QE-HR-max_sampled=3/microsoft/deberta-v3-large-ep1-lr1e-5/checkpoint-6000",
  "epoch": 0.5559968228752978,
  "eval_steps": 500,
  "global_step": 7000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.003971405877680699,
      "grad_norm": 7.128725528717041,
      "learning_rate": 1e-05,
      "loss": 2.8763,
      "step": 50
    },
    {
      "epoch": 0.007942811755361398,
      "grad_norm": 9.149222373962402,
      "learning_rate": 1e-05,
      "loss": 1.1921,
      "step": 100
    },
    {
      "epoch": 0.011914217633042097,
      "grad_norm": 4.94770622253418,
      "learning_rate": 1e-05,
      "loss": 1.1532,
      "step": 150
    },
    {
      "epoch": 0.015885623510722795,
      "grad_norm": 10.57177448272705,
      "learning_rate": 1e-05,
      "loss": 1.0871,
      "step": 200
    },
    {
      "epoch": 0.019857029388403495,
      "grad_norm": 11.798645973205566,
      "learning_rate": 1e-05,
      "loss": 1.1225,
      "step": 250
    },
    {
      "epoch": 0.023828435266084195,
      "grad_norm": 14.439325332641602,
      "learning_rate": 1e-05,
      "loss": 1.0576,
      "step": 300
    },
    {
      "epoch": 0.02779984114376489,
      "grad_norm": 13.764080047607422,
      "learning_rate": 1e-05,
      "loss": 1.0771,
      "step": 350
    },
    {
      "epoch": 0.03177124702144559,
      "grad_norm": 3.7446327209472656,
      "learning_rate": 1e-05,
      "loss": 1.0368,
      "step": 400
    },
    {
      "epoch": 0.035742652899126294,
      "grad_norm": 6.161148548126221,
      "learning_rate": 1e-05,
      "loss": 0.9906,
      "step": 450
    },
    {
      "epoch": 0.03971405877680699,
      "grad_norm": 8.587915420532227,
      "learning_rate": 1e-05,
      "loss": 1.0672,
      "step": 500
    },
    {
      "epoch": 0.03971405877680699,
      "eval_loss": 2.441805124282837,
      "eval_mse": 2.441606658905137,
      "eval_pearson": 0.5058027959033841,
      "eval_runtime": 186.7174,
      "eval_samples_per_second": 295.27,
      "eval_spearmanr": 0.5168952359400012,
      "eval_steps_per_second": 2.464,
      "step": 500
    },
    {
      "epoch": 0.043685464654487687,
      "grad_norm": 4.01556396484375,
      "learning_rate": 1e-05,
      "loss": 0.9998,
      "step": 550
    },
    {
      "epoch": 0.04765687053216839,
      "grad_norm": 8.421785354614258,
      "learning_rate": 1e-05,
      "loss": 1.0425,
      "step": 600
    },
    {
      "epoch": 0.051628276409849086,
      "grad_norm": 7.298883438110352,
      "learning_rate": 1e-05,
      "loss": 0.9818,
      "step": 650
    },
    {
      "epoch": 0.05559968228752978,
      "grad_norm": 6.534921169281006,
      "learning_rate": 1e-05,
      "loss": 1.0094,
      "step": 700
    },
    {
      "epoch": 0.059571088165210485,
      "grad_norm": 8.230679512023926,
      "learning_rate": 1e-05,
      "loss": 0.9255,
      "step": 750
    },
    {
      "epoch": 0.06354249404289118,
      "grad_norm": 9.587909698486328,
      "learning_rate": 1e-05,
      "loss": 0.9679,
      "step": 800
    },
    {
      "epoch": 0.06751389992057188,
      "grad_norm": 7.600534915924072,
      "learning_rate": 1e-05,
      "loss": 0.9578,
      "step": 850
    },
    {
      "epoch": 0.07148530579825259,
      "grad_norm": 8.432330131530762,
      "learning_rate": 1e-05,
      "loss": 0.9481,
      "step": 900
    },
    {
      "epoch": 0.07545671167593328,
      "grad_norm": 4.81662654876709,
      "learning_rate": 1e-05,
      "loss": 0.9796,
      "step": 950
    },
    {
      "epoch": 0.07942811755361398,
      "grad_norm": 9.582368850708008,
      "learning_rate": 1e-05,
      "loss": 0.9178,
      "step": 1000
    },
    {
      "epoch": 0.07942811755361398,
      "eval_loss": 2.447596549987793,
      "eval_mse": 2.4476057390062036,
      "eval_pearson": 0.545395594958123,
      "eval_runtime": 186.4059,
      "eval_samples_per_second": 295.763,
      "eval_spearmanr": 0.5475154711135454,
      "eval_steps_per_second": 2.468,
      "step": 1000
    },
    {
      "epoch": 0.08339952343129468,
      "grad_norm": 6.031950950622559,
      "learning_rate": 1e-05,
      "loss": 0.9217,
      "step": 1050
    },
    {
      "epoch": 0.08737092930897537,
      "grad_norm": 12.062664031982422,
      "learning_rate": 1e-05,
      "loss": 0.8891,
      "step": 1100
    },
    {
      "epoch": 0.09134233518665608,
      "grad_norm": 7.795124053955078,
      "learning_rate": 1e-05,
      "loss": 0.9249,
      "step": 1150
    },
    {
      "epoch": 0.09531374106433678,
      "grad_norm": 16.034202575683594,
      "learning_rate": 1e-05,
      "loss": 0.868,
      "step": 1200
    },
    {
      "epoch": 0.09928514694201747,
      "grad_norm": 12.280396461486816,
      "learning_rate": 1e-05,
      "loss": 0.8924,
      "step": 1250
    },
    {
      "epoch": 0.10325655281969817,
      "grad_norm": 7.255916118621826,
      "learning_rate": 1e-05,
      "loss": 0.8693,
      "step": 1300
    },
    {
      "epoch": 0.10722795869737888,
      "grad_norm": 7.95759391784668,
      "learning_rate": 1e-05,
      "loss": 0.8741,
      "step": 1350
    },
    {
      "epoch": 0.11119936457505956,
      "grad_norm": 14.233765602111816,
      "learning_rate": 1e-05,
      "loss": 0.8701,
      "step": 1400
    },
    {
      "epoch": 0.11517077045274027,
      "grad_norm": 7.499777317047119,
      "learning_rate": 1e-05,
      "loss": 0.8178,
      "step": 1450
    },
    {
      "epoch": 0.11914217633042097,
      "grad_norm": 11.495341300964355,
      "learning_rate": 1e-05,
      "loss": 0.8805,
      "step": 1500
    },
    {
      "epoch": 0.11914217633042097,
      "eval_loss": 2.3802835941314697,
      "eval_mse": 2.380869421814139,
      "eval_pearson": 0.5599581205216387,
      "eval_runtime": 186.4299,
      "eval_samples_per_second": 295.725,
      "eval_spearmanr": 0.5630320950955064,
      "eval_steps_per_second": 2.467,
      "step": 1500
    },
    {
      "epoch": 0.12311358220810167,
      "grad_norm": 10.528864860534668,
      "learning_rate": 1e-05,
      "loss": 0.8482,
      "step": 1550
    },
    {
      "epoch": 0.12708498808578236,
      "grad_norm": 6.271936416625977,
      "learning_rate": 1e-05,
      "loss": 0.8086,
      "step": 1600
    },
    {
      "epoch": 0.13105639396346305,
      "grad_norm": 10.38051986694336,
      "learning_rate": 1e-05,
      "loss": 0.8344,
      "step": 1650
    },
    {
      "epoch": 0.13502779984114377,
      "grad_norm": 14.426992416381836,
      "learning_rate": 1e-05,
      "loss": 0.8554,
      "step": 1700
    },
    {
      "epoch": 0.13899920571882446,
      "grad_norm": 8.5521240234375,
      "learning_rate": 1e-05,
      "loss": 0.8201,
      "step": 1750
    },
    {
      "epoch": 0.14297061159650518,
      "grad_norm": 6.837944507598877,
      "learning_rate": 1e-05,
      "loss": 0.8443,
      "step": 1800
    },
    {
      "epoch": 0.14694201747418587,
      "grad_norm": 6.943519592285156,
      "learning_rate": 1e-05,
      "loss": 0.7865,
      "step": 1850
    },
    {
      "epoch": 0.15091342335186655,
      "grad_norm": 9.515066146850586,
      "learning_rate": 1e-05,
      "loss": 0.7529,
      "step": 1900
    },
    {
      "epoch": 0.15488482922954727,
      "grad_norm": 6.933960914611816,
      "learning_rate": 1e-05,
      "loss": 0.7711,
      "step": 1950
    },
    {
      "epoch": 0.15885623510722796,
      "grad_norm": 9.540203094482422,
      "learning_rate": 1e-05,
      "loss": 0.7996,
      "step": 2000
    },
    {
      "epoch": 0.15885623510722796,
      "eval_loss": 2.2374634742736816,
      "eval_mse": 2.237516976812949,
      "eval_pearson": 0.556382491900596,
      "eval_runtime": 186.8037,
      "eval_samples_per_second": 295.133,
      "eval_spearmanr": 0.5607320805080863,
      "eval_steps_per_second": 2.462,
      "step": 2000
    },
    {
      "epoch": 0.16282764098490865,
      "grad_norm": 7.675663948059082,
      "learning_rate": 1e-05,
      "loss": 0.7839,
      "step": 2050
    },
    {
      "epoch": 0.16679904686258937,
      "grad_norm": 8.15121078491211,
      "learning_rate": 1e-05,
      "loss": 0.7529,
      "step": 2100
    },
    {
      "epoch": 0.17077045274027006,
      "grad_norm": 8.474928855895996,
      "learning_rate": 1e-05,
      "loss": 0.7478,
      "step": 2150
    },
    {
      "epoch": 0.17474185861795075,
      "grad_norm": 7.338844299316406,
      "learning_rate": 1e-05,
      "loss": 0.765,
      "step": 2200
    },
    {
      "epoch": 0.17871326449563146,
      "grad_norm": 9.292183876037598,
      "learning_rate": 1e-05,
      "loss": 0.7809,
      "step": 2250
    },
    {
      "epoch": 0.18268467037331215,
      "grad_norm": 7.455489635467529,
      "learning_rate": 1e-05,
      "loss": 0.7461,
      "step": 2300
    },
    {
      "epoch": 0.18665607625099284,
      "grad_norm": 10.285146713256836,
      "learning_rate": 1e-05,
      "loss": 0.763,
      "step": 2350
    },
    {
      "epoch": 0.19062748212867356,
      "grad_norm": 10.649538040161133,
      "learning_rate": 1e-05,
      "loss": 0.73,
      "step": 2400
    },
    {
      "epoch": 0.19459888800635425,
      "grad_norm": 6.007504940032959,
      "learning_rate": 1e-05,
      "loss": 0.738,
      "step": 2450
    },
    {
      "epoch": 0.19857029388403494,
      "grad_norm": 10.120699882507324,
      "learning_rate": 1e-05,
      "loss": 0.7314,
      "step": 2500
    },
    {
      "epoch": 0.19857029388403494,
      "eval_loss": 2.4862518310546875,
      "eval_mse": 2.4859176231547564,
      "eval_pearson": 0.5571783920133601,
      "eval_runtime": 186.6986,
      "eval_samples_per_second": 295.299,
      "eval_spearmanr": 0.5541767574852289,
      "eval_steps_per_second": 2.464,
      "step": 2500
    },
    {
      "epoch": 0.20254169976171565,
      "grad_norm": 8.476204872131348,
      "learning_rate": 1e-05,
      "loss": 0.7242,
      "step": 2550
    },
    {
      "epoch": 0.20651310563939634,
      "grad_norm": 8.974339485168457,
      "learning_rate": 1e-05,
      "loss": 0.7245,
      "step": 2600
    },
    {
      "epoch": 0.21048451151707703,
      "grad_norm": 8.479851722717285,
      "learning_rate": 1e-05,
      "loss": 0.7401,
      "step": 2650
    },
    {
      "epoch": 0.21445591739475775,
      "grad_norm": 13.095053672790527,
      "learning_rate": 1e-05,
      "loss": 0.7225,
      "step": 2700
    },
    {
      "epoch": 0.21842732327243844,
      "grad_norm": 14.074636459350586,
      "learning_rate": 1e-05,
      "loss": 0.7298,
      "step": 2750
    },
    {
      "epoch": 0.22239872915011913,
      "grad_norm": 6.871957778930664,
      "learning_rate": 1e-05,
      "loss": 0.7188,
      "step": 2800
    },
    {
      "epoch": 0.22637013502779985,
      "grad_norm": 9.248564720153809,
      "learning_rate": 1e-05,
      "loss": 0.7145,
      "step": 2850
    },
    {
      "epoch": 0.23034154090548054,
      "grad_norm": 6.860763072967529,
      "learning_rate": 1e-05,
      "loss": 0.6946,
      "step": 2900
    },
    {
      "epoch": 0.23431294678316125,
      "grad_norm": 7.1376237869262695,
      "learning_rate": 1e-05,
      "loss": 0.6641,
      "step": 2950
    },
    {
      "epoch": 0.23828435266084194,
      "grad_norm": 6.640180587768555,
      "learning_rate": 1e-05,
      "loss": 0.6723,
      "step": 3000
    },
    {
      "epoch": 0.23828435266084194,
      "eval_loss": 1.7253544330596924,
      "eval_mse": 1.725110437980214,
      "eval_pearson": 0.5727486281535544,
      "eval_runtime": 186.9449,
      "eval_samples_per_second": 294.91,
      "eval_spearmanr": 0.5721962906478409,
      "eval_steps_per_second": 2.461,
      "step": 3000
    },
    {
      "epoch": 0.24225575853852263,
      "grad_norm": 6.683454990386963,
      "learning_rate": 1e-05,
      "loss": 0.6517,
      "step": 3050
    },
    {
      "epoch": 0.24622716441620335,
      "grad_norm": 7.198923110961914,
      "learning_rate": 1e-05,
      "loss": 0.6535,
      "step": 3100
    },
    {
      "epoch": 0.25019857029388404,
      "grad_norm": 7.558894634246826,
      "learning_rate": 1e-05,
      "loss": 0.6411,
      "step": 3150
    },
    {
      "epoch": 0.2541699761715647,
      "grad_norm": 8.056567192077637,
      "learning_rate": 1e-05,
      "loss": 0.6819,
      "step": 3200
    },
    {
      "epoch": 0.2581413820492454,
      "grad_norm": 7.063068389892578,
      "learning_rate": 1e-05,
      "loss": 0.6786,
      "step": 3250
    },
    {
      "epoch": 0.2621127879269261,
      "grad_norm": 13.25412654876709,
      "learning_rate": 1e-05,
      "loss": 0.672,
      "step": 3300
    },
    {
      "epoch": 0.26608419380460685,
      "grad_norm": 10.146743774414062,
      "learning_rate": 1e-05,
      "loss": 0.6728,
      "step": 3350
    },
    {
      "epoch": 0.27005559968228754,
      "grad_norm": 8.604645729064941,
      "learning_rate": 1e-05,
      "loss": 0.6835,
      "step": 3400
    },
    {
      "epoch": 0.27402700555996823,
      "grad_norm": 6.629968166351318,
      "learning_rate": 1e-05,
      "loss": 0.668,
      "step": 3450
    },
    {
      "epoch": 0.2779984114376489,
      "grad_norm": 8.844193458557129,
      "learning_rate": 1e-05,
      "loss": 0.6505,
      "step": 3500
    },
    {
      "epoch": 0.2779984114376489,
      "eval_loss": 2.2191953659057617,
      "eval_mse": 2.2189435818279177,
      "eval_pearson": 0.5726366959276417,
      "eval_runtime": 186.4303,
      "eval_samples_per_second": 295.724,
      "eval_spearmanr": 0.5674350226091801,
      "eval_steps_per_second": 2.467,
      "step": 3500
    },
    {
      "epoch": 0.2819698173153296,
      "grad_norm": 8.205702781677246,
      "learning_rate": 1e-05,
      "loss": 0.603,
      "step": 3550
    },
    {
      "epoch": 0.28594122319301035,
      "grad_norm": 7.01746940612793,
      "learning_rate": 1e-05,
      "loss": 0.6409,
      "step": 3600
    },
    {
      "epoch": 0.28991262907069104,
      "grad_norm": 13.691716194152832,
      "learning_rate": 1e-05,
      "loss": 0.6112,
      "step": 3650
    },
    {
      "epoch": 0.29388403494837173,
      "grad_norm": 8.336668014526367,
      "learning_rate": 1e-05,
      "loss": 0.5939,
      "step": 3700
    },
    {
      "epoch": 0.2978554408260524,
      "grad_norm": 8.18796443939209,
      "learning_rate": 1e-05,
      "loss": 0.6021,
      "step": 3750
    },
    {
      "epoch": 0.3018268467037331,
      "grad_norm": 11.24533748626709,
      "learning_rate": 1e-05,
      "loss": 0.5946,
      "step": 3800
    },
    {
      "epoch": 0.3057982525814138,
      "grad_norm": 8.247515678405762,
      "learning_rate": 1e-05,
      "loss": 0.6156,
      "step": 3850
    },
    {
      "epoch": 0.30976965845909454,
      "grad_norm": 14.743156433105469,
      "learning_rate": 1e-05,
      "loss": 0.6125,
      "step": 3900
    },
    {
      "epoch": 0.31374106433677523,
      "grad_norm": 6.98247766494751,
      "learning_rate": 1e-05,
      "loss": 0.5774,
      "step": 3950
    },
    {
      "epoch": 0.3177124702144559,
      "grad_norm": 9.279014587402344,
      "learning_rate": 1e-05,
      "loss": 0.6227,
      "step": 4000
    },
    {
      "epoch": 0.3177124702144559,
      "eval_loss": 2.171217918395996,
      "eval_mse": 2.170911869458378,
      "eval_pearson": 0.5830402244222236,
      "eval_runtime": 186.8653,
      "eval_samples_per_second": 295.036,
      "eval_spearmanr": 0.5784348112990848,
      "eval_steps_per_second": 2.462,
      "step": 4000
    },
    {
      "epoch": 0.3216838760921366,
      "grad_norm": 12.143034934997559,
      "learning_rate": 1e-05,
      "loss": 0.602,
      "step": 4050
    },
    {
      "epoch": 0.3256552819698173,
      "grad_norm": 7.616622447967529,
      "learning_rate": 1e-05,
      "loss": 0.5972,
      "step": 4100
    },
    {
      "epoch": 0.329626687847498,
      "grad_norm": 9.427678108215332,
      "learning_rate": 1e-05,
      "loss": 0.5539,
      "step": 4150
    },
    {
      "epoch": 0.33359809372517873,
      "grad_norm": 9.304123878479004,
      "learning_rate": 1e-05,
      "loss": 0.5908,
      "step": 4200
    },
    {
      "epoch": 0.3375694996028594,
      "grad_norm": 8.962688446044922,
      "learning_rate": 1e-05,
      "loss": 0.5732,
      "step": 4250
    },
    {
      "epoch": 0.3415409054805401,
      "grad_norm": 11.023018836975098,
      "learning_rate": 1e-05,
      "loss": 0.5884,
      "step": 4300
    },
    {
      "epoch": 0.3455123113582208,
      "grad_norm": 9.486952781677246,
      "learning_rate": 1e-05,
      "loss": 0.5958,
      "step": 4350
    },
    {
      "epoch": 0.3494837172359015,
      "grad_norm": 9.02621078491211,
      "learning_rate": 1e-05,
      "loss": 0.5684,
      "step": 4400
    },
    {
      "epoch": 0.3534551231135822,
      "grad_norm": 11.685515403747559,
      "learning_rate": 1e-05,
      "loss": 0.5554,
      "step": 4450
    },
    {
      "epoch": 0.3574265289912629,
      "grad_norm": 13.288824081420898,
      "learning_rate": 1e-05,
      "loss": 0.607,
      "step": 4500
    },
    {
      "epoch": 0.3574265289912629,
      "eval_loss": 2.2975997924804688,
      "eval_mse": 2.2976265650420684,
      "eval_pearson": 0.5774986905595287,
      "eval_runtime": 186.4601,
      "eval_samples_per_second": 295.677,
      "eval_spearmanr": 0.5760747000284904,
      "eval_steps_per_second": 2.467,
      "step": 4500
    },
    {
      "epoch": 0.3613979348689436,
      "grad_norm": 7.069092273712158,
      "learning_rate": 1e-05,
      "loss": 0.5772,
      "step": 4550
    },
    {
      "epoch": 0.3653693407466243,
      "grad_norm": 11.247753143310547,
      "learning_rate": 1e-05,
      "loss": 0.5298,
      "step": 4600
    },
    {
      "epoch": 0.369340746624305,
      "grad_norm": 6.637270927429199,
      "learning_rate": 1e-05,
      "loss": 0.5401,
      "step": 4650
    },
    {
      "epoch": 0.3733121525019857,
      "grad_norm": 10.927962303161621,
      "learning_rate": 1e-05,
      "loss": 0.5513,
      "step": 4700
    },
    {
      "epoch": 0.37728355837966643,
      "grad_norm": 8.786982536315918,
      "learning_rate": 1e-05,
      "loss": 0.5468,
      "step": 4750
    },
    {
      "epoch": 0.3812549642573471,
      "grad_norm": 10.151372909545898,
      "learning_rate": 1e-05,
      "loss": 0.563,
      "step": 4800
    },
    {
      "epoch": 0.3852263701350278,
      "grad_norm": 15.039993286132812,
      "learning_rate": 1e-05,
      "loss": 0.5483,
      "step": 4850
    },
    {
      "epoch": 0.3891977760127085,
      "grad_norm": 7.337630271911621,
      "learning_rate": 1e-05,
      "loss": 0.5203,
      "step": 4900
    },
    {
      "epoch": 0.3931691818903892,
      "grad_norm": 8.46094799041748,
      "learning_rate": 1e-05,
      "loss": 0.5548,
      "step": 4950
    },
    {
      "epoch": 0.3971405877680699,
      "grad_norm": 9.263860702514648,
      "learning_rate": 1e-05,
      "loss": 0.5042,
      "step": 5000
    },
    {
      "epoch": 0.3971405877680699,
      "eval_loss": 1.817567229270935,
      "eval_mse": 1.8174270823495067,
      "eval_pearson": 0.5607271958764941,
      "eval_runtime": 186.8585,
      "eval_samples_per_second": 295.047,
      "eval_spearmanr": 0.5589455124918349,
      "eval_steps_per_second": 2.462,
      "step": 5000
    },
    {
      "epoch": 0.4011119936457506,
      "grad_norm": 9.532811164855957,
      "learning_rate": 1e-05,
      "loss": 0.5317,
      "step": 5050
    },
    {
      "epoch": 0.4050833995234313,
      "grad_norm": 25.954500198364258,
      "learning_rate": 1e-05,
      "loss": 0.509,
      "step": 5100
    },
    {
      "epoch": 0.409054805401112,
      "grad_norm": 8.160758018493652,
      "learning_rate": 1e-05,
      "loss": 0.5085,
      "step": 5150
    },
    {
      "epoch": 0.4130262112787927,
      "grad_norm": 10.318476676940918,
      "learning_rate": 1e-05,
      "loss": 0.512,
      "step": 5200
    },
    {
      "epoch": 0.4169976171564734,
      "grad_norm": 8.550435066223145,
      "learning_rate": 1e-05,
      "loss": 0.5157,
      "step": 5250
    },
    {
      "epoch": 0.42096902303415407,
      "grad_norm": 7.898629665374756,
      "learning_rate": 1e-05,
      "loss": 0.5258,
      "step": 5300
    },
    {
      "epoch": 0.4249404289118348,
      "grad_norm": 11.371565818786621,
      "learning_rate": 1e-05,
      "loss": 0.5237,
      "step": 5350
    },
    {
      "epoch": 0.4289118347895155,
      "grad_norm": 5.430365085601807,
      "learning_rate": 1e-05,
      "loss": 0.5092,
      "step": 5400
    },
    {
      "epoch": 0.4328832406671962,
      "grad_norm": 11.347589492797852,
      "learning_rate": 1e-05,
      "loss": 0.5205,
      "step": 5450
    },
    {
      "epoch": 0.4368546465448769,
      "grad_norm": 8.205941200256348,
      "learning_rate": 1e-05,
      "loss": 0.5195,
      "step": 5500
    },
    {
      "epoch": 0.4368546465448769,
      "eval_loss": 1.7324061393737793,
      "eval_mse": 1.7323985002188416,
      "eval_pearson": 0.5763888950207431,
      "eval_runtime": 186.7368,
      "eval_samples_per_second": 295.239,
      "eval_spearmanr": 0.5730745307780498,
      "eval_steps_per_second": 2.463,
      "step": 5500
    },
    {
      "epoch": 0.44082605242255757,
      "grad_norm": 9.712373733520508,
      "learning_rate": 1e-05,
      "loss": 0.495,
      "step": 5550
    },
    {
      "epoch": 0.44479745830023826,
      "grad_norm": 7.2315874099731445,
      "learning_rate": 1e-05,
      "loss": 0.5174,
      "step": 5600
    },
    {
      "epoch": 0.448768864177919,
      "grad_norm": 6.228603363037109,
      "learning_rate": 1e-05,
      "loss": 0.4724,
      "step": 5650
    },
    {
      "epoch": 0.4527402700555997,
      "grad_norm": 7.24098539352417,
      "learning_rate": 1e-05,
      "loss": 0.4778,
      "step": 5700
    },
    {
      "epoch": 0.4567116759332804,
      "grad_norm": 17.055755615234375,
      "learning_rate": 1e-05,
      "loss": 0.5207,
      "step": 5750
    },
    {
      "epoch": 0.46068308181096107,
      "grad_norm": 9.269291877746582,
      "learning_rate": 1e-05,
      "loss": 0.493,
      "step": 5800
    },
    {
      "epoch": 0.46465448768864176,
      "grad_norm": 9.414507865905762,
      "learning_rate": 1e-05,
      "loss": 0.4682,
      "step": 5850
    },
    {
      "epoch": 0.4686258935663225,
      "grad_norm": 9.74975872039795,
      "learning_rate": 1e-05,
      "loss": 0.4737,
      "step": 5900
    },
    {
      "epoch": 0.4725972994440032,
      "grad_norm": 8.893394470214844,
      "learning_rate": 1e-05,
      "loss": 0.4834,
      "step": 5950
    },
    {
      "epoch": 0.4765687053216839,
      "grad_norm": 7.322646617889404,
      "learning_rate": 1e-05,
      "loss": 0.5091,
      "step": 6000
    },
    {
      "epoch": 0.4765687053216839,
      "eval_loss": 2.226003885269165,
      "eval_mse": 2.226067170763469,
      "eval_pearson": 0.5954685290654329,
      "eval_runtime": 186.5448,
      "eval_samples_per_second": 295.543,
      "eval_spearmanr": 0.5963151463076831,
      "eval_steps_per_second": 2.466,
      "step": 6000
    },
    {
      "epoch": 0.4805401111993646,
      "grad_norm": 8.563319206237793,
      "learning_rate": 1e-05,
      "loss": 0.4667,
      "step": 6050
    },
    {
      "epoch": 0.48451151707704526,
      "grad_norm": 11.705179214477539,
      "learning_rate": 1e-05,
      "loss": 0.4663,
      "step": 6100
    },
    {
      "epoch": 0.48848292295472595,
      "grad_norm": 15.584653854370117,
      "learning_rate": 1e-05,
      "loss": 0.4508,
      "step": 6150
    },
    {
      "epoch": 0.4924543288324067,
      "grad_norm": 10.86409854888916,
      "learning_rate": 1e-05,
      "loss": 0.4543,
      "step": 6200
    },
    {
      "epoch": 0.4964257347100874,
      "grad_norm": 11.241052627563477,
      "learning_rate": 1e-05,
      "loss": 0.4901,
      "step": 6250
    },
    {
      "epoch": 0.5003971405877681,
      "grad_norm": 7.267946243286133,
      "learning_rate": 1e-05,
      "loss": 0.4647,
      "step": 6300
    },
    {
      "epoch": 0.5043685464654488,
      "grad_norm": 10.896074295043945,
      "learning_rate": 1e-05,
      "loss": 0.4674,
      "step": 6350
    },
    {
      "epoch": 0.5083399523431295,
      "grad_norm": 7.119740009307861,
      "learning_rate": 1e-05,
      "loss": 0.4724,
      "step": 6400
    },
    {
      "epoch": 0.5123113582208102,
      "grad_norm": 7.919500827789307,
      "learning_rate": 1e-05,
      "loss": 0.4388,
      "step": 6450
    },
    {
      "epoch": 0.5162827640984908,
      "grad_norm": 8.682840347290039,
      "learning_rate": 1e-05,
      "loss": 0.4613,
      "step": 6500
    },
    {
      "epoch": 0.5162827640984908,
      "eval_loss": 1.5301226377487183,
      "eval_mse": 1.5300020486059203,
      "eval_pearson": 0.5789731679937932,
      "eval_runtime": 186.5824,
      "eval_samples_per_second": 295.483,
      "eval_spearmanr": 0.574206245559814,
      "eval_steps_per_second": 2.465,
      "step": 6500
    },
    {
      "epoch": 0.5202541699761716,
      "grad_norm": 9.038985252380371,
      "learning_rate": 1e-05,
      "loss": 0.4579,
      "step": 6550
    },
    {
      "epoch": 0.5242255758538522,
      "grad_norm": 8.322395324707031,
      "learning_rate": 1e-05,
      "loss": 0.4478,
      "step": 6600
    },
    {
      "epoch": 0.528196981731533,
      "grad_norm": 5.942315101623535,
      "learning_rate": 1e-05,
      "loss": 0.4611,
      "step": 6650
    },
    {
      "epoch": 0.5321683876092137,
      "grad_norm": 9.966429710388184,
      "learning_rate": 1e-05,
      "loss": 0.4448,
      "step": 6700
    },
    {
      "epoch": 0.5361397934868943,
      "grad_norm": 6.363131523132324,
      "learning_rate": 1e-05,
      "loss": 0.4206,
      "step": 6750
    },
    {
      "epoch": 0.5401111993645751,
      "grad_norm": 11.692580223083496,
      "learning_rate": 1e-05,
      "loss": 0.4702,
      "step": 6800
    },
    {
      "epoch": 0.5440826052422557,
      "grad_norm": 9.31634521484375,
      "learning_rate": 1e-05,
      "loss": 0.4273,
      "step": 6850
    },
    {
      "epoch": 0.5480540111199365,
      "grad_norm": 11.91850471496582,
      "learning_rate": 1e-05,
      "loss": 0.4306,
      "step": 6900
    },
    {
      "epoch": 0.5520254169976172,
      "grad_norm": 7.657157897949219,
      "learning_rate": 1e-05,
      "loss": 0.4281,
      "step": 6950
    },
    {
      "epoch": 0.5559968228752978,
      "grad_norm": 7.524317264556885,
      "learning_rate": 1e-05,
      "loss": 0.4126,
      "step": 7000
    },
    {
      "epoch": 0.5559968228752978,
      "eval_loss": 1.7114979028701782,
      "eval_mse": 1.7113371033468205,
      "eval_pearson": 0.5875695863450345,
      "eval_runtime": 186.7847,
      "eval_samples_per_second": 295.163,
      "eval_spearmanr": 0.5844570029803867,
      "eval_steps_per_second": 2.463,
      "step": 7000
    }
  ],
  "logging_steps": 50,
  "max_steps": 7000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.2188331223547904e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
