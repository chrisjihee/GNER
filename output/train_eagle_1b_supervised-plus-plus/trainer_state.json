{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.975510204081632,
  "eval_steps": 500,
  "global_step": 732,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08163265306122448,
      "grad_norm": 8.352495161030568,
      "learning_rate": 1.3539849850576912e-05,
      "loss": 0.4485,
      "step": 10
    },
    {
      "epoch": 0.16326530612244897,
      "grad_norm": 2.3681291274807226,
      "learning_rate": 1.7615750792387035e-05,
      "loss": 0.2301,
      "step": 20
    },
    {
      "epoch": 0.24489795918367346,
      "grad_norm": 0.3029353428404361,
      "learning_rate": 2e-05,
      "loss": 0.068,
      "step": 30
    },
    {
      "epoch": 0.32653061224489793,
      "grad_norm": 1.4698386520276248,
      "learning_rate": 1.9743589743589745e-05,
      "loss": 0.0503,
      "step": 40
    },
    {
      "epoch": 0.40816326530612246,
      "grad_norm": 0.41814679070499755,
      "learning_rate": 1.945868945868946e-05,
      "loss": 0.0429,
      "step": 50
    },
    {
      "epoch": 0.4897959183673469,
      "grad_norm": 0.39673150164140697,
      "learning_rate": 1.9173789173789174e-05,
      "loss": 0.0366,
      "step": 60
    },
    {
      "epoch": 0.5714285714285714,
      "grad_norm": 0.7972958519311334,
      "learning_rate": 1.888888888888889e-05,
      "loss": 0.0328,
      "step": 70
    },
    {
      "epoch": 0.6530612244897959,
      "grad_norm": 1.2057134848358269,
      "learning_rate": 1.8603988603988604e-05,
      "loss": 0.0357,
      "step": 80
    },
    {
      "epoch": 0.7346938775510204,
      "grad_norm": 0.47352731060593983,
      "learning_rate": 1.8319088319088322e-05,
      "loss": 0.0344,
      "step": 90
    },
    {
      "epoch": 0.8163265306122449,
      "grad_norm": 0.21324887012437274,
      "learning_rate": 1.8034188034188037e-05,
      "loss": 0.0279,
      "step": 100
    },
    {
      "epoch": 0.8979591836734694,
      "grad_norm": 0.1551465169537166,
      "learning_rate": 1.774928774928775e-05,
      "loss": 0.0273,
      "step": 110
    },
    {
      "epoch": 0.9795918367346939,
      "grad_norm": 0.12331636753605495,
      "learning_rate": 1.7464387464387466e-05,
      "loss": 0.0246,
      "step": 120
    },
    {
      "epoch": 0.9959183673469387,
      "eval_average_f1": 0.49227680231909465,
      "eval_crossner_ai_f1": 0.29404900811820567,
      "eval_crossner_ai_precision": 0.27677100494232415,
      "eval_crossner_ai_recall": 0.31362787803358344,
      "eval_crossner_literature_f1": 0.34975845405635364,
      "eval_crossner_literature_precision": 0.3354958294717175,
      "eval_crossner_literature_recall": 0.3652875882946334,
      "eval_crossner_music_f1": 0.38601532562048607,
      "eval_crossner_music_precision": 0.3850318471337457,
      "eval_crossner_music_recall": 0.38700384122918097,
      "eval_crossner_politics_f1": 0.4716885742674905,
      "eval_crossner_politics_precision": 0.46510468594216187,
      "eval_crossner_politics_recall": 0.47846153846152617,
      "eval_crossner_science_f1": 0.4330621301277058,
      "eval_crossner_science_precision": 0.4068797776233354,
      "eval_crossner_science_recall": 0.4628458498023532,
      "eval_mit-movie_f1": 0.8086355458263282,
      "eval_mit-movie_precision": 0.8176943699731747,
      "eval_mit-movie_recall": 0.7997752388087507,
      "eval_mit-restaurant_f1": 0.7027285782170923,
      "eval_mit-restaurant_precision": 0.7064485081809205,
      "eval_mit-restaurant_recall": 0.6990476190475968,
      "eval_runtime": 304.3808,
      "eval_samples_per_second": 21.256,
      "eval_steps_per_second": 0.085,
      "step": 122
    },
    {
      "epoch": 1.0612244897959184,
      "grad_norm": 0.15360026101275523,
      "learning_rate": 1.717948717948718e-05,
      "loss": 0.0229,
      "step": 130
    },
    {
      "epoch": 1.1428571428571428,
      "grad_norm": 0.32614442858316806,
      "learning_rate": 1.6894586894586896e-05,
      "loss": 0.0215,
      "step": 140
    },
    {
      "epoch": 1.2244897959183674,
      "grad_norm": 0.14075905317924342,
      "learning_rate": 1.660968660968661e-05,
      "loss": 0.0224,
      "step": 150
    },
    {
      "epoch": 1.306122448979592,
      "grad_norm": 0.17614693750632826,
      "learning_rate": 1.6324786324786325e-05,
      "loss": 0.0205,
      "step": 160
    },
    {
      "epoch": 1.3877551020408163,
      "grad_norm": 0.16979210381558862,
      "learning_rate": 1.603988603988604e-05,
      "loss": 0.0211,
      "step": 170
    },
    {
      "epoch": 1.469387755102041,
      "grad_norm": 0.21302257613298461,
      "learning_rate": 1.5754985754985758e-05,
      "loss": 0.0204,
      "step": 180
    },
    {
      "epoch": 1.5510204081632653,
      "grad_norm": 0.10744656365794411,
      "learning_rate": 1.5470085470085473e-05,
      "loss": 0.0205,
      "step": 190
    },
    {
      "epoch": 1.6326530612244898,
      "grad_norm": 0.1849415894875166,
      "learning_rate": 1.5185185185185187e-05,
      "loss": 0.0208,
      "step": 200
    },
    {
      "epoch": 1.7142857142857144,
      "grad_norm": 0.11997497094543107,
      "learning_rate": 1.4900284900284902e-05,
      "loss": 0.0196,
      "step": 210
    },
    {
      "epoch": 1.7959183673469388,
      "grad_norm": 0.18735546263159547,
      "learning_rate": 1.4615384615384615e-05,
      "loss": 0.0189,
      "step": 220
    },
    {
      "epoch": 1.8775510204081631,
      "grad_norm": 0.29861718256024494,
      "learning_rate": 1.4330484330484332e-05,
      "loss": 0.0195,
      "step": 230
    },
    {
      "epoch": 1.9591836734693877,
      "grad_norm": 0.1264826346001397,
      "learning_rate": 1.4045584045584046e-05,
      "loss": 0.0181,
      "step": 240
    },
    {
      "epoch": 2.0,
      "eval_average_f1": 0.5940356140325145,
      "eval_crossner_ai_f1": 0.4150257497228057,
      "eval_crossner_ai_precision": 0.4043683589137896,
      "eval_crossner_ai_recall": 0.4262601120099299,
      "eval_crossner_literature_f1": 0.48745519708260254,
      "eval_crossner_literature_precision": 0.4948024948024691,
      "eval_crossner_literature_recall": 0.4803229061553743,
      "eval_crossner_music_f1": 0.4534544274556704,
      "eval_crossner_music_precision": 0.4595660749506752,
      "eval_crossner_music_recall": 0.44750320102431346,
      "eval_crossner_politics_f1": 0.6402905694142529,
      "eval_crossner_politics_precision": 0.6479390916250815,
      "eval_crossner_politics_recall": 0.6328205128204966,
      "eval_crossner_science_f1": 0.6010719754477292,
      "eval_crossner_science_precision": 0.5827765404602605,
      "eval_crossner_science_recall": 0.6205533596837699,
      "eval_mit-movie_f1": 0.8145153708252322,
      "eval_mit-movie_precision": 0.817667044167595,
      "eval_mit-movie_recall": 0.8113879003558567,
      "eval_mit-restaurant_f1": 0.746436008279309,
      "eval_mit-restaurant_precision": 0.7533139346912139,
      "eval_mit-restaurant_recall": 0.7396825396825162,
      "eval_runtime": 213.3897,
      "eval_samples_per_second": 30.32,
      "eval_steps_per_second": 0.122,
      "step": 245
    },
    {
      "epoch": 2.0408163265306123,
      "grad_norm": 0.15419103517372454,
      "learning_rate": 1.3760683760683761e-05,
      "loss": 0.0172,
      "step": 250
    },
    {
      "epoch": 2.122448979591837,
      "grad_norm": 0.13665015679773365,
      "learning_rate": 1.3475783475783478e-05,
      "loss": 0.0156,
      "step": 260
    },
    {
      "epoch": 2.204081632653061,
      "grad_norm": 0.2696670245534442,
      "learning_rate": 1.3190883190883192e-05,
      "loss": 0.0158,
      "step": 270
    },
    {
      "epoch": 2.2857142857142856,
      "grad_norm": 0.16068138696934078,
      "learning_rate": 1.2905982905982907e-05,
      "loss": 0.0152,
      "step": 280
    },
    {
      "epoch": 2.36734693877551,
      "grad_norm": 0.18812654043118246,
      "learning_rate": 1.2621082621082624e-05,
      "loss": 0.015,
      "step": 290
    },
    {
      "epoch": 2.4489795918367347,
      "grad_norm": 0.17328113582562604,
      "learning_rate": 1.2336182336182337e-05,
      "loss": 0.015,
      "step": 300
    },
    {
      "epoch": 2.5306122448979593,
      "grad_norm": 0.1790820266069613,
      "learning_rate": 1.2051282051282051e-05,
      "loss": 0.0143,
      "step": 310
    },
    {
      "epoch": 2.612244897959184,
      "grad_norm": 0.205334530349541,
      "learning_rate": 1.1766381766381768e-05,
      "loss": 0.0145,
      "step": 320
    },
    {
      "epoch": 2.693877551020408,
      "grad_norm": 0.12151023552700276,
      "learning_rate": 1.1481481481481482e-05,
      "loss": 0.014,
      "step": 330
    },
    {
      "epoch": 2.7755102040816326,
      "grad_norm": 0.17683388985437817,
      "learning_rate": 1.1196581196581197e-05,
      "loss": 0.0147,
      "step": 340
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.1335280719845805,
      "learning_rate": 1.0911680911680914e-05,
      "loss": 0.014,
      "step": 350
    },
    {
      "epoch": 2.938775510204082,
      "grad_norm": 0.09794354617274291,
      "learning_rate": 1.0626780626780628e-05,
      "loss": 0.0142,
      "step": 360
    },
    {
      "epoch": 2.9959183673469387,
      "eval_average_f1": 0.6428657545839637,
      "eval_crossner_ai_f1": 0.4911531421098427,
      "eval_crossner_ai_precision": 0.48174745661277785,
      "eval_crossner_ai_recall": 0.5009334163036403,
      "eval_crossner_literature_f1": 0.5460767537999359,
      "eval_crossner_literature_precision": 0.5296348980559256,
      "eval_crossner_literature_recall": 0.5635721493440684,
      "eval_crossner_music_f1": 0.5649246552882315,
      "eval_crossner_music_precision": 0.5658317276814205,
      "eval_crossner_music_recall": 0.5640204865556797,
      "eval_crossner_politics_f1": 0.6292444555320172,
      "eval_crossner_politics_precision": 0.6152903700073361,
      "eval_crossner_politics_recall": 0.6438461538461373,
      "eval_crossner_science_f1": 0.6488606648735482,
      "eval_crossner_science_precision": 0.6150849858356723,
      "eval_crossner_science_recall": 0.6865612648221072,
      "eval_mit-movie_f1": 0.8557521295016081,
      "eval_mit-movie_precision": 0.8553517964071696,
      "eval_mit-movie_recall": 0.8561528376100233,
      "eval_mit-restaurant_f1": 0.7640484809825624,
      "eval_mit-restaurant_precision": 0.7577271308148374,
      "eval_mit-restaurant_recall": 0.770476190476166,
      "eval_runtime": 241.2586,
      "eval_samples_per_second": 26.818,
      "eval_steps_per_second": 0.108,
      "step": 367
    },
    {
      "epoch": 3.020408163265306,
      "grad_norm": 0.10248911413095751,
      "learning_rate": 1.0341880341880343e-05,
      "loss": 0.0132,
      "step": 370
    },
    {
      "epoch": 3.1020408163265305,
      "grad_norm": 0.1049465213269538,
      "learning_rate": 1.0056980056980056e-05,
      "loss": 0.0112,
      "step": 380
    },
    {
      "epoch": 3.183673469387755,
      "grad_norm": 0.1674560885019876,
      "learning_rate": 9.772079772079773e-06,
      "loss": 0.0116,
      "step": 390
    },
    {
      "epoch": 3.2653061224489797,
      "grad_norm": 0.1360264621319683,
      "learning_rate": 9.487179487179487e-06,
      "loss": 0.0114,
      "step": 400
    },
    {
      "epoch": 3.3469387755102042,
      "grad_norm": 0.08616510237954249,
      "learning_rate": 9.202279202279202e-06,
      "loss": 0.0101,
      "step": 410
    },
    {
      "epoch": 3.4285714285714284,
      "grad_norm": 0.19002208614288388,
      "learning_rate": 8.917378917378919e-06,
      "loss": 0.011,
      "step": 420
    },
    {
      "epoch": 3.510204081632653,
      "grad_norm": 0.21064131747125528,
      "learning_rate": 8.632478632478633e-06,
      "loss": 0.0113,
      "step": 430
    },
    {
      "epoch": 3.5918367346938775,
      "grad_norm": 0.17855897289500497,
      "learning_rate": 8.347578347578348e-06,
      "loss": 0.0107,
      "step": 440
    },
    {
      "epoch": 3.673469387755102,
      "grad_norm": 0.10996025891543522,
      "learning_rate": 8.062678062678063e-06,
      "loss": 0.0112,
      "step": 450
    },
    {
      "epoch": 3.7551020408163263,
      "grad_norm": 0.10351397405063599,
      "learning_rate": 7.77777777777778e-06,
      "loss": 0.0104,
      "step": 460
    },
    {
      "epoch": 3.836734693877551,
      "grad_norm": 0.16245718492822936,
      "learning_rate": 7.492877492877494e-06,
      "loss": 0.0102,
      "step": 470
    },
    {
      "epoch": 3.9183673469387754,
      "grad_norm": 0.11907757200626501,
      "learning_rate": 7.207977207977208e-06,
      "loss": 0.0097,
      "step": 480
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.11827455824211316,
      "learning_rate": 6.923076923076923e-06,
      "loss": 0.0112,
      "step": 490
    },
    {
      "epoch": 4.0,
      "eval_average_f1": 0.6623775702232824,
      "eval_crossner_ai_f1": 0.5065789473185515,
      "eval_crossner_ai_precision": 0.5373342637822375,
      "eval_crossner_ai_recall": 0.47915370255130807,
      "eval_crossner_literature_f1": 0.5621286488779255,
      "eval_crossner_literature_precision": 0.5759661196399907,
      "eval_crossner_literature_recall": 0.5489404641775707,
      "eval_crossner_music_f1": 0.6299902628516447,
      "eval_crossner_music_precision": 0.6389071757735142,
      "eval_crossner_music_recall": 0.6213188220230275,
      "eval_crossner_politics_f1": 0.6858924395446909,
      "eval_crossner_politics_precision": 0.6951026856239944,
      "eval_crossner_politics_recall": 0.6769230769230595,
      "eval_crossner_science_f1": 0.6251999999499822,
      "eval_crossner_science_precision": 0.6327935222671809,
      "eval_crossner_science_recall": 0.6177865612647977,
      "eval_mit-movie_f1": 0.8573300879484861,
      "eval_mit-movie_precision": 0.857009170877768,
      "eval_mit-movie_recall": 0.8576512455515853,
      "eval_mit-restaurant_f1": 0.7695226050716963,
      "eval_mit-restaurant_precision": 0.7663727959697492,
      "eval_mit-restaurant_recall": 0.7726984126983881,
      "eval_runtime": 173.1564,
      "eval_samples_per_second": 37.365,
      "eval_steps_per_second": 0.15,
      "step": 490
    },
    {
      "epoch": 4.081632653061225,
      "grad_norm": 0.14908198934979514,
      "learning_rate": 6.638176638176639e-06,
      "loss": 0.0078,
      "step": 500
    },
    {
      "epoch": 4.163265306122449,
      "grad_norm": 0.12058196051057127,
      "learning_rate": 6.3532763532763546e-06,
      "loss": 0.0075,
      "step": 510
    },
    {
      "epoch": 4.244897959183674,
      "grad_norm": 0.13650429800230884,
      "learning_rate": 6.0683760683760684e-06,
      "loss": 0.0072,
      "step": 520
    },
    {
      "epoch": 4.326530612244898,
      "grad_norm": 0.1272749343356943,
      "learning_rate": 5.783475783475784e-06,
      "loss": 0.0075,
      "step": 530
    },
    {
      "epoch": 4.408163265306122,
      "grad_norm": 0.12352594710692215,
      "learning_rate": 5.498575498575499e-06,
      "loss": 0.0074,
      "step": 540
    },
    {
      "epoch": 4.489795918367347,
      "grad_norm": 0.11535197254370265,
      "learning_rate": 5.213675213675214e-06,
      "loss": 0.0077,
      "step": 550
    },
    {
      "epoch": 4.571428571428571,
      "grad_norm": 0.17215070502698832,
      "learning_rate": 4.928774928774929e-06,
      "loss": 0.0072,
      "step": 560
    },
    {
      "epoch": 4.653061224489796,
      "grad_norm": 0.11126606868038849,
      "learning_rate": 4.643874643874644e-06,
      "loss": 0.0074,
      "step": 570
    },
    {
      "epoch": 4.73469387755102,
      "grad_norm": 0.12008969062001527,
      "learning_rate": 4.358974358974359e-06,
      "loss": 0.0077,
      "step": 580
    },
    {
      "epoch": 4.816326530612245,
      "grad_norm": 0.12270382335186741,
      "learning_rate": 4.074074074074074e-06,
      "loss": 0.0073,
      "step": 590
    },
    {
      "epoch": 4.8979591836734695,
      "grad_norm": 0.1694483626906912,
      "learning_rate": 3.7891737891737893e-06,
      "loss": 0.0072,
      "step": 600
    },
    {
      "epoch": 4.979591836734694,
      "grad_norm": 0.14346526078833946,
      "learning_rate": 3.5042735042735045e-06,
      "loss": 0.0072,
      "step": 610
    },
    {
      "epoch": 4.995918367346938,
      "eval_average_f1": 0.6620364491783344,
      "eval_crossner_ai_f1": 0.4919463086751075,
      "eval_crossner_ai_precision": 0.5338674435542219,
      "eval_crossner_ai_recall": 0.45612943372741405,
      "eval_crossner_literature_f1": 0.5881443298469003,
      "eval_crossner_literature_precision": 0.6011591148577133,
      "eval_crossner_literature_recall": 0.5756811301715148,
      "eval_crossner_music_f1": 0.6191950463896245,
      "eval_crossner_music_precision": 0.6306007301692456,
      "eval_crossner_music_recall": 0.6081946222791098,
      "eval_crossner_politics_f1": 0.6779926816018567,
      "eval_crossner_politics_precision": 0.6913646055436916,
      "eval_crossner_politics_recall": 0.665128205128188,
      "eval_crossner_science_f1": 0.6193548386596728,
      "eval_crossner_science_precision": 0.6320987654320728,
      "eval_crossner_science_recall": 0.6071146245059048,
      "eval_mit-movie_f1": 0.8629852996107472,
      "eval_mit-movie_precision": 0.8683861179593995,
      "eval_mit-movie_recall": 0.8576512455515853,
      "eval_mit-restaurant_f1": 0.7746366394644317,
      "eval_mit-restaurant_precision": 0.7794921247187149,
      "eval_mit-restaurant_recall": 0.7698412698412453,
      "eval_runtime": 185.6647,
      "eval_samples_per_second": 34.848,
      "eval_steps_per_second": 0.14,
      "step": 612
    },
    {
      "epoch": 5.061224489795919,
      "grad_norm": 0.10037395212676367,
      "learning_rate": 3.2193732193732196e-06,
      "loss": 0.006,
      "step": 620
    },
    {
      "epoch": 5.142857142857143,
      "grad_norm": 0.11015326059627394,
      "learning_rate": 2.9344729344729344e-06,
      "loss": 0.005,
      "step": 630
    },
    {
      "epoch": 5.224489795918367,
      "grad_norm": 0.10931922137445768,
      "learning_rate": 2.64957264957265e-06,
      "loss": 0.0049,
      "step": 640
    },
    {
      "epoch": 5.3061224489795915,
      "grad_norm": 0.1845710088323143,
      "learning_rate": 2.3646723646723647e-06,
      "loss": 0.0052,
      "step": 650
    },
    {
      "epoch": 5.387755102040816,
      "grad_norm": 0.15762844021890202,
      "learning_rate": 2.07977207977208e-06,
      "loss": 0.0052,
      "step": 660
    },
    {
      "epoch": 5.469387755102041,
      "grad_norm": 0.10047451347591353,
      "learning_rate": 1.794871794871795e-06,
      "loss": 0.0047,
      "step": 670
    },
    {
      "epoch": 5.551020408163265,
      "grad_norm": 0.11016472892053775,
      "learning_rate": 1.5099715099715102e-06,
      "loss": 0.0048,
      "step": 680
    },
    {
      "epoch": 5.63265306122449,
      "grad_norm": 0.15189953376269658,
      "learning_rate": 1.2250712250712251e-06,
      "loss": 0.005,
      "step": 690
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.11043225351192117,
      "learning_rate": 9.401709401709402e-07,
      "loss": 0.0046,
      "step": 700
    },
    {
      "epoch": 5.795918367346939,
      "grad_norm": 0.10768474580289171,
      "learning_rate": 6.552706552706554e-07,
      "loss": 0.0045,
      "step": 710
    },
    {
      "epoch": 5.877551020408164,
      "grad_norm": 0.14825245968658182,
      "learning_rate": 3.7037037037037036e-07,
      "loss": 0.0045,
      "step": 720
    },
    {
      "epoch": 5.959183673469388,
      "grad_norm": 0.13262162095806915,
      "learning_rate": 8.547008547008549e-08,
      "loss": 0.0043,
      "step": 730
    },
    {
      "epoch": 5.975510204081632,
      "eval_average_f1": 0.6652133581110512,
      "eval_crossner_ai_f1": 0.5293164884502123,
      "eval_crossner_ai_precision": 0.5520270270269897,
      "eval_crossner_ai_recall": 0.5084007467330113,
      "eval_crossner_literature_f1": 0.5660764690287643,
      "eval_crossner_literature_precision": 0.5759791122715103,
      "eval_crossner_literature_recall": 0.5565085771947247,
      "eval_crossner_music_f1": 0.6093015718184047,
      "eval_crossner_music_precision": 0.6170003281916436,
      "eval_crossner_music_recall": 0.6017925736235402,
      "eval_crossner_politics_f1": 0.7008037334215981,
      "eval_crossner_politics_precision": 0.7087047718930071,
      "eval_crossner_politics_recall": 0.6930769230769053,
      "eval_crossner_science_f1": 0.6050618010094256,
      "eval_crossner_science_precision": 0.6007012076353486,
      "eval_crossner_science_recall": 0.6094861660078811,
      "eval_mit-movie_f1": 0.8645100796499369,
      "eval_mit-movie_precision": 0.8655651520840995,
      "eval_mit-movie_recall": 0.8634575763251383,
      "eval_mit-restaurant_f1": 0.7814233633990163,
      "eval_mit-restaurant_precision": 0.7803102247546445,
      "eval_mit-restaurant_recall": 0.7825396825396577,
      "eval_runtime": 160.8328,
      "eval_samples_per_second": 40.228,
      "eval_steps_per_second": 0.162,
      "step": 732
    },
    {
      "epoch": 5.975510204081632,
      "step": 732,
      "total_flos": 1.2982458870378004e+18,
      "train_loss": 0.024275298164190492,
      "train_runtime": 3206.4467,
      "train_samples_per_second": 58.656,
      "train_steps_per_second": 0.228
    }
  ],
  "logging_steps": 10,
  "max_steps": 732,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2982458870378004e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
