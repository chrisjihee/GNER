{
  "best_metric": 0.7847563763626133,
  "best_model_checkpoint": "output/GNER-QE/answerdotai/ModernBERT-large-num=10/checkpoint-16460",
  "epoch": 39.999089529590286,
  "eval_steps": 500,
  "global_step": 32920,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.9990895295902883,
      "grad_norm": 65.50630950927734,
      "learning_rate": 2e-05,
      "loss": 5.5301,
      "step": 823
    },
    {
      "epoch": 0.9990895295902883,
      "eval_loss": 1.3608428239822388,
      "eval_mse": 1.3604422248967327,
      "eval_pearson": 0.6322409380116851,
      "eval_runtime": 4.5557,
      "eval_samples_per_second": 151.677,
      "eval_spearmanr": 0.6497067090139033,
      "eval_steps_per_second": 37.974,
      "step": 823
    },
    {
      "epoch": 1.9990895295902882,
      "grad_norm": 54.142822265625,
      "learning_rate": 2e-05,
      "loss": 3.2442,
      "step": 1646
    },
    {
      "epoch": 1.9990895295902882,
      "eval_loss": 1.2213712930679321,
      "eval_mse": 1.2209234863045246,
      "eval_pearson": 0.6685361210712786,
      "eval_runtime": 2.8872,
      "eval_samples_per_second": 239.334,
      "eval_spearmanr": 0.6738062506384893,
      "eval_steps_per_second": 59.92,
      "step": 1646
    },
    {
      "epoch": 2.999089529590288,
      "grad_norm": 14.61706256866455,
      "learning_rate": 2e-05,
      "loss": 2.7996,
      "step": 2469
    },
    {
      "epoch": 2.999089529590288,
      "eval_loss": 1.3546876907348633,
      "eval_mse": 1.3545705425635912,
      "eval_pearson": 0.6600995615525416,
      "eval_runtime": 2.8668,
      "eval_samples_per_second": 241.034,
      "eval_spearmanr": 0.6769026442433038,
      "eval_steps_per_second": 60.346,
      "step": 2469
    },
    {
      "epoch": 3.999089529590288,
      "grad_norm": 13.688369750976562,
      "learning_rate": 2e-05,
      "loss": 2.6997,
      "step": 3292
    },
    {
      "epoch": 3.999089529590288,
      "eval_loss": 1.41013503074646,
      "eval_mse": 1.4099580092644035,
      "eval_pearson": 0.6652646539830794,
      "eval_runtime": 2.881,
      "eval_samples_per_second": 239.849,
      "eval_spearmanr": 0.6716339010816711,
      "eval_steps_per_second": 60.049,
      "step": 3292
    },
    {
      "epoch": 4.999089529590289,
      "grad_norm": 43.576759338378906,
      "learning_rate": 2e-05,
      "loss": 2.0402,
      "step": 4115
    },
    {
      "epoch": 4.999089529590289,
      "eval_loss": 1.1748194694519043,
      "eval_mse": 1.1752975056404127,
      "eval_pearson": 0.6889595829526904,
      "eval_runtime": 2.875,
      "eval_samples_per_second": 240.349,
      "eval_spearmanr": 0.6966323133868868,
      "eval_steps_per_second": 60.174,
      "step": 4115
    },
    {
      "epoch": 5.999089529590289,
      "grad_norm": 22.54746437072754,
      "learning_rate": 2e-05,
      "loss": 1.4786,
      "step": 4938
    },
    {
      "epoch": 5.999089529590289,
      "eval_loss": 1.2294992208480835,
      "eval_mse": 1.2298216833564548,
      "eval_pearson": 0.7218283502386336,
      "eval_runtime": 2.8852,
      "eval_samples_per_second": 239.501,
      "eval_spearmanr": 0.7307125999371644,
      "eval_steps_per_second": 59.962,
      "step": 4938
    },
    {
      "epoch": 6.999089529590289,
      "grad_norm": 7.934837818145752,
      "learning_rate": 2e-05,
      "loss": 1.264,
      "step": 5761
    },
    {
      "epoch": 6.999089529590289,
      "eval_loss": 1.135527491569519,
      "eval_mse": 1.136055973085188,
      "eval_pearson": 0.6978777763850759,
      "eval_runtime": 2.8886,
      "eval_samples_per_second": 239.218,
      "eval_spearmanr": 0.7037421022236976,
      "eval_steps_per_second": 59.891,
      "step": 5761
    },
    {
      "epoch": 7.999089529590289,
      "grad_norm": 24.92453956604004,
      "learning_rate": 2e-05,
      "loss": 1.3273,
      "step": 6584
    },
    {
      "epoch": 7.999089529590289,
      "eval_loss": 1.1696685552597046,
      "eval_mse": 1.1692796531749337,
      "eval_pearson": 0.7281248087206589,
      "eval_runtime": 2.8782,
      "eval_samples_per_second": 240.078,
      "eval_spearmanr": 0.7371399201541085,
      "eval_steps_per_second": 60.106,
      "step": 6584
    },
    {
      "epoch": 8.999089529590288,
      "grad_norm": 16.212120056152344,
      "learning_rate": 2e-05,
      "loss": 0.9419,
      "step": 7407
    },
    {
      "epoch": 8.999089529590288,
      "eval_loss": 1.1491025686264038,
      "eval_mse": 1.1492553257562663,
      "eval_pearson": 0.7207414676347785,
      "eval_runtime": 2.8746,
      "eval_samples_per_second": 240.38,
      "eval_spearmanr": 0.7258783818990521,
      "eval_steps_per_second": 60.182,
      "step": 7407
    },
    {
      "epoch": 9.999089529590288,
      "grad_norm": 10.71259880065918,
      "learning_rate": 2e-05,
      "loss": 0.6421,
      "step": 8230
    },
    {
      "epoch": 9.999089529590288,
      "eval_loss": 0.9537650346755981,
      "eval_mse": 0.9533418332443568,
      "eval_pearson": 0.752426786782503,
      "eval_runtime": 2.8781,
      "eval_samples_per_second": 240.091,
      "eval_spearmanr": 0.7565803566679993,
      "eval_steps_per_second": 60.109,
      "step": 8230
    },
    {
      "epoch": 10.999089529590288,
      "grad_norm": 16.261049270629883,
      "learning_rate": 2e-05,
      "loss": 0.5874,
      "step": 9053
    },
    {
      "epoch": 10.999089529590288,
      "eval_loss": 1.180546760559082,
      "eval_mse": 1.1803433870958695,
      "eval_pearson": 0.7167358062749766,
      "eval_runtime": 2.875,
      "eval_samples_per_second": 240.346,
      "eval_spearmanr": 0.7204136519510993,
      "eval_steps_per_second": 60.174,
      "step": 9053
    },
    {
      "epoch": 11.999089529590288,
      "grad_norm": 6.986252784729004,
      "learning_rate": 2e-05,
      "loss": 0.6463,
      "step": 9876
    },
    {
      "epoch": 11.999089529590288,
      "eval_loss": 1.078525424003601,
      "eval_mse": 1.0785864886815806,
      "eval_pearson": 0.7305502197408593,
      "eval_runtime": 2.8779,
      "eval_samples_per_second": 240.107,
      "eval_spearmanr": 0.7389579775551596,
      "eval_steps_per_second": 60.114,
      "step": 9876
    },
    {
      "epoch": 12.999089529590288,
      "grad_norm": 22.164833068847656,
      "learning_rate": 2e-05,
      "loss": 0.4513,
      "step": 10699
    },
    {
      "epoch": 12.999089529590288,
      "eval_loss": 1.0665643215179443,
      "eval_mse": 1.066703519669352,
      "eval_pearson": 0.7388341145635153,
      "eval_runtime": 2.8829,
      "eval_samples_per_second": 239.687,
      "eval_spearmanr": 0.7479361304624935,
      "eval_steps_per_second": 60.009,
      "step": 10699
    },
    {
      "epoch": 13.999089529590288,
      "grad_norm": 3.1547985076904297,
      "learning_rate": 2e-05,
      "loss": 0.3228,
      "step": 11522
    },
    {
      "epoch": 13.999089529590288,
      "eval_loss": 1.1566886901855469,
      "eval_mse": 1.1562040728529006,
      "eval_pearson": 0.7259059901908917,
      "eval_runtime": 2.8899,
      "eval_samples_per_second": 239.107,
      "eval_spearmanr": 0.7412142469701827,
      "eval_steps_per_second": 59.863,
      "step": 11522
    },
    {
      "epoch": 14.999089529590288,
      "grad_norm": 6.48703670501709,
      "learning_rate": 2e-05,
      "loss": 0.3078,
      "step": 12345
    },
    {
      "epoch": 14.999089529590288,
      "eval_loss": 1.0510027408599854,
      "eval_mse": 1.0509763302230284,
      "eval_pearson": 0.7306674273309686,
      "eval_runtime": 2.8806,
      "eval_samples_per_second": 239.883,
      "eval_spearmanr": 0.7450483472208945,
      "eval_steps_per_second": 60.058,
      "step": 12345
    },
    {
      "epoch": 15.999089529590288,
      "grad_norm": 8.603424072265625,
      "learning_rate": 2e-05,
      "loss": 0.4023,
      "step": 13168
    },
    {
      "epoch": 15.999089529590288,
      "eval_loss": 1.1632968187332153,
      "eval_mse": 1.1640544586347257,
      "eval_pearson": 0.7122119666245001,
      "eval_runtime": 2.8869,
      "eval_samples_per_second": 239.354,
      "eval_spearmanr": 0.7261560330417905,
      "eval_steps_per_second": 59.925,
      "step": 13168
    },
    {
      "epoch": 16.99908952959029,
      "grad_norm": 3.2382500171661377,
      "learning_rate": 2e-05,
      "loss": 0.2707,
      "step": 13991
    },
    {
      "epoch": 16.99908952959029,
      "eval_loss": 1.0592445135116577,
      "eval_mse": 1.0593709648949365,
      "eval_pearson": 0.7375068709805532,
      "eval_runtime": 2.8796,
      "eval_samples_per_second": 239.962,
      "eval_spearmanr": 0.7467711188470243,
      "eval_steps_per_second": 60.077,
      "step": 13991
    },
    {
      "epoch": 17.99908952959029,
      "grad_norm": 10.258193969726562,
      "learning_rate": 2e-05,
      "loss": 0.1753,
      "step": 14814
    },
    {
      "epoch": 17.99908952959029,
      "eval_loss": 1.0759645700454712,
      "eval_mse": 1.0758018590261897,
      "eval_pearson": 0.7272428858609207,
      "eval_runtime": 2.8758,
      "eval_samples_per_second": 240.278,
      "eval_spearmanr": 0.7355243138293787,
      "eval_steps_per_second": 60.156,
      "step": 14814
    },
    {
      "epoch": 18.99908952959029,
      "grad_norm": 3.1443114280700684,
      "learning_rate": 2e-05,
      "loss": 0.1818,
      "step": 15637
    },
    {
      "epoch": 18.99908952959029,
      "eval_loss": 1.1352940797805786,
      "eval_mse": 1.1354919749645007,
      "eval_pearson": 0.7128977330746415,
      "eval_runtime": 2.8797,
      "eval_samples_per_second": 239.956,
      "eval_spearmanr": 0.7245606203595949,
      "eval_steps_per_second": 60.076,
      "step": 15637
    },
    {
      "epoch": 19.99908952959029,
      "grad_norm": 2.1084165573120117,
      "learning_rate": 2e-05,
      "loss": 0.2389,
      "step": 16460
    },
    {
      "epoch": 19.99908952959029,
      "eval_loss": 0.9744005799293518,
      "eval_mse": 0.9740124418145496,
      "eval_pearson": 0.777620497484782,
      "eval_runtime": 2.8852,
      "eval_samples_per_second": 239.495,
      "eval_spearmanr": 0.7847563763626133,
      "eval_steps_per_second": 59.96,
      "step": 16460
    },
    {
      "epoch": 20.99908952959029,
      "grad_norm": 11.608816146850586,
      "learning_rate": 2e-05,
      "loss": 0.1807,
      "step": 17283
    },
    {
      "epoch": 20.99908952959029,
      "eval_loss": 1.0753850936889648,
      "eval_mse": 1.0748983050565817,
      "eval_pearson": 0.7524496554474569,
      "eval_runtime": 2.8824,
      "eval_samples_per_second": 239.727,
      "eval_spearmanr": 0.7695227403377243,
      "eval_steps_per_second": 60.018,
      "step": 17283
    },
    {
      "epoch": 21.99908952959029,
      "grad_norm": 3.6322224140167236,
      "learning_rate": 2e-05,
      "loss": 0.1339,
      "step": 18106
    },
    {
      "epoch": 21.99908952959029,
      "eval_loss": 1.0387026071548462,
      "eval_mse": 1.0388118085571378,
      "eval_pearson": 0.7584488771811135,
      "eval_runtime": 2.8835,
      "eval_samples_per_second": 239.639,
      "eval_spearmanr": 0.7734811265912084,
      "eval_steps_per_second": 59.997,
      "step": 18106
    },
    {
      "epoch": 22.99908952959029,
      "grad_norm": 1.416031837463379,
      "learning_rate": 2e-05,
      "loss": 0.126,
      "step": 18929
    },
    {
      "epoch": 22.99908952959029,
      "eval_loss": 1.1347780227661133,
      "eval_mse": 1.1352010794555398,
      "eval_pearson": 0.7220526140103265,
      "eval_runtime": 2.8738,
      "eval_samples_per_second": 240.448,
      "eval_spearmanr": 0.7398616857391295,
      "eval_steps_per_second": 60.199,
      "step": 18929
    },
    {
      "epoch": 23.99908952959029,
      "grad_norm": 0.6448718309402466,
      "learning_rate": 2e-05,
      "loss": 0.1819,
      "step": 19752
    },
    {
      "epoch": 23.99908952959029,
      "eval_loss": 1.159909963607788,
      "eval_mse": 1.1598534073394908,
      "eval_pearson": 0.7147670267703282,
      "eval_runtime": 2.8812,
      "eval_samples_per_second": 239.833,
      "eval_spearmanr": 0.7298085141459489,
      "eval_steps_per_second": 60.045,
      "step": 19752
    },
    {
      "epoch": 24.99908952959029,
      "grad_norm": 8.909976959228516,
      "learning_rate": 2e-05,
      "loss": 0.1299,
      "step": 20575
    },
    {
      "epoch": 24.99908952959029,
      "eval_loss": 1.2343255281448364,
      "eval_mse": 1.2338704776487888,
      "eval_pearson": 0.7002973704854405,
      "eval_runtime": 2.8821,
      "eval_samples_per_second": 239.754,
      "eval_spearmanr": 0.7186891112413303,
      "eval_steps_per_second": 60.025,
      "step": 20575
    },
    {
      "epoch": 25.99908952959029,
      "grad_norm": 1.550467610359192,
      "learning_rate": 2e-05,
      "loss": 0.0891,
      "step": 21398
    },
    {
      "epoch": 25.99908952959029,
      "eval_loss": 1.1276448965072632,
      "eval_mse": 1.1273403512758733,
      "eval_pearson": 0.7278465076607846,
      "eval_runtime": 2.8799,
      "eval_samples_per_second": 239.941,
      "eval_spearmanr": 0.7451074005966961,
      "eval_steps_per_second": 60.072,
      "step": 21398
    },
    {
      "epoch": 26.99908952959029,
      "grad_norm": 2.2869534492492676,
      "learning_rate": 2e-05,
      "loss": 0.1016,
      "step": 22221
    },
    {
      "epoch": 26.99908952959029,
      "eval_loss": 1.0969226360321045,
      "eval_mse": 1.0968556762949258,
      "eval_pearson": 0.7292517623318939,
      "eval_runtime": 2.8799,
      "eval_samples_per_second": 239.94,
      "eval_spearmanr": 0.7437520659374587,
      "eval_steps_per_second": 60.072,
      "step": 22221
    },
    {
      "epoch": 27.99908952959029,
      "grad_norm": 1.8803513050079346,
      "learning_rate": 2e-05,
      "loss": 0.1399,
      "step": 23044
    },
    {
      "epoch": 27.99908952959029,
      "eval_loss": 1.1925467252731323,
      "eval_mse": 1.1933257555651078,
      "eval_pearson": 0.7104543926840521,
      "eval_runtime": 2.8785,
      "eval_samples_per_second": 240.052,
      "eval_spearmanr": 0.7248125985263271,
      "eval_steps_per_second": 60.1,
      "step": 23044
    },
    {
      "epoch": 28.99908952959029,
      "grad_norm": 1.5586743354797363,
      "learning_rate": 2e-05,
      "loss": 0.1031,
      "step": 23867
    },
    {
      "epoch": 28.99908952959029,
      "eval_loss": 0.982368528842926,
      "eval_mse": 0.9819398229960595,
      "eval_pearson": 0.7575670784824169,
      "eval_runtime": 2.8863,
      "eval_samples_per_second": 239.404,
      "eval_spearmanr": 0.7717690137688992,
      "eval_steps_per_second": 59.938,
      "step": 23867
    },
    {
      "epoch": 29.99908952959029,
      "grad_norm": 0.5835530161857605,
      "learning_rate": 2e-05,
      "loss": 0.0948,
      "step": 24690
    },
    {
      "epoch": 29.99908952959029,
      "eval_loss": 1.01584792137146,
      "eval_mse": 1.0157849212458785,
      "eval_pearson": 0.7533937921083743,
      "eval_runtime": 2.8757,
      "eval_samples_per_second": 240.291,
      "eval_spearmanr": 0.7686329607291955,
      "eval_steps_per_second": 60.16,
      "step": 24690
    },
    {
      "epoch": 30.99908952959029,
      "grad_norm": 1.3510998487472534,
      "learning_rate": 2e-05,
      "loss": 0.0836,
      "step": 25513
    },
    {
      "epoch": 30.99908952959029,
      "eval_loss": 1.1269458532333374,
      "eval_mse": 1.1272590922895285,
      "eval_pearson": 0.7415960455543024,
      "eval_runtime": 2.8772,
      "eval_samples_per_second": 240.161,
      "eval_spearmanr": 0.759655269565151,
      "eval_steps_per_second": 60.127,
      "step": 25513
    },
    {
      "epoch": 31.99908952959029,
      "grad_norm": 2.3496322631835938,
      "learning_rate": 2e-05,
      "loss": 0.1042,
      "step": 26336
    },
    {
      "epoch": 31.99908952959029,
      "eval_loss": 1.1451847553253174,
      "eval_mse": 1.1457120457882475,
      "eval_pearson": 0.7369515026523871,
      "eval_runtime": 2.8907,
      "eval_samples_per_second": 239.039,
      "eval_spearmanr": 0.7560636483709542,
      "eval_steps_per_second": 59.846,
      "step": 26336
    },
    {
      "epoch": 32.999089529590286,
      "grad_norm": 5.134571552276611,
      "learning_rate": 2e-05,
      "loss": 0.0796,
      "step": 27159
    },
    {
      "epoch": 32.999089529590286,
      "eval_loss": 1.1698321104049683,
      "eval_mse": 1.1691990154006893,
      "eval_pearson": 0.7294963492748388,
      "eval_runtime": 2.875,
      "eval_samples_per_second": 240.35,
      "eval_spearmanr": 0.7495423706998389,
      "eval_steps_per_second": 60.174,
      "step": 27159
    },
    {
      "epoch": 33.999089529590286,
      "grad_norm": 3.9621236324310303,
      "learning_rate": 2e-05,
      "loss": 0.0575,
      "step": 27982
    },
    {
      "epoch": 33.999089529590286,
      "eval_loss": 1.1899852752685547,
      "eval_mse": 1.1901145906075727,
      "eval_pearson": 0.7144446279558203,
      "eval_runtime": 2.8698,
      "eval_samples_per_second": 240.784,
      "eval_spearmanr": 0.7325124916114243,
      "eval_steps_per_second": 60.283,
      "step": 27982
    },
    {
      "epoch": 34.999089529590286,
      "grad_norm": 0.8212283253669739,
      "learning_rate": 2e-05,
      "loss": 0.0694,
      "step": 28805
    },
    {
      "epoch": 34.999089529590286,
      "eval_loss": 1.122606873512268,
      "eval_mse": 1.1223762964589896,
      "eval_pearson": 0.7360161688393121,
      "eval_runtime": 2.8784,
      "eval_samples_per_second": 240.065,
      "eval_spearmanr": 0.7497444832371957,
      "eval_steps_per_second": 60.103,
      "step": 28805
    },
    {
      "epoch": 35.999089529590286,
      "grad_norm": 3.4226889610290527,
      "learning_rate": 2e-05,
      "loss": 0.1234,
      "step": 29628
    },
    {
      "epoch": 35.999089529590286,
      "eval_loss": 1.1834195852279663,
      "eval_mse": 1.1830877871313248,
      "eval_pearson": 0.7083897045691314,
      "eval_runtime": 2.866,
      "eval_samples_per_second": 241.099,
      "eval_spearmanr": 0.7272584112072016,
      "eval_steps_per_second": 60.362,
      "step": 29628
    },
    {
      "epoch": 36.999089529590286,
      "grad_norm": 3.6708903312683105,
      "learning_rate": 2e-05,
      "loss": 0.1106,
      "step": 30451
    },
    {
      "epoch": 36.999089529590286,
      "eval_loss": 1.3434748649597168,
      "eval_mse": 1.3428233135626388,
      "eval_pearson": 0.7089047781185536,
      "eval_runtime": 2.8784,
      "eval_samples_per_second": 240.064,
      "eval_spearmanr": 0.7282080046979338,
      "eval_steps_per_second": 60.103,
      "step": 30451
    },
    {
      "epoch": 37.999089529590286,
      "grad_norm": 0.8572603464126587,
      "learning_rate": 2e-05,
      "loss": 0.0899,
      "step": 31274
    },
    {
      "epoch": 37.999089529590286,
      "eval_loss": 1.14875328540802,
      "eval_mse": 1.1487765902203175,
      "eval_pearson": 0.7219223078886865,
      "eval_runtime": 2.889,
      "eval_samples_per_second": 239.182,
      "eval_spearmanr": 0.7354014296213213,
      "eval_steps_per_second": 59.882,
      "step": 31274
    },
    {
      "epoch": 38.999089529590286,
      "grad_norm": 91.84768676757812,
      "learning_rate": 2e-05,
      "loss": 0.092,
      "step": 32097
    },
    {
      "epoch": 38.999089529590286,
      "eval_loss": 1.2723759412765503,
      "eval_mse": 1.271749653450487,
      "eval_pearson": 0.7114283482720035,
      "eval_runtime": 2.8614,
      "eval_samples_per_second": 241.488,
      "eval_spearmanr": 0.7271715836820042,
      "eval_steps_per_second": 60.459,
      "step": 32097
    },
    {
      "epoch": 39.999089529590286,
      "grad_norm": 0.7631621360778809,
      "learning_rate": 2e-05,
      "loss": 0.0874,
      "step": 32920
    },
    {
      "epoch": 39.999089529590286,
      "eval_loss": 1.1692496538162231,
      "eval_mse": 1.1690249125622807,
      "eval_pearson": 0.7242377171861738,
      "eval_runtime": 2.877,
      "eval_samples_per_second": 240.182,
      "eval_spearmanr": 0.7480760381606221,
      "eval_steps_per_second": 60.132,
      "step": 32920
    }
  ],
  "logging_steps": 500,
  "max_steps": 32920,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 40,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5.571992284351693e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
