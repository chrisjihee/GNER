{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.986733001658375,
  "eval_steps": 500,
  "global_step": 900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06633499170812604,
      "grad_norm": 0.4066458937187286,
      "learning_rate": 1.2850972089384688e-05,
      "loss": 0.4413,
      "step": 10
    },
    {
      "epoch": 0.13266998341625208,
      "grad_norm": 0.18374254406185175,
      "learning_rate": 1.67195001617301e-05,
      "loss": 0.0969,
      "step": 20
    },
    {
      "epoch": 0.19900497512437812,
      "grad_norm": 0.07746841673973605,
      "learning_rate": 1.898244401703927e-05,
      "loss": 0.0561,
      "step": 30
    },
    {
      "epoch": 0.26533996683250416,
      "grad_norm": 0.091995010211183,
      "learning_rate": 1.9930555555555556e-05,
      "loss": 0.0445,
      "step": 40
    },
    {
      "epoch": 0.33167495854063017,
      "grad_norm": 0.10149145392381176,
      "learning_rate": 1.9699074074074076e-05,
      "loss": 0.0385,
      "step": 50
    },
    {
      "epoch": 0.39800995024875624,
      "grad_norm": 0.05514220465159116,
      "learning_rate": 1.9467592592592596e-05,
      "loss": 0.0349,
      "step": 60
    },
    {
      "epoch": 0.46434494195688225,
      "grad_norm": 0.06731575932930962,
      "learning_rate": 1.9236111111111113e-05,
      "loss": 0.0316,
      "step": 70
    },
    {
      "epoch": 0.5306799336650083,
      "grad_norm": 0.10012056507243228,
      "learning_rate": 1.9004629629629633e-05,
      "loss": 0.03,
      "step": 80
    },
    {
      "epoch": 0.5970149253731343,
      "grad_norm": 0.08893405054772398,
      "learning_rate": 1.877314814814815e-05,
      "loss": 0.0271,
      "step": 90
    },
    {
      "epoch": 0.6633499170812603,
      "grad_norm": 0.0868864631765694,
      "learning_rate": 1.854166666666667e-05,
      "loss": 0.0266,
      "step": 100
    },
    {
      "epoch": 0.7296849087893864,
      "grad_norm": 0.07504628325436935,
      "learning_rate": 1.831018518518519e-05,
      "loss": 0.0246,
      "step": 110
    },
    {
      "epoch": 0.7960199004975125,
      "grad_norm": 0.06688534541302767,
      "learning_rate": 1.8078703703703705e-05,
      "loss": 0.0243,
      "step": 120
    },
    {
      "epoch": 0.8623548922056384,
      "grad_norm": 0.07543079240089479,
      "learning_rate": 1.7847222222222225e-05,
      "loss": 0.0237,
      "step": 130
    },
    {
      "epoch": 0.9286898839137645,
      "grad_norm": 0.06067818776579931,
      "learning_rate": 1.7615740740740742e-05,
      "loss": 0.0226,
      "step": 140
    },
    {
      "epoch": 0.9950248756218906,
      "grad_norm": 0.08610577256190158,
      "learning_rate": 1.738425925925926e-05,
      "loss": 0.022,
      "step": 150
    },
    {
      "epoch": 0.9950248756218906,
      "eval_average_f1": 0.5816879504028264,
      "eval_crossner_ai_f1": 0.45576868016787087,
      "eval_crossner_ai_precision": 0.422057264050879,
      "eval_crossner_ai_recall": 0.495332918481612,
      "eval_crossner_literature_f1": 0.4847106393232382,
      "eval_crossner_literature_precision": 0.48556962025313993,
      "eval_crossner_literature_recall": 0.48385469223004623,
      "eval_crossner_music_f1": 0.5656473451501659,
      "eval_crossner_music_precision": 0.5389968106697437,
      "eval_crossner_music_recall": 0.5950704225351922,
      "eval_crossner_politics_f1": 0.5830049260584376,
      "eval_crossner_politics_precision": 0.560900473933636,
      "eval_crossner_politics_recall": 0.6069230769230614,
      "eval_crossner_science_f1": 0.46334741865315177,
      "eval_crossner_science_precision": 0.4328870580157764,
      "eval_crossner_science_recall": 0.4984189723319961,
      "eval_mit-movie_f1": 0.817717522468328,
      "eval_mit-movie_precision": 0.810865561694276,
      "eval_mit-movie_recall": 0.82468627083722,
      "eval_mit-restaurant_f1": 0.7016191209985927,
      "eval_mit-restaurant_precision": 0.6821589205397097,
      "eval_mit-restaurant_recall": 0.7222222222221993,
      "eval_runtime": 238.0692,
      "eval_samples_per_second": 27.177,
      "eval_steps_per_second": 0.109,
      "step": 150
    },
    {
      "epoch": 1.064676616915423,
      "grad_norm": 0.055349481660635046,
      "learning_rate": 1.715277777777778e-05,
      "loss": 0.0215,
      "step": 160
    },
    {
      "epoch": 1.1310116086235489,
      "grad_norm": 0.07413893096765196,
      "learning_rate": 1.6921296296296298e-05,
      "loss": 0.0196,
      "step": 170
    },
    {
      "epoch": 1.197346600331675,
      "grad_norm": 0.05504425796586483,
      "learning_rate": 1.6689814814814815e-05,
      "loss": 0.0183,
      "step": 180
    },
    {
      "epoch": 1.263681592039801,
      "grad_norm": 0.06738010000214915,
      "learning_rate": 1.6458333333333335e-05,
      "loss": 0.0189,
      "step": 190
    },
    {
      "epoch": 1.330016583747927,
      "grad_norm": 0.06161793006961246,
      "learning_rate": 1.622685185185185e-05,
      "loss": 0.0182,
      "step": 200
    },
    {
      "epoch": 1.3963515754560532,
      "grad_norm": 0.10077824310873773,
      "learning_rate": 1.599537037037037e-05,
      "loss": 0.0176,
      "step": 210
    },
    {
      "epoch": 1.462686567164179,
      "grad_norm": 0.165783355018202,
      "learning_rate": 1.576388888888889e-05,
      "loss": 0.0179,
      "step": 220
    },
    {
      "epoch": 1.529021558872305,
      "grad_norm": 0.07480277676544905,
      "learning_rate": 1.5532407407407408e-05,
      "loss": 0.0169,
      "step": 230
    },
    {
      "epoch": 1.5953565505804312,
      "grad_norm": 0.1192651121739962,
      "learning_rate": 1.5300925925925928e-05,
      "loss": 0.0168,
      "step": 240
    },
    {
      "epoch": 1.6616915422885572,
      "grad_norm": 0.0879676587221746,
      "learning_rate": 1.5069444444444446e-05,
      "loss": 0.0173,
      "step": 250
    },
    {
      "epoch": 1.7280265339966832,
      "grad_norm": 0.06087718930300061,
      "learning_rate": 1.4837962962962964e-05,
      "loss": 0.0161,
      "step": 260
    },
    {
      "epoch": 1.7943615257048093,
      "grad_norm": 0.07762643158133146,
      "learning_rate": 1.4606481481481482e-05,
      "loss": 0.0156,
      "step": 270
    },
    {
      "epoch": 1.8606965174129353,
      "grad_norm": 0.07415738517782144,
      "learning_rate": 1.4375e-05,
      "loss": 0.0154,
      "step": 280
    },
    {
      "epoch": 1.9270315091210612,
      "grad_norm": 0.05141924162377882,
      "learning_rate": 1.414351851851852e-05,
      "loss": 0.0151,
      "step": 290
    },
    {
      "epoch": 1.9933665008291874,
      "grad_norm": 0.06922763774937815,
      "learning_rate": 1.3912037037037039e-05,
      "loss": 0.0151,
      "step": 300
    },
    {
      "epoch": 1.9933665008291874,
      "eval_average_f1": 0.6682415388621481,
      "eval_crossner_ai_f1": 0.5698056800696241,
      "eval_crossner_ai_precision": 0.5483314154199914,
      "eval_crossner_ai_recall": 0.5930304915992164,
      "eval_crossner_literature_f1": 0.6019124307501712,
      "eval_crossner_literature_precision": 0.6004016064256726,
      "eval_crossner_literature_recall": 0.6034308779010795,
      "eval_crossner_music_f1": 0.655068796407364,
      "eval_crossner_music_precision": 0.6473898093153908,
      "eval_crossner_music_recall": 0.6629321382842297,
      "eval_crossner_politics_f1": 0.669385674178891,
      "eval_crossner_politics_precision": 0.6654840344652644,
      "eval_crossner_politics_recall": 0.673333333333316,
      "eval_crossner_science_f1": 0.5892448512086202,
      "eval_crossner_science_precision": 0.5692704495209813,
      "eval_crossner_science_recall": 0.6106719367588691,
      "eval_mit-movie_f1": 0.8426208298178428,
      "eval_mit-movie_precision": 0.8316307916818527,
      "eval_mit-movie_recall": 0.8539052256976802,
      "eval_mit-restaurant_f1": 0.7496525096025229,
      "eval_mit-restaurant_precision": 0.7299248120300532,
      "eval_mit-restaurant_recall": 0.770476190476166,
      "eval_runtime": 253.2622,
      "eval_samples_per_second": 25.547,
      "eval_steps_per_second": 0.103,
      "step": 300
    },
    {
      "epoch": 2.0630182421227197,
      "grad_norm": 0.048431636855376846,
      "learning_rate": 1.3680555555555557e-05,
      "loss": 0.0145,
      "step": 310
    },
    {
      "epoch": 2.129353233830846,
      "grad_norm": 0.08656034392897703,
      "learning_rate": 1.3449074074074075e-05,
      "loss": 0.014,
      "step": 320
    },
    {
      "epoch": 2.195688225538972,
      "grad_norm": 0.06316808424716105,
      "learning_rate": 1.3217592592592593e-05,
      "loss": 0.0136,
      "step": 330
    },
    {
      "epoch": 2.2620232172470978,
      "grad_norm": 0.07073266929531577,
      "learning_rate": 1.2986111111111113e-05,
      "loss": 0.0131,
      "step": 340
    },
    {
      "epoch": 2.328358208955224,
      "grad_norm": 0.09602685592621185,
      "learning_rate": 1.2754629629629631e-05,
      "loss": 0.0128,
      "step": 350
    },
    {
      "epoch": 2.39469320066335,
      "grad_norm": 0.10618635052265941,
      "learning_rate": 1.252314814814815e-05,
      "loss": 0.0133,
      "step": 360
    },
    {
      "epoch": 2.461028192371476,
      "grad_norm": 0.05331119557223764,
      "learning_rate": 1.2291666666666668e-05,
      "loss": 0.0131,
      "step": 370
    },
    {
      "epoch": 2.527363184079602,
      "grad_norm": 0.05242389656580604,
      "learning_rate": 1.2060185185185188e-05,
      "loss": 0.0126,
      "step": 380
    },
    {
      "epoch": 2.593698175787728,
      "grad_norm": 0.05122470258257105,
      "learning_rate": 1.1828703703703706e-05,
      "loss": 0.0121,
      "step": 390
    },
    {
      "epoch": 2.660033167495854,
      "grad_norm": 0.061123111293312035,
      "learning_rate": 1.1597222222222224e-05,
      "loss": 0.0123,
      "step": 400
    },
    {
      "epoch": 2.72636815920398,
      "grad_norm": 0.06239051841122001,
      "learning_rate": 1.1365740740740742e-05,
      "loss": 0.0123,
      "step": 410
    },
    {
      "epoch": 2.7927031509121063,
      "grad_norm": 0.07523702727700247,
      "learning_rate": 1.1134259259259259e-05,
      "loss": 0.0127,
      "step": 420
    },
    {
      "epoch": 2.859038142620232,
      "grad_norm": 0.05626248876691891,
      "learning_rate": 1.0902777777777777e-05,
      "loss": 0.0121,
      "step": 430
    },
    {
      "epoch": 2.925373134328358,
      "grad_norm": 0.054327467234883464,
      "learning_rate": 1.0671296296296295e-05,
      "loss": 0.0122,
      "step": 440
    },
    {
      "epoch": 2.9917081260364844,
      "grad_norm": 0.07649023211869561,
      "learning_rate": 1.0439814814814815e-05,
      "loss": 0.0116,
      "step": 450
    },
    {
      "epoch": 2.9917081260364844,
      "eval_average_f1": 0.6924689685190907,
      "eval_crossner_ai_f1": 0.5705348763966344,
      "eval_crossner_ai_precision": 0.5735849056603413,
      "eval_crossner_ai_recall": 0.5675171126321986,
      "eval_crossner_literature_f1": 0.640262361201229,
      "eval_crossner_literature_precision": 0.640262361251229,
      "eval_crossner_literature_recall": 0.640262361251229,
      "eval_crossner_music_f1": 0.67702659399035,
      "eval_crossner_music_precision": 0.6776779987171047,
      "eval_crossner_music_recall": 0.6763764404609258,
      "eval_crossner_politics_f1": 0.7090413801549439,
      "eval_crossner_politics_precision": 0.7175111577841765,
      "eval_crossner_politics_recall": 0.7007692307692128,
      "eval_crossner_science_f1": 0.6179116151240135,
      "eval_crossner_science_precision": 0.6114551083591094,
      "eval_crossner_science_recall": 0.6245059288537302,
      "eval_mit-movie_f1": 0.8572232644903218,
      "eval_mit-movie_precision": 0.8586731817327409,
      "eval_mit-movie_recall": 0.8557782356246327,
      "eval_mit-restaurant_f1": 0.7752826882761423,
      "eval_mit-restaurant_precision": 0.7778843080856255,
      "eval_mit-restaurant_recall": 0.7726984126983881,
      "eval_runtime": 303.9169,
      "eval_samples_per_second": 21.289,
      "eval_steps_per_second": 0.086,
      "step": 450
    },
    {
      "epoch": 3.0613598673300166,
      "grad_norm": 0.05896785043567017,
      "learning_rate": 1.0208333333333334e-05,
      "loss": 0.0108,
      "step": 460
    },
    {
      "epoch": 3.127694859038143,
      "grad_norm": 0.05383967014529142,
      "learning_rate": 9.976851851851853e-06,
      "loss": 0.0096,
      "step": 470
    },
    {
      "epoch": 3.1940298507462686,
      "grad_norm": 0.06096324881000293,
      "learning_rate": 9.745370370370372e-06,
      "loss": 0.0095,
      "step": 480
    },
    {
      "epoch": 3.2603648424543947,
      "grad_norm": 0.08130416623481132,
      "learning_rate": 9.51388888888889e-06,
      "loss": 0.0095,
      "step": 490
    },
    {
      "epoch": 3.326699834162521,
      "grad_norm": 0.05998670920363773,
      "learning_rate": 9.282407407407408e-06,
      "loss": 0.0095,
      "step": 500
    },
    {
      "epoch": 3.3930348258706466,
      "grad_norm": 0.06465161710451445,
      "learning_rate": 9.050925925925926e-06,
      "loss": 0.0097,
      "step": 510
    },
    {
      "epoch": 3.459369817578773,
      "grad_norm": 0.06540887416199334,
      "learning_rate": 8.819444444444445e-06,
      "loss": 0.0094,
      "step": 520
    },
    {
      "epoch": 3.525704809286899,
      "grad_norm": 0.0590352136949512,
      "learning_rate": 8.587962962962963e-06,
      "loss": 0.0094,
      "step": 530
    },
    {
      "epoch": 3.5920398009950247,
      "grad_norm": 0.058516441445836564,
      "learning_rate": 8.356481481481483e-06,
      "loss": 0.0092,
      "step": 540
    },
    {
      "epoch": 3.658374792703151,
      "grad_norm": 0.08153406540011145,
      "learning_rate": 8.125000000000001e-06,
      "loss": 0.0091,
      "step": 550
    },
    {
      "epoch": 3.724709784411277,
      "grad_norm": 0.0689887636631244,
      "learning_rate": 7.89351851851852e-06,
      "loss": 0.0091,
      "step": 560
    },
    {
      "epoch": 3.791044776119403,
      "grad_norm": 0.07181792831052926,
      "learning_rate": 7.662037037037037e-06,
      "loss": 0.0089,
      "step": 570
    },
    {
      "epoch": 3.857379767827529,
      "grad_norm": 0.05530724645641754,
      "learning_rate": 7.4305555555555565e-06,
      "loss": 0.0095,
      "step": 580
    },
    {
      "epoch": 3.923714759535655,
      "grad_norm": 0.06252918083731832,
      "learning_rate": 7.199074074074075e-06,
      "loss": 0.0087,
      "step": 590
    },
    {
      "epoch": 3.990049751243781,
      "grad_norm": 0.053484547947429295,
      "learning_rate": 6.967592592592594e-06,
      "loss": 0.0091,
      "step": 600
    },
    {
      "epoch": 3.996683250414594,
      "eval_average_f1": 0.7036841683838586,
      "eval_crossner_ai_f1": 0.5763440859714779,
      "eval_crossner_ai_precision": 0.5691747572815189,
      "eval_crossner_ai_recall": 0.5836963285625025,
      "eval_crossner_literature_f1": 0.6312863279762508,
      "eval_crossner_literature_precision": 0.6324050632911072,
      "eval_crossner_literature_recall": 0.6301715438950237,
      "eval_crossner_music_f1": 0.695303734522826,
      "eval_crossner_music_precision": 0.6963081861958043,
      "eval_crossner_music_recall": 0.6943021766965206,
      "eval_crossner_politics_f1": 0.7204342768014774,
      "eval_crossner_politics_precision": 0.7263487099296135,
      "eval_crossner_politics_recall": 0.7146153846153663,
      "eval_crossner_science_f1": 0.6578332033794464,
      "eval_crossner_science_precision": 0.6487317448116584,
      "eval_crossner_science_recall": 0.6671936758893017,
      "eval_mit-movie_f1": 0.8657812941008755,
      "eval_mit-movie_precision": 0.8707843880257509,
      "eval_mit-movie_recall": 0.8608353624274048,
      "eval_mit-restaurant_f1": 0.7788062559346557,
      "eval_mit-restaurant_precision": 0.7830551989730172,
      "eval_mit-restaurant_recall": 0.77460317460315,
      "eval_runtime": 288.0375,
      "eval_samples_per_second": 22.462,
      "eval_steps_per_second": 0.09,
      "step": 601
    },
    {
      "epoch": 4.059701492537314,
      "grad_norm": 0.05658004661795419,
      "learning_rate": 6.736111111111112e-06,
      "loss": 0.0078,
      "step": 610
    },
    {
      "epoch": 4.126036484245439,
      "grad_norm": 0.06915028997531651,
      "learning_rate": 6.504629629629629e-06,
      "loss": 0.0065,
      "step": 620
    },
    {
      "epoch": 4.192371475953566,
      "grad_norm": 0.08794272785772066,
      "learning_rate": 6.2731481481481485e-06,
      "loss": 0.0069,
      "step": 630
    },
    {
      "epoch": 4.258706467661692,
      "grad_norm": 0.06293707991832032,
      "learning_rate": 6.041666666666667e-06,
      "loss": 0.0067,
      "step": 640
    },
    {
      "epoch": 4.325041459369817,
      "grad_norm": 0.0820574945519757,
      "learning_rate": 5.810185185185186e-06,
      "loss": 0.0064,
      "step": 650
    },
    {
      "epoch": 4.391376451077944,
      "grad_norm": 0.07009148963594929,
      "learning_rate": 5.578703703703704e-06,
      "loss": 0.0064,
      "step": 660
    },
    {
      "epoch": 4.45771144278607,
      "grad_norm": 0.06944362578637986,
      "learning_rate": 5.347222222222222e-06,
      "loss": 0.0067,
      "step": 670
    },
    {
      "epoch": 4.5240464344941955,
      "grad_norm": 0.06700986470476408,
      "learning_rate": 5.115740740740741e-06,
      "loss": 0.0065,
      "step": 680
    },
    {
      "epoch": 4.590381426202322,
      "grad_norm": 0.05494642058854823,
      "learning_rate": 4.8842592592592595e-06,
      "loss": 0.0068,
      "step": 690
    },
    {
      "epoch": 4.656716417910448,
      "grad_norm": 0.08552458028429696,
      "learning_rate": 4.652777777777779e-06,
      "loss": 0.0068,
      "step": 700
    },
    {
      "epoch": 4.723051409618574,
      "grad_norm": 0.05602059665135246,
      "learning_rate": 4.421296296296297e-06,
      "loss": 0.0063,
      "step": 710
    },
    {
      "epoch": 4.7893864013267,
      "grad_norm": 0.06212529159926957,
      "learning_rate": 4.189814814814815e-06,
      "loss": 0.0064,
      "step": 720
    },
    {
      "epoch": 4.855721393034826,
      "grad_norm": 0.07774491238699151,
      "learning_rate": 3.958333333333333e-06,
      "loss": 0.0064,
      "step": 730
    },
    {
      "epoch": 4.922056384742952,
      "grad_norm": 0.062370189701647226,
      "learning_rate": 3.726851851851852e-06,
      "loss": 0.0065,
      "step": 740
    },
    {
      "epoch": 4.988391376451078,
      "grad_norm": 0.06890970166853647,
      "learning_rate": 3.4953703703703706e-06,
      "loss": 0.0062,
      "step": 750
    },
    {
      "epoch": 4.9950248756218905,
      "eval_average_f1": 0.7048058579865301,
      "eval_crossner_ai_f1": 0.5799999999499987,
      "eval_crossner_ai_precision": 0.5652687536916382,
      "eval_crossner_ai_recall": 0.59551960174234,
      "eval_crossner_literature_f1": 0.6279880477587421,
      "eval_crossner_literature_precision": 0.6199606686332045,
      "eval_crossner_literature_recall": 0.6362260343087469,
      "eval_crossner_music_f1": 0.7062182740616567,
      "eval_crossner_music_precision": 0.699999999999978,
      "eval_crossner_music_recall": 0.712548015364894,
      "eval_crossner_politics_f1": 0.7273424516948368,
      "eval_crossner_politics_precision": 0.7252102982411235,
      "eval_crossner_politics_recall": 0.7294871794871608,
      "eval_crossner_science_f1": 0.6411856473758809,
      "eval_crossner_science_precision": 0.6327944572748024,
      "eval_crossner_science_recall": 0.6498023715414762,
      "eval_mit-movie_f1": 0.8660447760693876,
      "eval_mit-movie_precision": 0.8626649321687259,
      "eval_mit-movie_recall": 0.8694512080913865,
      "eval_mit-restaurant_f1": 0.7848618089952073,
      "eval_mit-restaurant_precision": 0.7765692977004109,
      "eval_mit-restaurant_recall": 0.7933333333333081,
      "eval_runtime": 270.3724,
      "eval_samples_per_second": 23.93,
      "eval_steps_per_second": 0.096,
      "step": 751
    },
    {
      "epoch": 5.05804311774461,
      "grad_norm": 0.05298962015245435,
      "learning_rate": 3.2638888888888892e-06,
      "loss": 0.0051,
      "step": 760
    },
    {
      "epoch": 5.124378109452737,
      "grad_norm": 0.07429683806140676,
      "learning_rate": 3.032407407407408e-06,
      "loss": 0.0047,
      "step": 770
    },
    {
      "epoch": 5.1907131011608625,
      "grad_norm": 0.06215801591088329,
      "learning_rate": 2.8009259259259265e-06,
      "loss": 0.0046,
      "step": 780
    },
    {
      "epoch": 5.257048092868988,
      "grad_norm": 0.0699810055098096,
      "learning_rate": 2.5694444444444443e-06,
      "loss": 0.0043,
      "step": 790
    },
    {
      "epoch": 5.323383084577115,
      "grad_norm": 0.08881697965602024,
      "learning_rate": 2.3379629629629634e-06,
      "loss": 0.0046,
      "step": 800
    },
    {
      "epoch": 5.389718076285241,
      "grad_norm": 0.04940751365946309,
      "learning_rate": 2.1064814814814816e-06,
      "loss": 0.0046,
      "step": 810
    },
    {
      "epoch": 5.456053067993366,
      "grad_norm": 0.07051852955828096,
      "learning_rate": 1.8750000000000003e-06,
      "loss": 0.0043,
      "step": 820
    },
    {
      "epoch": 5.522388059701493,
      "grad_norm": 0.06647389486777047,
      "learning_rate": 1.6435185185185187e-06,
      "loss": 0.0042,
      "step": 830
    },
    {
      "epoch": 5.588723051409619,
      "grad_norm": 0.06238673982159497,
      "learning_rate": 1.4120370370370371e-06,
      "loss": 0.0048,
      "step": 840
    },
    {
      "epoch": 5.655058043117744,
      "grad_norm": 0.04829731669651306,
      "learning_rate": 1.1805555555555556e-06,
      "loss": 0.0041,
      "step": 850
    },
    {
      "epoch": 5.721393034825871,
      "grad_norm": 0.06499562115775132,
      "learning_rate": 9.490740740740742e-07,
      "loss": 0.0044,
      "step": 860
    },
    {
      "epoch": 5.787728026533997,
      "grad_norm": 0.04640247177869365,
      "learning_rate": 7.175925925925927e-07,
      "loss": 0.0044,
      "step": 870
    },
    {
      "epoch": 5.8540630182421225,
      "grad_norm": 0.07962217142453493,
      "learning_rate": 4.861111111111112e-07,
      "loss": 0.0043,
      "step": 880
    },
    {
      "epoch": 5.920398009950249,
      "grad_norm": 0.07511010854238676,
      "learning_rate": 2.5462962962962963e-07,
      "loss": 0.0044,
      "step": 890
    },
    {
      "epoch": 5.986733001658375,
      "grad_norm": 0.07095165947936037,
      "learning_rate": 2.3148148148148148e-08,
      "loss": 0.0044,
      "step": 900
    },
    {
      "epoch": 5.986733001658375,
      "eval_average_f1": 0.7034808401114486,
      "eval_crossner_ai_f1": 0.5885997521184899,
      "eval_crossner_ai_precision": 0.5860579888957071,
      "eval_crossner_ai_recall": 0.5911636589918736,
      "eval_crossner_literature_f1": 0.6235323506869209,
      "eval_crossner_literature_precision": 0.617516081147916,
      "eval_crossner_literature_recall": 0.6296670030272135,
      "eval_crossner_music_f1": 0.7007509186270827,
      "eval_crossner_music_precision": 0.6995215311004561,
      "eval_crossner_music_recall": 0.7019846350832042,
      "eval_crossner_politics_f1": 0.7237113401561682,
      "eval_crossner_politics_precision": 0.7274611398963542,
      "eval_crossner_politics_recall": 0.7199999999999815,
      "eval_crossner_science_f1": 0.6375372392747027,
      "eval_crossner_science_precision": 0.6407185628742259,
      "eval_crossner_science_recall": 0.634387351778631,
      "eval_mit-movie_f1": 0.868450598752379,
      "eval_mit-movie_precision": 0.8676388109926927,
      "eval_mit-movie_recall": 0.8692639070986913,
      "eval_mit-restaurant_f1": 0.7817836811643972,
      "eval_mit-restaurant_precision": 0.7788279773156654,
      "eval_mit-restaurant_recall": 0.7847619047618798,
      "eval_runtime": 270.9256,
      "eval_samples_per_second": 23.881,
      "eval_steps_per_second": 0.096,
      "step": 900
    },
    {
      "epoch": 5.986733001658375,
      "step": 900,
      "total_flos": 3.959411018811048e+18,
      "train_loss": 0.01894148143215312,
      "train_runtime": 6798.8601,
      "train_samples_per_second": 34.027,
      "train_steps_per_second": 0.132
    }
  ],
  "logging_steps": 10,
  "max_steps": 900,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": false,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.959411018811048e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
