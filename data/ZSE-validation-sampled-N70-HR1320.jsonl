{"id":"0.S","dataset":"mit-movie","split":"dev","instance":{"id":"0.S","prompt_labels":"are(O) there(O) any(O) good(O) romantic(B-genre) comedies(I-genre) out(O) right(B-year) now(I-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, trailer, average_ratings, director, rating, actor, review, year, genre, song, plot, title\nGIVEN SENTENCE: are there any good romantic comedies out right now\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["are","there","any","good","romantic","comedies","out","right","now"],"labels":["O","O","O","O","B-genre","I-genre","O","B-year","I-year"],"target_index":null,"target_label":null},"label_list":["character","trailer","average_ratings","director","rating","actor","review","year","genre","song","plot","title"]}
{"id":"1.S","dataset":"mit-movie","split":"dev","instance":{"id":"1.S","prompt_labels":"show(O) me(O) a(O) movie(O) about(O) cars(B-plot) that(I-plot) talk(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, rating, average_ratings, actor, title, song, plot, review, trailer, character, director, genre\nGIVEN SENTENCE: show me a movie about cars that talk\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["show","me","a","movie","about","cars","that","talk"],"labels":["O","O","O","O","O","B-plot","I-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["year","rating","average_ratings","actor","title","song","plot","review","trailer","character","director","genre"]}
{"id":"2.S","dataset":"mit-movie","split":"dev","instance":{"id":"2.S","prompt_labels":"list(O) the(O) five(B-average_ratings) star(I-average_ratings) rated(O) movies(O) starring(O) mel(B-actor) gibson(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: director, average_ratings, song, review, trailer, plot, title, genre, actor, rating, character, year\nGIVEN SENTENCE: list the five star rated movies starring mel gibson\n","prediction_output":null,"prediction_outputs":null,"group":"2","words":["list","the","five","star","rated","movies","starring","mel","gibson"],"labels":["O","O","B-average_ratings","I-average_ratings","O","O","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["director","average_ratings","song","review","trailer","plot","title","genre","actor","rating","character","year"]}
{"id":"3.S","dataset":"mit-movie","split":"dev","instance":{"id":"3.S","prompt_labels":"what(O) science(B-genre) fiction(I-genre) films(O) have(O) come(O) out(O) recently(B-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: average_ratings, plot, review, genre, year, director, rating, character, title, trailer, song, actor\nGIVEN SENTENCE: what science fiction films have come out recently\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["what","science","fiction","films","have","come","out","recently"],"labels":["O","B-genre","I-genre","O","O","O","O","B-year"],"target_index":null,"target_label":null},"label_list":["average_ratings","plot","review","genre","year","director","rating","character","title","trailer","song","actor"]}
{"id":"4.S","dataset":"mit-movie","split":"dev","instance":{"id":"4.S","prompt_labels":"did(O) the(O) same(O) director(O) make(O) all(O) of(O) the(O) harry(B-title) potter(I-title) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, title, review, character, rating, year, average_ratings, director, genre, song, trailer, plot\nGIVEN SENTENCE: did the same director make all of the harry potter movies\n","prediction_output":null,"prediction_outputs":null,"group":"4","words":["did","the","same","director","make","all","of","the","harry","potter","movies"],"labels":["O","O","O","O","O","O","O","O","B-title","I-title","O"],"target_index":null,"target_label":null},"label_list":["actor","title","review","character","rating","year","average_ratings","director","genre","song","trailer","plot"]}
{"id":"5.S","dataset":"mit-movie","split":"dev","instance":{"id":"5.S","prompt_labels":"show(O) me(O) 1980s(B-year) action(B-genre) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, actor, title, review, song, rating, character, year, average_ratings, genre, trailer, director\nGIVEN SENTENCE: show me 1980s action movies\n","prediction_output":null,"prediction_outputs":null,"group":"5","words":["show","me","1980s","action","movies"],"labels":["O","O","B-year","B-genre","O"],"target_index":null,"target_label":null},"label_list":["plot","actor","title","review","song","rating","character","year","average_ratings","genre","trailer","director"]}
{"id":"6.S","dataset":"mit-movie","split":"dev","instance":{"id":"6.S","prompt_labels":"what(O) is(O) the(O) name(O) of(O) the(O) third(O) movie(O) in(O) the(O) star(B-title) trek(I-title) series(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, plot, average_ratings, character, trailer, rating, director, year, song, actor, review, title\nGIVEN SENTENCE: what is the name of the third movie in the star trek series\n","prediction_output":null,"prediction_outputs":null,"group":"6","words":["what","is","the","name","of","the","third","movie","in","the","star","trek","series"],"labels":["O","O","O","O","O","O","O","O","O","O","B-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["genre","plot","average_ratings","character","trailer","rating","director","year","song","actor","review","title"]}
{"id":"7.S","dataset":"mit-movie","split":"dev","instance":{"id":"7.S","prompt_labels":"can(O) you(O) get(O) a(O) soundtrac(B-song) for(O) the(O) harry(B-title) potter(I-title) films(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, trailer, review, genre, year, character, title, rating, average_ratings, director, song, plot\nGIVEN SENTENCE: can you get a soundtrac for the harry potter films\n","prediction_output":null,"prediction_outputs":null,"group":"7","words":["can","you","get","a","soundtrac","for","the","harry","potter","films"],"labels":["O","O","O","O","B-song","O","O","B-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["actor","trailer","review","genre","year","character","title","rating","average_ratings","director","song","plot"]}
{"id":"8.S","dataset":"mit-movie","split":"dev","instance":{"id":"8.S","prompt_labels":"find(O) me(O) science(B-genre) fiction(I-genre) movies(O) since(B-year) 2005(I-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: trailer, review, actor, rating, title, genre, year, plot, song, character, director, average_ratings\nGIVEN SENTENCE: find me science fiction movies since 2005\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["find","me","science","fiction","movies","since","2005"],"labels":["O","O","B-genre","I-genre","O","B-year","I-year"],"target_index":null,"target_label":null},"label_list":["trailer","review","actor","rating","title","genre","year","plot","song","character","director","average_ratings"]}
{"id":"9.S","dataset":"mit-movie","split":"dev","instance":{"id":"9.S","prompt_labels":"what(O) is(O) the(O) most(O) current(B-year) movie(O) featuring(O) mat(B-actor) damon(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, character, year, actor, rating, director, genre, average_ratings, trailer, review, plot, title\nGIVEN SENTENCE: what is the most current movie featuring mat damon\n","prediction_output":null,"prediction_outputs":null,"group":"9","words":["what","is","the","most","current","movie","featuring","mat","damon"],"labels":["O","O","O","O","B-year","O","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["song","character","year","actor","rating","director","genre","average_ratings","trailer","review","plot","title"]}
{"id":"15.S","dataset":"mit-movie","split":"dev","instance":{"id":"15.S","prompt_labels":"find(O) rated(O) g(B-rating) films(O) with(O) flying(B-plot) cars(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, average_ratings, title, genre, character, song, rating, director, actor, review, year, trailer\nGIVEN SENTENCE: find rated g films with flying cars\n","prediction_output":null,"prediction_outputs":null,"group":"15","words":["find","rated","g","films","with","flying","cars"],"labels":["O","O","B-rating","O","O","B-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["plot","average_ratings","title","genre","character","song","rating","director","actor","review","year","trailer"]}
{"id":"16.S","dataset":"mit-movie","split":"dev","instance":{"id":"16.S","prompt_labels":"what(O) was(O) the(O) best(B-review) rated(O) stanley(B-director) kubrick(I-director) film(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, character, actor, song, title, trailer, review, director, year, average_ratings, genre, plot\nGIVEN SENTENCE: what was the best rated stanley kubrick film\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["what","was","the","best","rated","stanley","kubrick","film"],"labels":["O","O","O","B-review","O","B-director","I-director","O"],"target_index":null,"target_label":null},"label_list":["rating","character","actor","song","title","trailer","review","director","year","average_ratings","genre","plot"]}
{"id":"17.S","dataset":"mit-movie","split":"dev","instance":{"id":"17.S","prompt_labels":"are(O) there(O) any(O) films(O) directed(O) by(O) shawn(B-director) levy(I-director) about(O) large(B-plot) families(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, song, genre, plot, director, rating, title, trailer, character, year, actor, average_ratings\nGIVEN SENTENCE: are there any films directed by shawn levy about large families\n","prediction_output":null,"prediction_outputs":null,"group":"17","words":["are","there","any","films","directed","by","shawn","levy","about","large","families"],"labels":["O","O","O","O","O","O","B-director","I-director","O","B-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["review","song","genre","plot","director","rating","title","trailer","character","year","actor","average_ratings"]}
{"id":"18.S","dataset":"mit-movie","split":"dev","instance":{"id":"18.S","prompt_labels":"list(O) pg(B-rating) rated(O) movies(O) about(O) cars(B-plot) released(O) in(O) the(O) 1990s(B-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, average_ratings, song, title, trailer, review, plot, character, rating, director, actor, genre\nGIVEN SENTENCE: list pg rated movies about cars released in the 1990s\n","prediction_output":null,"prediction_outputs":null,"group":"18","words":["list","pg","rated","movies","about","cars","released","in","the","1990s"],"labels":["O","B-rating","O","O","O","B-plot","O","O","O","B-year"],"target_index":null,"target_label":null},"label_list":["year","average_ratings","song","title","trailer","review","plot","character","rating","director","actor","genre"]}
{"id":"19.S","dataset":"mit-movie","split":"dev","instance":{"id":"19.S","prompt_labels":"what(O) movie(O) won(O) best(B-average_ratings) picure(I-average_ratings) at(O) the(O) 2012(B-average_ratings) oscars(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, year, actor, title, plot, rating, review, director, song, average_ratings, trailer, character\nGIVEN SENTENCE: what movie won best picure at the 2012 oscars\n","prediction_output":null,"prediction_outputs":null,"group":"19","words":["what","movie","won","best","picure","at","the","2012","oscars"],"labels":["O","O","O","B-average_ratings","I-average_ratings","O","O","B-average_ratings","O"],"target_index":null,"target_label":null},"label_list":["genre","year","actor","title","plot","rating","review","director","song","average_ratings","trailer","character"]}
{"id":"23.S","dataset":"mit-movie","split":"dev","instance":{"id":"23.S","prompt_labels":"who(O) directed(B-director) the(O) film(O) pulp(B-title) fiction(I-title) that(O) starred(O) john(B-actor) travolta(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, title, average_ratings, review, actor, song, year, trailer, rating, genre, director, character\nGIVEN SENTENCE: who directed the film pulp fiction that starred john travolta\n","prediction_output":null,"prediction_outputs":null,"group":"23","words":["who","directed","the","film","pulp","fiction","that","starred","john","travolta"],"labels":["O","B-director","O","O","B-title","I-title","O","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["plot","title","average_ratings","review","actor","song","year","trailer","rating","genre","director","character"]}
{"id":"29.S","dataset":"mit-movie","split":"dev","instance":{"id":"29.S","prompt_labels":"is(O) there(O) a(O) pg(B-rating) 13(I-rating) movie(O) thats(O) scary(B-genre)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, character, rating, review, year, genre, title, actor, average_ratings, song, director, trailer\nGIVEN SENTENCE: is there a pg 13 movie thats scary\n","prediction_output":null,"prediction_outputs":null,"group":"29","words":["is","there","a","pg","13","movie","thats","scary"],"labels":["O","O","O","B-rating","I-rating","O","O","B-genre"],"target_index":null,"target_label":null},"label_list":["plot","character","rating","review","year","genre","title","actor","average_ratings","song","director","trailer"]}
{"id":"30.S","dataset":"mit-movie","split":"dev","instance":{"id":"30.S","prompt_labels":"what(O) movies(O) made(O) in(O) 2004(B-year) were(O) pg(B-rating)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, plot, rating, genre, character, year, trailer, title, average_ratings, song, director, actor\nGIVEN SENTENCE: what movies made in 2004 were pg\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["what","movies","made","in","2004","were","pg"],"labels":["O","O","O","O","B-year","O","B-rating"],"target_index":null,"target_label":null},"label_list":["review","plot","rating","genre","character","year","trailer","title","average_ratings","song","director","actor"]}
{"id":"31.S","dataset":"mit-movie","split":"dev","instance":{"id":"31.S","prompt_labels":"find(O) movies(O) with(O) robert(B-actor) diniero(I-actor) in(O) it(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, character, actor, average_ratings, genre, trailer, plot, director, review, song, rating, title\nGIVEN SENTENCE: find movies with robert diniero in it\n","prediction_output":null,"prediction_outputs":null,"group":"31","words":["find","movies","with","robert","diniero","in","it"],"labels":["O","O","O","B-actor","I-actor","O","O"],"target_index":null,"target_label":null},"label_list":["year","character","actor","average_ratings","genre","trailer","plot","director","review","song","rating","title"]}
{"id":"32.S","dataset":"mit-movie","split":"dev","instance":{"id":"32.S","prompt_labels":"have(O) pg(B-rating) 13(I-rating) movies(O) for(O) the(O) kidz(B-genre)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, actor, average_ratings, title, genre, year, plot, director, song, review, rating, trailer\nGIVEN SENTENCE: have pg 13 movies for the kidz\n","prediction_output":null,"prediction_outputs":null,"group":"32","words":["have","pg","13","movies","for","the","kidz"],"labels":["O","B-rating","I-rating","O","O","O","B-genre"],"target_index":null,"target_label":null},"label_list":["character","actor","average_ratings","title","genre","year","plot","director","song","review","rating","trailer"]}
{"id":"35.S","dataset":"mit-movie","split":"dev","instance":{"id":"35.S","prompt_labels":"did(O) george(B-director) clooney(I-director) direct(O) any(O) comedy(B-genre) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, trailer, genre, song, rating, year, review, director, average_ratings, character, title, actor\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":null},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"37.S","dataset":"mit-movie","split":"dev","instance":{"id":"37.S","prompt_labels":"find(O) me(O) the(O) movie(O) that(O) has(O) a(O) aerosmith(B-song) song(I-song)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, title, actor, director, trailer, review, rating, song, year, plot, average_ratings, genre\nGIVEN SENTENCE: find me the movie that has a aerosmith song\n","prediction_output":null,"prediction_outputs":null,"group":"37","words":["find","me","the","movie","that","has","a","aerosmith","song"],"labels":["O","O","O","O","O","O","O","B-song","I-song"],"target_index":null,"target_label":null},"label_list":["character","title","actor","director","trailer","review","rating","song","year","plot","average_ratings","genre"]}
{"id":"40.S","dataset":"mit-movie","split":"dev","instance":{"id":"40.S","prompt_labels":"what(O) is(O) the(O) highest(B-average_ratings) rated(I-average_ratings) kids(B-genre) new(B-year) release(I-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: director, actor, character, trailer, song, title, plot, genre, rating, average_ratings, review, year\nGIVEN SENTENCE: what is the highest rated kids new release\n","prediction_output":null,"prediction_outputs":null,"group":"40","words":["what","is","the","highest","rated","kids","new","release"],"labels":["O","O","O","B-average_ratings","I-average_ratings","B-genre","B-year","I-year"],"target_index":null,"target_label":null},"label_list":["director","actor","character","trailer","song","title","plot","genre","rating","average_ratings","review","year"]}
{"id":"41.S","dataset":"mit-movie","split":"dev","instance":{"id":"41.S","prompt_labels":"worst(B-average_ratings) review(I-average_ratings) for(O) 2011(B-year) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, trailer, year, average_ratings, director, rating, title, genre, character, plot, song, review\nGIVEN SENTENCE: worst review for 2011 movies\n","prediction_output":null,"prediction_outputs":null,"group":"41","words":["worst","review","for","2011","movies"],"labels":["B-average_ratings","I-average_ratings","O","B-year","O"],"target_index":null,"target_label":null},"label_list":["actor","trailer","year","average_ratings","director","rating","title","genre","character","plot","song","review"]}
{"id":"43.S","dataset":"mit-movie","split":"dev","instance":{"id":"43.S","prompt_labels":"lets(O) find(O) an(O) independent(B-genre) film(I-genre) company(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, genre, trailer, director, title, character, plot, review, year, rating, song, average_ratings\nGIVEN SENTENCE: lets find an independent film company\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["lets","find","an","independent","film","company"],"labels":["O","O","O","B-genre","I-genre","O"],"target_index":null,"target_label":null},"label_list":["actor","genre","trailer","director","title","character","plot","review","year","rating","song","average_ratings"]}
{"id":"44.S","dataset":"mit-movie","split":"dev","instance":{"id":"44.S","prompt_labels":"which(O) movies(O) were(O) based(B-plot) off(I-plot) of(I-plot) video(I-plot) games(I-plot) besides(O) resident(B-title) evil(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, rating, director, plot, character, review, average_ratings, song, actor, title, trailer, genre\nGIVEN SENTENCE: which movies were based off of video games besides resident evil\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["which","movies","were","based","off","of","video","games","besides","resident","evil"],"labels":["O","O","O","B-plot","I-plot","I-plot","I-plot","I-plot","O","B-title","I-title"],"target_index":null,"target_label":null},"label_list":["year","rating","director","plot","character","review","average_ratings","song","actor","title","trailer","genre"]}
{"id":"45.S","dataset":"mit-movie","split":"dev","instance":{"id":"45.S","prompt_labels":"did(O) dame(B-actor) judy(I-actor) dench(I-actor) star(O) in(O) a(O) british(B-plot) film(O) about(O) queen(B-character) elizabeth(I-character)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, genre, plot, song, title, year, average_ratings, review, character, director, trailer, actor\nGIVEN SENTENCE: did dame judy dench star in a british film about queen elizabeth\n","prediction_output":null,"prediction_outputs":null,"group":"45","words":["did","dame","judy","dench","star","in","a","british","film","about","queen","elizabeth"],"labels":["O","B-actor","I-actor","I-actor","O","O","O","B-plot","O","O","B-character","I-character"],"target_index":null,"target_label":null},"label_list":["rating","genre","plot","song","title","year","average_ratings","review","character","director","trailer","actor"]}
{"id":"46.S","dataset":"mit-movie","split":"dev","instance":{"id":"46.S","prompt_labels":"present(O) list(O) of(O) family(B-genre) movies(I-genre) that(O) chris(B-director) columbus(I-director) directed(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, average_ratings, plot, year, rating, director, genre, review, song, trailer, character, actor\nGIVEN SENTENCE: present list of family movies that chris columbus directed\n","prediction_output":null,"prediction_outputs":null,"group":"46","words":["present","list","of","family","movies","that","chris","columbus","directed"],"labels":["O","O","O","B-genre","I-genre","O","B-director","I-director","O"],"target_index":null,"target_label":null},"label_list":["title","average_ratings","plot","year","rating","director","genre","review","song","trailer","character","actor"]}
{"id":"47.S","dataset":"mit-movie","split":"dev","instance":{"id":"47.S","prompt_labels":"find(O) a(O) movie(O) with(O) dogs(B-plot) as(O) the(O) main(O) character(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, director, review, trailer, character, plot, average_ratings, year, rating, actor, genre, song\nGIVEN SENTENCE: find a movie with dogs as the main character\n","prediction_output":null,"prediction_outputs":null,"group":"47","words":["find","a","movie","with","dogs","as","the","main","character"],"labels":["O","O","O","O","B-plot","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["title","director","review","trailer","character","plot","average_ratings","year","rating","actor","genre","song"]}
{"id":"50.S","dataset":"mit-movie","split":"dev","instance":{"id":"50.S","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(B-actor) hathaway(I-actor) and(O) julie(B-actor) andrews(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, song, character, average_ratings, rating, director, genre, year, actor, title, plot, trailer\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"52.S","dataset":"mit-movie","split":"dev","instance":{"id":"52.S","prompt_labels":"list(O) the(O) dirty(B-title) harry(I-title) films(O) from(O) the(O) 1980s(B-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, song, genre, rating, plot, average_ratings, director, character, title, review, actor, trailer\nGIVEN SENTENCE: list the dirty harry films from the 1980s\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["list","the","dirty","harry","films","from","the","1980s"],"labels":["O","O","B-title","I-title","O","O","O","B-year"],"target_index":null,"target_label":null},"label_list":["year","song","genre","rating","plot","average_ratings","director","character","title","review","actor","trailer"]}
{"id":"54.S","dataset":"mit-movie","split":"dev","instance":{"id":"54.S","prompt_labels":"are(O) there(O) any(O) meg(B-actor) ryan(I-actor) romantic(B-genre) comedy(I-genre) movies(O) that(O) are(O) considered(O) must(B-review) see(I-review)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, genre, title, trailer, rating, director, average_ratings, year, actor, song, plot, review\nGIVEN SENTENCE: are there any meg ryan romantic comedy movies that are considered must see\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["are","there","any","meg","ryan","romantic","comedy","movies","that","are","considered","must","see"],"labels":["O","O","O","B-actor","I-actor","B-genre","I-genre","O","O","O","O","B-review","I-review"],"target_index":null,"target_label":null},"label_list":["character","genre","title","trailer","rating","director","average_ratings","year","actor","song","plot","review"]}
{"id":"55.S","dataset":"mit-movie","split":"dev","instance":{"id":"55.S","prompt_labels":"what(O) was(O) james(B-director) camerons(I-director) directorial(O) debut(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, year, title, genre, director, average_ratings, plot, trailer, character, song, review, actor\nGIVEN SENTENCE: what was james camerons directorial debut\n","prediction_output":null,"prediction_outputs":null,"group":"55","words":["what","was","james","camerons","directorial","debut"],"labels":["O","O","B-director","I-director","O","O"],"target_index":null,"target_label":null},"label_list":["rating","year","title","genre","director","average_ratings","plot","trailer","character","song","review","actor"]}
{"id":"56.S","dataset":"mit-movie","split":"dev","instance":{"id":"56.S","prompt_labels":"what(O) are(O) top(B-average_ratings) 50(I-average_ratings) movies(O) of(O) all(B-average_ratings) time(I-average_ratings)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, title, genre, actor, director, song, average_ratings, rating, character, trailer, plot, year\nGIVEN SENTENCE: what are top 50 movies of all time\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["what","are","top","50","movies","of","all","time"],"labels":["O","O","B-average_ratings","I-average_ratings","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":null},"label_list":["review","title","genre","actor","director","song","average_ratings","rating","character","trailer","plot","year"]}
{"id":"57.S","dataset":"mit-movie","split":"dev","instance":{"id":"57.S","prompt_labels":"find(O) me(O) comedy(B-genre) movies(O) with(O) liam(B-actor) hemsworth(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, average_ratings, plot, actor, year, director, song, trailer, character, title, rating, review\nGIVEN SENTENCE: find me comedy movies with liam hemsworth\n","prediction_output":null,"prediction_outputs":null,"group":"57","words":["find","me","comedy","movies","with","liam","hemsworth"],"labels":["O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["genre","average_ratings","plot","actor","year","director","song","trailer","character","title","rating","review"]}
{"id":"58.S","dataset":"mit-movie","split":"dev","instance":{"id":"58.S","prompt_labels":"i(O) want(O) to(O) see(O) cradle(B-title) 2(I-title) the(I-title) grave(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, average_ratings, plot, director, genre, song, character, trailer, title, rating, actor, year\nGIVEN SENTENCE: i want to see cradle 2 the grave\n","prediction_output":null,"prediction_outputs":null,"group":"58","words":["i","want","to","see","cradle","2","the","grave"],"labels":["O","O","O","O","B-title","I-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["review","average_ratings","plot","director","genre","song","character","trailer","title","rating","actor","year"]}
{"id":"59.S","dataset":"mit-movie","split":"dev","instance":{"id":"59.S","prompt_labels":"what(O) was(O) the(O) most(B-review) popular(I-review) movie(I-review) from(O) 2004(B-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, actor, year, title, song, character, trailer, plot, average_ratings, director, rating, review\nGIVEN SENTENCE: what was the most popular movie from 2004\n","prediction_output":null,"prediction_outputs":null,"group":"59","words":["what","was","the","most","popular","movie","from","2004"],"labels":["O","O","O","B-review","I-review","I-review","O","B-year"],"target_index":null,"target_label":null},"label_list":["genre","actor","year","title","song","character","trailer","plot","average_ratings","director","rating","review"]}
{"id":"60.S","dataset":"mit-movie","split":"dev","instance":{"id":"60.S","prompt_labels":"what(O) is(O) the(O) g(B-rating) rated(I-rating) movie(O) about(O) rabbits(B-plot) looking(I-plot) for(I-plot) a(I-plot) new(I-plot) home(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, trailer, average_ratings, director, year, rating, character, title, actor, song, plot, genre\nGIVEN SENTENCE: what is the g rated movie about rabbits looking for a new home\n","prediction_output":null,"prediction_outputs":null,"group":"60","words":["what","is","the","g","rated","movie","about","rabbits","looking","for","a","new","home"],"labels":["O","O","O","B-rating","I-rating","O","O","B-plot","I-plot","I-plot","I-plot","I-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["review","trailer","average_ratings","director","year","rating","character","title","actor","song","plot","genre"]}
{"id":"63.S","dataset":"mit-movie","split":"dev","instance":{"id":"63.S","prompt_labels":"how(O) many(O) times(O) has(O) matt(B-actor) damon(I-actor) been(O) jason(B-character) bourne(I-character)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, average_ratings, song, title, year, director, plot, actor, review, character, trailer, rating\nGIVEN SENTENCE: how many times has matt damon been jason bourne\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["how","many","times","has","matt","damon","been","jason","bourne"],"labels":["O","O","O","O","B-actor","I-actor","O","B-character","I-character"],"target_index":null,"target_label":null},"label_list":["genre","average_ratings","song","title","year","director","plot","actor","review","character","trailer","rating"]}
{"id":"64.S","dataset":"mit-movie","split":"dev","instance":{"id":"64.S","prompt_labels":"whats(O) the(O) latetest(B-year) foreign(B-genre) romantic(I-genre) movie(O) with(O) lots(O) of(O) sex(B-plot) and(O) sadness(B-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: average_ratings, review, year, character, rating, title, director, actor, trailer, song, genre, plot\nGIVEN SENTENCE: whats the latetest foreign romantic movie with lots of sex and sadness\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["whats","the","latetest","foreign","romantic","movie","with","lots","of","sex","and","sadness"],"labels":["O","O","B-year","B-genre","I-genre","O","O","O","O","B-plot","O","B-plot"],"target_index":null,"target_label":null},"label_list":["average_ratings","review","year","character","rating","title","director","actor","trailer","song","genre","plot"]}
{"id":"65.S","dataset":"mit-movie","split":"dev","instance":{"id":"65.S","prompt_labels":"list(O) movies(O) with(O) jeremy(B-actor) piven(I-actor) released(O) in(O) the(O) 1990s(B-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, character, actor, trailer, average_ratings, year, song, review, genre, plot, title, director\nGIVEN SENTENCE: list movies with jeremy piven released in the 1990s\n","prediction_output":null,"prediction_outputs":null,"group":"65","words":["list","movies","with","jeremy","piven","released","in","the","1990s"],"labels":["O","O","O","B-actor","I-actor","O","O","O","B-year"],"target_index":null,"target_label":null},"label_list":["rating","character","actor","trailer","average_ratings","year","song","review","genre","plot","title","director"]}
{"id":"66.S","dataset":"mit-movie","split":"dev","instance":{"id":"66.S","prompt_labels":"show(O) me(O) the(O) collection(O) of(O) action(B-genre) movies(I-genre) of(O) arnold(B-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: director, year, song, review, title, plot, actor, genre, average_ratings, rating, trailer, character\nGIVEN SENTENCE: show me the collection of action movies of arnold\n","prediction_output":null,"prediction_outputs":null,"group":"66","words":["show","me","the","collection","of","action","movies","of","arnold"],"labels":["O","O","O","O","O","B-genre","I-genre","O","B-actor"],"target_index":null,"target_label":null},"label_list":["director","year","song","review","title","plot","actor","genre","average_ratings","rating","trailer","character"]}
{"id":"67.S","dataset":"mit-movie","split":"dev","instance":{"id":"67.S","prompt_labels":"are(O) there(O) comic(B-genre) book(I-genre) movies(I-genre) that(O) are(O) over(O) pg(B-rating) 13(I-rating)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, review, character, year, song, trailer, average_ratings, rating, director, title, actor, plot\nGIVEN SENTENCE: are there comic book movies that are over pg 13\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["are","there","comic","book","movies","that","are","over","pg","13"],"labels":["O","O","B-genre","I-genre","I-genre","O","O","O","B-rating","I-rating"],"target_index":null,"target_label":null},"label_list":["genre","review","character","year","song","trailer","average_ratings","rating","director","title","actor","plot"]}
{"id":"68.S","dataset":"mit-movie","split":"dev","instance":{"id":"68.S","prompt_labels":"the(O) new(O) batman(B-title) movie(O) looks(O) epic(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, song, character, rating, genre, actor, plot, title, year, trailer, director, average_ratings\nGIVEN SENTENCE: the new batman movie looks epic\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["the","new","batman","movie","looks","epic"],"labels":["O","O","B-title","O","O","O"],"target_index":null,"target_label":null},"label_list":["review","song","character","rating","genre","actor","plot","title","year","trailer","director","average_ratings"]}
{"id":"69.S","dataset":"mit-movie","split":"dev","instance":{"id":"69.S","prompt_labels":"show(O) me(O) movies(O) who(O) won(O) awards(B-average_ratings)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, year, trailer, rating, character, director, genre, title, plot, review, song, average_ratings\nGIVEN SENTENCE: show me movies who won awards\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["show","me","movies","who","won","awards"],"labels":["O","O","O","O","O","B-average_ratings"],"target_index":null,"target_label":null},"label_list":["actor","year","trailer","rating","character","director","genre","title","plot","review","song","average_ratings"]}
{"id":"70.S","dataset":"mit-movie","split":"dev","instance":{"id":"70.S","prompt_labels":"what(O) is(O) the(O) year(B-year) that(O) dirty(B-title) dancing(I-title) was(O) released(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, actor, song, rating, plot, review, average_ratings, character, director, genre, title, trailer\nGIVEN SENTENCE: what is the year that dirty dancing was released\n","prediction_output":null,"prediction_outputs":null,"group":"70","words":["what","is","the","year","that","dirty","dancing","was","released"],"labels":["O","O","O","B-year","O","B-title","I-title","O","O"],"target_index":null,"target_label":null},"label_list":["year","actor","song","rating","plot","review","average_ratings","character","director","genre","title","trailer"]}
{"id":"73.S","dataset":"mit-movie","split":"dev","instance":{"id":"73.S","prompt_labels":"are(O) there(O) any(O) silent(B-genre) movies(O) made(O) after(B-year) 1930(I-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, plot, title, character, director, average_ratings, actor, year, rating, review, trailer, song\nGIVEN SENTENCE: are there any silent movies made after 1930\n","prediction_output":null,"prediction_outputs":null,"group":"73","words":["are","there","any","silent","movies","made","after","1930"],"labels":["O","O","O","B-genre","O","O","B-year","I-year"],"target_index":null,"target_label":null},"label_list":["genre","plot","title","character","director","average_ratings","actor","year","rating","review","trailer","song"]}
{"id":"74.S","dataset":"mit-movie","split":"dev","instance":{"id":"74.S","prompt_labels":"who(O) was(O) the(O) actress(O) in(O) the(B-title) goodbye(I-title) girl(I-title) with(O) richard(B-actor) dreyfuss(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: director, average_ratings, plot, review, genre, year, title, trailer, character, rating, song, actor\nGIVEN SENTENCE: who was the actress in the goodbye girl with richard dreyfuss\n","prediction_output":null,"prediction_outputs":null,"group":"74","words":["who","was","the","actress","in","the","goodbye","girl","with","richard","dreyfuss"],"labels":["O","O","O","O","O","B-title","I-title","I-title","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["director","average_ratings","plot","review","genre","year","title","trailer","character","rating","song","actor"]}
{"id":"78.S","dataset":"mit-movie","split":"dev","instance":{"id":"78.S","prompt_labels":"what(O) movie(O) has(O) the(O) most(B-review) remakes(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, rating, actor, director, year, title, character, average_ratings, review, song, genre, trailer\nGIVEN SENTENCE: what movie has the most remakes\n","prediction_output":null,"prediction_outputs":null,"group":"78","words":["what","movie","has","the","most","remakes"],"labels":["O","O","O","O","B-review","O"],"target_index":null,"target_label":null},"label_list":["plot","rating","actor","director","year","title","character","average_ratings","review","song","genre","trailer"]}
{"id":"81.S","dataset":"mit-movie","split":"dev","instance":{"id":"81.S","prompt_labels":"i(O) would(O) like(O) a(O) list(O) of(O) movies(O) about(O) dancing(B-plot) from(O) the(O) past(B-year) 10(I-year) years(I-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, year, rating, genre, director, title, actor, song, average_ratings, plot, trailer, review\nGIVEN SENTENCE: i would like a list of movies about dancing from the past 10 years\n","prediction_output":null,"prediction_outputs":null,"group":"81","words":["i","would","like","a","list","of","movies","about","dancing","from","the","past","10","years"],"labels":["O","O","O","O","O","O","O","O","B-plot","O","O","B-year","I-year","I-year"],"target_index":null,"target_label":null},"label_list":["character","year","rating","genre","director","title","actor","song","average_ratings","plot","trailer","review"]}
{"id":"82.S","dataset":"mit-movie","split":"dev","instance":{"id":"82.S","prompt_labels":"who(O) stars(O) in(O) project(B-title) x(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, plot, character, rating, genre, title, average_ratings, director, year, actor, trailer, song\nGIVEN SENTENCE: who stars in project x\n","prediction_output":null,"prediction_outputs":null,"group":"82","words":["who","stars","in","project","x"],"labels":["O","O","O","B-title","I-title"],"target_index":null,"target_label":null},"label_list":["review","plot","character","rating","genre","title","average_ratings","director","year","actor","trailer","song"]}
{"id":"83.S","dataset":"mit-movie","split":"dev","instance":{"id":"83.S","prompt_labels":"find(O) action(B-genre) movies(O) featuring(O) comic(B-plot) book(I-plot) characters(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, director, rating, year, character, song, plot, actor, trailer, average_ratings, title, review\nGIVEN SENTENCE: find action movies featuring comic book characters\n","prediction_output":null,"prediction_outputs":null,"group":"83","words":["find","action","movies","featuring","comic","book","characters"],"labels":["O","B-genre","O","O","B-plot","I-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["genre","director","rating","year","character","song","plot","actor","trailer","average_ratings","title","review"]}
{"id":"84.S","dataset":"mit-movie","split":"dev","instance":{"id":"84.S","prompt_labels":"what(O) are(O) some(O) g(B-rating) rated(O) movies(O) with(O) fairies(B-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: trailer, plot, title, genre, song, rating, director, actor, average_ratings, review, character, year\nGIVEN SENTENCE: what are some g rated movies with fairies\n","prediction_output":null,"prediction_outputs":null,"group":"84","words":["what","are","some","g","rated","movies","with","fairies"],"labels":["O","O","O","B-rating","O","O","O","B-plot"],"target_index":null,"target_label":null},"label_list":["trailer","plot","title","genre","song","rating","director","actor","average_ratings","review","character","year"]}
{"id":"86.S","dataset":"mit-movie","split":"dev","instance":{"id":"86.S","prompt_labels":"what(O) movie(O) did(O) rod(B-director) serling(I-director) write(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, actor, review, average_ratings, director, trailer, title, rating, year, genre, character, plot\nGIVEN SENTENCE: what movie did rod serling write\n","prediction_output":null,"prediction_outputs":null,"group":"86","words":["what","movie","did","rod","serling","write"],"labels":["O","O","O","B-director","I-director","O"],"target_index":null,"target_label":null},"label_list":["song","actor","review","average_ratings","director","trailer","title","rating","year","genre","character","plot"]}
{"id":"87.S","dataset":"mit-movie","split":"dev","instance":{"id":"87.S","prompt_labels":"is(O) there(O) an(O) animated(B-genre) adult(I-genre) fantasy(I-genre) movie(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, director, song, average_ratings, character, year, rating, review, genre, actor, trailer, plot\nGIVEN SENTENCE: is there an animated adult fantasy movie\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["is","there","an","animated","adult","fantasy","movie"],"labels":["O","O","O","B-genre","I-genre","I-genre","O"],"target_index":null,"target_label":null},"label_list":["title","director","song","average_ratings","character","year","rating","review","genre","actor","trailer","plot"]}
{"id":"93.S","dataset":"mit-movie","split":"dev","instance":{"id":"93.S","prompt_labels":"who(O) directed(O) princess(B-title) bride(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, plot, character, year, trailer, title, review, genre, rating, actor, average_ratings, director\nGIVEN SENTENCE: who directed princess bride\n","prediction_output":null,"prediction_outputs":null,"group":"93","words":["who","directed","princess","bride"],"labels":["O","O","B-title","I-title"],"target_index":null,"target_label":null},"label_list":["song","plot","character","year","trailer","title","review","genre","rating","actor","average_ratings","director"]}
{"id":"95.S","dataset":"mit-movie","split":"dev","instance":{"id":"95.S","prompt_labels":"name(O) a(O) western(B-genre) comedy(I-genre)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, genre, trailer, average_ratings, title, song, actor, character, review, plot, rating, director\nGIVEN SENTENCE: name a western comedy\n","prediction_output":null,"prediction_outputs":null,"group":"95","words":["name","a","western","comedy"],"labels":["O","O","B-genre","I-genre"],"target_index":null,"target_label":null},"label_list":["year","genre","trailer","average_ratings","title","song","actor","character","review","plot","rating","director"]}
{"id":"97.S","dataset":"mit-movie","split":"dev","instance":{"id":"97.S","prompt_labels":"how(O) many(O) movies(O) have(O) starred(O) brad(B-actor) pitt(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, director, title, actor, rating, character, song, plot, average_ratings, genre, trailer, review\nGIVEN SENTENCE: how many movies have starred brad pitt\n","prediction_output":null,"prediction_outputs":null,"group":"97","words":["how","many","movies","have","starred","brad","pitt"],"labels":["O","O","O","O","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["year","director","title","actor","rating","character","song","plot","average_ratings","genre","trailer","review"]}
{"id":"100.S","dataset":"mit-movie","split":"dev","instance":{"id":"100.S","prompt_labels":"channing(B-actor) tatum(I-actor) has(O) played(O) what(O) starring(O) roles(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, average_ratings, director, review, title, rating, year, genre, actor, trailer, plot, song\nGIVEN SENTENCE: channing tatum has played what starring roles\n","prediction_output":null,"prediction_outputs":null,"group":"100","words":["channing","tatum","has","played","what","starring","roles"],"labels":["B-actor","I-actor","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["character","average_ratings","director","review","title","rating","year","genre","actor","trailer","plot","song"]}
{"id":"101.S","dataset":"mit-movie","split":"dev","instance":{"id":"101.S","prompt_labels":"list(O) of(O) actors(O) a(B-title) beautiful(I-title) mind(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, rating, song, director, year, actor, review, trailer, average_ratings, character, genre, plot\nGIVEN SENTENCE: list of actors a beautiful mind\n","prediction_output":null,"prediction_outputs":null,"group":"101","words":["list","of","actors","a","beautiful","mind"],"labels":["O","O","O","B-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["title","rating","song","director","year","actor","review","trailer","average_ratings","character","genre","plot"]}
{"id":"113.S","dataset":"mit-movie","split":"dev","instance":{"id":"113.S","prompt_labels":"are(O) there(O) any(O) pg(B-rating) movies(I-rating) with(O) car(B-plot) chases(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, genre, title, plot, rating, actor, director, song, year, trailer, average_ratings, character\nGIVEN SENTENCE: are there any pg movies with car chases\n","prediction_output":null,"prediction_outputs":null,"group":"113","words":["are","there","any","pg","movies","with","car","chases"],"labels":["O","O","O","B-rating","I-rating","O","B-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["review","genre","title","plot","rating","actor","director","song","year","trailer","average_ratings","character"]}
{"id":"117.S","dataset":"mit-movie","split":"dev","instance":{"id":"117.S","prompt_labels":"who(O) directed(B-director) runaway(B-title) jury(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, year, review, plot, character, director, rating, genre, actor, average_ratings, song, trailer\nGIVEN SENTENCE: who directed runaway jury\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["who","directed","runaway","jury"],"labels":["O","B-director","B-title","I-title"],"target_index":null,"target_label":null},"label_list":["title","year","review","plot","character","director","rating","genre","actor","average_ratings","song","trailer"]}
{"id":"119.S","dataset":"mit-movie","split":"dev","instance":{"id":"119.S","prompt_labels":"what(O) popular(B-review) films(O) released(O) last(B-year) month(I-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: trailer, year, title, genre, plot, director, average_ratings, actor, song, rating, review, character\nGIVEN SENTENCE: what popular films released last month\n","prediction_output":null,"prediction_outputs":null,"group":"119","words":["what","popular","films","released","last","month"],"labels":["O","B-review","O","O","B-year","I-year"],"target_index":null,"target_label":null},"label_list":["trailer","year","title","genre","plot","director","average_ratings","actor","song","rating","review","character"]}
{"id":"120.S","dataset":"mit-movie","split":"dev","instance":{"id":"120.S","prompt_labels":"did(O) dean(B-director) parisot(I-director) direct(O) sigourney(B-actor) weaver(I-actor) and(O) tim(B-actor) allen(I-actor) in(O) a(O) comedy(B-genre)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, average_ratings, trailer, genre, song, character, year, actor, plot, rating, director, title\nGIVEN SENTENCE: did dean parisot direct sigourney weaver and tim allen in a comedy\n","prediction_output":null,"prediction_outputs":null,"group":"120","words":["did","dean","parisot","direct","sigourney","weaver","and","tim","allen","in","a","comedy"],"labels":["O","B-director","I-director","O","B-actor","I-actor","O","B-actor","I-actor","O","O","B-genre"],"target_index":null,"target_label":null},"label_list":["review","average_ratings","trailer","genre","song","character","year","actor","plot","rating","director","title"]}
{"id":"124.S","dataset":"mit-movie","split":"dev","instance":{"id":"124.S","prompt_labels":"how(O) many(O) films(O) did(O) clive(B-actor) owen(I-actor) play(O) in(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, genre, trailer, song, character, actor, director, title, review, rating, plot, average_ratings\nGIVEN SENTENCE: how many films did clive owen play in\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["how","many","films","did","clive","owen","play","in"],"labels":["O","O","O","O","B-actor","I-actor","O","O"],"target_index":null,"target_label":null},"label_list":["year","genre","trailer","song","character","actor","director","title","review","rating","plot","average_ratings"]}
{"id":"125.S","dataset":"mit-movie","split":"dev","instance":{"id":"125.S","prompt_labels":"are(O) there(O) any(O) films(O) that(O) harmony(B-director) korine(I-director) regrets(B-review) directing(O) andor(O) releasing(O) to(O) the(O) public(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, genre, director, actor, review, character, title, trailer, song, plot, year, average_ratings\nGIVEN SENTENCE: are there any films that harmony korine regrets directing andor releasing to the public\n","prediction_output":null,"prediction_outputs":null,"group":"125","words":["are","there","any","films","that","harmony","korine","regrets","directing","andor","releasing","to","the","public"],"labels":["O","O","O","O","O","B-director","I-director","B-review","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["rating","genre","director","actor","review","character","title","trailer","song","plot","year","average_ratings"]}
{"id":"133.S","dataset":"mit-movie","split":"dev","instance":{"id":"133.S","prompt_labels":"how(O) many(O) movies(O) did(O) christopher(B-actor) walkin(I-actor) star(O) in(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, year, average_ratings, director, song, trailer, plot, rating, review, actor, genre, title\nGIVEN SENTENCE: how many movies did christopher walkin star in\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["how","many","movies","did","christopher","walkin","star","in"],"labels":["O","O","O","O","B-actor","I-actor","O","O"],"target_index":null,"target_label":null},"label_list":["character","year","average_ratings","director","song","trailer","plot","rating","review","actor","genre","title"]}
{"id":"136.S","dataset":"mit-movie","split":"dev","instance":{"id":"136.S","prompt_labels":"waht(O) was(O) the(O) plot(O) of(O) the(B-title) deep(I-title) blue(I-title) sea(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, genre, review, trailer, character, year, average_ratings, rating, title, actor, song, director\nGIVEN SENTENCE: waht was the plot of the deep blue sea\n","prediction_output":null,"prediction_outputs":null,"group":"136","words":["waht","was","the","plot","of","the","deep","blue","sea"],"labels":["O","O","O","O","O","B-title","I-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["plot","genre","review","trailer","character","year","average_ratings","rating","title","actor","song","director"]}
{"id":"142.S","dataset":"mit-movie","split":"dev","instance":{"id":"142.S","prompt_labels":"what(O) techno(B-genre) thriller(O) gets(O) a(O) low(B-average_ratings) rating(I-average_ratings)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, actor, director, review, song, genre, rating, title, plot, average_ratings, trailer, year\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":null},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"145.S","dataset":"mit-movie","split":"dev","instance":{"id":"145.S","prompt_labels":"what(O) is(O) the(O) most(B-year) recent(I-year) sean(B-actor) connery(I-actor) film(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, song, rating, title, genre, character, year, trailer, average_ratings, review, plot, director\nGIVEN SENTENCE: what is the most recent sean connery film\n","prediction_output":null,"prediction_outputs":null,"group":"145","words":["what","is","the","most","recent","sean","connery","film"],"labels":["O","O","O","B-year","I-year","B-actor","I-actor","O"],"target_index":null,"target_label":null},"label_list":["actor","song","rating","title","genre","character","year","trailer","average_ratings","review","plot","director"]}
{"id":"147.S","dataset":"mit-movie","split":"dev","instance":{"id":"147.S","prompt_labels":"what(O) is(O) a(O) recent(O) george(B-actor) clooney(I-actor) movie(O) with(O) high(B-average_ratings) viewers(I-average_ratings) rating(I-average_ratings)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: character, plot, average_ratings, actor, director, year, review, song, rating, title, genre, trailer\nGIVEN SENTENCE: what is a recent george clooney movie with high viewers rating\n","prediction_output":null,"prediction_outputs":null,"group":"147","words":["what","is","a","recent","george","clooney","movie","with","high","viewers","rating"],"labels":["O","O","O","O","B-actor","I-actor","O","O","B-average_ratings","I-average_ratings","I-average_ratings"],"target_index":null,"target_label":null},"label_list":["character","plot","average_ratings","actor","director","year","review","song","rating","title","genre","trailer"]}
{"id":"148.S","dataset":"mit-movie","split":"dev","instance":{"id":"148.S","prompt_labels":"which(O) animated(B-genre) childrens(I-genre) movies(I-genre) are(O) considered(B-review) timeless(I-review)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, director, average_ratings, song, character, title, actor, review, plot, trailer, year, genre\nGIVEN SENTENCE: which animated childrens movies are considered timeless\n","prediction_output":null,"prediction_outputs":null,"group":"148","words":["which","animated","childrens","movies","are","considered","timeless"],"labels":["O","B-genre","I-genre","I-genre","O","B-review","I-review"],"target_index":null,"target_label":null},"label_list":["rating","director","average_ratings","song","character","title","actor","review","plot","trailer","year","genre"]}
{"id":"152.S","dataset":"mit-movie","split":"dev","instance":{"id":"152.S","prompt_labels":"show(O) me(O) terry(B-director) gilliam(I-director) movies(O) starring(O) jeff(B-actor) bridges(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, director, genre, review, rating, actor, character, plot, song, average_ratings, year, trailer\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"153.S","dataset":"mit-movie","split":"dev","instance":{"id":"153.S","prompt_labels":"was(O) there(O) a(O) trailer(O) for(O) bowling(B-title) for(I-title) columbine(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: average_ratings, plot, character, year, song, title, trailer, genre, director, rating, review, actor\nGIVEN SENTENCE: was there a trailer for bowling for columbine\n","prediction_output":null,"prediction_outputs":null,"group":"153","words":["was","there","a","trailer","for","bowling","for","columbine"],"labels":["O","O","O","O","O","B-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["average_ratings","plot","character","year","song","title","trailer","genre","director","rating","review","actor"]}
{"id":"157.S","dataset":"mit-movie","split":"dev","instance":{"id":"157.S","prompt_labels":"what(O) movies(O) have(O) batman(B-plot) and(I-plot) robin(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: trailer, actor, director, genre, average_ratings, title, song, plot, character, year, review, rating\nGIVEN SENTENCE: what movies have batman and robin\n","prediction_output":null,"prediction_outputs":null,"group":"157","words":["what","movies","have","batman","and","robin"],"labels":["O","O","O","B-plot","I-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["trailer","actor","director","genre","average_ratings","title","song","plot","character","year","review","rating"]}
{"id":"160.S","dataset":"mit-movie","split":"dev","instance":{"id":"160.S","prompt_labels":"did(O) vin(B-actor) diesel(I-actor) star(O) in(O) any(O) comdedies(B-genre)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: director, actor, rating, title, year, review, plot, character, song, trailer, average_ratings, genre\nGIVEN SENTENCE: did vin diesel star in any comdedies\n","prediction_output":null,"prediction_outputs":null,"group":"160","words":["did","vin","diesel","star","in","any","comdedies"],"labels":["O","B-actor","I-actor","O","O","O","B-genre"],"target_index":null,"target_label":null},"label_list":["director","actor","rating","title","year","review","plot","character","song","trailer","average_ratings","genre"]}
{"id":"161.S","dataset":"mit-movie","split":"dev","instance":{"id":"161.S","prompt_labels":"did(O) ray(B-director) liota(I-director) direct(O) any(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, trailer, rating, director, genre, actor, average_ratings, title, character, plot, review, song\nGIVEN SENTENCE: did ray liota direct any films\n","prediction_output":null,"prediction_outputs":null,"group":"161","words":["did","ray","liota","direct","any","films"],"labels":["O","B-director","I-director","O","O","O"],"target_index":null,"target_label":null},"label_list":["year","trailer","rating","director","genre","actor","average_ratings","title","character","plot","review","song"]}
{"id":"164.S","dataset":"mit-movie","split":"dev","instance":{"id":"164.S","prompt_labels":"find(O) me(O) a(O) movie(O) with(O) the(O) song(O) lets(B-song) hear(I-song) it(I-song) for(I-song) the(I-song) boys(I-song)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, average_ratings, title, actor, character, trailer, rating, year, genre, review, plot, director\nGIVEN SENTENCE: find me a movie with the song lets hear it for the boys\n","prediction_output":null,"prediction_outputs":null,"group":"164","words":["find","me","a","movie","with","the","song","lets","hear","it","for","the","boys"],"labels":["O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song"],"target_index":null,"target_label":null},"label_list":["song","average_ratings","title","actor","character","trailer","rating","year","genre","review","plot","director"]}
{"id":"165.S","dataset":"mit-movie","split":"dev","instance":{"id":"165.S","prompt_labels":"what(O) was(O) the(B-title) fog(I-title) rated(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, song, trailer, actor, average_ratings, genre, review, character, year, rating, director, plot\nGIVEN SENTENCE: what was the fog rated\n","prediction_output":null,"prediction_outputs":null,"group":"165","words":["what","was","the","fog","rated"],"labels":["O","O","B-title","I-title","O"],"target_index":null,"target_label":null},"label_list":["title","song","trailer","actor","average_ratings","genre","review","character","year","rating","director","plot"]}
{"id":"167.S","dataset":"mit-movie","split":"dev","instance":{"id":"167.S","prompt_labels":"what(O) was(O) goodfellas(B-title) rated(B-rating)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, year, character, director, plot, genre, average_ratings, song, actor, review, trailer, title\nGIVEN SENTENCE: what was goodfellas rated\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["what","was","goodfellas","rated"],"labels":["O","O","B-title","B-rating"],"target_index":null,"target_label":null},"label_list":["rating","year","character","director","plot","genre","average_ratings","song","actor","review","trailer","title"]}
{"id":"168.S","dataset":"mit-movie","split":"dev","instance":{"id":"168.S","prompt_labels":"what(O) was(O) the(O) name(O) of(O) the(O) donkey(B-character) in(O) shrek(B-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, actor, director, average_ratings, rating, plot, song, trailer, character, genre, review, year\nGIVEN SENTENCE: what was the name of the donkey in shrek\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["what","was","the","name","of","the","donkey","in","shrek"],"labels":["O","O","O","O","O","O","B-character","O","B-title"],"target_index":null,"target_label":null},"label_list":["title","actor","director","average_ratings","rating","plot","song","trailer","character","genre","review","year"]}
{"id":"170.S","dataset":"mit-movie","split":"dev","instance":{"id":"170.S","prompt_labels":"what(O) are(O) some(O) horror(B-genre) movies(O) from(O) the(O) 1970s(B-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, trailer, review, director, year, plot, character, title, genre, actor, song, average_ratings\nGIVEN SENTENCE: what are some horror movies from the 1970s\n","prediction_output":null,"prediction_outputs":null,"group":"170","words":["what","are","some","horror","movies","from","the","1970s"],"labels":["O","O","O","B-genre","O","O","O","B-year"],"target_index":null,"target_label":null},"label_list":["rating","trailer","review","director","year","plot","character","title","genre","actor","song","average_ratings"]}
{"id":"171.S","dataset":"mit-movie","split":"dev","instance":{"id":"171.S","prompt_labels":"show(O) me(O) a(O) deborah(B-actor) harry(I-actor) movie(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, character, plot, year, actor, director, review, average_ratings, song, title, trailer, genre\nGIVEN SENTENCE: show me a deborah harry movie\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["show","me","a","deborah","harry","movie"],"labels":["O","O","O","B-actor","I-actor","O"],"target_index":null,"target_label":null},"label_list":["rating","character","plot","year","actor","director","review","average_ratings","song","title","trailer","genre"]}
{"id":"172.S","dataset":"mit-movie","split":"dev","instance":{"id":"172.S","prompt_labels":"kung(B-title) fu(I-title) panda(I-title) 2(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, genre, trailer, review, character, year, director, plot, title, average_ratings, rating, song\nGIVEN SENTENCE: kung fu panda 2\n","prediction_output":null,"prediction_outputs":null,"group":"172","words":["kung","fu","panda","2"],"labels":["B-title","I-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["actor","genre","trailer","review","character","year","director","plot","title","average_ratings","rating","song"]}
{"id":"173.S","dataset":"mit-movie","split":"dev","instance":{"id":"173.S","prompt_labels":"what(O) year(B-year) was(O) the(O) movie(O) the(B-title) seven(I-title) year(I-title) itch(I-title) made(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, actor, genre, rating, song, review, director, character, average_ratings, plot, year, trailer\nGIVEN SENTENCE: what year was the movie the seven year itch made\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["what","year","was","the","movie","the","seven","year","itch","made"],"labels":["O","B-year","O","O","O","B-title","I-title","I-title","I-title","O"],"target_index":null,"target_label":null},"label_list":["title","actor","genre","rating","song","review","director","character","average_ratings","plot","year","trailer"]}
{"id":"175.S","dataset":"mit-movie","split":"dev","instance":{"id":"175.S","prompt_labels":"what(O) movie(O) stared(O) john(B-actor) travolta(I-actor) and(O) debra(B-actor) winger(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: title, genre, trailer, review, year, actor, character, song, plot, rating, director, average_ratings\nGIVEN SENTENCE: what movie stared john travolta and debra winger\n","prediction_output":null,"prediction_outputs":null,"group":"175","words":["what","movie","stared","john","travolta","and","debra","winger"],"labels":["O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["title","genre","trailer","review","year","actor","character","song","plot","rating","director","average_ratings"]}
{"id":"176.S","dataset":"mit-movie","split":"dev","instance":{"id":"176.S","prompt_labels":"directors(O) of(O) all(O) the(O) batman(B-title) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: year, title, genre, average_ratings, character, director, trailer, review, rating, plot, song, actor\nGIVEN SENTENCE: directors of all the batman movies\n","prediction_output":null,"prediction_outputs":null,"group":"176","words":["directors","of","all","the","batman","movies"],"labels":["O","O","O","O","B-title","O"],"target_index":null,"target_label":null},"label_list":["year","title","genre","average_ratings","character","director","trailer","review","rating","plot","song","actor"]}
{"id":"177.S","dataset":"mit-movie","split":"dev","instance":{"id":"177.S","prompt_labels":"what(O) are(O) the(O) best(B-review) werewolf(B-plot) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: average_ratings, title, year, plot, rating, song, genre, trailer, review, director, actor, character\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":null},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"182.S","dataset":"mit-movie","split":"dev","instance":{"id":"182.S","prompt_labels":"are(O) there(O) any(O) movies(O) set(O) in(O) the(O) middle(B-plot) east(I-plot) starring(O) george(B-actor) clooney(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: actor, average_ratings, title, genre, song, character, plot, review, year, rating, trailer, director\nGIVEN SENTENCE: are there any movies set in the middle east starring george clooney\n","prediction_output":null,"prediction_outputs":null,"group":"182","words":["are","there","any","movies","set","in","the","middle","east","starring","george","clooney"],"labels":["O","O","O","O","O","O","O","B-plot","I-plot","O","B-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["actor","average_ratings","title","genre","song","character","plot","review","year","rating","trailer","director"]}
{"id":"183.S","dataset":"mit-movie","split":"dev","instance":{"id":"183.S","prompt_labels":"what(O) was(O) a(O) love(B-plot) story(I-plot) about(I-plot) a(I-plot) woman(I-plot) who(I-plot) had(I-plot) alzheimers(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, title, average_ratings, character, year, trailer, song, review, director, rating, plot, actor\nGIVEN SENTENCE: what was a love story about a woman who had alzheimers\n","prediction_output":null,"prediction_outputs":null,"group":"183","words":["what","was","a","love","story","about","a","woman","who","had","alzheimers"],"labels":["O","O","O","B-plot","I-plot","I-plot","I-plot","I-plot","I-plot","I-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["genre","title","average_ratings","character","year","trailer","song","review","director","rating","plot","actor"]}
{"id":"185.S","dataset":"mit-movie","split":"dev","instance":{"id":"185.S","prompt_labels":"who(O) played(O) as(O) princess(B-character) fiona(I-character) in(O) shrek(B-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: plot, title, review, year, song, director, average_ratings, genre, character, actor, trailer, rating\nGIVEN SENTENCE: who played as princess fiona in shrek\n","prediction_output":null,"prediction_outputs":null,"group":"185","words":["who","played","as","princess","fiona","in","shrek"],"labels":["O","O","O","B-character","I-character","O","B-title"],"target_index":null,"target_label":null},"label_list":["plot","title","review","year","song","director","average_ratings","genre","character","actor","trailer","rating"]}
{"id":"186.S","dataset":"mit-movie","split":"dev","instance":{"id":"186.S","prompt_labels":"is(O) the(B-title) last(I-title) airbender(I-title) rated(B-rating) g(I-rating)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, average_ratings, character, actor, title, director, trailer, year, song, plot, genre, review\nGIVEN SENTENCE: is the last airbender rated g\n","prediction_output":null,"prediction_outputs":null,"group":"186","words":["is","the","last","airbender","rated","g"],"labels":["O","B-title","I-title","I-title","B-rating","I-rating"],"target_index":null,"target_label":null},"label_list":["rating","average_ratings","character","actor","title","director","trailer","year","song","plot","genre","review"]}
{"id":"188.S","dataset":"mit-movie","split":"dev","instance":{"id":"188.S","prompt_labels":"show(O) me(O) dramas(B-genre) about(O) the(O) british(B-plot) royal(I-plot) family(I-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: director, title, rating, song, character, year, plot, actor, trailer, average_ratings, review, genre\nGIVEN SENTENCE: show me dramas about the british royal family\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["show","me","dramas","about","the","british","royal","family"],"labels":["O","O","B-genre","O","O","B-plot","I-plot","I-plot"],"target_index":null,"target_label":null},"label_list":["director","title","rating","song","character","year","plot","actor","trailer","average_ratings","review","genre"]}
{"id":"189.S","dataset":"mit-movie","split":"dev","instance":{"id":"189.S","prompt_labels":"what(O) was(O) the(O) first(B-year) movie(O) ever(O) released(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, song, character, director, plot, title, review, trailer, actor, average_ratings, genre, year\nGIVEN SENTENCE: what was the first movie ever released\n","prediction_output":null,"prediction_outputs":null,"group":"189","words":["what","was","the","first","movie","ever","released"],"labels":["O","O","O","B-year","O","O","O"],"target_index":null,"target_label":null},"label_list":["rating","song","character","director","plot","title","review","trailer","actor","average_ratings","genre","year"]}
{"id":"192.S","dataset":"mit-movie","split":"dev","instance":{"id":"192.S","prompt_labels":"what(O) was(O) the(O) title(O) of(O) the(O) bio(O) pic(O) about(O) robert(B-actor) e(I-actor) howard(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, actor, year, average_ratings, title, director, plot, trailer, genre, review, character, song\nGIVEN SENTENCE: what was the title of the bio pic about robert e howard\n","prediction_output":null,"prediction_outputs":null,"group":"192","words":["what","was","the","title","of","the","bio","pic","about","robert","e","howard"],"labels":["O","O","O","O","O","O","O","O","O","B-actor","I-actor","I-actor"],"target_index":null,"target_label":null},"label_list":["rating","actor","year","average_ratings","title","director","plot","trailer","genre","review","character","song"]}
{"id":"193.S","dataset":"mit-movie","split":"dev","instance":{"id":"193.S","prompt_labels":"what(O) is(O) the(O) theme(O) song(O) to(O) stand(B-title) by(I-title) me(I-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, review, average_ratings, director, trailer, actor, character, song, rating, year, plot, title\nGIVEN SENTENCE: what is the theme song to stand by me\n","prediction_output":null,"prediction_outputs":null,"group":"193","words":["what","is","the","theme","song","to","stand","by","me"],"labels":["O","O","O","O","O","O","B-title","I-title","I-title"],"target_index":null,"target_label":null},"label_list":["genre","review","average_ratings","director","trailer","actor","character","song","rating","year","plot","title"]}
{"id":"194.S","dataset":"mit-movie","split":"dev","instance":{"id":"194.S","prompt_labels":"when(O) did(O) runaway(B-title) jury(I-title) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: average_ratings, genre, title, trailer, year, director, character, song, plot, review, rating, actor\nGIVEN SENTENCE: when did runaway jury come out\n","prediction_output":null,"prediction_outputs":null,"group":"194","words":["when","did","runaway","jury","come","out"],"labels":["O","O","B-title","I-title","O","O"],"target_index":null,"target_label":null},"label_list":["average_ratings","genre","title","trailer","year","director","character","song","plot","review","rating","actor"]}
{"id":"195.S","dataset":"mit-movie","split":"dev","instance":{"id":"195.S","prompt_labels":"who(O) directed(O) the(O) japanese(O) film(O) versus(B-title)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: genre, director, title, actor, plot, average_ratings, review, year, trailer, song, character, rating\nGIVEN SENTENCE: who directed the japanese film versus\n","prediction_output":null,"prediction_outputs":null,"group":"195","words":["who","directed","the","japanese","film","versus"],"labels":["O","O","O","O","O","B-title"],"target_index":null,"target_label":null},"label_list":["genre","director","title","actor","plot","average_ratings","review","year","trailer","song","character","rating"]}
{"id":"197.S","dataset":"mit-movie","split":"dev","instance":{"id":"197.S","prompt_labels":"name(O) a(O) kirk(B-actor) douglas(I-actor) science(B-genre) fiction(I-genre) film(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: rating, actor, director, title, review, year, plot, song, genre, average_ratings, trailer, character\nGIVEN SENTENCE: name a kirk douglas science fiction film\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["name","a","kirk","douglas","science","fiction","film"],"labels":["O","O","B-actor","I-actor","B-genre","I-genre","O"],"target_index":null,"target_label":null},"label_list":["rating","actor","director","title","review","year","plot","song","genre","average_ratings","trailer","character"]}
{"id":"198.S","dataset":"mit-movie","split":"dev","instance":{"id":"198.S","prompt_labels":"are(O) there(O) any(O) five(B-average_ratings) star(I-average_ratings) kevin(B-actor) bacon(I-actor) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: review, actor, character, year, song, average_ratings, trailer, rating, title, director, genre, plot\nGIVEN SENTENCE: are there any five star kevin bacon movies\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["are","there","any","five","star","kevin","bacon","movies"],"labels":["O","O","O","B-average_ratings","I-average_ratings","B-actor","I-actor","O"],"target_index":null,"target_label":null},"label_list":["review","actor","character","year","song","average_ratings","trailer","rating","title","director","genre","plot"]}
{"id":"1.S","dataset":"crossner_ai","split":"dev","instance":{"id":"1.S","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(B-algorithm) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(B-algorithm) least-squares(I-algorithm) logistic(B-algorithm) regression(I-algorithm) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, researcher, metric, programming_language, person, conference, product, algorithm, organization, field, location, country, university\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":null},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"2.S","dataset":"crossner_ai","split":"dev","instance":{"id":"2.S","prompt_labels":"Brion(B-person) James(I-person) portrays(O) Leon(B-person) Kowalski(I-person) ,(O) a(O) combat(O) and(O) laborer(O) replicant(O) ,(O) and(O) Joanna(B-person) Cassidy(I-person) portrays(O) Zhora(B-person) ,(O) an(O) assassin(O) replicant(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, programming_language, metric, field, location, product, algorithm, task, conference, researcher, university, person\nGIVEN SENTENCE: Brion James portrays Leon Kowalski , a combat and laborer replicant , and Joanna Cassidy portrays Zhora , an assassin replicant .\n","prediction_output":null,"prediction_outputs":null,"group":"2","words":["Brion","James","portrays","Leon","Kowalski",",","a","combat","and","laborer","replicant",",","and","Joanna","Cassidy","portrays","Zhora",",","an","assassin","replicant","."],"labels":["B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","B-person","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","country","programming_language","metric","field","location","product","algorithm","task","conference","researcher","university","person"]}
{"id":"3.S","dataset":"crossner_ai","split":"dev","instance":{"id":"3.S","prompt_labels":"The(O) first(O) picture(O) to(O) be(O) scanned(O) ,(O) stored(O) ,(O) and(O) recreated(O) in(O) digital(O) pixels(O) was(O) displayed(O) on(O) the(O) Standards(B-product) Eastern(I-product) Automatic(I-product) Computer(I-product) ((O) SEAC(B-product) )(O) at(O) NIST(B-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, field, algorithm, task, country, university, product, researcher, location, person, organization, conference, metric\nGIVEN SENTENCE: The first picture to be scanned , stored , and recreated in digital pixels was displayed on the Standards Eastern Automatic Computer ( SEAC ) at NIST .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["The","first","picture","to","be","scanned",",","stored",",","and","recreated","in","digital","pixels","was","displayed","on","the","Standards","Eastern","Automatic","Computer","(","SEAC",")","at","NIST","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","I-product","I-product","I-product","O","B-product","O","O","B-organization","O"],"target_index":null,"target_label":null},"label_list":["programming_language","field","algorithm","task","country","university","product","researcher","location","person","organization","conference","metric"]}
{"id":"7.S","dataset":"crossner_ai","split":"dev","instance":{"id":"7.S","prompt_labels":"Since(O) the(O) Google(B-organization) acquisition(O) ,(O) the(O) company(O) has(O) notched(O) up(O) a(O) number(O) of(O) significant(O) achievements(O) ,(O) perhaps(O) the(O) most(O) notable(O) being(O) the(O) creation(O) of(O) AlphaGo(B-product) ,(O) a(O) program(O) that(O) defeated(O) world(O) champion(O) Lee(B-person) Sedol(I-person) at(O) the(O) complex(O) game(O) of(O) Go(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, field, university, task, metric, algorithm, programming_language, product, conference, person, researcher, location, country\nGIVEN SENTENCE: Since the Google acquisition , the company has notched up a number of significant achievements , perhaps the most notable being the creation of AlphaGo , a program that defeated world champion Lee Sedol at the complex game of Go .\n","prediction_output":null,"prediction_outputs":null,"group":"7","words":["Since","the","Google","acquisition",",","the","company","has","notched","up","a","number","of","significant","achievements",",","perhaps","the","most","notable","being","the","creation","of","AlphaGo",",","a","program","that","defeated","world","champion","Lee","Sedol","at","the","complex","game","of","Go","."],"labels":["O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","field","university","task","metric","algorithm","programming_language","product","conference","person","researcher","location","country"]}
{"id":"9.S","dataset":"crossner_ai","split":"dev","instance":{"id":"9.S","prompt_labels":"Machine(B-field) learning(I-field) techniques(O) ,(O) either(O) Supervised(B-field) learning(I-field) or(O) Unsupervised(B-field) learning(I-field) ,(O) have(O) been(O) used(O) to(O) induce(O) such(O) rules(O) automatically(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, person, field, researcher, task, location, product, university, conference, metric, algorithm, organization, country\nGIVEN SENTENCE: Machine learning techniques , either Supervised learning or Unsupervised learning , have been used to induce such rules automatically .\n","prediction_output":null,"prediction_outputs":null,"group":"9","words":["Machine","learning","techniques",",","either","Supervised","learning","or","Unsupervised","learning",",","have","been","used","to","induce","such","rules","automatically","."],"labels":["B-field","I-field","O","O","O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["programming_language","person","field","researcher","task","location","product","university","conference","metric","algorithm","organization","country"]}
{"id":"11.S","dataset":"crossner_ai","split":"dev","instance":{"id":"11.S","prompt_labels":"Since(O) the(O) Log(B-metric) loss(I-metric) is(O) differentiable(O) ,(O) a(O) gradient-based(O) method(O) can(O) be(O) used(O) to(O) optimize(O) the(O) model(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, algorithm, organization, product, location, country, task, university, person, programming_language, metric, conference, field\nGIVEN SENTENCE: Since the Log loss is differentiable , a gradient-based method can be used to optimize the model .\n","prediction_output":null,"prediction_outputs":null,"group":"11","words":["Since","the","Log","loss","is","differentiable",",","a","gradient-based","method","can","be","used","to","optimize","the","model","."],"labels":["O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["researcher","algorithm","organization","product","location","country","task","university","person","programming_language","metric","conference","field"]}
{"id":"13.S","dataset":"crossner_ai","split":"dev","instance":{"id":"13.S","prompt_labels":",(O) ((O) 2002(O) )(O) as(O) the(O) automatic(O) metric(O) for(O) Machine(B-task) translation(I-task) ((O) MT(B-task) )(O) evaluation(O) ,(O) many(O) other(O) methods(O) have(O) been(O) proposed(O) to(O) revise(O) or(O) improve(O) it(O) ,(O) such(O) as(O) TER(B-metric) ,(O) METEOR(B-metric) ,(O) Banerjee(B-researcher) and(O) Lavie(B-researcher) ,(O) ((O) 2005(O) )(O) etc(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, product, person, conference, organization, location, researcher, field, algorithm, task, metric, country, programming_language\nGIVEN SENTENCE: , ( 2002 ) as the automatic metric for Machine translation ( MT ) evaluation , many other methods have been proposed to revise or improve it , such as TER , METEOR , Banerjee and Lavie , ( 2005 ) etc .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":[",","(","2002",")","as","the","automatic","metric","for","Machine","translation","(","MT",")","evaluation",",","many","other","methods","have","been","proposed","to","revise","or","improve","it",",","such","as","TER",",","METEOR",",","Banerjee","and","Lavie",",","(","2005",")","etc","."],"labels":["O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","O","B-metric","O","B-researcher","O","B-researcher","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["university","product","person","conference","organization","location","researcher","field","algorithm","task","metric","country","programming_language"]}
{"id":"14.S","dataset":"crossner_ai","split":"dev","instance":{"id":"14.S","prompt_labels":"It(O) includes(O) an(O) upper(O) ontology(O) ,(O) created(O) by(O) the(O) IEEE(B-organization) working(O) group(O) P1600.1(O) ((O) originally(O) by(O) Ian(B-researcher) Niles(I-researcher) and(O) Adam(B-researcher) Pease(I-researcher) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, task, person, product, conference, researcher, organization, location, algorithm, programming_language, metric, country, field\nGIVEN SENTENCE: It includes an upper ontology , created by the IEEE working group P1600.1 ( originally by Ian Niles and Adam Pease ) .\n","prediction_output":null,"prediction_outputs":null,"group":"14","words":["It","includes","an","upper","ontology",",","created","by","the","IEEE","working","group","P1600.1","(","originally","by","Ian","Niles","and","Adam","Pease",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","O"],"target_index":null,"target_label":null},"label_list":["university","task","person","product","conference","researcher","organization","location","algorithm","programming_language","metric","country","field"]}
{"id":"15.S","dataset":"crossner_ai","split":"dev","instance":{"id":"15.S","prompt_labels":"In(O) Cryo(O) Electron(O) Tomography(O) ,(O) where(O) the(O) limited(O) number(O) of(O) projections(O) are(O) acquired(O) due(O) to(O) the(O) hardware(O) limitations(O) and(O) to(O) avoid(O) the(O) biological(O) specimen(O) damage(O) ,(O) it(O) can(O) be(O) used(O) along(O) with(O) compressive(B-algorithm) sensing(I-algorithm) techniques(I-algorithm) or(O) regularization(B-algorithm) functions(I-algorithm) ((O) e.g.(O) Huber(B-metric) loss(I-metric) )(O) to(O) improve(O) the(O) reconstruction(O) for(O) better(O) interpretation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, product, programming_language, university, person, field, location, conference, algorithm, organization, task, country, researcher\nGIVEN SENTENCE: In Cryo Electron Tomography , where the limited number of projections are acquired due to the hardware limitations and to avoid the biological specimen damage , it can be used along with compressive sensing techniques or regularization functions ( e.g. Huber loss ) to improve the reconstruction for better interpretation .\n","prediction_output":null,"prediction_outputs":null,"group":"15","words":["In","Cryo","Electron","Tomography",",","where","the","limited","number","of","projections","are","acquired","due","to","the","hardware","limitations","and","to","avoid","the","biological","specimen","damage",",","it","can","be","used","along","with","compressive","sensing","techniques","or","regularization","functions","(","e.g.","Huber","loss",")","to","improve","the","reconstruction","for","better","interpretation","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["metric","product","programming_language","university","person","field","location","conference","algorithm","organization","task","country","researcher"]}
{"id":"19.S","dataset":"crossner_ai","split":"dev","instance":{"id":"19.S","prompt_labels":"Unsupervised(B-field) learning(I-field) ,(O) on(O) the(O) other(O) hand(O) ,(O) assumes(O) training(O) data(O) that(O) has(O) not(O) been(O) hand-labeled(O) ,(O) and(O) attempts(O) to(O) find(O) inherent(O) patterns(O) in(O) the(O) data(O) that(O) can(O) then(O) be(O) used(O) to(O) determine(O) the(O) correct(O) output(O) value(O) for(O) new(O) data(O) instances(O) ..(O) A(O) combination(O) of(O) the(O) two(O) that(O) has(O) recently(O) been(O) explored(O) is(O) semi-supervised(B-field) learning(I-field) ,(O) which(O) uses(O) a(O) combination(O) of(O) labeled(O) and(O) unlabeled(O) data(O) ((O) typically(O) a(O) small(O) set(O) of(O) labeled(O) data(O) combined(O) with(O) a(O) large(O) amount(O) of(O) unlabeled(O) data(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, metric, person, researcher, algorithm, task, location, programming_language, university, country, conference, field, organization\nGIVEN SENTENCE: Unsupervised learning , on the other hand , assumes training data that has not been hand-labeled , and attempts to find inherent patterns in the data that can then be used to determine the correct output value for new data instances .. A combination of the two that has recently been explored is semi-supervised learning , which uses a combination of labeled and unlabeled data ( typically a small set of labeled data combined with a large amount of unlabeled data ) .\n","prediction_output":null,"prediction_outputs":null,"group":"19","words":["Unsupervised","learning",",","on","the","other","hand",",","assumes","training","data","that","has","not","been","hand-labeled",",","and","attempts","to","find","inherent","patterns","in","the","data","that","can","then","be","used","to","determine","the","correct","output","value","for","new","data","instances","..","A","combination","of","the","two","that","has","recently","been","explored","is","semi-supervised","learning",",","which","uses","a","combination","of","labeled","and","unlabeled","data","(","typically","a","small","set","of","labeled","data","combined","with","a","large","amount","of","unlabeled","data",")","."],"labels":["B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["product","metric","person","researcher","algorithm","task","location","programming_language","university","country","conference","field","organization"]}
{"id":"20.S","dataset":"crossner_ai","split":"dev","instance":{"id":"20.S","prompt_labels":"Despite(O) those(O) humanoid(O) robots(O) for(O) utilitarian(O) uses(O) ,(O) there(O) are(O) some(O) humanoid(O) robots(O) which(O) aims(O) at(O) entertainment(O) uses(O) ,(O) such(O) as(O) Sony(B-organization) '(O) s(O) QRIO(B-product) and(O) Wow(B-organization) Wee(I-organization) '(O) s(O) RoboSapien(B-product) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, location, algorithm, country, organization, task, product, university, person, conference, programming_language, metric, field\nGIVEN SENTENCE: Despite those humanoid robots for utilitarian uses , there are some humanoid robots which aims at entertainment uses , such as Sony ' s QRIO and Wow Wee ' s RoboSapien .\n","prediction_output":null,"prediction_outputs":null,"group":"20","words":["Despite","those","humanoid","robots","for","utilitarian","uses",",","there","are","some","humanoid","robots","which","aims","at","entertainment","uses",",","such","as","Sony","'","s","QRIO","and","Wow","Wee","'","s","RoboSapien","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","B-product","O","B-organization","I-organization","O","O","B-product","O"],"target_index":null,"target_label":null},"label_list":["researcher","location","algorithm","country","organization","task","product","university","person","conference","programming_language","metric","field"]}
{"id":"21.S","dataset":"crossner_ai","split":"dev","instance":{"id":"21.S","prompt_labels":"Webber(B-researcher) became(O) a(O) Fellow(O) of(O) the(O) Association(B-conference) for(I-conference) the(I-conference) Advancement(I-conference) of(I-conference) Artificial(I-conference) Intelligence(I-conference) in(O) 1991(O) ,(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, field, algorithm, programming_language, location, university, researcher, organization, product, metric, person, task, conference\nGIVEN SENTENCE: Webber became a Fellow of the Association for the Advancement of Artificial Intelligence in 1991 ,\n","prediction_output":null,"prediction_outputs":null,"group":"21","words":["Webber","became","a","Fellow","of","the","Association","for","the","Advancement","of","Artificial","Intelligence","in","1991",","],"labels":["B-researcher","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","field","algorithm","programming_language","location","university","researcher","organization","product","metric","person","task","conference"]}
{"id":"25.S","dataset":"crossner_ai","split":"dev","instance":{"id":"25.S","prompt_labels":"Expo(B-location) II(I-location) was(O) announced(O) as(O) being(O) the(O) locale(O) for(O) the(O) world(O) premiere(O) of(O) several(O) films(O) never(O) before(O) seen(O) in(O) 3D(O) ,(O) including(O) The(O) Diamond(O) Wizard(O) and(O) the(O) Universal(O) short(O) ,(O) Hawaiian(O) Nights(O) with(O) Mamie(B-person) Van(I-person) Doren(I-person) and(O) Pinky(B-person) Lee(I-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, algorithm, person, researcher, metric, university, product, location, conference, organization, country, task, field\nGIVEN SENTENCE: Expo II was announced as being the locale for the world premiere of several films never before seen in 3D , including The Diamond Wizard and the Universal short , Hawaiian Nights with Mamie Van Doren and Pinky Lee .\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["Expo","II","was","announced","as","being","the","locale","for","the","world","premiere","of","several","films","never","before","seen","in","3D",",","including","The","Diamond","Wizard","and","the","Universal","short",",","Hawaiian","Nights","with","Mamie","Van","Doren","and","Pinky","Lee","."],"labels":["B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","I-person","O","B-person","I-person","O"],"target_index":null,"target_label":null},"label_list":["programming_language","algorithm","person","researcher","metric","university","product","location","conference","organization","country","task","field"]}
{"id":"28.S","dataset":"crossner_ai","split":"dev","instance":{"id":"28.S","prompt_labels":"It(O) 's(O) easy(O) to(O) check(O) that(O) the(O) logistic(B-metric) loss(I-metric) and(O) binary(B-metric) cross(I-metric) entropy(I-metric) loss(I-metric) ((O) Log(B-metric) loss(I-metric) )(O) are(O) in(O) fact(O) the(O) same(O) ((O) up(O) to(O) a(O) multiplicative(O) constant(O) math(O) \\(O) frac(O) {(O) 1(O) }(O) {(O) \\(O) log(O) ((O) 2(O) )(O) }(O) /(O) math(O) )(O) .The(O) cross(B-metric) entropy(I-metric) loss(I-metric) is(O) closely(O) related(O) to(O) the(O) Kullback-Leibler(B-metric) divergence(I-metric) between(O) the(O) empirical(O) distribution(O) and(O) the(O) predicted(O) distribution(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, task, person, algorithm, country, conference, product, university, metric, field, researcher, organization, programming_language\nGIVEN SENTENCE: It 's easy to check that the logistic loss and binary cross entropy loss ( Log loss ) are in fact the same ( up to a multiplicative constant math \\ frac { 1 } { \\ log ( 2 ) } / math ) .The cross entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution .\n","prediction_output":null,"prediction_outputs":null,"group":"28","words":["It","'s","easy","to","check","that","the","logistic","loss","and","binary","cross","entropy","loss","(","Log","loss",")","are","in","fact","the","same","(","up","to","a","multiplicative","constant","math","\\","frac","{","1","}","{","\\","log","(","2",")","}","/","math",")",".The","cross","entropy","loss","is","closely","related","to","the","Kullback-Leibler","divergence","between","the","empirical","distribution","and","the","predicted","distribution","."],"labels":["O","O","O","O","O","O","O","B-metric","I-metric","O","B-metric","I-metric","I-metric","I-metric","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","task","person","algorithm","country","conference","product","university","metric","field","researcher","organization","programming_language"]}
{"id":"30.S","dataset":"crossner_ai","split":"dev","instance":{"id":"30.S","prompt_labels":"This(O) research(O) was(O) fundamental(O) to(O) the(O) development(O) of(O) modern(O) techniques(O) of(O) speech(B-task) synthesis(I-task) ,(O) reading(B-task) machines(I-task) for(I-task) the(I-task) blind(I-task) ,(O) the(O) study(O) of(O) speech(B-task) perception(I-task) and(O) speech(B-task) recognition(I-task) ,(O) and(O) the(O) development(O) of(O) the(O) motor(B-task) theory(I-task) of(I-task) speech(I-task) perception(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: algorithm, product, location, programming_language, person, country, field, researcher, organization, conference, university, metric, task\nGIVEN SENTENCE: This research was fundamental to the development of modern techniques of speech synthesis , reading machines for the blind , the study of speech perception and speech recognition , and the development of the motor theory of speech perception .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["This","research","was","fundamental","to","the","development","of","modern","techniques","of","speech","synthesis",",","reading","machines","for","the","blind",",","the","study","of","speech","perception","and","speech","recognition",",","and","the","development","of","the","motor","theory","of","speech","perception","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","I-task","I-task","I-task","I-task","O","O","O","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","B-task","I-task","I-task","I-task","I-task","O"],"target_index":null,"target_label":null},"label_list":["algorithm","product","location","programming_language","person","country","field","researcher","organization","conference","university","metric","task"]}
{"id":"31.S","dataset":"crossner_ai","split":"dev","instance":{"id":"31.S","prompt_labels":"The(O) Arduino(B-product) integrated(O) development(O) environment(O) ((O) IDE(O) )(O) is(O) a(O) cross-platform(O) application(O) ((O) for(O) Windows(B-product) ,(O) macOS(B-product) ,(O) and(O) Linux(B-product) )(O) that(O) is(O) written(O) in(O) the(O) programming(O) language(O) Java(B-programming_language) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, product, conference, metric, field, researcher, person, location, algorithm, organization, programming_language, task, country\nGIVEN SENTENCE: The Arduino integrated development environment ( IDE ) is a cross-platform application ( for Windows , macOS , and Linux ) that is written in the programming language Java .\n","prediction_output":null,"prediction_outputs":null,"group":"31","words":["The","Arduino","integrated","development","environment","(","IDE",")","is","a","cross-platform","application","(","for","Windows",",","macOS",",","and","Linux",")","that","is","written","in","the","programming","language","Java","."],"labels":["O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","O","B-product","O","O","O","O","O","O","O","O","B-programming_language","O"],"target_index":null,"target_label":null},"label_list":["university","product","conference","metric","field","researcher","person","location","algorithm","organization","programming_language","task","country"]}
{"id":"33.S","dataset":"crossner_ai","split":"dev","instance":{"id":"33.S","prompt_labels":"Only(O) a(O) few(O) non-Japanese(O) companies(O) ultimately(O) managed(O) to(O) survive(O) in(O) this(O) market(O) ,(O) the(O) major(O) ones(O) being(O) :(O) Adept(B-organization) Technology(I-organization) ,(O) Stäubli(B-organization) ,(O) the(O) Sweden(B-country) -(O) Switzerland(B-country) company(O) ABB(B-organization) Asea(I-organization) Brown(I-organization) Boveri(I-organization) ,(O) the(O) Germany(B-country) company(O) KUKA(B-organization) Robotics(I-organization) and(O) the(O) Italy(B-country) company(O) Comau(B-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, country, programming_language, product, field, researcher, location, conference, task, university, algorithm, person, organization\nGIVEN SENTENCE: Only a few non-Japanese companies ultimately managed to survive in this market , the major ones being : Adept Technology , Stäubli , the Sweden - Switzerland company ABB Asea Brown Boveri , the Germany company KUKA Robotics and the Italy company Comau .\n","prediction_output":null,"prediction_outputs":null,"group":"33","words":["Only","a","few","non-Japanese","companies","ultimately","managed","to","survive","in","this","market",",","the","major","ones","being",":","Adept","Technology",",","Stäubli",",","the","Sweden","-","Switzerland","company","ABB","Asea","Brown","Boveri",",","the","Germany","company","KUKA","Robotics","and","the","Italy","company","Comau","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","O","O","B-country","O","B-country","O","B-organization","I-organization","I-organization","I-organization","O","O","B-country","O","B-organization","I-organization","O","O","B-country","O","B-organization","O"],"target_index":null,"target_label":null},"label_list":["metric","country","programming_language","product","field","researcher","location","conference","task","university","algorithm","person","organization"]}
{"id":"34.S","dataset":"crossner_ai","split":"dev","instance":{"id":"34.S","prompt_labels":"The(O) research(O) activities(O) include(O) an(O) annual(O) research(O) conference(O) ,(O) the(O) RuleML(B-conference) Symposium(I-conference) ,(O) also(O) known(O) as(O) RuleML(B-conference) for(O) short(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, algorithm, metric, field, task, conference, product, organization, researcher, programming_language, university, person\nGIVEN SENTENCE: The research activities include an annual research conference , the RuleML Symposium , also known as RuleML for short .\n","prediction_output":null,"prediction_outputs":null,"group":"34","words":["The","research","activities","include","an","annual","research","conference",",","the","RuleML","Symposium",",","also","known","as","RuleML","for","short","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","O","O","O","O","B-conference","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","country","algorithm","metric","field","task","conference","product","organization","researcher","programming_language","university","person"]}
{"id":"36.S","dataset":"crossner_ai","split":"dev","instance":{"id":"36.S","prompt_labels":"He(O) has(O) won(O) awards(O) from(O) the(O) American(B-organization) Psychological(I-organization) Association(I-organization) ,(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) Royal(B-organization) ,(O) the(O) Cognitive(B-organization) Neuroscience(I-organization) Society(I-organization) and(O) the(O) American(B-organization) Humanist(I-organization) Association(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, metric, researcher, programming_language, university, task, field, country, algorithm, person, organization, conference, location\nGIVEN SENTENCE: He has won awards from the American Psychological Association , the National Academy of Sciences , the Royal , the Cognitive Neuroscience Society and the American Humanist Association .\n","prediction_output":null,"prediction_outputs":null,"group":"36","words":["He","has","won","awards","from","the","American","Psychological","Association",",","the","National","Academy","of","Sciences",",","the","Royal",",","the","Cognitive","Neuroscience","Society","and","the","American","Humanist","Association","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["product","metric","researcher","programming_language","university","task","field","country","algorithm","person","organization","conference","location"]}
{"id":"39.S","dataset":"crossner_ai","split":"dev","instance":{"id":"39.S","prompt_labels":"General(O) sampling(O) from(O) the(O) truncated(O) normal(O) can(O) be(O) achieved(O) using(O) approximations(O) to(O) the(O) normal(O) CDF(B-algorithm) and(O) the(O) probit(B-algorithm) function(I-algorithm) ,(O) and(O) R(B-programming_language) has(O) a(O) function(O) codertnorm(O) ((O) )(O) /(O) code(O) for(O) generating(O) truncated-normal(O) samples(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, person, product, researcher, university, organization, task, location, metric, field, conference, country, algorithm\nGIVEN SENTENCE: General sampling from the truncated normal can be achieved using approximations to the normal CDF and the probit function , and R has a function codertnorm ( ) / code for generating truncated-normal samples .\n","prediction_output":null,"prediction_outputs":null,"group":"39","words":["General","sampling","from","the","truncated","normal","can","be","achieved","using","approximations","to","the","normal","CDF","and","the","probit","function",",","and","R","has","a","function","codertnorm","(",")","/","code","for","generating","truncated-normal","samples","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","O","O","B-algorithm","I-algorithm","O","O","B-programming_language","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["programming_language","person","product","researcher","university","organization","task","location","metric","field","conference","country","algorithm"]}
{"id":"41.S","dataset":"crossner_ai","split":"dev","instance":{"id":"41.S","prompt_labels":"A(O) Java(B-programming_language) implementation(O) using(O) zero(O) based(O) array(O) indexes(O) along(O) with(O) a(O) convenience(O) method(O) for(O) printing(O) the(O) solved(O) order(O) of(O) operations(O) :(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, field, organization, programming_language, metric, university, location, algorithm, conference, product, task, country, researcher\nGIVEN SENTENCE: A Java implementation using zero based array indexes along with a convenience method for printing the solved order of operations :\n","prediction_output":null,"prediction_outputs":null,"group":"41","words":["A","Java","implementation","using","zero","based","array","indexes","along","with","a","convenience","method","for","printing","the","solved","order","of","operations",":"],"labels":["O","B-programming_language","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","field","organization","programming_language","metric","university","location","algorithm","conference","product","task","country","researcher"]}
{"id":"43.S","dataset":"crossner_ai","split":"dev","instance":{"id":"43.S","prompt_labels":"The(O) ACL(B-conference) has(O) a(O) European(O) ((O) European(B-conference) Chapter(I-conference) of(I-conference) the(I-conference) Association(I-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) )(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, researcher, university, product, country, algorithm, field, conference, task, location, programming_language, metric, organization\nGIVEN SENTENCE: The ACL has a European ( European Chapter of the Association for Computational Linguistics )\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["The","ACL","has","a","European","(","European","Chapter","of","the","Association","for","Computational","Linguistics",")"],"labels":["O","B-conference","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O"],"target_index":null,"target_label":null},"label_list":["person","researcher","university","product","country","algorithm","field","conference","task","location","programming_language","metric","organization"]}
{"id":"50.S","dataset":"crossner_ai","split":"dev","instance":{"id":"50.S","prompt_labels":"An(O) example(O) of(O) a(O) typical(O) computer(B-field) vision(I-field) computation(O) pipeline(O) for(O) Facial(B-product) recognition(I-product) system(I-product) using(O) k(B-algorithm) -NN(I-algorithm) including(O) feature(B-task) extraction(I-task) and(O) dimension(B-task) reduction(I-task) pre-processing(O) steps(O) ((O) usually(O) implemented(O) with(O) OpenCV(B-product) )(O) :(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, organization, algorithm, metric, person, product, university, location, field, programming_language, researcher, conference, task\nGIVEN SENTENCE: An example of a typical computer vision computation pipeline for Facial recognition system using k -NN including feature extraction and dimension reduction pre-processing steps ( usually implemented with OpenCV ) :\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["An","example","of","a","typical","computer","vision","computation","pipeline","for","Facial","recognition","system","using","k","-NN","including","feature","extraction","and","dimension","reduction","pre-processing","steps","(","usually","implemented","with","OpenCV",")",":"],"labels":["O","O","O","O","O","B-field","I-field","O","O","O","B-product","I-product","I-product","O","B-algorithm","I-algorithm","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","B-product","O","O"],"target_index":null,"target_label":null},"label_list":["country","organization","algorithm","metric","person","product","university","location","field","programming_language","researcher","conference","task"]}
{"id":"51.S","dataset":"crossner_ai","split":"dev","instance":{"id":"51.S","prompt_labels":"It(O) has(O) a(O) rich(O) set(O) of(O) features(O) ,(O) libraries(O) for(O) constraint(B-algorithm) logic(I-algorithm) programming(I-algorithm) ,(O) multithreading(O) ,(O) unit(O) testing(O) ,(O) GUI(O) ,(O) interfacing(O) to(O) Java(B-programming_language) ,(O) ODBC(B-product) and(O) others(O) ,(O) literate(B-algorithm) programming(I-algorithm) ,(O) a(O) web(O) server(O) ,(O) SGML(O) ,(O) RDF(O) ,(O) RDFS(O) ,(O) developer(O) tools(O) ((O) including(O) an(O) IDE(O) with(O) a(O) GUI(O) debugger(O) and(O) GUI(O) profiler(O) )(O) ,(O) and(O) extensive(O) documentation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, algorithm, country, task, researcher, programming_language, organization, conference, field, university, person, metric, product\nGIVEN SENTENCE: It has a rich set of features , libraries for constraint logic programming , multithreading , unit testing , GUI , interfacing to Java , ODBC and others , literate programming , a web server , SGML , RDF , RDFS , developer tools ( including an IDE with a GUI debugger and GUI profiler ) , and extensive documentation .\n","prediction_output":null,"prediction_outputs":null,"group":"51","words":["It","has","a","rich","set","of","features",",","libraries","for","constraint","logic","programming",",","multithreading",",","unit","testing",",","GUI",",","interfacing","to","Java",",","ODBC","and","others",",","literate","programming",",","a","web","server",",","SGML",",","RDF",",","RDFS",",","developer","tools","(","including","an","IDE","with","a","GUI","debugger","and","GUI","profiler",")",",","and","extensive","documentation","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","B-programming_language","O","B-product","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","algorithm","country","task","researcher","programming_language","organization","conference","field","university","person","metric","product"]}
{"id":"52.S","dataset":"crossner_ai","split":"dev","instance":{"id":"52.S","prompt_labels":"In(O) computer(B-field) vision(I-field) and(O) image(B-field) processing(I-field) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, researcher, organization, country, programming_language, product, metric, field, task, university, conference, location, algorithm\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"53.S","dataset":"crossner_ai","split":"dev","instance":{"id":"53.S","prompt_labels":"He(O) is(O) also(O) the(O) President(O) of(O) the(O) Neural(B-organization) Information(I-organization) Processing(I-organization) Systems(I-organization) Foundation(I-organization) ,(O) a(O) non-profit(O) organization(O) that(O) oversees(O) the(O) annual(O) Conference(B-conference) on(I-conference) Neural(I-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) Conference(I-conference) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, organization, algorithm, field, conference, product, person, location, programming_language, researcher, task, university, metric\nGIVEN SENTENCE: He is also the President of the Neural Information Processing Systems Foundation , a non-profit organization that oversees the annual Conference on Neural Information Processing Systems Conference .\n","prediction_output":null,"prediction_outputs":null,"group":"53","words":["He","is","also","the","President","of","the","Neural","Information","Processing","Systems","Foundation",",","a","non-profit","organization","that","oversees","the","annual","Conference","on","Neural","Information","Processing","Systems","Conference","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O"],"target_index":null,"target_label":null},"label_list":["country","organization","algorithm","field","conference","product","person","location","programming_language","researcher","task","university","metric"]}
{"id":"54.S","dataset":"crossner_ai","split":"dev","instance":{"id":"54.S","prompt_labels":"For(O) regression(B-task) analysis(I-task) problems(O) the(O) squared(B-metric) error(I-metric) can(O) be(O) used(O) as(O) a(O) loss(O) function(O) ,(O) for(O) classification(B-task) the(O) cross(B-metric) entropy(I-metric) can(O) be(O) used(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, algorithm, metric, conference, university, person, task, product, organization, field, country, programming_language, researcher\nGIVEN SENTENCE: For regression analysis problems the squared error can be used as a loss function , for classification the cross entropy can be used .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["For","regression","analysis","problems","the","squared","error","can","be","used","as","a","loss","function",",","for","classification","the","cross","entropy","can","be","used","."],"labels":["O","B-task","I-task","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","B-task","O","B-metric","I-metric","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","algorithm","metric","conference","university","person","task","product","organization","field","country","programming_language","researcher"]}
{"id":"55.S","dataset":"crossner_ai","split":"dev","instance":{"id":"55.S","prompt_labels":"Lafferty(B-researcher) served(O) many(O) prestigious(O) positions(O) ,(O) including(O) :(O) 1(O) )(O) program(O) co-chair(O) and(O) general(O) co-chair(O) of(O) the(O) Neural(B-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) ((O) Conference(B-conference) on(I-conference) Neural(I-conference) Information(I-conference) Processing(I-conference) Systems(I-conference) )(O) Foundation(O) conferences(O) ;(O) 2(O) )(O) co-director(O) of(O) CMU(B-university) 's(O) new(O) Ph.D.(O) Machine(B-field) Learning(I-field) Ph.D.(O) Program(O) ;(O) 3(O) )(O) associate(O) editor(O) of(O) the(O) Journal(B-conference) of(I-conference) Machine(I-conference) Learning(I-conference) Research(I-conference)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, country, programming_language, university, organization, task, conference, person, location, metric, field, product, algorithm\nGIVEN SENTENCE: Lafferty served many prestigious positions , including : 1 ) program co-chair and general co-chair of the Neural Information Processing Systems ( Conference on Neural Information Processing Systems ) Foundation conferences ; 2 ) co-director of CMU 's new Ph.D. Machine Learning Ph.D. Program ; 3 ) associate editor of the Journal of Machine Learning Research\n","prediction_output":null,"prediction_outputs":null,"group":"55","words":["Lafferty","served","many","prestigious","positions",",","including",":","1",")","program","co-chair","and","general","co-chair","of","the","Neural","Information","Processing","Systems","(","Conference","on","Neural","Information","Processing","Systems",")","Foundation","conferences",";","2",")","co-director","of","CMU","'s","new","Ph.D.","Machine","Learning","Ph.D.","Program",";","3",")","associate","editor","of","the","Journal","of","Machine","Learning","Research"],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","O","O","O","O","O","O","O","B-university","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference"],"target_index":null,"target_label":null},"label_list":["researcher","country","programming_language","university","organization","task","conference","person","location","metric","field","product","algorithm"]}
{"id":"57.S","dataset":"crossner_ai","split":"dev","instance":{"id":"57.S","prompt_labels":"Apertium(B-product) is(O) a(O) shallow-transfer(B-product) machine(I-product) translation(I-product) system(I-product) ,(O) which(O) uses(O) finite(B-algorithm) state(I-algorithm) transducer(I-algorithm) s(O) for(O) all(O) of(O) its(O) lexical(O) transformations(O) ,(O) and(O) hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) for(O) part-of-speech(B-task) tagging(I-task) or(O) word(B-task) category(I-task) disambiguation(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, country, organization, conference, metric, researcher, person, programming_language, field, task, algorithm, university, location\nGIVEN SENTENCE: Apertium is a shallow-transfer machine translation system , which uses finite state transducer s for all of its lexical transformations , and hidden Markov model s for part-of-speech tagging or word category disambiguation .\n","prediction_output":null,"prediction_outputs":null,"group":"57","words":["Apertium","is","a","shallow-transfer","machine","translation","system",",","which","uses","finite","state","transducer","s","for","all","of","its","lexical","transformations",",","and","hidden","Markov","model","s","for","part-of-speech","tagging","or","word","category","disambiguation","."],"labels":["B-product","O","O","B-product","I-product","I-product","I-product","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-task","I-task","O","B-task","I-task","I-task","O"],"target_index":null,"target_label":null},"label_list":["product","country","organization","conference","metric","researcher","person","programming_language","field","task","algorithm","university","location"]}
{"id":"58.S","dataset":"crossner_ai","split":"dev","instance":{"id":"58.S","prompt_labels":"The(O) natural(O) gradient(O) of(O) mathE(O) f(O) ((O) x(O) )(O) /(O) math(O) ,(O) complying(O) with(O) the(O) Fisher(B-metric) information(I-metric) metric(I-metric) ((O) an(O) informational(O) distance(O) measure(O) between(O) probability(O) distributions(O) and(O) the(O) curvature(O) of(O) the(O) relative(B-metric) entropy(I-metric) )(O) ,(O) now(O) reads(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, field, metric, algorithm, conference, university, task, programming_language, organization, location, country, person, researcher\nGIVEN SENTENCE: The natural gradient of mathE f ( x ) / math , complying with the Fisher information metric ( an informational distance measure between probability distributions and the curvature of the relative entropy ) , now reads\n","prediction_output":null,"prediction_outputs":null,"group":"58","words":["The","natural","gradient","of","mathE","f","(","x",")","/","math",",","complying","with","the","Fisher","information","metric","(","an","informational","distance","measure","between","probability","distributions","and","the","curvature","of","the","relative","entropy",")",",","now","reads"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["product","field","metric","algorithm","conference","university","task","programming_language","organization","location","country","person","researcher"]}
{"id":"60.S","dataset":"crossner_ai","split":"dev","instance":{"id":"60.S","prompt_labels":"The(O) most(O) influential(O) implementation(O) of(O) Planner(B-product) was(O) the(O) subset(O) of(O) Planner(B-product) ,(O) called(O) Micro-Planner(B-product) ,(O) implemented(O) by(O) Gerald(B-researcher) Jay(I-researcher) Sussman(I-researcher) ,(O) Eugene(B-researcher) Charniak(I-researcher) and(O) Terry(B-researcher) Winograd(I-researcher) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: algorithm, country, university, field, metric, product, person, task, location, programming_language, organization, conference, researcher\nGIVEN SENTENCE: The most influential implementation of Planner was the subset of Planner , called Micro-Planner , implemented by Gerald Jay Sussman , Eugene Charniak and Terry Winograd .\n","prediction_output":null,"prediction_outputs":null,"group":"60","words":["The","most","influential","implementation","of","Planner","was","the","subset","of","Planner",",","called","Micro-Planner",",","implemented","by","Gerald","Jay","Sussman",",","Eugene","Charniak","and","Terry","Winograd","."],"labels":["O","O","O","O","O","B-product","O","O","O","O","B-product","O","O","B-product","O","O","O","B-researcher","I-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O"],"target_index":null,"target_label":null},"label_list":["algorithm","country","university","field","metric","product","person","task","location","programming_language","organization","conference","researcher"]}
{"id":"62.S","dataset":"crossner_ai","split":"dev","instance":{"id":"62.S","prompt_labels":"New(O) features(O) in(O) Office(B-product) XP(I-product) include(O) smart(O) tags(O) ,(O) a(O) selection-based(O) search(O) feature(O) that(O) recognizes(O) different(O) types(O) of(O) text(O) in(O) a(O) document(O) so(O) that(O) users(O) can(O) perform(O) additional(O) actions(O) ;(O) a(O) task(O) pane(O) interface(O) that(O) consolidates(O) popular(O) menu(O) bar(O) commands(O) on(O) the(O) right(O) side(O) of(O) the(O) screen(O) to(O) facilitate(O) quick(O) access(O) to(O) them(O) ;(O) new(O) document(B-task) collaboration(I-task) capabilities(O) ,(O) support(O) for(O) MSN(B-product) Groups(I-product) and(O) SharePoint(B-product) ;(O) and(O) integrated(O) handwriting(B-task) recognition(I-task) and(O) speech(B-task) recognition(I-task) capabilities(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, conference, person, programming_language, researcher, algorithm, field, organization, task, metric, product, location, university\nGIVEN SENTENCE: New features in Office XP include smart tags , a selection-based search feature that recognizes different types of text in a document so that users can perform additional actions ; a task pane interface that consolidates popular menu bar commands on the right side of the screen to facilitate quick access to them ; new document collaboration capabilities , support for MSN Groups and SharePoint ; and integrated handwriting recognition and speech recognition capabilities .\n","prediction_output":null,"prediction_outputs":null,"group":"62","words":["New","features","in","Office","XP","include","smart","tags",",","a","selection-based","search","feature","that","recognizes","different","types","of","text","in","a","document","so","that","users","can","perform","additional","actions",";","a","task","pane","interface","that","consolidates","popular","menu","bar","commands","on","the","right","side","of","the","screen","to","facilitate","quick","access","to","them",";","new","document","collaboration","capabilities",",","support","for","MSN","Groups","and","SharePoint",";","and","integrated","handwriting","recognition","and","speech","recognition","capabilities","."],"labels":["O","O","O","B-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","O","O","O","B-product","I-product","O","B-product","O","O","O","B-task","I-task","O","B-task","I-task","O","O"],"target_index":null,"target_label":null},"label_list":["country","conference","person","programming_language","researcher","algorithm","field","organization","task","metric","product","location","university"]}
{"id":"64.S","dataset":"crossner_ai","split":"dev","instance":{"id":"64.S","prompt_labels":"In(O) 2001(O) ,(O) Mehler(B-researcher) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, product, task, conference, university, algorithm, location, country, organization, field, metric, researcher, person\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"65.S","dataset":"crossner_ai","split":"dev","instance":{"id":"65.S","prompt_labels":"The(O) extension(O) of(O) this(O) concept(O) to(O) non-binary(B-task) classifications(I-task) yields(O) the(O) confusion(B-metric) matrix(I-metric) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, field, product, location, country, person, organization, conference, metric, researcher, task, algorithm, university\nGIVEN SENTENCE: The extension of this concept to non-binary classifications yields the confusion matrix .\n","prediction_output":null,"prediction_outputs":null,"group":"65","words":["The","extension","of","this","concept","to","non-binary","classifications","yields","the","confusion","matrix","."],"labels":["O","O","O","O","O","O","B-task","I-task","O","O","B-metric","I-metric","O"],"target_index":null,"target_label":null},"label_list":["programming_language","field","product","location","country","person","organization","conference","metric","researcher","task","algorithm","university"]}
{"id":"66.S","dataset":"crossner_ai","split":"dev","instance":{"id":"66.S","prompt_labels":"An(O) updated(O) measurement(O) noise(O) variance(O) estimate(O) can(O) be(O) obtained(O) from(O) the(O) maximum(B-algorithm) likelihood(I-algorithm) calculation(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, algorithm, task, person, university, field, conference, programming_language, organization, product, location, researcher, metric\nGIVEN SENTENCE: An updated measurement noise variance estimate can be obtained from the maximum likelihood calculation\n","prediction_output":null,"prediction_outputs":null,"group":"66","words":["An","updated","measurement","noise","variance","estimate","can","be","obtained","from","the","maximum","likelihood","calculation"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":null},"label_list":["country","algorithm","task","person","university","field","conference","programming_language","organization","product","location","researcher","metric"]}
{"id":"67.S","dataset":"crossner_ai","split":"dev","instance":{"id":"67.S","prompt_labels":"In(O) machine(B-field) learning(I-field) ,(O) the(O) perceptron(B-algorithm) is(O) an(O) algorithm(O) for(O) supervised(B-field) learning(I-field) of(O) binary(B-task) classification(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, programming_language, metric, country, person, task, product, conference, organization, algorithm, location, field, researcher\nGIVEN SENTENCE: In machine learning , the perceptron is an algorithm for supervised learning of binary classification .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["In","machine","learning",",","the","perceptron","is","an","algorithm","for","supervised","learning","of","binary","classification","."],"labels":["O","B-field","I-field","O","O","B-algorithm","O","O","O","O","B-field","I-field","O","B-task","I-task","O"],"target_index":null,"target_label":null},"label_list":["university","programming_language","metric","country","person","task","product","conference","organization","algorithm","location","field","researcher"]}
{"id":"70.S","dataset":"crossner_ai","split":"dev","instance":{"id":"70.S","prompt_labels":"Information(B-task) Dissemination(I-task) is(O) also(O) part(O) of(O) ELRA(B-conference) 's(O) missions(O) which(O) is(O) carried(O) through(O) both(O) the(O) organisation(O) of(O) the(O) conference(O) LREC(B-conference) and(O) the(O) Language(B-conference) Resources(I-conference) and(I-conference) Evaluation(I-conference) Journal(I-conference) edited(O) by(O) Springer(B-conference) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, task, researcher, location, conference, country, product, university, person, algorithm, organization, programming_language, field\nGIVEN SENTENCE: Information Dissemination is also part of ELRA 's missions which is carried through both the organisation of the conference LREC and the Language Resources and Evaluation Journal edited by Springer .\n","prediction_output":null,"prediction_outputs":null,"group":"70","words":["Information","Dissemination","is","also","part","of","ELRA","'s","missions","which","is","carried","through","both","the","organisation","of","the","conference","LREC","and","the","Language","Resources","and","Evaluation","Journal","edited","by","Springer","."],"labels":["B-task","I-task","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","O","O","B-conference","O"],"target_index":null,"target_label":null},"label_list":["metric","task","researcher","location","conference","country","product","university","person","algorithm","organization","programming_language","field"]}
{"id":"73.S","dataset":"crossner_ai","split":"dev","instance":{"id":"73.S","prompt_labels":"Stochastic(B-algorithm) gradient(I-algorithm) descent(I-algorithm) is(O) a(O) popular(O) algorithm(O) for(O) training(O) a(O) wide(O) range(O) of(O) models(O) in(O) machine(B-field) learning(I-field) ,(O) including(O) ((O) linear(O) )(O) support(B-algorithm) vector(I-algorithm) machine(I-algorithm) s(O) ,(O) logistic(B-algorithm) regression(I-algorithm) ((O) see(O) ,(O) e.g.(O) ,(O) Vowpal(B-algorithm) Wabbit(I-algorithm) )(O) and(O) graphical(B-algorithm) model(I-algorithm) s.Jenny(B-researcher) Rose(I-researcher) Finkel(I-researcher) ,(O) Alex(B-researcher) Kleeman(I-researcher) ,(O) Christopher(B-researcher) D.(I-researcher) Manning(I-researcher) ((O) 2008(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, task, programming_language, location, conference, product, person, organization, algorithm, metric, researcher, field, country\nGIVEN SENTENCE: Stochastic gradient descent is a popular algorithm for training a wide range of models in machine learning , including ( linear ) support vector machine s , logistic regression ( see , e.g. , Vowpal Wabbit ) and graphical model s.Jenny Rose Finkel , Alex Kleeman , Christopher D. Manning ( 2008 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"73","words":["Stochastic","gradient","descent","is","a","popular","algorithm","for","training","a","wide","range","of","models","in","machine","learning",",","including","(","linear",")","support","vector","machine","s",",","logistic","regression","(","see",",","e.g.",",","Vowpal","Wabbit",")","and","graphical","model","s.Jenny","Rose","Finkel",",","Alex","Kleeman",",","Christopher","D.","Manning","(","2008",")","."],"labels":["B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","O","O","O","O","O","B-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","B-researcher","I-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","I-researcher","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["university","task","programming_language","location","conference","product","person","organization","algorithm","metric","researcher","field","country"]}
{"id":"76.S","dataset":"crossner_ai","split":"dev","instance":{"id":"76.S","prompt_labels":"Sensitivity(B-metric) is(O) not(O) the(O) same(O) as(O) the(O) precision(B-metric) or(O) positive(B-metric) predictive(I-metric) value(I-metric) ((O) ratio(O) of(O) TRUE(B-metric) positives(I-metric) to(O) combined(O) TRUE(B-metric) and(I-metric) FALSE(I-metric) positives(I-metric) )(O) ,(O) which(O) is(O) as(O) much(O) a(O) statement(O) about(O) the(O) proportion(O) of(O) actual(O) positives(O) in(O) the(O) population(O) being(O) tested(O) as(O) it(O) is(O) about(O) the(O) test(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, organization, product, university, researcher, person, conference, task, country, algorithm, field, metric, location\nGIVEN SENTENCE: Sensitivity is not the same as the precision or positive predictive value ( ratio of TRUE positives to combined TRUE and FALSE positives ) , which is as much a statement about the proportion of actual positives in the population being tested as it is about the test .\n","prediction_output":null,"prediction_outputs":null,"group":"76","words":["Sensitivity","is","not","the","same","as","the","precision","or","positive","predictive","value","(","ratio","of","TRUE","positives","to","combined","TRUE","and","FALSE","positives",")",",","which","is","as","much","a","statement","about","the","proportion","of","actual","positives","in","the","population","being","tested","as","it","is","about","the","test","."],"labels":["B-metric","O","O","O","O","O","O","B-metric","O","B-metric","I-metric","I-metric","O","O","O","B-metric","I-metric","O","O","B-metric","I-metric","I-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["programming_language","organization","product","university","researcher","person","conference","task","country","algorithm","field","metric","location"]}
{"id":"77.S","dataset":"crossner_ai","split":"dev","instance":{"id":"77.S","prompt_labels":"The(O) screenplay(O) by(O) Hampton(B-person) Fancher(I-person) !(O) --(O) Not(O) titled(O) Android(B-product) initially(O) -(O) See(O) Sammon(B-person) ,(O) pp.(O) 32(O) and(O) 38(O) for(O) explanation(O) --(O) was(O) optioned(O) in(O) 1977(O) .(O) Sammon(B-person) ,(O) pp.(O) 23-30(O) Producer(O) Michael(B-person) Deeley(I-person) became(O) interested(O) in(O) Fancher(B-person) 's(O) draft(O) and(O) convinced(O) director(O) Ridley(B-person) Scott(I-person) to(O) film(O) it(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, task, metric, country, programming_language, product, field, algorithm, person, conference, researcher, organization, location\nGIVEN SENTENCE: The screenplay by Hampton Fancher ! -- Not titled Android initially - See Sammon , pp. 32 and 38 for explanation -- was optioned in 1977 . Sammon , pp. 23-30 Producer Michael Deeley became interested in Fancher 's draft and convinced director Ridley Scott to film it .\n","prediction_output":null,"prediction_outputs":null,"group":"77","words":["The","screenplay","by","Hampton","Fancher","!","--","Not","titled","Android","initially","-","See","Sammon",",","pp.","32","and","38","for","explanation","--","was","optioned","in","1977",".","Sammon",",","pp.","23-30","Producer","Michael","Deeley","became","interested","in","Fancher","'s","draft","and","convinced","director","Ridley","Scott","to","film","it","."],"labels":["O","O","O","B-person","I-person","O","O","O","O","B-product","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","B-person","I-person","O","O","O","B-person","O","O","O","O","O","B-person","I-person","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["university","task","metric","country","programming_language","product","field","algorithm","person","conference","researcher","organization","location"]}
{"id":"80.S","dataset":"crossner_ai","split":"dev","instance":{"id":"80.S","prompt_labels":"The(O) system(O) uses(O) a(O) combination(O) of(O) techniques(O) from(O) computational(B-field) linguistics(I-field) ,(O) information(B-task) retrieval(I-task) and(O) knowledge(B-task) representation(I-task) for(I-task) finding(I-task) answers(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, person, algorithm, researcher, country, organization, field, conference, location, metric, product, university, task\nGIVEN SENTENCE: The system uses a combination of techniques from computational linguistics , information retrieval and knowledge representation for finding answers .\n","prediction_output":null,"prediction_outputs":null,"group":"80","words":["The","system","uses","a","combination","of","techniques","from","computational","linguistics",",","information","retrieval","and","knowledge","representation","for","finding","answers","."],"labels":["O","O","O","O","O","O","O","O","B-field","I-field","O","B-task","I-task","O","B-task","I-task","I-task","I-task","I-task","O"],"target_index":null,"target_label":null},"label_list":["programming_language","person","algorithm","researcher","country","organization","field","conference","location","metric","product","university","task"]}
{"id":"82.S","dataset":"crossner_ai","split":"dev","instance":{"id":"82.S","prompt_labels":"Researchers(O) have(O) attempted(O) a(O) number(O) of(O) methods(O) such(O) as(O) optical(B-algorithm) flow(I-algorithm) ,(O) Kalman(B-algorithm) filtering(I-algorithm) ,(O) Hidden(B-algorithm) Markov(I-algorithm) model(I-algorithm) s(O) ,(O) etc(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, researcher, organization, product, algorithm, programming_language, university, field, task, location, person, conference, country\nGIVEN SENTENCE: Researchers have attempted a number of methods such as optical flow , Kalman filtering , Hidden Markov model s , etc .\n","prediction_output":null,"prediction_outputs":null,"group":"82","words":["Researchers","have","attempted","a","number","of","methods","such","as","optical","flow",",","Kalman","filtering",",","Hidden","Markov","model","s",",","etc","."],"labels":["O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["metric","researcher","organization","product","algorithm","programming_language","university","field","task","location","person","conference","country"]}
{"id":"83.S","dataset":"crossner_ai","split":"dev","instance":{"id":"83.S","prompt_labels":"She(O) has(O) held(O) the(O) positions(O) of(O) President(O) ,(O) Vice(O) President(O) ,(O) and(O) Secretary-Treasurer(O) of(O) the(O) Association(B-conference) for(I-conference) Computational(I-conference) Linguistics(I-conference) and(O) has(O) been(O) a(O) board(O) member(O) and(O) secretary(O) of(O) the(O) board(O) of(O) the(O) Computing(B-organization) Research(I-organization) Association(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, field, product, programming_language, metric, task, location, country, organization, algorithm, university, person, conference\nGIVEN SENTENCE: She has held the positions of President , Vice President , and Secretary-Treasurer of the Association for Computational Linguistics and has been a board member and secretary of the board of the Computing Research Association .\n","prediction_output":null,"prediction_outputs":null,"group":"83","words":["She","has","held","the","positions","of","President",",","Vice","President",",","and","Secretary-Treasurer","of","the","Association","for","Computational","Linguistics","and","has","been","a","board","member","and","secretary","of","the","board","of","the","Computing","Research","Association","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["researcher","field","product","programming_language","metric","task","location","country","organization","algorithm","university","person","conference"]}
{"id":"86.S","dataset":"crossner_ai","split":"dev","instance":{"id":"86.S","prompt_labels":"A(O) collaborative(B-product) robot(I-product) or(O) cobot(B-product) is(O) a(O) robot(O) that(O) can(O) safely(O) and(O) effectively(O) interact(O) with(O) human(O) workers(O) while(O) performing(O) simple(O) industrial(O) tasks(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: algorithm, task, researcher, product, location, university, conference, field, metric, programming_language, country, person, organization\nGIVEN SENTENCE: A collaborative robot or cobot is a robot that can safely and effectively interact with human workers while performing simple industrial tasks .\n","prediction_output":null,"prediction_outputs":null,"group":"86","words":["A","collaborative","robot","or","cobot","is","a","robot","that","can","safely","and","effectively","interact","with","human","workers","while","performing","simple","industrial","tasks","."],"labels":["O","B-product","I-product","O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["algorithm","task","researcher","product","location","university","conference","field","metric","programming_language","country","person","organization"]}
{"id":"87.S","dataset":"crossner_ai","split":"dev","instance":{"id":"87.S","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(B-field) vision(I-field) ,(O) including(O) feature(B-task) detection(I-task) ,(O) feature(B-task) classification(I-task) ,(O) image(B-task) segmentation(I-task) ,(O) image(B-task) matching(I-task) ,(O) motion(B-task) estimation(I-task) ,(O) computation(B-task) of(I-task) shape(I-task) cues(I-task) and(O) object(B-task) recognition(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, conference, task, country, field, organization, person, researcher, product, algorithm, metric, programming_language, location\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":null},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"88.S","dataset":"crossner_ai","split":"dev","instance":{"id":"88.S","prompt_labels":"In(O) many(O) practical(O) applications(O) ,(O) parameter(B-task) estimation(I-task) for(O) naive(B-algorithm) Bayes(I-algorithm) models(I-algorithm) uses(O) the(O) method(O) of(O) maximum(B-algorithm) likelihood(I-algorithm) ;(O) other(O) words(O) ,(O) one(O) can(O) work(O) with(O) the(O) naive(B-algorithm) Bayes(I-algorithm) model(O) without(O) accepting(O) Bayesian(B-algorithm) probability(I-algorithm) or(O) using(O) any(O) Bayesian(B-algorithm) methods(I-algorithm) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, task, university, researcher, organization, programming_language, country, person, location, algorithm, conference, field, metric\nGIVEN SENTENCE: In many practical applications , parameter estimation for naive Bayes models uses the method of maximum likelihood ; other words , one can work with the naive Bayes model without accepting Bayesian probability or using any Bayesian methods .\n","prediction_output":null,"prediction_outputs":null,"group":"88","words":["In","many","practical","applications",",","parameter","estimation","for","naive","Bayes","models","uses","the","method","of","maximum","likelihood",";","other","words",",","one","can","work","with","the","naive","Bayes","model","without","accepting","Bayesian","probability","or","using","any","Bayesian","methods","."],"labels":["O","O","O","O","O","B-task","I-task","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":null},"label_list":["product","task","university","researcher","organization","programming_language","country","person","location","algorithm","conference","field","metric"]}
{"id":"89.S","dataset":"crossner_ai","split":"dev","instance":{"id":"89.S","prompt_labels":"Brothers(O) -(O) Victor(B-researcher) Gershevich(I-researcher) Katz(I-researcher) ,(O) American(O) mathematician(O) ,(O) professor(O) at(O) the(O) Massachusetts(B-university) Institute(I-university) of(I-university) Technology(I-university) ;(O) Mikhail(B-researcher) Gershevich(I-researcher) Katz(I-researcher) ,(O) Israeli(O) mathematician(O) ,(O) graduate(O) of(O) Harvard(B-university) and(O) Columbia(B-university) ((O) Ph.D.(O) ,(O) 1984(O) )(O) universities(O) ,(O) professor(O) at(O) Bar-Ilan(B-university) University(I-university) ,(O) author(O) of(O) the(O) monograph(O) Systolic(O) Geometry(O) and(O) Topology(O) ((O) Mathematical(O) Surveys(O) and(O) Monographs(O) ,(O) vol(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, university, country, person, conference, researcher, algorithm, task, organization, field, location, programming_language, metric\nGIVEN SENTENCE: Brothers - Victor Gershevich Katz , American mathematician , professor at the Massachusetts Institute of Technology ; Mikhail Gershevich Katz , Israeli mathematician , graduate of Harvard and Columbia ( Ph.D. , 1984 ) universities , professor at Bar-Ilan University , author of the monograph Systolic Geometry and Topology ( Mathematical Surveys and Monographs , vol .\n","prediction_output":null,"prediction_outputs":null,"group":"89","words":["Brothers","-","Victor","Gershevich","Katz",",","American","mathematician",",","professor","at","the","Massachusetts","Institute","of","Technology",";","Mikhail","Gershevich","Katz",",","Israeli","mathematician",",","graduate","of","Harvard","and","Columbia","(","Ph.D.",",","1984",")","universities",",","professor","at","Bar-Ilan","University",",","author","of","the","monograph","Systolic","Geometry","and","Topology","(","Mathematical","Surveys","and","Monographs",",","vol","."],"labels":["O","O","B-researcher","I-researcher","I-researcher","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-researcher","I-researcher","I-researcher","O","O","O","O","O","O","B-university","O","B-university","O","O","O","O","O","O","O","O","O","B-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["product","university","country","person","conference","researcher","algorithm","task","organization","field","location","programming_language","metric"]}
{"id":"90.S","dataset":"crossner_ai","split":"dev","instance":{"id":"90.S","prompt_labels":"In(O) 2000(O) Manuel(B-person) Toharia(I-person) ,(O) a(O) speaker(O) at(O) previous(O) Campus(B-conference) Parties(I-conference) ,(O) and(O) director(O) of(O) Príncipe(B-organization) Felipe(I-organization) 's(I-organization) Museum(I-organization) of(I-organization) Sciences(I-organization) in(O) Valencia(B-location) 's(I-location) City(I-location) of(I-location) arts(I-location) and(I-location) Sciences(I-location) suggested(O) that(O) Ragageles(B-person) expand(O) and(O) make(O) the(O) event(O) more(O) international(O) by(O) moving(O) it(O) to(O) the(O) famous(O) museum(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, metric, algorithm, organization, product, university, conference, researcher, person, task, field, programming_language, location\nGIVEN SENTENCE: In 2000 Manuel Toharia , a speaker at previous Campus Parties , and director of Príncipe Felipe 's Museum of Sciences in Valencia 's City of arts and Sciences suggested that Ragageles expand and make the event more international by moving it to the famous museum .\n","prediction_output":null,"prediction_outputs":null,"group":"90","words":["In","2000","Manuel","Toharia",",","a","speaker","at","previous","Campus","Parties",",","and","director","of","Príncipe","Felipe","'s","Museum","of","Sciences","in","Valencia","'s","City","of","arts","and","Sciences","suggested","that","Ragageles","expand","and","make","the","event","more","international","by","moving","it","to","the","famous","museum","."],"labels":["O","O","B-person","I-person","O","O","O","O","O","B-conference","I-conference","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","I-location","I-location","I-location","I-location","I-location","I-location","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","metric","algorithm","organization","product","university","conference","researcher","person","task","field","programming_language","location"]}
{"id":"98.S","dataset":"crossner_ai","split":"dev","instance":{"id":"98.S","prompt_labels":"Common(O) criteria(O) are(O) the(O) Mean(B-metric) Squared(I-metric) Error(I-metric) criterion(O) implemented(O) in(O) MSECriterion(B-metric) and(O) the(O) cross-entropy(B-metric) criterion(I-metric) implemented(O) in(O) NLLCriterion(B-metric) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, field, location, university, researcher, person, organization, task, programming_language, conference, metric, algorithm, country\nGIVEN SENTENCE: Common criteria are the Mean Squared Error criterion implemented in MSECriterion and the cross-entropy criterion implemented in NLLCriterion .\n","prediction_output":null,"prediction_outputs":null,"group":"98","words":["Common","criteria","are","the","Mean","Squared","Error","criterion","implemented","in","MSECriterion","and","the","cross-entropy","criterion","implemented","in","NLLCriterion","."],"labels":["O","O","O","O","B-metric","I-metric","I-metric","O","O","O","B-metric","O","O","B-metric","I-metric","O","O","B-metric","O"],"target_index":null,"target_label":null},"label_list":["product","field","location","university","researcher","person","organization","task","programming_language","conference","metric","algorithm","country"]}
{"id":"100.S","dataset":"crossner_ai","split":"dev","instance":{"id":"100.S","prompt_labels":"In(O) general(O) ,(O) computational(B-field) linguistics(I-field) draws(O) upon(O) the(O) involvement(O) of(O) linguists(O) ,(O) computer(B-field) science(I-field) ,(O) experts(O) in(O) artificial(B-field) intelligence(I-field) ,(O) mathematicians(O) ,(O) logicians(O) ,(O) philosophers(O) ,(O) cognitive(O) scientists(O) ,(O) cognitive(O) psychologists(O) ,(O) psycholinguists(O) ,(O) anthropologists(O) and(O) neuroscientists(O) ,(O) among(O) others(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, algorithm, organization, metric, conference, programming_language, researcher, location, person, country, task, product, university\nGIVEN SENTENCE: In general , computational linguistics draws upon the involvement of linguists , computer science , experts in artificial intelligence , mathematicians , logicians , philosophers , cognitive scientists , cognitive psychologists , psycholinguists , anthropologists and neuroscientists , among others .\n","prediction_output":null,"prediction_outputs":null,"group":"100","words":["In","general",",","computational","linguistics","draws","upon","the","involvement","of","linguists",",","computer","science",",","experts","in","artificial","intelligence",",","mathematicians",",","logicians",",","philosophers",",","cognitive","scientists",",","cognitive","psychologists",",","psycholinguists",",","anthropologists","and","neuroscientists",",","among","others","."],"labels":["O","O","O","B-field","I-field","O","O","O","O","O","O","O","B-field","I-field","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","algorithm","organization","metric","conference","programming_language","researcher","location","person","country","task","product","university"]}
{"id":"105.S","dataset":"crossner_ai","split":"dev","instance":{"id":"105.S","prompt_labels":"For(O) many(O) years(O) starting(O) from(O) 1986(O) ,(O) Miller(B-researcher) directed(O) the(O) development(O) of(O) WordNet(B-product) ,(O) a(O) large(O) computer-readable(O) electronic(O) reference(O) usable(O) in(O) applications(O) such(O) as(O) search(B-product) engines(I-product) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, person, university, task, algorithm, conference, organization, field, location, metric, product, programming_language, researcher\nGIVEN SENTENCE: For many years starting from 1986 , Miller directed the development of WordNet , a large computer-readable electronic reference usable in applications such as search engines .\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["For","many","years","starting","from","1986",",","Miller","directed","the","development","of","WordNet",",","a","large","computer-readable","electronic","reference","usable","in","applications","such","as","search","engines","."],"labels":["O","O","O","O","O","O","O","B-researcher","O","O","O","O","B-product","O","O","O","O","O","O","O","O","O","O","O","B-product","I-product","O"],"target_index":null,"target_label":null},"label_list":["country","person","university","task","algorithm","conference","organization","field","location","metric","product","programming_language","researcher"]}
{"id":"106.S","dataset":"crossner_ai","split":"dev","instance":{"id":"106.S","prompt_labels":"Since(O) 2009(O) ,(O) the(O) recurrent(B-algorithm) neural(I-algorithm) network(I-algorithm) s(O) and(O) deep(B-algorithm) feedforward(I-algorithm) neural(I-algorithm) networks(I-algorithm) developed(O) in(O) the(O) research(O) group(O) of(O) Jürgen(B-researcher) Schmidhuber(I-researcher) at(O) the(O) Swiss(B-organization) AI(I-organization) Lab(I-organization) IDSIA(I-organization) have(O) won(O) several(O) international(O) handwriting(O) competitions(O) ..(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, conference, researcher, university, programming_language, algorithm, country, organization, product, person, task, field, location\nGIVEN SENTENCE: Since 2009 , the recurrent neural network s and deep feedforward neural networks developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won several international handwriting competitions ..\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["Since","2009",",","the","recurrent","neural","network","s","and","deep","feedforward","neural","networks","developed","in","the","research","group","of","Jürgen","Schmidhuber","at","the","Swiss","AI","Lab","IDSIA","have","won","several","international","handwriting","competitions",".."],"labels":["O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","B-researcher","I-researcher","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["metric","conference","researcher","university","programming_language","algorithm","country","organization","product","person","task","field","location"]}
{"id":"107.S","dataset":"crossner_ai","split":"dev","instance":{"id":"107.S","prompt_labels":"The(O) software(O) is(O) implemented(O) in(O) C(B-programming_language) +(I-programming_language) +(I-programming_language) and(O) it(O) is(O) wrapped(O) for(O) Python(B-programming_language) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, product, metric, programming_language, organization, country, researcher, algorithm, person, location, university, field, conference\nGIVEN SENTENCE: The software is implemented in C + + and it is wrapped for Python .\n","prediction_output":null,"prediction_outputs":null,"group":"107","words":["The","software","is","implemented","in","C","+","+","and","it","is","wrapped","for","Python","."],"labels":["O","O","O","O","O","B-programming_language","I-programming_language","I-programming_language","O","O","O","O","O","B-programming_language","O"],"target_index":null,"target_label":null},"label_list":["task","product","metric","programming_language","organization","country","researcher","algorithm","person","location","university","field","conference"]}
{"id":"108.S","dataset":"crossner_ai","split":"dev","instance":{"id":"108.S","prompt_labels":"In(O) 1857(O) ,(O) at(O) the(O) request(O) of(O) the(O) Tokugawa(B-country) Shogunate(I-country) ,(O) a(O) group(O) of(O) Dutch(O) engineers(O) began(O) work(O) on(O) the(O) Nagasaki(O) Yotetsusho(O) ,(O) a(O) modern(O) ,(O) Western-style(O) foundry(O) and(O) shipyard(O) near(O) the(O) Dutch(O) settlement(O) of(O) Dejima(O) ,(O) at(O) Nagasaki(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, field, metric, algorithm, university, researcher, person, product, task, programming_language, country, conference, location\nGIVEN SENTENCE: In 1857 , at the request of the Tokugawa Shogunate , a group of Dutch engineers began work on the Nagasaki Yotetsusho , a modern , Western-style foundry and shipyard near the Dutch settlement of Dejima , at Nagasaki .\n","prediction_output":null,"prediction_outputs":null,"group":"108","words":["In","1857",",","at","the","request","of","the","Tokugawa","Shogunate",",","a","group","of","Dutch","engineers","began","work","on","the","Nagasaki","Yotetsusho",",","a","modern",",","Western-style","foundry","and","shipyard","near","the","Dutch","settlement","of","Dejima",",","at","Nagasaki","."],"labels":["O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","field","metric","algorithm","university","researcher","person","product","task","programming_language","country","conference","location"]}
{"id":"109.S","dataset":"crossner_ai","split":"dev","instance":{"id":"109.S","prompt_labels":"We(O) make(O) as(O) well(O) as(O) possible(O) precise(O) by(O) measuring(O) the(O) mean(B-metric) squared(I-metric) error(I-metric) between(O) mathy(O) /(O) math(O) and(O) math(O) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) /(O) math(O) :(O) we(O) want(O) math(O) ((O) y(O) -(O) \\(O) hat(O) {(O) f(O) }(O) ((O) x(O) ;(O) D(O) )(O) )(O) ^(O) 2(O) /(O) math(O) to(O) be(O) minimal(O) ,(O) both(O) for(O) mathx(O) _(O) 1(O) ,(O) \\(O) dots(O) ,(O) x(O) _(O) n(O) /(O) math(O) and(O) for(O) points(O) outside(O) of(O) our(O) sample(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, university, task, location, researcher, conference, organization, field, algorithm, country, programming_language, person, product\nGIVEN SENTENCE: We make as well as possible precise by measuring the mean squared error between mathy / math and math \\ hat { f } ( x ; D ) / math : we want math ( y - \\ hat { f } ( x ; D ) ) ^ 2 / math to be minimal , both for mathx _ 1 , \\ dots , x _ n / math and for points outside of our sample .\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["We","make","as","well","as","possible","precise","by","measuring","the","mean","squared","error","between","mathy","/","math","and","math","\\","hat","{","f","}","(","x",";","D",")","/","math",":","we","want","math","(","y","-","\\","hat","{","f","}","(","x",";","D",")",")","^","2","/","math","to","be","minimal",",","both","for","mathx","_","1",",","\\","dots",",","x","_","n","/","math","and","for","points","outside","of","our","sample","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["metric","university","task","location","researcher","conference","organization","field","algorithm","country","programming_language","person","product"]}
{"id":"113.S","dataset":"crossner_ai","split":"dev","instance":{"id":"113.S","prompt_labels":")(O) In(O) addition(O) to(O) the(O) taxonomic(O) information(O) contained(O) in(O) OpenCyc(B-product) ,(O) ResearchCyc(B-product) includes(O) significantly(O) more(O) semantic(O) knowledge(O) ((O) i.e.(O) ,(O) additional(O) facts(O) and(O) rules(O) of(O) thumb(O) )(O) involving(O) the(O) concepts(O) in(O) its(O) knowledge(O) base(O) ;(O) it(O) also(O) includes(O) a(O) large(B-product) lexicon(I-product) ,(I-product) English(I-product) parsing(I-product) and(I-product) generation(I-product) tools(I-product) ,(O) and(O) Java(B-programming_language) based(O) interfaces(B-product) for(I-product) knowledge(I-product) editing(I-product) and(I-product) querying(I-product) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, location, programming_language, organization, algorithm, person, metric, country, researcher, field, conference, product, university\nGIVEN SENTENCE: ) In addition to the taxonomic information contained in OpenCyc , ResearchCyc includes significantly more semantic knowledge ( i.e. , additional facts and rules of thumb ) involving the concepts in its knowledge base ; it also includes a large lexicon , English parsing and generation tools , and Java based interfaces for knowledge editing and querying .\n","prediction_output":null,"prediction_outputs":null,"group":"113","words":[")","In","addition","to","the","taxonomic","information","contained","in","OpenCyc",",","ResearchCyc","includes","significantly","more","semantic","knowledge","(","i.e.",",","additional","facts","and","rules","of","thumb",")","involving","the","concepts","in","its","knowledge","base",";","it","also","includes","a","large","lexicon",",","English","parsing","and","generation","tools",",","and","Java","based","interfaces","for","knowledge","editing","and","querying","."],"labels":["O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","I-product","I-product","I-product","I-product","I-product","I-product","I-product","O","O","B-programming_language","O","B-product","I-product","I-product","I-product","I-product","I-product","O"],"target_index":null,"target_label":null},"label_list":["task","location","programming_language","organization","algorithm","person","metric","country","researcher","field","conference","product","university"]}
{"id":"114.S","dataset":"crossner_ai","split":"dev","instance":{"id":"114.S","prompt_labels":"The(O) Hough(B-algorithm) transform(I-algorithm) is(O) a(O) feature(B-task) extraction(I-task) technique(O) used(O) in(O) image(B-field) analysis(I-field) ,(O) computer(B-field) vision(I-field) ,(O) and(O) digital(B-field) image(I-field) processing(I-field) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, field, country, location, product, person, algorithm, metric, organization, university, conference, task, researcher\nGIVEN SENTENCE: The Hough transform is a feature extraction technique used in image analysis , computer vision , and digital image processing .\n","prediction_output":null,"prediction_outputs":null,"group":"114","words":["The","Hough","transform","is","a","feature","extraction","technique","used","in","image","analysis",",","computer","vision",",","and","digital","image","processing","."],"labels":["O","B-algorithm","I-algorithm","O","O","B-task","I-task","O","O","O","B-field","I-field","O","B-field","I-field","O","O","B-field","I-field","I-field","O"],"target_index":null,"target_label":null},"label_list":["programming_language","field","country","location","product","person","algorithm","metric","organization","university","conference","task","researcher"]}
{"id":"116.S","dataset":"crossner_ai","split":"dev","instance":{"id":"116.S","prompt_labels":"LSTM(B-algorithm) was(O) proposed(O) in(O) 1997(O) by(O) Sepp(B-researcher) Hochreiter(I-researcher) and(O) Jürgen(B-researcher) Schmidhuber(I-researcher) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, programming_language, product, metric, person, algorithm, country, task, university, location, organization, conference, researcher\nGIVEN SENTENCE: LSTM was proposed in 1997 by Sepp Hochreiter and Jürgen Schmidhuber .\n","prediction_output":null,"prediction_outputs":null,"group":"116","words":["LSTM","was","proposed","in","1997","by","Sepp","Hochreiter","and","Jürgen","Schmidhuber","."],"labels":["B-algorithm","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O"],"target_index":null,"target_label":null},"label_list":["field","programming_language","product","metric","person","algorithm","country","task","university","location","organization","conference","researcher"]}
{"id":"118.S","dataset":"crossner_ai","split":"dev","instance":{"id":"118.S","prompt_labels":"He(O) also(O) contributed(O) much(O) through(O) the(O) establishment(O) of(O) ELRA(B-conference) and(O) the(O) LREC(B-conference) conference(I-conference) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, programming_language, location, product, conference, task, field, algorithm, person, organization, country, metric, researcher\nGIVEN SENTENCE: He also contributed much through the establishment of ELRA and the LREC conference .\n","prediction_output":null,"prediction_outputs":null,"group":"118","words":["He","also","contributed","much","through","the","establishment","of","ELRA","and","the","LREC","conference","."],"labels":["O","O","O","O","O","O","O","O","B-conference","O","O","B-conference","I-conference","O"],"target_index":null,"target_label":null},"label_list":["university","programming_language","location","product","conference","task","field","algorithm","person","organization","country","metric","researcher"]}
{"id":"122.S","dataset":"crossner_ai","split":"dev","instance":{"id":"122.S","prompt_labels":"The(O) robot(O) kit(O) is(O) Android-based(O) ,(O) and(O) it(O) is(O) programmed(O) using(O) Java(B-programming_language) ,(O) the(O) Blocks(O) programming(O) interface(O) ,(O) or(O) other(O) Android(B-product) programming(I-product) systems(I-product) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, location, task, country, product, university, organization, programming_language, field, algorithm, person, metric, conference\nGIVEN SENTENCE: The robot kit is Android-based , and it is programmed using Java , the Blocks programming interface , or other Android programming systems .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["The","robot","kit","is","Android-based",",","and","it","is","programmed","using","Java",",","the","Blocks","programming","interface",",","or","other","Android","programming","systems","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-programming_language","O","O","O","O","O","O","O","O","B-product","I-product","I-product","O"],"target_index":null,"target_label":null},"label_list":["researcher","location","task","country","product","university","organization","programming_language","field","algorithm","person","metric","conference"]}
{"id":"123.S","dataset":"crossner_ai","split":"dev","instance":{"id":"123.S","prompt_labels":"The(O) method(O) of(O) defining(O) the(O) linked(O) list(O) specifies(O) the(O) use(O) of(O) a(O) depth-first(B-algorithm) search(I-algorithm) or(O) a(O) breadth-first(B-algorithm) search(I-algorithm) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, country, organization, location, researcher, field, person, conference, algorithm, metric, product, university, task\nGIVEN SENTENCE: The method of defining the linked list specifies the use of a depth-first search or a breadth-first search .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["The","method","of","defining","the","linked","list","specifies","the","use","of","a","depth-first","search","or","a","breadth-first","search","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":null},"label_list":["programming_language","country","organization","location","researcher","field","person","conference","algorithm","metric","product","university","task"]}
{"id":"125.S","dataset":"crossner_ai","split":"dev","instance":{"id":"125.S","prompt_labels":"An(O) example(O) of(O) a(O) semantic(B-algorithm) network(I-algorithm) is(O) WordNet(B-product) ,(O) a(O) lexical(O) database(O) of(O) English(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, algorithm, metric, country, programming_language, researcher, location, conference, university, field, person, product, organization\nGIVEN SENTENCE: An example of a semantic network is WordNet , a lexical database of English .\n","prediction_output":null,"prediction_outputs":null,"group":"125","words":["An","example","of","a","semantic","network","is","WordNet",",","a","lexical","database","of","English","."],"labels":["O","O","O","O","B-algorithm","I-algorithm","O","B-product","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["task","algorithm","metric","country","programming_language","researcher","location","conference","university","field","person","product","organization"]}
{"id":"126.S","dataset":"crossner_ai","split":"dev","instance":{"id":"126.S","prompt_labels":"Speech(B-task) recognition(I-task) is(O) an(O) interdisciplinary(O) subfield(O) of(O) computer(B-field) science(I-field) and(O) computational(B-field) linguistics(I-field) that(O) develops(O) methodologies(O) and(O) technologies(O) that(O) enable(O) the(O) recognition(B-task) and(I-task) translation(I-task) of(I-task) spoken(I-task) language(I-task) into(O) text(O) by(O) computers(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, metric, researcher, programming_language, location, task, country, product, person, university, conference, organization, algorithm\nGIVEN SENTENCE: Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers .\n","prediction_output":null,"prediction_outputs":null,"group":"126","words":["Speech","recognition","is","an","interdisciplinary","subfield","of","computer","science","and","computational","linguistics","that","develops","methodologies","and","technologies","that","enable","the","recognition","and","translation","of","spoken","language","into","text","by","computers","."],"labels":["B-task","I-task","O","O","O","O","O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","B-task","I-task","I-task","I-task","I-task","I-task","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","metric","researcher","programming_language","location","task","country","product","person","university","conference","organization","algorithm"]}
{"id":"129.S","dataset":"crossner_ai","split":"dev","instance":{"id":"129.S","prompt_labels":"He(O) was(O) elected(O) to(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) and(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) and(O) has(O) received(O) a(O) series(O) of(O) awards(O) :(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, programming_language, country, organization, conference, university, person, product, task, metric, researcher, location, algorithm\nGIVEN SENTENCE: He was elected to the American Academy of Arts and Sciences and the National Academy of Sciences and has received a series of awards :\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","was","elected","to","the","American","Academy","of","Arts","and","Sciences","and","the","National","Academy","of","Sciences","and","has","received","a","series","of","awards",":"],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","programming_language","country","organization","conference","university","person","product","task","metric","researcher","location","algorithm"]}
{"id":"131.S","dataset":"crossner_ai","split":"dev","instance":{"id":"131.S","prompt_labels":"Where(O) BLEU(B-metric) simply(O) calculates(O) n-gram(B-metric) precision(I-metric) adding(O) equal(O) weight(O) to(O) each(O) one(O) ,(O) NIST(B-metric) also(O) calculates(O) how(O) informative(O) a(O) particular(O) n-gram(O) is(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, product, country, metric, university, algorithm, programming_language, organization, field, location, researcher, conference, person\nGIVEN SENTENCE: Where BLEU simply calculates n-gram precision adding equal weight to each one , NIST also calculates how informative a particular n-gram is .\n","prediction_output":null,"prediction_outputs":null,"group":"131","words":["Where","BLEU","simply","calculates","n-gram","precision","adding","equal","weight","to","each","one",",","NIST","also","calculates","how","informative","a","particular","n-gram","is","."],"labels":["O","B-metric","O","O","B-metric","I-metric","O","O","O","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["task","product","country","metric","university","algorithm","programming_language","organization","field","location","researcher","conference","person"]}
{"id":"134.S","dataset":"crossner_ai","split":"dev","instance":{"id":"134.S","prompt_labels":"The(O) following(O) MATLAB(B-product) code(O) demonstrates(O) a(O) concrete(O) solution(O) for(O) solving(O) the(O) non-linear(O) system(O) of(O) equations(O) presented(O) in(O) the(O) previous(O) section(O) :(O) See(O) also(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, person, researcher, field, location, conference, product, university, algorithm, programming_language, country, organization, metric\nGIVEN SENTENCE: The following MATLAB code demonstrates a concrete solution for solving the non-linear system of equations presented in the previous section : See also\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["The","following","MATLAB","code","demonstrates","a","concrete","solution","for","solving","the","non-linear","system","of","equations","presented","in","the","previous","section",":","See","also"],"labels":["O","O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["task","person","researcher","field","location","conference","product","university","algorithm","programming_language","country","organization","metric"]}
{"id":"136.S","dataset":"crossner_ai","split":"dev","instance":{"id":"136.S","prompt_labels":"It(O) was(O) first(O) used(O) by(O) Lawrence(B-researcher) J.(I-researcher) Fogel(I-researcher) in(O) the(O) US(B-country) in(O) 1960(O) in(O) order(O) to(O) use(O) simulated(O) evolution(O) as(O) a(O) learning(O) process(O) aiming(O) to(O) generate(O) artificial(B-field) intelligence(I-field) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, person, algorithm, programming_language, conference, location, product, university, task, country, metric, organization, researcher\nGIVEN SENTENCE: It was first used by Lawrence J. Fogel in the US in 1960 in order to use simulated evolution as a learning process aiming to generate artificial intelligence .\n","prediction_output":null,"prediction_outputs":null,"group":"136","words":["It","was","first","used","by","Lawrence","J.","Fogel","in","the","US","in","1960","in","order","to","use","simulated","evolution","as","a","learning","process","aiming","to","generate","artificial","intelligence","."],"labels":["O","O","O","O","O","B-researcher","I-researcher","I-researcher","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O"],"target_index":null,"target_label":null},"label_list":["field","person","algorithm","programming_language","conference","location","product","university","task","country","metric","organization","researcher"]}
{"id":"138.S","dataset":"crossner_ai","split":"dev","instance":{"id":"138.S","prompt_labels":"In(O) such(O) cases(O) ,(O) cloud(B-field) computing(I-field) and(O) open(O) source(O) programming(O) language(O) R(B-programming_language) can(O) help(O) smaller(O) banks(O) to(O) adopt(O) risk(O) analytics(O) and(O) support(O) branch(O) level(O) monitoring(O) by(O) applying(O) predictive(B-field) analytics(I-field) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, metric, product, programming_language, organization, university, country, conference, algorithm, researcher, field, person, location\nGIVEN SENTENCE: In such cases , cloud computing and open source programming language R can help smaller banks to adopt risk analytics and support branch level monitoring by applying predictive analytics .\n","prediction_output":null,"prediction_outputs":null,"group":"138","words":["In","such","cases",",","cloud","computing","and","open","source","programming","language","R","can","help","smaller","banks","to","adopt","risk","analytics","and","support","branch","level","monitoring","by","applying","predictive","analytics","."],"labels":["O","O","O","O","B-field","I-field","O","O","O","O","O","B-programming_language","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O"],"target_index":null,"target_label":null},"label_list":["task","metric","product","programming_language","organization","university","country","conference","algorithm","researcher","field","person","location"]}
{"id":"140.S","dataset":"crossner_ai","split":"dev","instance":{"id":"140.S","prompt_labels":"In(O) this(O) process(O) ,(O) which(O) is(O) known(O) as(O) cross-validation(B-algorithm) ,(O) the(O) MSE(B-metric) is(O) often(O) called(O) the(O) mean(B-metric) squared(I-metric) prediction(I-metric) error(I-metric) ,(O) and(O) is(O) computed(O) as(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, organization, algorithm, researcher, university, task, country, conference, field, person, programming_language, metric, product\nGIVEN SENTENCE: In this process , which is known as cross-validation , the MSE is often called the mean squared prediction error , and is computed as\n","prediction_output":null,"prediction_outputs":null,"group":"140","words":["In","this","process",",","which","is","known","as","cross-validation",",","the","MSE","is","often","called","the","mean","squared","prediction","error",",","and","is","computed","as"],"labels":["O","O","O","O","O","O","O","O","B-algorithm","O","O","B-metric","O","O","O","O","B-metric","I-metric","I-metric","I-metric","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","organization","algorithm","researcher","university","task","country","conference","field","person","programming_language","metric","product"]}
{"id":"141.S","dataset":"crossner_ai","split":"dev","instance":{"id":"141.S","prompt_labels":"OMR(B-task) is(O) generally(O) distinguished(O) from(O) optical(B-task) character(I-task) recognition(I-task) ((O) OCR(B-task) )(O) by(O) the(O) fact(O) that(O) a(O) complicated(O) pattern(B-field) recognition(I-field) engine(O) is(O) not(O) required(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, task, conference, metric, researcher, person, country, algorithm, programming_language, product, university, location, organization\nGIVEN SENTENCE: OMR is generally distinguished from optical character recognition ( OCR ) by the fact that a complicated pattern recognition engine is not required .\n","prediction_output":null,"prediction_outputs":null,"group":"141","words":["OMR","is","generally","distinguished","from","optical","character","recognition","(","OCR",")","by","the","fact","that","a","complicated","pattern","recognition","engine","is","not","required","."],"labels":["B-task","O","O","O","O","B-task","I-task","I-task","O","B-task","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","task","conference","metric","researcher","person","country","algorithm","programming_language","product","university","location","organization"]}
{"id":"142.S","dataset":"crossner_ai","split":"dev","instance":{"id":"142.S","prompt_labels":"In(O) 2018(O) and(O) 2019(O) ,(O) the(O) Championship(O) was(O) be(O) held(O) in(O) Houston(B-location) and(O) Detroit(B-location) ,(O) Michigan(B-location) at(O) the(O) TCF(B-location) Center(I-location) and(O) Ford(B-location) Field(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, field, person, conference, organization, metric, product, algorithm, task, programming_language, location, university, researcher\nGIVEN SENTENCE: In 2018 and 2019 , the Championship was be held in Houston and Detroit , Michigan at the TCF Center and Ford Field .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2018","and","2019",",","the","Championship","was","be","held","in","Houston","and","Detroit",",","Michigan","at","the","TCF","Center","and","Ford","Field","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-location","O","B-location","O","O","B-location","I-location","O","B-location","I-location","O"],"target_index":null,"target_label":null},"label_list":["country","field","person","conference","organization","metric","product","algorithm","task","programming_language","location","university","researcher"]}
{"id":"144.S","dataset":"crossner_ai","split":"dev","instance":{"id":"144.S","prompt_labels":"Two(O) examples(O) of(O) popular(O) parallel(B-product) robots(I-product) are(O) the(O) Stewart(B-product) platform(I-product) and(O) the(O) Delta(B-product) robot(I-product) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, field, task, product, conference, metric, organization, person, country, location, programming_language, algorithm, researcher\nGIVEN SENTENCE: Two examples of popular parallel robots are the Stewart platform and the Delta robot .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["Two","examples","of","popular","parallel","robots","are","the","Stewart","platform","and","the","Delta","robot","."],"labels":["O","O","O","O","B-product","I-product","O","O","B-product","I-product","O","O","B-product","I-product","O"],"target_index":null,"target_label":null},"label_list":["university","field","task","product","conference","metric","organization","person","country","location","programming_language","algorithm","researcher"]}
{"id":"145.S","dataset":"crossner_ai","split":"dev","instance":{"id":"145.S","prompt_labels":"((O) Nevertheless(O) ,(O) the(O) ReLU(B-algorithm) activation(I-algorithm) function(I-algorithm) ,(O) which(O) is(O) non-differentiable(O) at(O) 0(O) ,(O) has(O) become(O) quite(O) popular(O) ,(O) e.g.(O) in(O) AlexNet(B-algorithm) )(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, conference, university, product, field, organization, researcher, person, task, algorithm, programming_language, metric\nGIVEN SENTENCE: ( Nevertheless , the ReLU activation function , which is non-differentiable at 0 , has become quite popular , e.g. in AlexNet )\n","prediction_output":null,"prediction_outputs":null,"group":"145","words":["(","Nevertheless",",","the","ReLU","activation","function",",","which","is","non-differentiable","at","0",",","has","become","quite","popular",",","e.g.","in","AlexNet",")"],"labels":["O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","O"],"target_index":null,"target_label":null},"label_list":["location","country","conference","university","product","field","organization","researcher","person","task","algorithm","programming_language","metric"]}
{"id":"149.S","dataset":"crossner_ai","split":"dev","instance":{"id":"149.S","prompt_labels":"Since(O) paraphrase(B-task) recognition(I-task) can(O) be(O) posed(O) as(O) a(O) classification(B-task) problem(O) ,(O) most(O) standard(O) evaluations(O) metrics(O) such(O) as(O) accuracy(B-metric) ,(O) f1(B-metric) score(I-metric) ,(O) or(O) an(O) ROC(B-metric) curve(I-metric) do(O) relatively(O) well(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, person, organization, country, programming_language, location, task, metric, product, algorithm, university, conference, field\nGIVEN SENTENCE: Since paraphrase recognition can be posed as a classification problem , most standard evaluations metrics such as accuracy , f1 score , or an ROC curve do relatively well .\n","prediction_output":null,"prediction_outputs":null,"group":"149","words":["Since","paraphrase","recognition","can","be","posed","as","a","classification","problem",",","most","standard","evaluations","metrics","such","as","accuracy",",","f1","score",",","or","an","ROC","curve","do","relatively","well","."],"labels":["O","B-task","I-task","O","O","O","O","O","B-task","O","O","O","O","O","O","O","O","B-metric","O","B-metric","I-metric","O","O","O","B-metric","I-metric","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["researcher","person","organization","country","programming_language","location","task","metric","product","algorithm","university","conference","field"]}
{"id":"152.S","dataset":"crossner_ai","split":"dev","instance":{"id":"152.S","prompt_labels":"An(O) example(O) of(O) non-linear(O) normalization(O) is(O) when(O) the(O) normalization(O) follows(O) a(O) sigmoid(B-algorithm) function(I-algorithm) ,(O) in(O) that(O) case(O) ,(O) the(O) normalized(O) image(O) is(O) computed(O) according(O) to(O) the(O) formula(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, organization, product, task, researcher, country, programming_language, conference, field, university, algorithm, location, person\nGIVEN SENTENCE: An example of non-linear normalization is when the normalization follows a sigmoid function , in that case , the normalized image is computed according to the formula\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["An","example","of","non-linear","normalization","is","when","the","normalization","follows","a","sigmoid","function",",","in","that","case",",","the","normalized","image","is","computed","according","to","the","formula"],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["metric","organization","product","task","researcher","country","programming_language","conference","field","university","algorithm","location","person"]}
{"id":"153.S","dataset":"crossner_ai","split":"dev","instance":{"id":"153.S","prompt_labels":"It(O) has(O) been(O) pointed(O) out(O) that(O) precision(B-metric) is(O) usually(O) twinned(O) with(O) recall(B-metric) to(O) overcome(O) this(O) problem(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, university, task, organization, product, algorithm, metric, person, location, conference, programming_language, researcher, country\nGIVEN SENTENCE: It has been pointed out that precision is usually twinned with recall to overcome this problem\n","prediction_output":null,"prediction_outputs":null,"group":"153","words":["It","has","been","pointed","out","that","precision","is","usually","twinned","with","recall","to","overcome","this","problem"],"labels":["O","O","O","O","O","O","B-metric","O","O","O","O","B-metric","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","university","task","organization","product","algorithm","metric","person","location","conference","programming_language","researcher","country"]}
{"id":"157.S","dataset":"crossner_ai","split":"dev","instance":{"id":"157.S","prompt_labels":"These(O) Intelligent(O) Chatbots(B-product) make(O) use(O) of(O) all(O) kinds(O) of(O) artificial(B-field) intelligence(I-field) like(O) image(B-task) moderation(I-task) and(O) natural(B-task) language(I-task) understanding(I-task) ((O) NLU(B-task) )(O) ,(O) natural(B-task) language(I-task) generation(I-task) ((O) NLG(B-task) )(O) ,(O) machine(B-field) learning(I-field) and(O) deep(B-field) learning(I-field) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, task, product, university, organization, conference, algorithm, country, location, programming_language, field, person, metric\nGIVEN SENTENCE: These Intelligent Chatbots make use of all kinds of artificial intelligence like image moderation and natural language understanding ( NLU ) , natural language generation ( NLG ) , machine learning and deep learning .\n","prediction_output":null,"prediction_outputs":null,"group":"157","words":["These","Intelligent","Chatbots","make","use","of","all","kinds","of","artificial","intelligence","like","image","moderation","and","natural","language","understanding","(","NLU",")",",","natural","language","generation","(","NLG",")",",","machine","learning","and","deep","learning","."],"labels":["O","O","B-product","O","O","O","O","O","O","B-field","I-field","O","B-task","I-task","O","B-task","I-task","I-task","O","B-task","O","O","B-task","I-task","I-task","O","B-task","O","O","B-field","I-field","O","B-field","I-field","O"],"target_index":null,"target_label":null},"label_list":["researcher","task","product","university","organization","conference","algorithm","country","location","programming_language","field","person","metric"]}
{"id":"159.S","dataset":"crossner_ai","split":"dev","instance":{"id":"159.S","prompt_labels":"The(O) information(O) is(O) a(O) blend(O) of(O) sitemaps(O) and(O) RSS(O) and(O) is(O) created(O) using(O) the(O) Information(B-algorithm) Model(I-algorithm) ((O) IM(B-algorithm) )(O) and(O) Biomedical(B-algorithm) Resource(I-algorithm) Ontology(I-algorithm) ((O) BRO(B-algorithm) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, product, university, programming_language, researcher, location, algorithm, field, person, metric, task, country, conference\nGIVEN SENTENCE: The information is a blend of sitemaps and RSS and is created using the Information Model ( IM ) and Biomedical Resource Ontology ( BRO ) .\n","prediction_output":null,"prediction_outputs":null,"group":"159","words":["The","information","is","a","blend","of","sitemaps","and","RSS","and","is","created","using","the","Information","Model","(","IM",")","and","Biomedical","Resource","Ontology","(","BRO",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","B-algorithm","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","O","O"],"target_index":null,"target_label":null},"label_list":["organization","product","university","programming_language","researcher","location","algorithm","field","person","metric","task","country","conference"]}
{"id":"160.S","dataset":"crossner_ai","split":"dev","instance":{"id":"160.S","prompt_labels":"Recent(O) text(B-task) recognition(I-task) is(O) based(O) on(O) Recurrent(B-algorithm) neural(I-algorithm) network(I-algorithm) ((O) Long(B-algorithm) short-term(I-algorithm) memory(I-algorithm) )(O) and(O) does(O) not(O) require(O) a(O) language(B-algorithm) model(I-algorithm) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, metric, programming_language, field, conference, university, task, country, organization, researcher, person, location, algorithm\nGIVEN SENTENCE: Recent text recognition is based on Recurrent neural network ( Long short-term memory ) and does not require a language model .\n","prediction_output":null,"prediction_outputs":null,"group":"160","words":["Recent","text","recognition","is","based","on","Recurrent","neural","network","(","Long","short-term","memory",")","and","does","not","require","a","language","model","."],"labels":["O","B-task","I-task","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":null},"label_list":["product","metric","programming_language","field","conference","university","task","country","organization","researcher","person","location","algorithm"]}
{"id":"161.S","dataset":"crossner_ai","split":"dev","instance":{"id":"161.S","prompt_labels":"Popular(O) loss(O) functions(O) include(O) the(O) hinge(B-metric) loss(I-metric) ((O) for(O) linear(B-algorithm) SVMs(I-algorithm) )(O) and(O) the(O) log(B-metric) loss(I-metric) ((O) for(O) logistic(B-algorithm) regression(I-algorithm) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: conference, task, researcher, university, organization, location, metric, product, country, field, person, algorithm, programming_language\nGIVEN SENTENCE: Popular loss functions include the hinge loss ( for linear SVMs ) and the log loss ( for logistic regression ) .\n","prediction_output":null,"prediction_outputs":null,"group":"161","words":["Popular","loss","functions","include","the","hinge","loss","(","for","linear","SVMs",")","and","the","log","loss","(","for","logistic","regression",")","."],"labels":["O","O","O","O","O","B-metric","I-metric","O","O","B-algorithm","I-algorithm","O","O","O","B-metric","I-metric","O","O","B-algorithm","I-algorithm","O","O"],"target_index":null,"target_label":null},"label_list":["conference","task","researcher","university","organization","location","metric","product","country","field","person","algorithm","programming_language"]}
{"id":"162.S","dataset":"crossner_ai","split":"dev","instance":{"id":"162.S","prompt_labels":"SSIM(B-metric) is(O) designed(O) to(O) improve(O) on(O) traditional(O) methods(O) such(O) as(O) peak(B-metric) signal-to-noise(I-metric) ratio(I-metric) ((O) PSNR(B-metric) )(O) and(O) mean(B-metric) squared(I-metric) error(I-metric) ((O) MSE(B-metric) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, algorithm, location, researcher, conference, product, university, metric, field, person, task, organization, country\nGIVEN SENTENCE: SSIM is designed to improve on traditional methods such as peak signal-to-noise ratio ( PSNR ) and mean squared error ( MSE ) .\n","prediction_output":null,"prediction_outputs":null,"group":"162","words":["SSIM","is","designed","to","improve","on","traditional","methods","such","as","peak","signal-to-noise","ratio","(","PSNR",")","and","mean","squared","error","(","MSE",")","."],"labels":["B-metric","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O","B-metric","I-metric","I-metric","O","B-metric","O","O"],"target_index":null,"target_label":null},"label_list":["programming_language","algorithm","location","researcher","conference","product","university","metric","field","person","task","organization","country"]}
{"id":"163.S","dataset":"crossner_ai","split":"dev","instance":{"id":"163.S","prompt_labels":"His(O) work(O) inspired(O) subsequent(O) generations(O) of(O) robotics(O) researchers(O) such(O) as(O) Rodney(B-researcher) Brooks(I-researcher) ,(O) Hans(B-researcher) Moravec(I-researcher) and(O) Mark(B-researcher) Tilden(I-researcher) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: conference, algorithm, researcher, programming_language, location, field, person, task, organization, university, country, product, metric\nGIVEN SENTENCE: His work inspired subsequent generations of robotics researchers such as Rodney Brooks , Hans Moravec and Mark Tilden .\n","prediction_output":null,"prediction_outputs":null,"group":"163","words":["His","work","inspired","subsequent","generations","of","robotics","researchers","such","as","Rodney","Brooks",",","Hans","Moravec","and","Mark","Tilden","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O"],"target_index":null,"target_label":null},"label_list":["conference","algorithm","researcher","programming_language","location","field","person","task","organization","university","country","product","metric"]}
{"id":"164.S","dataset":"crossner_ai","split":"dev","instance":{"id":"164.S","prompt_labels":"Further(O) pulse(O) training(O) is(O) not(O) differentiable(O) ,(O) eliminating(O) backpropagation(B-algorithm) -based(O) training(O) methods(O) like(O) gradient(B-algorithm) descent(I-algorithm) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, field, metric, person, product, programming_language, organization, university, conference, researcher, location, country, algorithm\nGIVEN SENTENCE: Further pulse training is not differentiable , eliminating backpropagation -based training methods like gradient descent .\n","prediction_output":null,"prediction_outputs":null,"group":"164","words":["Further","pulse","training","is","not","differentiable",",","eliminating","backpropagation","-based","training","methods","like","gradient","descent","."],"labels":["O","O","O","O","O","O","O","O","B-algorithm","O","O","O","O","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":null},"label_list":["task","field","metric","person","product","programming_language","organization","university","conference","researcher","location","country","algorithm"]}
{"id":"165.S","dataset":"crossner_ai","split":"dev","instance":{"id":"165.S","prompt_labels":"This(O) relations(O) can(O) be(O) easily(O) represented(O) with(O) a(O) confusion(B-metric) matrix(I-metric) ,(O) a(O) table(O) which(O) describes(O) the(O) accuracy(B-metric) of(O) a(O) classification(B-task) model(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, researcher, country, product, task, person, university, field, conference, organization, programming_language, location, algorithm\nGIVEN SENTENCE: This relations can be easily represented with a confusion matrix , a table which describes the accuracy of a classification model .\n","prediction_output":null,"prediction_outputs":null,"group":"165","words":["This","relations","can","be","easily","represented","with","a","confusion","matrix",",","a","table","which","describes","the","accuracy","of","a","classification","model","."],"labels":["O","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","B-metric","O","O","B-task","O","O"],"target_index":null,"target_label":null},"label_list":["metric","researcher","country","product","task","person","university","field","conference","organization","programming_language","location","algorithm"]}
{"id":"167.S","dataset":"crossner_ai","split":"dev","instance":{"id":"167.S","prompt_labels":"During(O) his(O) time(O) at(O) Duke(B-university) ,(O) he(O) worked(O) on(O) an(O) automated(O) crossword(O) solver(O) PROVERB(B-product) ,(O) which(O) won(O) an(O) Outstanding(O) Paper(O) Award(O) in(O) 1999(O) from(O) AAAI(B-conference) and(O) competed(O) in(O) the(O) American(O) Crossword(O) Puzzle(O) Tournament(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: algorithm, country, researcher, person, task, product, organization, university, conference, field, programming_language, location, metric\nGIVEN SENTENCE: During his time at Duke , he worked on an automated crossword solver PROVERB , which won an Outstanding Paper Award in 1999 from AAAI and competed in the American Crossword Puzzle Tournament .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["During","his","time","at","Duke",",","he","worked","on","an","automated","crossword","solver","PROVERB",",","which","won","an","Outstanding","Paper","Award","in","1999","from","AAAI","and","competed","in","the","American","Crossword","Puzzle","Tournament","."],"labels":["O","O","O","O","B-university","O","O","O","O","O","O","O","O","B-product","O","O","O","O","O","O","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["algorithm","country","researcher","person","task","product","organization","university","conference","field","programming_language","location","metric"]}
{"id":"168.S","dataset":"crossner_ai","split":"dev","instance":{"id":"168.S","prompt_labels":"Headquartered(O) in(O) Rochester(B-location) Hills(I-location) ,(O) Michigan(B-location) ,(O) the(O) company(O) had(O) 10(O) regional(O) locations(O) in(O) the(B-country) U.S.(I-country) ,(O) Canada(B-country) ,(O) Mexico(B-country) and(O) Brazil(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, algorithm, product, programming_language, conference, field, task, researcher, person, university, organization, metric, location\nGIVEN SENTENCE: Headquartered in Rochester Hills , Michigan , the company had 10 regional locations in the U.S. , Canada , Mexico and Brazil .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["Headquartered","in","Rochester","Hills",",","Michigan",",","the","company","had","10","regional","locations","in","the","U.S.",",","Canada",",","Mexico","and","Brazil","."],"labels":["O","O","B-location","I-location","O","B-location","O","O","O","O","O","O","O","O","B-country","I-country","O","B-country","O","B-country","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["country","algorithm","product","programming_language","conference","field","task","researcher","person","university","organization","metric","location"]}
{"id":"172.S","dataset":"crossner_ai","split":"dev","instance":{"id":"172.S","prompt_labels":"The(O) Apple(B-product) iOS(I-product) operating(I-product) system(I-product) used(O) on(O) the(O) iPhone(B-product) ,(O) iPad(B-product) and(O) iPod(B-product) Touch(I-product) uses(O) VoiceOver(B-product) speech(I-product) synthesis(I-product) accessibility(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, programming_language, location, algorithm, conference, researcher, task, person, university, product, field, country, metric\nGIVEN SENTENCE: The Apple iOS operating system used on the iPhone , iPad and iPod Touch uses VoiceOver speech synthesis accessibility .\n","prediction_output":null,"prediction_outputs":null,"group":"172","words":["The","Apple","iOS","operating","system","used","on","the","iPhone",",","iPad","and","iPod","Touch","uses","VoiceOver","speech","synthesis","accessibility","."],"labels":["O","B-product","I-product","I-product","I-product","O","O","O","B-product","O","B-product","O","B-product","I-product","O","B-product","I-product","I-product","O","O"],"target_index":null,"target_label":null},"label_list":["organization","programming_language","location","algorithm","conference","researcher","task","person","university","product","field","country","metric"]}
{"id":"174.S","dataset":"crossner_ai","split":"dev","instance":{"id":"174.S","prompt_labels":"This(O) is(O) done(O) using(O) standard(O) neural(O) net(O) training(O) algorithms(O) such(O) as(O) stochastic(B-algorithm) gradient(I-algorithm) descent(I-algorithm) with(O) backpropagation(B-algorithm) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, organization, metric, university, task, person, country, programming_language, location, conference, product, algorithm, researcher\nGIVEN SENTENCE: This is done using standard neural net training algorithms such as stochastic gradient descent with backpropagation .\n","prediction_output":null,"prediction_outputs":null,"group":"174","words":["This","is","done","using","standard","neural","net","training","algorithms","such","as","stochastic","gradient","descent","with","backpropagation","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","O"],"target_index":null,"target_label":null},"label_list":["field","organization","metric","university","task","person","country","programming_language","location","conference","product","algorithm","researcher"]}
{"id":"178.S","dataset":"crossner_ai","split":"dev","instance":{"id":"178.S","prompt_labels":"Decision(B-algorithm) tree(I-algorithm) learning(I-algorithm) ,(O) neural(B-algorithm) networks(I-algorithm) ,(O) or(O) a(O) naive(B-algorithm) Bayes(I-algorithm) classifier(I-algorithm) could(O) be(O) used(O) in(O) combination(O) with(O) measures(O) of(O) model(O) quality(O) such(O) as(O) balanced(B-metric) accuracy(I-metric)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: conference, person, researcher, task, country, programming_language, field, university, product, organization, metric, algorithm, location\nGIVEN SENTENCE: Decision tree learning , neural networks , or a naive Bayes classifier could be used in combination with measures of model quality such as balanced accuracy\n","prediction_output":null,"prediction_outputs":null,"group":"178","words":["Decision","tree","learning",",","neural","networks",",","or","a","naive","Bayes","classifier","could","be","used","in","combination","with","measures","of","model","quality","such","as","balanced","accuracy"],"labels":["B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric"],"target_index":null,"target_label":null},"label_list":["conference","person","researcher","task","country","programming_language","field","university","product","organization","metric","algorithm","location"]}
{"id":"181.S","dataset":"crossner_ai","split":"dev","instance":{"id":"181.S","prompt_labels":"In(O) information(B-field) theory(I-field) and(O) computer(B-field) science(I-field) ,(O) a(O) code(O) is(O) usually(O) considered(O) as(O) an(O) algorithm(O) that(O) uniquely(O) represents(O) symbols(O) from(O) some(O) source(O) alphabet(O) ,(O) by(O) encoded(O) strings(O) ,(O) which(O) may(O) be(O) in(O) some(O) other(O) target(O) alphabet(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: product, researcher, task, conference, algorithm, university, programming_language, person, country, metric, organization, location, field\nGIVEN SENTENCE: In information theory and computer science , a code is usually considered as an algorithm that uniquely represents symbols from some source alphabet , by encoded strings , which may be in some other target alphabet .\n","prediction_output":null,"prediction_outputs":null,"group":"181","words":["In","information","theory","and","computer","science",",","a","code","is","usually","considered","as","an","algorithm","that","uniquely","represents","symbols","from","some","source","alphabet",",","by","encoded","strings",",","which","may","be","in","some","other","target","alphabet","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["product","researcher","task","conference","algorithm","university","programming_language","person","country","metric","organization","location","field"]}
{"id":"182.S","dataset":"crossner_ai","split":"dev","instance":{"id":"182.S","prompt_labels":"A(O) fairly(O) simple(O) non-linear(O) function(O) ,(O) the(O) sigmoid(B-algorithm) function(I-algorithm) such(O) as(O) the(O) logistic(B-algorithm) function(I-algorithm) also(O) has(O) an(O) easily(O) calculated(O) derivative(O) ,(O) which(O) can(O) be(O) important(O) when(O) calculating(O) the(O) weight(O) updates(O) in(O) the(O) network(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, field, person, product, country, metric, location, task, organization, algorithm, university, conference, programming_language\nGIVEN SENTENCE: A fairly simple non-linear function , the sigmoid function such as the logistic function also has an easily calculated derivative , which can be important when calculating the weight updates in the network .\n","prediction_output":null,"prediction_outputs":null,"group":"182","words":["A","fairly","simple","non-linear","function",",","the","sigmoid","function","such","as","the","logistic","function","also","has","an","easily","calculated","derivative",",","which","can","be","important","when","calculating","the","weight","updates","in","the","network","."],"labels":["O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["researcher","field","person","product","country","metric","location","task","organization","algorithm","university","conference","programming_language"]}
{"id":"183.S","dataset":"crossner_ai","split":"dev","instance":{"id":"183.S","prompt_labels":"Čapek(B-person) was(O) born(O) in(O) Hronov(B-location) ,(O) Bohemia(B-location) ((O) Austria-Hungary(B-country) ,(O) later(O) Czechoslovakia(B-country) ,(O) now(O) the(O) Czech(B-country) Republic(I-country) )(O) in(O) 1887(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: field, product, conference, university, task, country, metric, researcher, programming_language, person, organization, location, algorithm\nGIVEN SENTENCE: Čapek was born in Hronov , Bohemia ( Austria-Hungary , later Czechoslovakia , now the Czech Republic ) in 1887 .\n","prediction_output":null,"prediction_outputs":null,"group":"183","words":["Čapek","was","born","in","Hronov",",","Bohemia","(","Austria-Hungary",",","later","Czechoslovakia",",","now","the","Czech","Republic",")","in","1887","."],"labels":["B-person","O","O","O","B-location","O","B-location","O","B-country","O","O","B-country","O","O","O","B-country","I-country","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["field","product","conference","university","task","country","metric","researcher","programming_language","person","organization","location","algorithm"]}
{"id":"185.S","dataset":"crossner_ai","split":"dev","instance":{"id":"185.S","prompt_labels":"Aspects(O) of(O) ontology(O) editors(O) include(O) :(O) visual(B-task) navigation(I-task) possibilities(O) within(O) the(O) knowledge(B-task) model(I-task) ,(O) inference(B-task) engine(I-task) s(O) and(O) extraction(B-task) ;(O) support(B-task) for(I-task) modules(I-task) ;(O) the(O) import(O) and(O) export(O) of(O) foreign(O) knowledge(B-task) representation(I-task) languages(O) for(O) ontology(B-task) matching(I-task) ;(O) and(O) the(O) support(O) of(O) meta-ontologies(B-task) such(O) as(O) OWL-S(B-product) ,(O) Dublin(B-product) Core(I-product) ,(O) etc(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, location, programming_language, task, field, country, person, algorithm, metric, organization, product, conference, university\nGIVEN SENTENCE: Aspects of ontology editors include : visual navigation possibilities within the knowledge model , inference engine s and extraction ; support for modules ; the import and export of foreign knowledge representation languages for ontology matching ; and the support of meta-ontologies such as OWL-S , Dublin Core , etc .\n","prediction_output":null,"prediction_outputs":null,"group":"185","words":["Aspects","of","ontology","editors","include",":","visual","navigation","possibilities","within","the","knowledge","model",",","inference","engine","s","and","extraction",";","support","for","modules",";","the","import","and","export","of","foreign","knowledge","representation","languages","for","ontology","matching",";","and","the","support","of","meta-ontologies","such","as","OWL-S",",","Dublin","Core",",","etc","."],"labels":["O","O","O","O","O","O","B-task","I-task","O","O","O","B-task","I-task","O","B-task","I-task","O","O","B-task","O","B-task","I-task","I-task","O","O","O","O","O","O","O","B-task","I-task","O","O","B-task","I-task","O","O","O","O","O","B-task","O","O","B-product","O","B-product","I-product","O","O","O"],"target_index":null,"target_label":null},"label_list":["researcher","location","programming_language","task","field","country","person","algorithm","metric","organization","product","conference","university"]}
{"id":"186.S","dataset":"crossner_ai","split":"dev","instance":{"id":"186.S","prompt_labels":"The(O) FBI(B-organization) has(O) also(O) instituted(O) its(O) Next(O) Generation(O) Identification(O) program(O) to(O) include(O) face(B-task) recognition(I-task) ,(O) as(O) well(O) as(O) more(O) traditional(O) biometrics(B-field) like(O) fingerprints(O) and(O) iris(O) scans(O) ,(O) which(O) can(O) pull(O) from(O) both(O) criminal(O) and(O) civil(O) databases(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, conference, organization, product, person, algorithm, location, field, task, programming_language, country, researcher, university\nGIVEN SENTENCE: The FBI has also instituted its Next Generation Identification program to include face recognition , as well as more traditional biometrics like fingerprints and iris scans , which can pull from both criminal and civil databases .\n","prediction_output":null,"prediction_outputs":null,"group":"186","words":["The","FBI","has","also","instituted","its","Next","Generation","Identification","program","to","include","face","recognition",",","as","well","as","more","traditional","biometrics","like","fingerprints","and","iris","scans",",","which","can","pull","from","both","criminal","and","civil","databases","."],"labels":["O","B-organization","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","O","O","O","O","O","B-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["metric","conference","organization","product","person","algorithm","location","field","task","programming_language","country","researcher","university"]}
{"id":"187.S","dataset":"crossner_ai","split":"dev","instance":{"id":"187.S","prompt_labels":"For(O) the(O) 2016(O) season(O) ,(O) Samantha(B-person) Ponder(I-person) was(O) added(O) as(O) host(O) ,(O) replacing(O) Molly(B-person) McGrath(I-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, algorithm, country, metric, researcher, task, location, person, university, field, conference, programming_language, product\nGIVEN SENTENCE: For the 2016 season , Samantha Ponder was added as host , replacing Molly McGrath .\n","prediction_output":null,"prediction_outputs":null,"group":"187","words":["For","the","2016","season",",","Samantha","Ponder","was","added","as","host",",","replacing","Molly","McGrath","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","B-person","I-person","O"],"target_index":null,"target_label":null},"label_list":["organization","algorithm","country","metric","researcher","task","location","person","university","field","conference","programming_language","product"]}
{"id":"191.S","dataset":"crossner_ai","split":"dev","instance":{"id":"191.S","prompt_labels":"Apple(B-organization) Inc(I-organization) introduced(O) Face(B-product) ID(I-product) on(O) the(O) flagship(O) iPhone(B-product) X(I-product) as(O) a(O) biometric(O) authentication(O) successor(O) to(O) the(O) Touch(B-product) ID(I-product) ,(O) a(O) fingerprint(O) based(O) system(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: researcher, algorithm, country, person, programming_language, organization, task, conference, field, metric, product, university, location\nGIVEN SENTENCE: Apple Inc introduced Face ID on the flagship iPhone X as a biometric authentication successor to the Touch ID , a fingerprint based system .\n","prediction_output":null,"prediction_outputs":null,"group":"191","words":["Apple","Inc","introduced","Face","ID","on","the","flagship","iPhone","X","as","a","biometric","authentication","successor","to","the","Touch","ID",",","a","fingerprint","based","system","."],"labels":["B-organization","I-organization","O","B-product","I-product","O","O","O","B-product","I-product","O","O","O","O","O","O","O","B-product","I-product","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["researcher","algorithm","country","person","programming_language","organization","task","conference","field","metric","product","university","location"]}
{"id":"192.S","dataset":"crossner_ai","split":"dev","instance":{"id":"192.S","prompt_labels":"Or(O) combine(O) the(O) F-measure(B-metric) with(O) the(O) R-square(B-metric) evaluated(O) for(O) the(O) raw(O) model(O) output(O) and(O) the(O) target(O) ;(O) or(O) the(O) cost(B-metric) /(I-metric) gain(I-metric) matrix(I-metric) with(O) the(O) correlation(B-metric) coefficient(I-metric) ,(O) and(O) so(O) on(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: programming_language, metric, location, university, conference, product, researcher, task, organization, algorithm, person, country, field\nGIVEN SENTENCE: Or combine the F-measure with the R-square evaluated for the raw model output and the target ; or the cost / gain matrix with the correlation coefficient , and so on .\n","prediction_output":null,"prediction_outputs":null,"group":"192","words":["Or","combine","the","F-measure","with","the","R-square","evaluated","for","the","raw","model","output","and","the","target",";","or","the","cost","/","gain","matrix","with","the","correlation","coefficient",",","and","so","on","."],"labels":["O","O","O","B-metric","O","O","B-metric","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","I-metric","O","O","B-metric","I-metric","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["programming_language","metric","location","university","conference","product","researcher","task","organization","algorithm","person","country","field"]}
{"id":"197.S","dataset":"crossner_ai","split":"dev","instance":{"id":"197.S","prompt_labels":"These(O) systems(O) ,(O) such(O) as(O) Siri(B-product) of(O) the(O) iOS(B-product) operating(I-product) system(I-product) ,(O) operate(O) on(O) a(O) similar(O) pattern-recognizing(O) technique(O) as(O) that(O) of(O) text-based(O) systems(O) ,(O) but(O) with(O) the(O) former(O) ,(O) the(O) user(O) input(O) is(O) conducted(O) through(O) speech(B-task) recognition(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: metric, programming_language, location, task, researcher, person, organization, university, product, country, conference, algorithm, field\nGIVEN SENTENCE: These systems , such as Siri of the iOS operating system , operate on a similar pattern-recognizing technique as that of text-based systems , but with the former , the user input is conducted through speech recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["These","systems",",","such","as","Siri","of","the","iOS","operating","system",",","operate","on","a","similar","pattern-recognizing","technique","as","that","of","text-based","systems",",","but","with","the","former",",","the","user","input","is","conducted","through","speech","recognition","."],"labels":["O","O","O","O","O","B-product","O","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O"],"target_index":null,"target_label":null},"label_list":["metric","programming_language","location","task","researcher","person","organization","university","product","country","conference","algorithm","field"]}
{"id":"198.S","dataset":"crossner_ai","split":"dev","instance":{"id":"198.S","prompt_labels":"More(O) exotic(B-algorithm) fitness(I-algorithm) functions(I-algorithm) that(O) explore(O) model(O) granularity(O) include(O) the(O) area(O) under(O) the(O) ROC(B-metric) curve(I-metric) and(O) rank(O) measure(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: task, product, algorithm, conference, programming_language, country, metric, organization, location, university, field, person, researcher\nGIVEN SENTENCE: More exotic fitness functions that explore model granularity include the area under the ROC curve and rank measure .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["More","exotic","fitness","functions","that","explore","model","granularity","include","the","area","under","the","ROC","curve","and","rank","measure","."],"labels":["O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["task","product","algorithm","conference","programming_language","country","metric","organization","location","university","field","person","researcher"]}
{"id":"199.S","dataset":"crossner_ai","split":"dev","instance":{"id":"199.S","prompt_labels":"The(O) term(O) Semantic(B-product) Web(I-product) was(O) coined(O) by(O) Tim(B-researcher) Berners-Lee(I-researcher) ,(O) the(O) inventor(O) of(O) the(O) World(B-product) Wide(I-product) Web(I-product) and(O) director(O) of(O) the(O) World(B-organization) Wide(I-organization) Web(I-organization) Consortium(I-organization) ((O) W3C(B-organization) )(O) ,(O) which(O) oversees(O) the(O) development(O) of(O) proposed(O) Semantic(B-product) Web(I-product) standards(I-product) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, person, organization, product, country, location, researcher, metric, task, field, conference, programming_language, algorithm\nGIVEN SENTENCE: The term Semantic Web was coined by Tim Berners-Lee , the inventor of the World Wide Web and director of the World Wide Web Consortium ( W3C ) , which oversees the development of proposed Semantic Web standards .\n","prediction_output":null,"prediction_outputs":null,"group":"199","words":["The","term","Semantic","Web","was","coined","by","Tim","Berners-Lee",",","the","inventor","of","the","World","Wide","Web","and","director","of","the","World","Wide","Web","Consortium","(","W3C",")",",","which","oversees","the","development","of","proposed","Semantic","Web","standards","."],"labels":["O","O","B-product","I-product","O","O","O","B-researcher","I-researcher","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","O","O","B-product","I-product","I-product","O"],"target_index":null,"target_label":null},"label_list":["university","person","organization","product","country","location","researcher","metric","task","field","conference","programming_language","algorithm"]}
{"id":"0.S","dataset":"crossner_literature","split":"dev","instance":{"id":"0.S","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(B-literary_genre) The(B-book) Color(I-book) Purple(I-book) ,(O) for(O) which(O) she(O) won(O) the(O) National(B-award) Book(I-award) Award(I-award) for(I-award) hardcover(I-award) fiction(I-award) ,(O) and(O) the(O) Pulitzer(B-award) Prize(I-award) for(I-award) Fiction(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, location, writer, organization, country, person, literary_genre, poem, event, magazine, award\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"1.S","dataset":"crossner_literature","split":"dev","instance":{"id":"1.S","prompt_labels":"His(O) most(O) famous(O) work(O) is(O) the(O) versified(O) topographical(O) description(O) of(O) northern(B-location) Norway(I-location) ,(O) Nordlands(B-poem) Trompet(I-poem) ((O) The(B-poem) Trumpet(I-poem) of(I-poem) Nordland(I-poem) )(O) ,(O) and(O) some(O) psalms(O) still(O) in(O) use(O) ,(O) most(O) prominently(O) Herre(B-poem) Gud(I-poem) ,(I-poem) ditt(I-poem) dyre(I-poem) navn(I-poem) og(I-poem) ære(I-poem) ((O) Good(B-poem) Lord(I-poem) ,(I-poem) thy(I-poem) precious(I-poem) name(I-poem) and(I-poem) glory(I-poem) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, award, organization, person, location, literary_genre, poem, book, country, writer, magazine\nGIVEN SENTENCE: His most famous work is the versified topographical description of northern Norway , Nordlands Trompet ( The Trumpet of Nordland ) , and some psalms still in use , most prominently Herre Gud , ditt dyre navn og ære ( Good Lord , thy precious name and glory ) .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["His","most","famous","work","is","the","versified","topographical","description","of","northern","Norway",",","Nordlands","Trompet","(","The","Trumpet","of","Nordland",")",",","and","some","psalms","still","in","use",",","most","prominently","Herre","Gud",",","ditt","dyre","navn","og","ære","(","Good","Lord",",","thy","precious","name","and","glory",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-poem","I-poem","O","B-poem","I-poem","I-poem","I-poem","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","O","B-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","I-poem","O","O"],"target_index":null,"target_label":null},"label_list":["event","award","organization","person","location","literary_genre","poem","book","country","writer","magazine"]}
{"id":"9.S","dataset":"crossner_literature","split":"dev","instance":{"id":"9.S","prompt_labels":"In(O) 2012(O) ,(O) the(O) Nobel(O) Records(O) were(O) opened(O) after(O) 50(O) years(O) and(O) it(O) was(O) revealed(O) that(O) Anouilh(B-writer) was(O) among(O) a(O) shortlist(O) of(O) authors(O) considered(O) for(O) the(O) 1962(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) ,(O) along(O) with(O) John(B-writer) Steinbeck(I-writer) ((O) winner(O) )(O) ,(O) Robert(B-writer) Graves(I-writer) ,(O) Lawrence(B-writer) Durrell(I-writer) and(O) Karen(B-writer) Blixen(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, organization, person, magazine, poem, writer, book, literary_genre, award, event, country\nGIVEN SENTENCE: In 2012 , the Nobel Records were opened after 50 years and it was revealed that Anouilh was among a shortlist of authors considered for the 1962 Nobel Prize in Literature , along with John Steinbeck ( winner ) , Robert Graves , Lawrence Durrell and Karen Blixen .\n","prediction_output":null,"prediction_outputs":null,"group":"9","words":["In","2012",",","the","Nobel","Records","were","opened","after","50","years","and","it","was","revealed","that","Anouilh","was","among","a","shortlist","of","authors","considered","for","the","1962","Nobel","Prize","in","Literature",",","along","with","John","Steinbeck","(","winner",")",",","Robert","Graves",",","Lawrence","Durrell","and","Karen","Blixen","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["location","organization","person","magazine","poem","writer","book","literary_genre","award","event","country"]}
{"id":"12.S","dataset":"crossner_literature","split":"dev","instance":{"id":"12.S","prompt_labels":"Later(O) in(O) his(O) life(O) ,(O) Ginsberg(B-writer) formed(O) a(O) bridge(O) between(O) the(O) beat(O) movement(O) of(O) the(O) 1950s(O) and(O) the(O) hippie(O) s(O) of(O) the(O) 1960s(O) ,(O) befriending(O) ,(O) among(O) others(O) ,(O) Timothy(B-writer) Leary(I-writer) ,(O) Ken(B-writer) Kesey(I-writer) ,(O) Hunter(B-writer) S.(I-writer) Thompson(I-writer) ,(O) and(O) Bob(B-writer) Dylan(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, magazine, person, location, award, book, country, organization, writer, literary_genre, poem\nGIVEN SENTENCE: Later in his life , Ginsberg formed a bridge between the beat movement of the 1950s and the hippie s of the 1960s , befriending , among others , Timothy Leary , Ken Kesey , Hunter S. Thompson , and Bob Dylan .\n","prediction_output":null,"prediction_outputs":null,"group":"12","words":["Later","in","his","life",",","Ginsberg","formed","a","bridge","between","the","beat","movement","of","the","1950s","and","the","hippie","s","of","the","1960s",",","befriending",",","among","others",",","Timothy","Leary",",","Ken","Kesey",",","Hunter","S.","Thompson",",","and","Bob","Dylan","."],"labels":["O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["event","magazine","person","location","award","book","country","organization","writer","literary_genre","poem"]}
{"id":"14.S","dataset":"crossner_literature","split":"dev","instance":{"id":"14.S","prompt_labels":"He(O) is(O) the(O) protagonist(O) of(O) Robert(B-book) Coover(I-book) '(O) s(O) short(B-literary_genre) story(I-literary_genre) Charlie(B-book) in(I-book) the(I-book) House(I-book) of(I-book) Rue(I-book) ((O) 1980(O) ;(O) reprinted(O) in(O) Coover(B-writer) 's(O) 1987(O) collection(O) A(B-book) Night(I-book) at(I-book) the(I-book) Movies(I-book) )(O) ,(O) and(O) of(O) Glen(B-writer) David(I-writer) Gold(I-writer) '(O) s(O) Sunnyside(B-book) ((O) 2009(O) )(O) ,(O) a(O) historical(B-literary_genre) novel(I-literary_genre) set(O) in(O) the(O) First(B-event) World(I-event) War(I-event) period(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, country, book, magazine, organization, poem, event, location, writer, literary_genre, person\nGIVEN SENTENCE: He is the protagonist of Robert Coover ' s short story Charlie in the House of Rue ( 1980 ; reprinted in Coover 's 1987 collection A Night at the Movies ) , and of Glen David Gold ' s Sunnyside ( 2009 ) , a historical novel set in the First World War period .\n","prediction_output":null,"prediction_outputs":null,"group":"14","words":["He","is","the","protagonist","of","Robert","Coover","'","s","short","story","Charlie","in","the","House","of","Rue","(","1980",";","reprinted","in","Coover","'s","1987","collection","A","Night","at","the","Movies",")",",","and","of","Glen","David","Gold","'","s","Sunnyside","(","2009",")",",","a","historical","novel","set","in","the","First","World","War","period","."],"labels":["O","O","O","O","O","B-book","I-book","O","O","B-literary_genre","I-literary_genre","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","B-writer","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","B-writer","I-writer","I-writer","O","O","B-book","O","O","O","O","O","B-literary_genre","I-literary_genre","O","O","O","B-event","I-event","I-event","O","O"],"target_index":null,"target_label":null},"label_list":["award","country","book","magazine","organization","poem","event","location","writer","literary_genre","person"]}
{"id":"19.S","dataset":"crossner_literature","split":"dev","instance":{"id":"19.S","prompt_labels":"When(O) Davies(B-writer) retired(O) from(O) his(O) position(O) at(O) the(O) university(O) ,(O) his(O) seventh(O) novel(B-literary_genre) ,(O) a(O) satire(B-literary_genre) of(O) academic(O) life(O) ,(O) The(B-book) Rebel(I-book) Angels(I-book) ((O) 1981(O) )(O) ,(O) was(O) published(O) ,(O) followed(O) by(O) What(B-book) 's(I-book) Bred(I-book) in(I-book) the(I-book) Bone(I-book) ((O) 1985(O) )(O) which(O) was(O) short-listed(O) for(O) the(O) Booker(B-award) Prize(I-award) for(I-award) fiction(I-award) in(O) 1986(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, magazine, poem, book, literary_genre, event, person, writer, organization, country, location\nGIVEN SENTENCE: When Davies retired from his position at the university , his seventh novel , a satire of academic life , The Rebel Angels ( 1981 ) , was published , followed by What 's Bred in the Bone ( 1985 ) which was short-listed for the Booker Prize for fiction in 1986 .\n","prediction_output":null,"prediction_outputs":null,"group":"19","words":["When","Davies","retired","from","his","position","at","the","university",",","his","seventh","novel",",","a","satire","of","academic","life",",","The","Rebel","Angels","(","1981",")",",","was","published",",","followed","by","What","'s","Bred","in","the","Bone","(","1985",")","which","was","short-listed","for","the","Booker","Prize","for","fiction","in","1986","."],"labels":["O","B-writer","O","O","O","O","O","O","O","O","O","O","B-literary_genre","O","O","B-literary_genre","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","magazine","poem","book","literary_genre","event","person","writer","organization","country","location"]}
{"id":"26.S","dataset":"crossner_literature","split":"dev","instance":{"id":"26.S","prompt_labels":"His(O) father(O) Noah(B-person) Webster(I-person) Sr.(I-person) ((O) 1722-1813(O) )(O) was(O) a(O) descendant(O) of(O) Connecticut(B-location) Governor(O) John(B-writer) Webster(I-writer) ;(O) his(O) mother(O) Mercy(B-person) ((I-person) Steele(I-person) )(I-person) Webster(I-person) ((O) 1727-1794(O) )(O) was(O) a(O) descendant(O) of(O) Governor(O) William(B-person) Bradford(I-person) of(O) Plymouth(B-country) Colony(I-country) .(O) Noah(B-person) had(O) two(O) brothers(O) ,(O) Abraham(B-person) ((O) 1751-1831(O) )(O) and(O) Charles(B-person) ((O) b(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: poem, person, event, writer, literary_genre, organization, book, magazine, country, award, location\nGIVEN SENTENCE: His father Noah Webster Sr. ( 1722-1813 ) was a descendant of Connecticut Governor John Webster ; his mother Mercy ( Steele ) Webster ( 1727-1794 ) was a descendant of Governor William Bradford of Plymouth Colony . Noah had two brothers , Abraham ( 1751-1831 ) and Charles ( b .\n","prediction_output":null,"prediction_outputs":null,"group":"26","words":["His","father","Noah","Webster","Sr.","(","1722-1813",")","was","a","descendant","of","Connecticut","Governor","John","Webster",";","his","mother","Mercy","(","Steele",")","Webster","(","1727-1794",")","was","a","descendant","of","Governor","William","Bradford","of","Plymouth","Colony",".","Noah","had","two","brothers",",","Abraham","(","1751-1831",")","and","Charles","(","b","."],"labels":["O","O","B-person","I-person","I-person","O","O","O","O","O","O","O","B-location","O","B-writer","I-writer","O","O","O","B-person","I-person","I-person","I-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","B-country","I-country","O","B-person","O","O","O","O","B-person","O","O","O","O","B-person","O","O","O"],"target_index":null,"target_label":null},"label_list":["poem","person","event","writer","literary_genre","organization","book","magazine","country","award","location"]}
{"id":"29.S","dataset":"crossner_literature","split":"dev","instance":{"id":"29.S","prompt_labels":"Other(O) figures(O) in(O) literature(O) who(O) were(O) strongly(O) influenced(O) by(O) Schopenhauer(B-writer) were(O) Thomas(B-writer) Mann(I-writer) ,(O) Afanasy(B-writer) Fet(I-writer) ,(O) Joris-Karl(B-writer) Huysmans(I-writer) and(O) George(B-writer) Santayana(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, organization, writer, event, person, magazine, literary_genre, book, award, poem\nGIVEN SENTENCE: Other figures in literature who were strongly influenced by Schopenhauer were Thomas Mann , Afanasy Fet , Joris-Karl Huysmans and George Santayana .\n","prediction_output":null,"prediction_outputs":null,"group":"29","words":["Other","figures","in","literature","who","were","strongly","influenced","by","Schopenhauer","were","Thomas","Mann",",","Afanasy","Fet",",","Joris-Karl","Huysmans","and","George","Santayana","."],"labels":["O","O","O","O","O","O","O","O","O","B-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["location","country","organization","writer","event","person","magazine","literary_genre","book","award","poem"]}
{"id":"30.S","dataset":"crossner_literature","split":"dev","instance":{"id":"30.S","prompt_labels":"In(O) addition(O) ,(O) Dogpatch(O) characters(O) were(O) used(O) in(O) national(O) campaigns(O) for(O) the(O) U.S.(B-organization) Treasury(I-organization) ,(O) the(O) Cancer(B-organization) Foundation(I-organization) ,(O) the(O) March(B-organization) of(I-organization) Dimes(I-organization) ,(O) the(O) National(B-organization) Heart(I-organization) Fund(I-organization) ,(O) the(O) Sister(B-organization) Kenny(I-organization) Foundation(I-organization) ,(O) the(O) Boy(B-organization) Scouts(I-organization) of(I-organization) America(I-organization) ,(O) Community(B-organization) Chest(I-organization) ,(O) the(O) National(B-organization) Reading(I-organization) Council(I-organization) ,(O) Minnesota(B-organization) Tuberculosis(I-organization) and(I-organization) Health(I-organization) Association(I-organization) ,(O) Christmas(B-organization) Seals(I-organization) ,(O) the(O) National(B-organization) Amputation(I-organization) Foundation(I-organization) ,(O) and(O) Disabled(B-organization) American(I-organization) Veterans(I-organization) ,(O) among(O) others(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, book, event, person, poem, country, magazine, organization, writer, award, location\nGIVEN SENTENCE: In addition , Dogpatch characters were used in national campaigns for the U.S. Treasury , the Cancer Foundation , the March of Dimes , the National Heart Fund , the Sister Kenny Foundation , the Boy Scouts of America , Community Chest , the National Reading Council , Minnesota Tuberculosis and Health Association , Christmas Seals , the National Amputation Foundation , and Disabled American Veterans , among others .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","addition",",","Dogpatch","characters","were","used","in","national","campaigns","for","the","U.S.","Treasury",",","the","Cancer","Foundation",",","the","March","of","Dimes",",","the","National","Heart","Fund",",","the","Sister","Kenny","Foundation",",","the","Boy","Scouts","of","America",",","Community","Chest",",","the","National","Reading","Council",",","Minnesota","Tuberculosis","and","Health","Association",",","Christmas","Seals",",","the","National","Amputation","Foundation",",","and","Disabled","American","Veterans",",","among","others","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","book","event","person","poem","country","magazine","organization","writer","award","location"]}
{"id":"31.S","dataset":"crossner_literature","split":"dev","instance":{"id":"31.S","prompt_labels":"According(O) to(O) Entertainment(B-magazine) Weekly(I-magazine) ,(O) Raimi(B-person) had(O) expressed(O) an(O) interest(O) in(O) directing(O) a(O) film(O) version(O) of(O) The(B-book) Hobbit(I-book) ,(O) the(O) prequel(O) to(O) the(O) Lord(B-book) of(I-book) the(I-book) Rings(I-book) trilogy(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, book, event, poem, literary_genre, location, person, magazine, country, writer, award\nGIVEN SENTENCE: According to Entertainment Weekly , Raimi had expressed an interest in directing a film version of The Hobbit , the prequel to the Lord of the Rings trilogy .\n","prediction_output":null,"prediction_outputs":null,"group":"31","words":["According","to","Entertainment","Weekly",",","Raimi","had","expressed","an","interest","in","directing","a","film","version","of","The","Hobbit",",","the","prequel","to","the","Lord","of","the","Rings","trilogy","."],"labels":["O","O","B-magazine","I-magazine","O","B-person","O","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O"],"target_index":null,"target_label":null},"label_list":["organization","book","event","poem","literary_genre","location","person","magazine","country","writer","award"]}
{"id":"32.S","dataset":"crossner_literature","split":"dev","instance":{"id":"32.S","prompt_labels":"Ansgar(B-writer) received(O) the(O) mission(O) of(O) evangelizing(O) pagan(O) Denmark(B-country) ,(O) Norway(B-country) and(O) Sweden(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, award, person, writer, organization, magazine, poem, event, country, literary_genre, book\nGIVEN SENTENCE: Ansgar received the mission of evangelizing pagan Denmark , Norway and Sweden .\n","prediction_output":null,"prediction_outputs":null,"group":"32","words":["Ansgar","received","the","mission","of","evangelizing","pagan","Denmark",",","Norway","and","Sweden","."],"labels":["B-writer","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["location","award","person","writer","organization","magazine","poem","event","country","literary_genre","book"]}
{"id":"33.S","dataset":"crossner_literature","split":"dev","instance":{"id":"33.S","prompt_labels":"The(O) poem(B-literary_genre) is(O) quoted(O) by(O) Sue(B-writer) Bridehead(I-writer) in(O) Thomas(B-writer) Hardy(I-writer) '(O) s(O) 1895(O) novel(B-literary_genre) ,(O) Jude(B-book) the(I-book) Obscure(I-book) and(O) also(O) by(O) Edward(B-writer) Ashburnham(I-writer) in(O) Ford(B-writer) Madox(I-writer) .(O) Ford(B-writer) '(O) s(O) The(B-book) Good(I-book) Soldier(I-book) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, organization, writer, award, book, magazine, event, person, poem, country, literary_genre\nGIVEN SENTENCE: The poem is quoted by Sue Bridehead in Thomas Hardy ' s 1895 novel , Jude the Obscure and also by Edward Ashburnham in Ford Madox . Ford ' s The Good Soldier .\n","prediction_output":null,"prediction_outputs":null,"group":"33","words":["The","poem","is","quoted","by","Sue","Bridehead","in","Thomas","Hardy","'","s","1895","novel",",","Jude","the","Obscure","and","also","by","Edward","Ashburnham","in","Ford","Madox",".","Ford","'","s","The","Good","Soldier","."],"labels":["O","B-literary_genre","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","B-literary_genre","O","B-book","I-book","I-book","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","O","O","B-book","I-book","I-book","O"],"target_index":null,"target_label":null},"label_list":["location","organization","writer","award","book","magazine","event","person","poem","country","literary_genre"]}
{"id":"38.S","dataset":"crossner_literature","split":"dev","instance":{"id":"38.S","prompt_labels":"Marsters(B-person) moved(O) to(O) Chicago(B-location) ,(O) where(O) his(O) first(O) professional(O) acting(O) role(O) was(O) Ferdinand(O) in(O) The(B-book) Tempest(I-book) at(O) the(O) Goodman(B-location) Theatre(I-location) in(O) 1987(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, organization, location, book, award, writer, event, person, magazine, literary_genre, poem\nGIVEN SENTENCE: Marsters moved to Chicago , where his first professional acting role was Ferdinand in The Tempest at the Goodman Theatre in 1987 .\n","prediction_output":null,"prediction_outputs":null,"group":"38","words":["Marsters","moved","to","Chicago",",","where","his","first","professional","acting","role","was","Ferdinand","in","The","Tempest","at","the","Goodman","Theatre","in","1987","."],"labels":["B-person","O","O","B-location","O","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","organization","location","book","award","writer","event","person","magazine","literary_genre","poem"]}
{"id":"42.S","dataset":"crossner_literature","split":"dev","instance":{"id":"42.S","prompt_labels":"She(O) was(O) appointed(O) Burmese(O) ambassador(O) to(O) India(B-country) and(O) Nepal(B-country) in(O) 1960(O) ,(O) and(O) Aung(B-writer) San(I-writer) Suu(I-writer) Kyi(I-writer) followed(O) her(O) there(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, literary_genre, award, writer, organization, magazine, event, book, location, person, poem\nGIVEN SENTENCE: She was appointed Burmese ambassador to India and Nepal in 1960 , and Aung San Suu Kyi followed her there .\n","prediction_output":null,"prediction_outputs":null,"group":"42","words":["She","was","appointed","Burmese","ambassador","to","India","and","Nepal","in","1960",",","and","Aung","San","Suu","Kyi","followed","her","there","."],"labels":["O","O","O","O","O","O","B-country","O","B-country","O","O","O","O","B-writer","I-writer","I-writer","I-writer","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","literary_genre","award","writer","organization","magazine","event","book","location","person","poem"]}
{"id":"43.S","dataset":"crossner_literature","split":"dev","instance":{"id":"43.S","prompt_labels":"Although(O) the(O) reforms(O) brought(O) by(O) Nikita(B-person) Khrushchev(I-person) freed(O) him(O) from(O) exile(O) in(O) 1956(O) ,(O) the(O) publication(O) of(O) Cancer(B-book) Ward(I-book) ((O) 1968(O) )(O) ,(O) August(B-book) 1914(I-book) ((O) 1971(O) )(O) ,(O) and(O) The(B-book) Gulag(I-book) Archipelago(I-book) ((O) 1973(O) )(O) beyond(O) the(O) Soviet(B-country) Union(I-country) angered(O) authorities(O) ,(O) and(O) Solzhenitsyn(B-writer) lost(O) his(O) Soviet(O) citizenship(O) in(O) 1974(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, event, organization, location, person, poem, magazine, country, book, writer, literary_genre\nGIVEN SENTENCE: Although the reforms brought by Nikita Khrushchev freed him from exile in 1956 , the publication of Cancer Ward ( 1968 ) , August 1914 ( 1971 ) , and The Gulag Archipelago ( 1973 ) beyond the Soviet Union angered authorities , and Solzhenitsyn lost his Soviet citizenship in 1974 .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Although","the","reforms","brought","by","Nikita","Khrushchev","freed","him","from","exile","in","1956",",","the","publication","of","Cancer","Ward","(","1968",")",",","August","1914","(","1971",")",",","and","The","Gulag","Archipelago","(","1973",")","beyond","the","Soviet","Union","angered","authorities",",","and","Solzhenitsyn","lost","his","Soviet","citizenship","in","1974","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","B-country","I-country","O","O","O","O","B-writer","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","event","organization","location","person","poem","magazine","country","book","writer","literary_genre"]}
{"id":"44.S","dataset":"crossner_literature","split":"dev","instance":{"id":"44.S","prompt_labels":"Hesser(B-writer) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O) ,(O) Tad(B-writer) Friend(I-writer) ,(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, location, award, writer, magazine, literary_genre, organization, poem, person, book, event\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"45.S","dataset":"crossner_literature","split":"dev","instance":{"id":"45.S","prompt_labels":"He(O) dedicated(O) his(O) poem(B-literary_genre) Fragments(B-poem) of(I-poem) Olympian(I-poem) Gossip(I-poem) to(O) Viereck(B-location) ,(O) a(O) work(O) in(O) which(O) Tesla(B-organization) ridiculed(O) the(O) scientific(O) establishment(O) of(O) the(O) day(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, writer, award, magazine, literary_genre, country, poem, location, book, event, organization\nGIVEN SENTENCE: He dedicated his poem Fragments of Olympian Gossip to Viereck , a work in which Tesla ridiculed the scientific establishment of the day .\n","prediction_output":null,"prediction_outputs":null,"group":"45","words":["He","dedicated","his","poem","Fragments","of","Olympian","Gossip","to","Viereck",",","a","work","in","which","Tesla","ridiculed","the","scientific","establishment","of","the","day","."],"labels":["O","O","O","B-literary_genre","B-poem","I-poem","I-poem","I-poem","O","B-location","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","writer","award","magazine","literary_genre","country","poem","location","book","event","organization"]}
{"id":"47.S","dataset":"crossner_literature","split":"dev","instance":{"id":"47.S","prompt_labels":"In(O) March(O) 2020(O) ,(O) a(O) third(O) season(O) of(O) Cosmos(O) named(O) Cosmos(O) :(O) Possible(O) Worlds(O) ,(O) for(O) which(O) Druyan(B-writer) was(O) executive(O) producer(O) ,(O) writer(O) ,(O) and(O) director(O) premiered(O) on(O) National(B-magazine) Geographic(I-magazine) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, poem, event, literary_genre, magazine, organization, writer, book, location, country, person\nGIVEN SENTENCE: In March 2020 , a third season of Cosmos named Cosmos : Possible Worlds , for which Druyan was executive producer , writer , and director premiered on National Geographic .\n","prediction_output":null,"prediction_outputs":null,"group":"47","words":["In","March","2020",",","a","third","season","of","Cosmos","named","Cosmos",":","Possible","Worlds",",","for","which","Druyan","was","executive","producer",",","writer",",","and","director","premiered","on","National","Geographic","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O"],"target_index":null,"target_label":null},"label_list":["award","poem","event","literary_genre","magazine","organization","writer","book","location","country","person"]}
{"id":"48.S","dataset":"crossner_literature","split":"dev","instance":{"id":"48.S","prompt_labels":"He(O) spent(O) most(O) of(O) the(O) war(O) flying(O) between(O) the(O) U.S.(B-country) and(O) India(B-country) ,(O) via(O) the(O) Azores(B-location) and(O) North(B-location) Africa(I-location) or(O) South(B-location) America(I-location) ,(O) Nigeria(B-country) ,(O) and(O) Central(B-location) Africa(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, magazine, literary_genre, writer, book, person, location, poem, award, country, event\nGIVEN SENTENCE: He spent most of the war flying between the U.S. and India , via the Azores and North Africa or South America , Nigeria , and Central Africa .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["He","spent","most","of","the","war","flying","between","the","U.S.","and","India",",","via","the","Azores","and","North","Africa","or","South","America",",","Nigeria",",","and","Central","Africa","."],"labels":["O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","O","O","B-location","O","B-location","I-location","O","B-location","I-location","O","B-country","O","O","B-location","I-location","O"],"target_index":null,"target_label":null},"label_list":["organization","magazine","literary_genre","writer","book","person","location","poem","award","country","event"]}
{"id":"50.S","dataset":"crossner_literature","split":"dev","instance":{"id":"50.S","prompt_labels":"Kirkus(B-magazine) Reviews(I-magazine) described(O) it(O) as(O) Predictable(O) ,(O) certainly(O) ,(O) and(O) less(O) imaginative(O) than(O) Consider(B-book) Phlebas(I-book) Consider(B-book) Phlebas(I-book) ,(O) but(O) technically(O) much(O) more(O) solid(O) :(O) honorably(O) crafted(O) work(O) ,(O) often(O) engrossing(O) despite(O) some(O) sluggish(O) patches(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, person, writer, literary_genre, country, event, location, award, organization, book, poem\nGIVEN SENTENCE: Kirkus Reviews described it as Predictable , certainly , and less imaginative than Consider Phlebas Consider Phlebas , but technically much more solid : honorably crafted work , often engrossing despite some sluggish patches .\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["Kirkus","Reviews","described","it","as","Predictable",",","certainly",",","and","less","imaginative","than","Consider","Phlebas","Consider","Phlebas",",","but","technically","much","more","solid",":","honorably","crafted","work",",","often","engrossing","despite","some","sluggish","patches","."],"labels":["B-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","B-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["magazine","person","writer","literary_genre","country","event","location","award","organization","book","poem"]}
{"id":"53.S","dataset":"crossner_literature","split":"dev","instance":{"id":"53.S","prompt_labels":"Rolling(B-magazine) Stone(I-magazine) magazine(O) ranked(O) him(O) number(O) 13(O) in(O) its(O) list(O) of(O) 100(O) Greatest(O) Artists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, event, person, award, location, magazine, poem, organization, writer, book, literary_genre\nGIVEN SENTENCE: Rolling Stone magazine ranked him number 13 in its list of 100 Greatest Artists .\n","prediction_output":null,"prediction_outputs":null,"group":"53","words":["Rolling","Stone","magazine","ranked","him","number","13","in","its","list","of","100","Greatest","Artists","."],"labels":["B-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","event","person","award","location","magazine","poem","organization","writer","book","literary_genre"]}
{"id":"55.S","dataset":"crossner_literature","split":"dev","instance":{"id":"55.S","prompt_labels":"Mere(B-book) Christianity(I-book) was(O) voted(O) best(O) book(O) of(O) the(O) 20th(O) century(O) by(O) Christianity(B-magazine) Today(I-magazine) in(O) 2000(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, award, organization, person, writer, event, literary_genre, poem, country, magazine, location\nGIVEN SENTENCE: Mere Christianity was voted best book of the 20th century by Christianity Today in 2000 .\n","prediction_output":null,"prediction_outputs":null,"group":"55","words":["Mere","Christianity","was","voted","best","book","of","the","20th","century","by","Christianity","Today","in","2000","."],"labels":["B-book","I-book","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O"],"target_index":null,"target_label":null},"label_list":["book","award","organization","person","writer","event","literary_genre","poem","country","magazine","location"]}
{"id":"57.S","dataset":"crossner_literature","split":"dev","instance":{"id":"57.S","prompt_labels":"Although(O) Nietzsche(B-writer) had(O) previously(O) announced(O) at(O) the(O) end(O) of(O) On(B-book) the(I-book) Genealogy(I-book) of(I-book) Morality(I-book) a(O) new(O) work(O) with(O) the(O) title(O) The(B-book) Will(I-book) to(I-book) Power(I-book) :(I-book) Attempt(I-book) at(I-book) a(I-book) Revaluation(I-book) of(I-book) All(I-book) Values(I-book) ,(O) he(O) eventually(O) seems(O) to(O) have(O) abandoned(O) this(O) idea(O) and(O) instead(O) used(O) some(O) of(O) the(O) draft(O) passages(O) to(O) compose(O) Twilight(B-book) of(I-book) the(I-book) Idols(I-book) and(O) The(B-book) Antichrist(I-book) in(O) 1888(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, poem, magazine, award, book, person, writer, literary_genre, event, organization, location\nGIVEN SENTENCE: Although Nietzsche had previously announced at the end of On the Genealogy of Morality a new work with the title The Will to Power : Attempt at a Revaluation of All Values , he eventually seems to have abandoned this idea and instead used some of the draft passages to compose Twilight of the Idols and The Antichrist in 1888 .\n","prediction_output":null,"prediction_outputs":null,"group":"57","words":["Although","Nietzsche","had","previously","announced","at","the","end","of","On","the","Genealogy","of","Morality","a","new","work","with","the","title","The","Will","to","Power",":","Attempt","at","a","Revaluation","of","All","Values",",","he","eventually","seems","to","have","abandoned","this","idea","and","instead","used","some","of","the","draft","passages","to","compose","Twilight","of","the","Idols","and","The","Antichrist","in","1888","."],"labels":["O","B-writer","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","O","B-book","I-book","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","poem","magazine","award","book","person","writer","literary_genre","event","organization","location"]}
{"id":"59.S","dataset":"crossner_literature","split":"dev","instance":{"id":"59.S","prompt_labels":"He(O) received(O) an(O) Academy(B-award) Awards(I-award) nomination(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actor(I-award) for(O) 1987(O) 's(O) Broadcast(O) News(O) and(O) was(O) widely(O) praised(O) for(O) his(O) performance(O) in(O) the(O) 2011(O) film(O) Drive(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: writer, award, event, book, poem, organization, location, magazine, country, person, literary_genre\nGIVEN SENTENCE: He received an Academy Awards nomination for Academy Award for Best Supporting Actor for 1987 's Broadcast News and was widely praised for his performance in the 2011 film Drive .\n","prediction_output":null,"prediction_outputs":null,"group":"59","words":["He","received","an","Academy","Awards","nomination","for","Academy","Award","for","Best","Supporting","Actor","for","1987","'s","Broadcast","News","and","was","widely","praised","for","his","performance","in","the","2011","film","Drive","."],"labels":["O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["writer","award","event","book","poem","organization","location","magazine","country","person","literary_genre"]}
{"id":"61.S","dataset":"crossner_literature","split":"dev","instance":{"id":"61.S","prompt_labels":"Bernard(B-person) Miles(I-person) gave(O) Milligan(B-person) his(O) first(O) straight(O) acting(O) role(O) ,(O) as(O) Ben(B-person) Gunn(I-person) ,(O) in(O) the(O) Mermaid(B-location) Theatre(I-location) production(O) of(O) Treasure(B-book) Island(I-book) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, location, award, event, person, poem, writer, book, organization, country, literary_genre\nGIVEN SENTENCE: Bernard Miles gave Milligan his first straight acting role , as Ben Gunn , in the Mermaid Theatre production of Treasure Island .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Bernard","Miles","gave","Milligan","his","first","straight","acting","role",",","as","Ben","Gunn",",","in","the","Mermaid","Theatre","production","of","Treasure","Island","."],"labels":["B-person","I-person","O","B-person","O","O","O","O","O","O","O","B-person","I-person","O","O","O","B-location","I-location","O","O","B-book","I-book","O"],"target_index":null,"target_label":null},"label_list":["magazine","location","award","event","person","poem","writer","book","organization","country","literary_genre"]}
{"id":"63.S","dataset":"crossner_literature","split":"dev","instance":{"id":"63.S","prompt_labels":"In(O) 1930(O) he(O) was(O) nominated(O) for(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Literature(I-award) by(O) Swedish(O) author(O) Anders(B-writer) Österling(I-writer) ,(O) but(O) was(O) passed(O) over(O) in(O) favor(O) of(O) Sinclair(B-writer) Lewis(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, organization, person, writer, literary_genre, magazine, poem, event, book, award, country\nGIVEN SENTENCE: In 1930 he was nominated for the Nobel Prize in Literature by Swedish author Anders Österling , but was passed over in favor of Sinclair Lewis .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","1930","he","was","nominated","for","the","Nobel","Prize","in","Literature","by","Swedish","author","Anders","Österling",",","but","was","passed","over","in","favor","of","Sinclair","Lewis","."],"labels":["O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["location","organization","person","writer","literary_genre","magazine","poem","event","book","award","country"]}
{"id":"64.S","dataset":"crossner_literature","split":"dev","instance":{"id":"64.S","prompt_labels":"Among(O) his(O) childhood(O) favorites(O) were(O) Charles(B-writer) Dickens(I-writer) ,(O) Tobias(B-writer) Smollett(I-writer) ,(O) Mark(B-writer) Twain(I-writer) ,(O) Booth(B-writer) Tarkington(I-writer) ,(O) and(O) later(O) ,(O) Robert(B-writer) Benchley(I-writer) and(O) S.(B-writer) J.(I-writer) Perelman(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, award, country, organization, magazine, writer, location, literary_genre, poem, book, event\nGIVEN SENTENCE: Among his childhood favorites were Charles Dickens , Tobias Smollett , Mark Twain , Booth Tarkington , and later , Robert Benchley and S. J. Perelman .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Among","his","childhood","favorites","were","Charles","Dickens",",","Tobias","Smollett",",","Mark","Twain",",","Booth","Tarkington",",","and","later",",","Robert","Benchley","and","S.","J.","Perelman","."],"labels":["O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["person","award","country","organization","magazine","writer","location","literary_genre","poem","book","event"]}
{"id":"65.S","dataset":"crossner_literature","split":"dev","instance":{"id":"65.S","prompt_labels":"Among(O) the(O) books(O) found(O) in(O) his(O) library(O) ((O) as(O) evidenced(O) in(O) Lovecraft(B-book) 's(I-book) Library(I-book) by(O) S.(B-writer) T.(I-writer) Joshi(I-writer) )(O) was(O) The(B-book) Seven(I-book) Who(I-book) Were(I-book) Hanged(I-book) by(O) Leonid(B-writer) Andreyev(I-writer) and(O) A(B-book) Strange(I-book) Manuscript(I-book) Found(I-book) in(I-book) a(I-book) Copper(I-book) Cylinder(I-book) by(O) James(B-writer) De(I-writer) Mille(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, magazine, location, person, literary_genre, book, poem, event, award, writer\nGIVEN SENTENCE: Among the books found in his library ( as evidenced in Lovecraft 's Library by S. T. Joshi ) was The Seven Who Were Hanged by Leonid Andreyev and A Strange Manuscript Found in a Copper Cylinder by James De Mille .\n","prediction_output":null,"prediction_outputs":null,"group":"65","words":["Among","the","books","found","in","his","library","(","as","evidenced","in","Lovecraft","'s","Library","by","S.","T.","Joshi",")","was","The","Seven","Who","Were","Hanged","by","Leonid","Andreyev","and","A","Strange","Manuscript","Found","in","a","Copper","Cylinder","by","James","De","Mille","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","B-writer","I-writer","I-writer","O","O","B-book","I-book","I-book","I-book","I-book","O","B-writer","I-writer","O","B-book","I-book","I-book","I-book","I-book","I-book","I-book","I-book","O","B-writer","I-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["organization","country","magazine","location","person","literary_genre","book","poem","event","award","writer"]}
{"id":"66.S","dataset":"crossner_literature","split":"dev","instance":{"id":"66.S","prompt_labels":"He(O) soon(O) produced(O) acclaimed(O) translations(O) of(O) Sándor(B-writer) Petőfi(I-writer) ,(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Rainer(B-writer) Maria(I-writer) Rilke(I-writer) ,(O) Paul(B-writer) Verlaine(I-writer) ,(O) Taras(B-writer) Shevchenko(I-writer) ,(O) and(O) Nikoloz(B-writer) Baratashvili(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, magazine, event, poem, literary_genre, country, organization, person, location, writer, award\nGIVEN SENTENCE: He soon produced acclaimed translations of Sándor Petőfi , Johann Wolfgang von Goethe , Rainer Maria Rilke , Paul Verlaine , Taras Shevchenko , and Nikoloz Baratashvili .\n","prediction_output":null,"prediction_outputs":null,"group":"66","words":["He","soon","produced","acclaimed","translations","of","Sándor","Petőfi",",","Johann","Wolfgang","von","Goethe",",","Rainer","Maria","Rilke",",","Paul","Verlaine",",","Taras","Shevchenko",",","and","Nikoloz","Baratashvili","."],"labels":["O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["book","magazine","event","poem","literary_genre","country","organization","person","location","writer","award"]}
{"id":"67.S","dataset":"crossner_literature","split":"dev","instance":{"id":"67.S","prompt_labels":"This(O) aversion(O) to(O) war(O) also(O) led(O) Einstein(B-person) to(O) befriend(O) author(O) Upton(B-writer) Sinclair(I-writer) and(O) film(O) star(O) Charlie(B-person) Chaplin(I-person) ,(O) both(O) noted(O) for(O) their(O) pacifism(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, location, organization, person, writer, poem, literary_genre, award, country, book, magazine\nGIVEN SENTENCE: This aversion to war also led Einstein to befriend author Upton Sinclair and film star Charlie Chaplin , both noted for their pacifism .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["This","aversion","to","war","also","led","Einstein","to","befriend","author","Upton","Sinclair","and","film","star","Charlie","Chaplin",",","both","noted","for","their","pacifism","."],"labels":["O","O","O","O","O","O","B-person","O","O","O","B-writer","I-writer","O","O","O","B-person","I-person","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","location","organization","person","writer","poem","literary_genre","award","country","book","magazine"]}
{"id":"69.S","dataset":"crossner_literature","split":"dev","instance":{"id":"69.S","prompt_labels":"Since(O) release(O) ,(O) the(O) film(O) has(O) divided(O) critics(O) but(O) generally(O) received(O) praise(O) ;(O) initial(O) reviews(O) ranged(O) from(O) Melody(B-magazine) Maker(I-magazine) calling(O) it(O) the(O) greatest(O) horror(O) film(O) made(O) in(O) Britain(B-country) ,(O) to(O) Roger(B-writer) Ebert(I-writer) decrying(O) its(O) bankruptcy(O) of(O) imagination(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, poem, book, country, organization, magazine, literary_genre, location, writer, award, person\nGIVEN SENTENCE: Since release , the film has divided critics but generally received praise ; initial reviews ranged from Melody Maker calling it the greatest horror film made in Britain , to Roger Ebert decrying its bankruptcy of imagination .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["Since","release",",","the","film","has","divided","critics","but","generally","received","praise",";","initial","reviews","ranged","from","Melody","Maker","calling","it","the","greatest","horror","film","made","in","Britain",",","to","Roger","Ebert","decrying","its","bankruptcy","of","imagination","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O","O","O","O","O","O","B-country","O","O","B-writer","I-writer","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","poem","book","country","organization","magazine","literary_genre","location","writer","award","person"]}
{"id":"70.S","dataset":"crossner_literature","split":"dev","instance":{"id":"70.S","prompt_labels":"Tarkovsky(B-writer) was(O) the(O) recipient(O) of(O) several(O) awards(O) at(O) the(O) Cannes(B-event) Film(I-event) Festival(I-event) throughout(O) his(O) career(O) ((O) including(O) the(O) FIPRESCI(B-award) prize(I-award) ,(O) the(O) Prize(B-award) of(I-award) the(I-award) Ecumenical(I-award) Jury(I-award) ,(O) and(O) the(O) Grand(B-award) Prix(I-award) Spécial(I-award) du(I-award) Jury(I-award) )(O) and(O) winner(O) of(O) the(O) Golden(B-award) Lion(I-award) award(I-award) at(O) the(O) Venice(B-event) Film(I-event) Festival(I-event) for(O) his(O) debut(O) film(O) Ivan(O) 's(O) Childhood(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, award, book, poem, literary_genre, country, magazine, writer, event, person, location\nGIVEN SENTENCE: Tarkovsky was the recipient of several awards at the Cannes Film Festival throughout his career ( including the FIPRESCI prize , the Prize of the Ecumenical Jury , and the Grand Prix Spécial du Jury ) and winner of the Golden Lion award at the Venice Film Festival for his debut film Ivan 's Childhood .\n","prediction_output":null,"prediction_outputs":null,"group":"70","words":["Tarkovsky","was","the","recipient","of","several","awards","at","the","Cannes","Film","Festival","throughout","his","career","(","including","the","FIPRESCI","prize",",","the","Prize","of","the","Ecumenical","Jury",",","and","the","Grand","Prix","Spécial","du","Jury",")","and","winner","of","the","Golden","Lion","award","at","the","Venice","Film","Festival","for","his","debut","film","Ivan","'s","Childhood","."],"labels":["B-writer","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","B-award","I-award","I-award","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","award","book","poem","literary_genre","country","magazine","writer","event","person","location"]}
{"id":"71.S","dataset":"crossner_literature","split":"dev","instance":{"id":"71.S","prompt_labels":"The(O) first(O) global(O) recognition(O) came(O) in(O) 1950(O) when(O) Gwendolyn(B-writer) Brooks(I-writer) was(O) the(O) first(O) black(O) American(O) to(O) win(O) a(O) Pulitzer(B-award) Prize(I-award) for(O) Literature(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, location, country, poem, book, organization, award, magazine, event, writer, person\nGIVEN SENTENCE: The first global recognition came in 1950 when Gwendolyn Brooks was the first black American to win a Pulitzer Prize for Literature .\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["The","first","global","recognition","came","in","1950","when","Gwendolyn","Brooks","was","the","first","black","American","to","win","a","Pulitzer","Prize","for","Literature","."],"labels":["O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","location","country","poem","book","organization","award","magazine","event","writer","person"]}
{"id":"74.S","dataset":"crossner_literature","split":"dev","instance":{"id":"74.S","prompt_labels":"He(O) is(O) best(O) remembered(O) for(O) his(O) science(B-literary_genre) fiction(I-literary_genre) ,(O) including(O) The(B-book) Demolished(I-book) Man(I-book) ,(O) winner(O) of(O) the(O) inaugural(O) Hugo(B-award) Award(I-award) in(O) 1953(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: poem, magazine, award, event, organization, country, book, person, literary_genre, location, writer\nGIVEN SENTENCE: He is best remembered for his science fiction , including The Demolished Man , winner of the inaugural Hugo Award in 1953 .\n","prediction_output":null,"prediction_outputs":null,"group":"74","words":["He","is","best","remembered","for","his","science","fiction",",","including","The","Demolished","Man",",","winner","of","the","inaugural","Hugo","Award","in","1953","."],"labels":["O","O","O","O","O","O","B-literary_genre","I-literary_genre","O","O","B-book","I-book","I-book","O","O","O","O","O","B-award","I-award","O","O","O"],"target_index":null,"target_label":null},"label_list":["poem","magazine","award","event","organization","country","book","person","literary_genre","location","writer"]}
{"id":"75.S","dataset":"crossner_literature","split":"dev","instance":{"id":"75.S","prompt_labels":"Amos(B-writer) prophesied(O) during(O) the(O) reign(O) of(O) Jeroboam(B-person) II(I-person) ,(O) King(O) of(O) Israel(B-country) ,(O) and(O) of(O) Uzziah(B-person) of(O) Kingdom(B-country) of(I-country) Judah(I-country) ,(O) which(O) places(O) him(O) in(O) the(O) first(O) half(O) of(O) the(O) 8th(O) century(O) BC(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, magazine, location, book, person, poem, award, organization, literary_genre, writer, country\nGIVEN SENTENCE: Amos prophesied during the reign of Jeroboam II , King of Israel , and of Uzziah of Kingdom of Judah , which places him in the first half of the 8th century BC .\n","prediction_output":null,"prediction_outputs":null,"group":"75","words":["Amos","prophesied","during","the","reign","of","Jeroboam","II",",","King","of","Israel",",","and","of","Uzziah","of","Kingdom","of","Judah",",","which","places","him","in","the","first","half","of","the","8th","century","BC","."],"labels":["B-writer","O","O","O","O","O","B-person","I-person","O","O","O","B-country","O","O","O","B-person","O","B-country","I-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","magazine","location","book","person","poem","award","organization","literary_genre","writer","country"]}
{"id":"76.S","dataset":"crossner_literature","split":"dev","instance":{"id":"76.S","prompt_labels":"Jorge(B-writer) Luis(I-writer) Borges(I-writer) wrote(O) a(O) contemporary(O) bestiary(O) of(O) sorts(O) ,(O) the(O) Book(B-book) of(I-book) Imaginary(I-book) Beings(I-book) ,(O) which(O) collects(O) imaginary(O) beasts(O) from(O) bestiaries(O) and(O) fiction(B-literary_genre) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, magazine, person, award, event, writer, organization, location, poem, literary_genre, country\nGIVEN SENTENCE: Jorge Luis Borges wrote a contemporary bestiary of sorts , the Book of Imaginary Beings , which collects imaginary beasts from bestiaries and fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"76","words":["Jorge","Luis","Borges","wrote","a","contemporary","bestiary","of","sorts",",","the","Book","of","Imaginary","Beings",",","which","collects","imaginary","beasts","from","bestiaries","and","fiction","."],"labels":["B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-literary_genre","O"],"target_index":null,"target_label":null},"label_list":["book","magazine","person","award","event","writer","organization","location","poem","literary_genre","country"]}
{"id":"77.S","dataset":"crossner_literature","split":"dev","instance":{"id":"77.S","prompt_labels":"The(O) Australia(B-country) n(O) composer(O) Peter(B-writer) Sculthorpe(I-writer) quoted(O) parts(O) of(O) it(O) in(O) his(O) opera(O) or(O) music(O) theatre(O) work(O) Rites(O) of(O) Passage(O) ((O) 1972-73(O) )(O) ,(O) which(O) was(O) commissioned(O) for(O) the(O) opening(O) of(O) the(O) Sydney(B-location) Opera(I-location) House(I-location) but(O) was(O) not(O) ready(O) in(O) time(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, person, event, poem, literary_genre, magazine, country, organization, award, writer, book\nGIVEN SENTENCE: The Australia n composer Peter Sculthorpe quoted parts of it in his opera or music theatre work Rites of Passage ( 1972-73 ) , which was commissioned for the opening of the Sydney Opera House but was not ready in time .\n","prediction_output":null,"prediction_outputs":null,"group":"77","words":["The","Australia","n","composer","Peter","Sculthorpe","quoted","parts","of","it","in","his","opera","or","music","theatre","work","Rites","of","Passage","(","1972-73",")",",","which","was","commissioned","for","the","opening","of","the","Sydney","Opera","House","but","was","not","ready","in","time","."],"labels":["O","B-country","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","person","event","poem","literary_genre","magazine","country","organization","award","writer","book"]}
{"id":"79.S","dataset":"crossner_literature","split":"dev","instance":{"id":"79.S","prompt_labels":"He(O) came(O) to(O) wide(O) public(O) attention(O) with(O) his(O) first(O) book(O) Poems(B-poem) at(O) the(O) age(O) of(O) twenty-three(O) in(O) 1930(O) ;(O) it(O) was(O) followed(O) in(O) 1932(O) by(O) The(B-poem) Orators(I-poem) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, country, event, poem, writer, book, location, organization, magazine, person, award\nGIVEN SENTENCE: He came to wide public attention with his first book Poems at the age of twenty-three in 1930 ; it was followed in 1932 by The Orators .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["He","came","to","wide","public","attention","with","his","first","book","Poems","at","the","age","of","twenty-three","in","1930",";","it","was","followed","in","1932","by","The","Orators","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-poem","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","country","event","poem","writer","book","location","organization","magazine","person","award"]}
{"id":"80.S","dataset":"crossner_literature","split":"dev","instance":{"id":"80.S","prompt_labels":"Julia(B-writer) was(O) the(O) niece(O) of(O) poet(O) and(O) critic(O) Matthew(B-writer) Arnold(I-writer) and(O) the(O) sister(O) of(O) Mary(B-writer) Augusta(I-writer) Ward(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: poem, literary_genre, location, organization, country, person, book, award, magazine, writer, event\nGIVEN SENTENCE: Julia was the niece of poet and critic Matthew Arnold and the sister of Mary Augusta Ward .\n","prediction_output":null,"prediction_outputs":null,"group":"80","words":["Julia","was","the","niece","of","poet","and","critic","Matthew","Arnold","and","the","sister","of","Mary","Augusta","Ward","."],"labels":["B-writer","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["poem","literary_genre","location","organization","country","person","book","award","magazine","writer","event"]}
{"id":"81.S","dataset":"crossner_literature","split":"dev","instance":{"id":"81.S","prompt_labels":"It(O) was(O) adapted(O) by(O) Talbot(B-writer) Jennings(I-writer) ,(O) Tess(B-writer) Slesinger(I-writer) ,(O) and(O) Claudine(B-writer) West(I-writer) from(O) the(O) play(O) by(O) Owen(B-writer) Davis(I-writer) and(O) Donald(B-writer) Davis(I-writer) ,(O) which(O) was(O) in(O) itself(O) based(O) on(O) the(O) 1931(O) The(B-book) Good(I-book) Earth(I-book) by(O) Nobel(B-award) Prize(I-award) -winning(O) author(O) Pearl(B-writer) S.(I-writer) Buck(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, poem, country, magazine, person, book, event, location, literary_genre, writer, award\nGIVEN SENTENCE: It was adapted by Talbot Jennings , Tess Slesinger , and Claudine West from the play by Owen Davis and Donald Davis , which was in itself based on the 1931 The Good Earth by Nobel Prize -winning author Pearl S. Buck .\n","prediction_output":null,"prediction_outputs":null,"group":"81","words":["It","was","adapted","by","Talbot","Jennings",",","Tess","Slesinger",",","and","Claudine","West","from","the","play","by","Owen","Davis","and","Donald","Davis",",","which","was","in","itself","based","on","the","1931","The","Good","Earth","by","Nobel","Prize","-winning","author","Pearl","S.","Buck","."],"labels":["O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-book","I-book","I-book","O","B-award","I-award","O","O","B-writer","I-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["organization","poem","country","magazine","person","book","event","location","literary_genre","writer","award"]}
{"id":"82.S","dataset":"crossner_literature","split":"dev","instance":{"id":"82.S","prompt_labels":"His(O) best-known(O) works(O) include(O) Demian(B-book) ,(O) Steppenwolf(B-book) ,(O) Siddhartha(B-book) ,(O) and(O) The(B-book) Glass(I-book) Bead(I-book) Game(I-book) ,(O) each(O) of(O) which(O) explores(O) an(O) individual(O) 's(O) search(O) for(O) authenticity(O) ,(O) self-knowledge(O) and(O) spirituality(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: poem, organization, literary_genre, person, magazine, writer, event, country, book, location, award\nGIVEN SENTENCE: His best-known works include Demian , Steppenwolf , Siddhartha , and The Glass Bead Game , each of which explores an individual 's search for authenticity , self-knowledge and spirituality .\n","prediction_output":null,"prediction_outputs":null,"group":"82","words":["His","best-known","works","include","Demian",",","Steppenwolf",",","Siddhartha",",","and","The","Glass","Bead","Game",",","each","of","which","explores","an","individual","'s","search","for","authenticity",",","self-knowledge","and","spirituality","."],"labels":["O","O","O","O","B-book","O","B-book","O","B-book","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["poem","organization","literary_genre","person","magazine","writer","event","country","book","location","award"]}
{"id":"84.S","dataset":"crossner_literature","split":"dev","instance":{"id":"84.S","prompt_labels":"In(O) New(B-location) York(I-location) ,(O) he(O) socialized(O) at(O) the(O) Hydra(B-organization) Club(I-organization) ,(O) an(O) organization(O) of(O) New(B-location) York(I-location) 's(O) science(B-literary_genre) fiction(I-literary_genre) writers(O) ,(O) including(O) such(O) luminaries(O) as(O) Isaac(B-writer) Asimov(I-writer) ,(O) James(B-writer) Blish(I-writer) ,(O) Anthony(B-writer) Boucher(I-writer) ,(O) Avram(B-writer) Davidson(I-writer) ,(O) Judith(B-writer) Merril(I-writer) ,(O) and(O) Theodore(B-writer) Sturgeon(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, writer, poem, award, book, country, event, organization, literary_genre, location, person\nGIVEN SENTENCE: In New York , he socialized at the Hydra Club , an organization of New York 's science fiction writers , including such luminaries as Isaac Asimov , James Blish , Anthony Boucher , Avram Davidson , Judith Merril , and Theodore Sturgeon .\n","prediction_output":null,"prediction_outputs":null,"group":"84","words":["In","New","York",",","he","socialized","at","the","Hydra","Club",",","an","organization","of","New","York","'s","science","fiction","writers",",","including","such","luminaries","as","Isaac","Asimov",",","James","Blish",",","Anthony","Boucher",",","Avram","Davidson",",","Judith","Merril",",","and","Theodore","Sturgeon","."],"labels":["O","B-location","I-location","O","O","O","O","O","B-organization","I-organization","O","O","O","O","B-location","I-location","O","B-literary_genre","I-literary_genre","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["magazine","writer","poem","award","book","country","event","organization","literary_genre","location","person"]}
{"id":"85.S","dataset":"crossner_literature","split":"dev","instance":{"id":"85.S","prompt_labels":"Wajda(B-person) made(O) two(O) more(O) increasingly(O) accomplished(O) films(O) ,(O) which(O) developed(O) further(O) the(O) anti-war(O) theme(O) of(O) A(O) Generation(O) :(O) Kanał(O) ((O) 1956(O) )(O) ((O) Special(B-award) Jury(I-award) Prize(I-award) at(O) Cannes(B-event) Film(I-event) Festival(I-event) in(O) 1957(O) ,(O) shared(O) with(O) Bergman(B-person) 's(O) The(O) Seventh(O) Seal(O) )(O) and(O) Ashes(O) and(O) Diamonds(O) ((O) 1958(O) )(O) with(O) Zbigniew(B-person) Cybulski(I-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, writer, organization, magazine, event, country, person, location, poem, award, literary_genre\nGIVEN SENTENCE: Wajda made two more increasingly accomplished films , which developed further the anti-war theme of A Generation : Kanał ( 1956 ) ( Special Jury Prize at Cannes Film Festival in 1957 , shared with Bergman 's The Seventh Seal ) and Ashes and Diamonds ( 1958 ) with Zbigniew Cybulski .\n","prediction_output":null,"prediction_outputs":null,"group":"85","words":["Wajda","made","two","more","increasingly","accomplished","films",",","which","developed","further","the","anti-war","theme","of","A","Generation",":","Kanał","(","1956",")","(","Special","Jury","Prize","at","Cannes","Film","Festival","in","1957",",","shared","with","Bergman","'s","The","Seventh","Seal",")","and","Ashes","and","Diamonds","(","1958",")","with","Zbigniew","Cybulski","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O","B-event","I-event","I-event","O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O"],"target_index":null,"target_label":null},"label_list":["book","writer","organization","magazine","event","country","person","location","poem","award","literary_genre"]}
{"id":"87.S","dataset":"crossner_literature","split":"dev","instance":{"id":"87.S","prompt_labels":"The(B-book) Great(I-book) Hunt(I-book) is(O) a(O) fantasy(B-literary_genre) novel(I-literary_genre) by(O) United(B-country) States(I-country) author(O) Robert(B-writer) Jordan(I-writer) ,(O) the(O) second(O) book(O) of(O) The(B-book) Wheel(I-book) of(I-book) Time(I-book) series(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, organization, award, magazine, person, book, event, poem, writer, location, country\nGIVEN SENTENCE: The Great Hunt is a fantasy novel by United States author Robert Jordan , the second book of The Wheel of Time series .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["The","Great","Hunt","is","a","fantasy","novel","by","United","States","author","Robert","Jordan",",","the","second","book","of","The","Wheel","of","Time","series","."],"labels":["B-book","I-book","I-book","O","O","B-literary_genre","I-literary_genre","O","B-country","I-country","O","B-writer","I-writer","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","organization","award","magazine","person","book","event","poem","writer","location","country"]}
{"id":"88.S","dataset":"crossner_literature","split":"dev","instance":{"id":"88.S","prompt_labels":"The(B-book) Man(I-book) in(I-book) the(I-book) High(I-book) Castle(I-book) ((O) 1962(O) )(O) is(O) set(O) in(O) an(O) alternate(B-literary_genre) history(I-literary_genre) in(O) which(O) the(O) United(B-country) States(I-country) is(O) ruled(O) by(O) the(O) victorious(O) Axis(O) powers(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, event, award, writer, poem, book, country, location, magazine, person, literary_genre\nGIVEN SENTENCE: The Man in the High Castle ( 1962 ) is set in an alternate history in which the United States is ruled by the victorious Axis powers .\n","prediction_output":null,"prediction_outputs":null,"group":"88","words":["The","Man","in","the","High","Castle","(","1962",")","is","set","in","an","alternate","history","in","which","the","United","States","is","ruled","by","the","victorious","Axis","powers","."],"labels":["B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","B-literary_genre","I-literary_genre","O","O","O","B-country","I-country","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","event","award","writer","poem","book","country","location","magazine","person","literary_genre"]}
{"id":"90.S","dataset":"crossner_literature","split":"dev","instance":{"id":"90.S","prompt_labels":"Confucianism(O) reached(O) its(O) peak(O) of(O) influence(O) during(O) the(O) Tang(B-country) dynasty(I-country) and(O) Song(B-country) dynasty(I-country) Dynasties(O) under(O) a(O) rebranded(O) Confucianism(O) called(O) Neo-Confucianism(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, literary_genre, person, writer, award, organization, magazine, event, book, poem, location\nGIVEN SENTENCE: Confucianism reached its peak of influence during the Tang dynasty and Song dynasty Dynasties under a rebranded Confucianism called Neo-Confucianism .\n","prediction_output":null,"prediction_outputs":null,"group":"90","words":["Confucianism","reached","its","peak","of","influence","during","the","Tang","dynasty","and","Song","dynasty","Dynasties","under","a","rebranded","Confucianism","called","Neo-Confucianism","."],"labels":["O","O","O","O","O","O","O","O","B-country","I-country","O","B-country","I-country","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","literary_genre","person","writer","award","organization","magazine","event","book","poem","location"]}
{"id":"92.S","dataset":"crossner_literature","split":"dev","instance":{"id":"92.S","prompt_labels":"Before(O) writing(O) Dracula(B-book) ,(O) Stoker(B-writer) met(O) Ármin(B-writer) Vámbéry(I-writer) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(B-location) ,(O) Kingdom(B-country) of(I-country) Hungary(I-country) now(O) Svätý(B-location) Jur(I-location) ,(O) Slovakia(B-country) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, event, poem, person, book, country, magazine, award, location, writer, literary_genre\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":null},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"100.S","dataset":"crossner_literature","split":"dev","instance":{"id":"100.S","prompt_labels":"During(O) his(O) first(O) years(O) as(O) bishop(O) ,(O) Athanasius(B-writer) visited(O) the(O) churches(O) of(O) his(O) territory(O) ,(O) which(O) at(O) that(O) time(O) included(O) all(O) of(O) Egypt(B-country) and(O) Libya(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: writer, event, country, award, magazine, person, book, poem, location, organization, literary_genre\nGIVEN SENTENCE: During his first years as bishop , Athanasius visited the churches of his territory , which at that time included all of Egypt and Libya .\n","prediction_output":null,"prediction_outputs":null,"group":"100","words":["During","his","first","years","as","bishop",",","Athanasius","visited","the","churches","of","his","territory",",","which","at","that","time","included","all","of","Egypt","and","Libya","."],"labels":["O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["writer","event","country","award","magazine","person","book","poem","location","organization","literary_genre"]}
{"id":"101.S","dataset":"crossner_literature","split":"dev","instance":{"id":"101.S","prompt_labels":"Nimzowitsch(B-person) 's(O) vanity(O) and(O) faith(O) in(O) his(O) ideas(O) of(O) overprotection(O) provoked(O) Hans(B-person) Kmoch(I-person) to(O) write(O) a(O) parody(O) about(O) him(O) in(O) February(O) 1928(O) in(O) the(O) Wiener(B-magazine) Schachzeitung(I-magazine) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, award, book, person, writer, location, poem, organization, magazine, country, literary_genre\nGIVEN SENTENCE: Nimzowitsch 's vanity and faith in his ideas of overprotection provoked Hans Kmoch to write a parody about him in February 1928 in the Wiener Schachzeitung .\n","prediction_output":null,"prediction_outputs":null,"group":"101","words":["Nimzowitsch","'s","vanity","and","faith","in","his","ideas","of","overprotection","provoked","Hans","Kmoch","to","write","a","parody","about","him","in","February","1928","in","the","Wiener","Schachzeitung","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O"],"target_index":null,"target_label":null},"label_list":["event","award","book","person","writer","location","poem","organization","magazine","country","literary_genre"]}
{"id":"102.S","dataset":"crossner_literature","split":"dev","instance":{"id":"102.S","prompt_labels":"He(O) liked(O) Pedro(B-writer) Calderón(I-writer) de(I-writer) la(I-writer) Barca(I-writer) ,(O) Lope(B-writer) de(I-writer) Vega(I-writer) ,(O) Miguel(B-writer) de(I-writer) Cervantes(I-writer) ,(O) and(O) especially(O) Baltasar(B-writer) Gracián(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, writer, organization, location, event, poem, book, award, country, literary_genre, person\nGIVEN SENTENCE: He liked Pedro Calderón de la Barca , Lope de Vega , Miguel de Cervantes , and especially Baltasar Gracián .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["He","liked","Pedro","Calderón","de","la","Barca",",","Lope","de","Vega",",","Miguel","de","Cervantes",",","and","especially","Baltasar","Gracián","."],"labels":["O","O","B-writer","I-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["magazine","writer","organization","location","event","poem","book","award","country","literary_genre","person"]}
{"id":"107.S","dataset":"crossner_literature","split":"dev","instance":{"id":"107.S","prompt_labels":"The(O) work(O) was(O) such(O) a(O) popular(O) success(O) that(O) the(O) poet(O) wrote(O) a(O) sequel(O) ,(O) Remedia(B-poem) Amoris(I-poem) ((O) Remedies(B-poem) for(I-poem) Love(I-poem) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, location, award, magazine, country, book, writer, poem, person, event, organization\nGIVEN SENTENCE: The work was such a popular success that the poet wrote a sequel , Remedia Amoris ( Remedies for Love ) .\n","prediction_output":null,"prediction_outputs":null,"group":"107","words":["The","work","was","such","a","popular","success","that","the","poet","wrote","a","sequel",",","Remedia","Amoris","(","Remedies","for","Love",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","O","B-poem","I-poem","I-poem","O","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","location","award","magazine","country","book","writer","poem","person","event","organization"]}
{"id":"108.S","dataset":"crossner_literature","split":"dev","instance":{"id":"108.S","prompt_labels":"As(O) early(O) as(O) the(O) 13th(O) century(O) when(O) Dante(B-writer) Alighieri(I-writer) depicted(O) him(O) in(O) Limbo(O) alongside(O) the(O) virtuous(O) non-Christian(O) thinkers(O) in(O) his(O) Divine(B-poem) Comedy(I-poem) such(O) as(O) Virgil(B-person) ,(O) Averroes(B-person) ,(O) Homer(B-person) ,(O) Horace(B-person) ,(O) Ovid(B-person) ,(O) Lucan(B-person) ,(O) Socrates(B-person) ,(O) Plato(B-person) ,(O) and(O) Saladin(B-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, country, person, organization, magazine, award, poem, literary_genre, writer, book, location\nGIVEN SENTENCE: As early as the 13th century when Dante Alighieri depicted him in Limbo alongside the virtuous non-Christian thinkers in his Divine Comedy such as Virgil , Averroes , Homer , Horace , Ovid , Lucan , Socrates , Plato , and Saladin .\n","prediction_output":null,"prediction_outputs":null,"group":"108","words":["As","early","as","the","13th","century","when","Dante","Alighieri","depicted","him","in","Limbo","alongside","the","virtuous","non-Christian","thinkers","in","his","Divine","Comedy","such","as","Virgil",",","Averroes",",","Homer",",","Horace",",","Ovid",",","Lucan",",","Socrates",",","Plato",",","and","Saladin","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","B-poem","I-poem","O","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","B-person","O","O","B-person","O"],"target_index":null,"target_label":null},"label_list":["event","country","person","organization","magazine","award","poem","literary_genre","writer","book","location"]}
{"id":"111.S","dataset":"crossner_literature","split":"dev","instance":{"id":"111.S","prompt_labels":"The(O) three(O) films(O) garnered(O) prestigious(O) international(O) awards(O) ,(O) including(O) the(O) Golden(B-award) Lion(I-award) for(O) Best(O) Film(O) at(O) the(O) Venice(B-event) Film(I-event) Festival(I-event) and(O) the(O) Silver(B-award) Bear(I-award) for(I-award) Best(I-award) Director(I-award) at(O) the(O) 44th(B-event) Berlin(I-event) International(I-event) Film(I-event) Festival(I-event) ,(O) in(O) addition(O) to(O) three(O) Academy(B-award) Awards(I-award) nominations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, organization, award, country, magazine, person, literary_genre, book, writer, event, poem\nGIVEN SENTENCE: The three films garnered prestigious international awards , including the Golden Lion for Best Film at the Venice Film Festival and the Silver Bear for Best Director at the 44th Berlin International Film Festival , in addition to three Academy Awards nominations .\n","prediction_output":null,"prediction_outputs":null,"group":"111","words":["The","three","films","garnered","prestigious","international","awards",",","including","the","Golden","Lion","for","Best","Film","at","the","Venice","Film","Festival","and","the","Silver","Bear","for","Best","Director","at","the","44th","Berlin","International","Film","Festival",",","in","addition","to","three","Academy","Awards","nominations","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O","O","O","B-event","I-event","I-event","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-event","I-event","I-event","I-event","I-event","O","O","O","O","O","B-award","I-award","O","O"],"target_index":null,"target_label":null},"label_list":["location","organization","award","country","magazine","person","literary_genre","book","writer","event","poem"]}
{"id":"115.S","dataset":"crossner_literature","split":"dev","instance":{"id":"115.S","prompt_labels":"He(O) particularly(O) revered(O) Johann(B-writer) Wolfgang(I-writer) von(I-writer) Goethe(I-writer) ,(O) Petrarch(B-writer) ,(O) Pedro(B-writer) Calderón(I-writer) de(I-writer) la(I-writer) Barca(I-writer) and(O) William(B-writer) Shakespeare(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, award, event, magazine, writer, organization, book, location, person, poem, country\nGIVEN SENTENCE: He particularly revered Johann Wolfgang von Goethe , Petrarch , Pedro Calderón de la Barca and William Shakespeare .\n","prediction_output":null,"prediction_outputs":null,"group":"115","words":["He","particularly","revered","Johann","Wolfgang","von","Goethe",",","Petrarch",",","Pedro","Calderón","de","la","Barca","and","William","Shakespeare","."],"labels":["O","O","O","B-writer","I-writer","I-writer","I-writer","O","B-writer","O","B-writer","I-writer","I-writer","I-writer","I-writer","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","award","event","magazine","writer","organization","book","location","person","poem","country"]}
{"id":"118.S","dataset":"crossner_literature","split":"dev","instance":{"id":"118.S","prompt_labels":"Liszt(B-writer) included(O) Weißheimer(B-writer) 's(O) symphony(O) on(O) Friedrich(B-writer) Schiller(I-writer) '(O) s(O) Ritter(B-poem) Toggenburg(I-poem) on(O) the(O) program(O) for(O) the(O) court(O) concerts(O) that(O) he(O) conducted(O) on(O) 13(O) March(O) 1860(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, magazine, person, award, book, event, poem, writer, organization, literary_genre\nGIVEN SENTENCE: Liszt included Weißheimer 's symphony on Friedrich Schiller ' s Ritter Toggenburg on the program for the court concerts that he conducted on 13 March 1860 .\n","prediction_output":null,"prediction_outputs":null,"group":"118","words":["Liszt","included","Weißheimer","'s","symphony","on","Friedrich","Schiller","'","s","Ritter","Toggenburg","on","the","program","for","the","court","concerts","that","he","conducted","on","13","March","1860","."],"labels":["B-writer","O","B-writer","O","O","O","B-writer","I-writer","O","O","B-poem","I-poem","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","country","magazine","person","award","book","event","poem","writer","organization","literary_genre"]}
{"id":"120.S","dataset":"crossner_literature","split":"dev","instance":{"id":"120.S","prompt_labels":"The(O) only(O) completed(O) screenplay(O) ,(O) Heaven(B-book) ,(O) was(O) filmed(O) by(O) Tom(B-person) Tykwer(I-person) and(O) premiered(O) in(O) 2002(O) at(O) the(O) Berlin(B-event) International(I-event) Film(I-event) Festival(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: poem, person, location, literary_genre, country, book, organization, writer, magazine, award, event\nGIVEN SENTENCE: The only completed screenplay , Heaven , was filmed by Tom Tykwer and premiered in 2002 at the Berlin International Film Festival .\n","prediction_output":null,"prediction_outputs":null,"group":"120","words":["The","only","completed","screenplay",",","Heaven",",","was","filmed","by","Tom","Tykwer","and","premiered","in","2002","at","the","Berlin","International","Film","Festival","."],"labels":["O","O","O","O","O","B-book","O","O","O","O","B-person","I-person","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["poem","person","location","literary_genre","country","book","organization","writer","magazine","award","event"]}
{"id":"127.S","dataset":"crossner_literature","split":"dev","instance":{"id":"127.S","prompt_labels":"Federico(B-writer) Fellini(I-writer) ,(O) Burke(B-writer) and(O) Waller(B-writer) ,(O) 12(O) His(O) films(O) have(O) ranked(O) in(O) polls(O) such(O) as(O) Cahiers(B-magazine) du(I-magazine) cinéma(I-magazine) and(O) Sight(B-magazine) &(I-magazine) Sound(I-magazine) ,(O) which(O) lists(O) his(O) 1963(O) film(O) 8(O) ½(O) as(O) the(O) 10th-greatest(O) film(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, event, location, literary_genre, person, poem, magazine, country, award, writer, organization\nGIVEN SENTENCE: Federico Fellini , Burke and Waller , 12 His films have ranked in polls such as Cahiers du cinéma and Sight & Sound , which lists his 1963 film 8 ½ as the 10th-greatest film .\n","prediction_output":null,"prediction_outputs":null,"group":"127","words":["Federico","Fellini",",","Burke","and","Waller",",","12","His","films","have","ranked","in","polls","such","as","Cahiers","du","cinéma","and","Sight","&","Sound",",","which","lists","his","1963","film","8","½","as","the","10th-greatest","film","."],"labels":["B-writer","I-writer","O","B-writer","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["book","event","location","literary_genre","person","poem","magazine","country","award","writer","organization"]}
{"id":"128.S","dataset":"crossner_literature","split":"dev","instance":{"id":"128.S","prompt_labels":"David(B-writer) Lardner(I-writer) worked(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) as(O) a(O) general(O) reporter(O) and(O) war(O) correspondent(O) before(O) he(O) was(O) killed(O) by(O) a(O) landmine(O) near(O) Aachen(B-location) ,(O) Germany(B-country) on(O) October(O) 19(O) ,(O) 1944(O) ,(O) less(O) than(O) one(O) month(O) after(O) his(O) arrival(O) in(O) Europe(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, organization, literary_genre, writer, book, poem, award, event, location, country, magazine\nGIVEN SENTENCE: David Lardner worked for The New Yorker as a general reporter and war correspondent before he was killed by a landmine near Aachen , Germany on October 19 , 1944 , less than one month after his arrival in Europe .\n","prediction_output":null,"prediction_outputs":null,"group":"128","words":["David","Lardner","worked","for","The","New","Yorker","as","a","general","reporter","and","war","correspondent","before","he","was","killed","by","a","landmine","near","Aachen",",","Germany","on","October","19",",","1944",",","less","than","one","month","after","his","arrival","in","Europe","."],"labels":["B-writer","I-writer","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["person","organization","literary_genre","writer","book","poem","award","event","location","country","magazine"]}
{"id":"129.S","dataset":"crossner_literature","split":"dev","instance":{"id":"129.S","prompt_labels":"His(O) most(O) famous(O) works(O) are(O) The(B-book) Book(I-book) of(I-book) Healing(I-book) ,(O) a(O) philosophical(O) and(O) scientific(O) encyclopedia(O) ,(O) and(O) The(B-book) Canon(I-book) of(I-book) Medicine(I-book) ,(O) a(O) medical(O) encyclopedia(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, book, event, literary_genre, organization, country, poem, location, award, writer, person\nGIVEN SENTENCE: His most famous works are The Book of Healing , a philosophical and scientific encyclopedia , and The Canon of Medicine , a medical encyclopedia\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["His","most","famous","works","are","The","Book","of","Healing",",","a","philosophical","and","scientific","encyclopedia",",","and","The","Canon","of","Medicine",",","a","medical","encyclopedia"],"labels":["O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["magazine","book","event","literary_genre","organization","country","poem","location","award","writer","person"]}
{"id":"130.S","dataset":"crossner_literature","split":"dev","instance":{"id":"130.S","prompt_labels":"At(O) the(O) National(B-award) Book(I-award) Award(I-award) s(O) ceremony(O) in(O) November(O) 2014(O) ,(O) Handler(B-writer) made(O) a(O) controversial(O) remark(O) after(O) author(O) Jacqueline(B-writer) Woodson(I-writer) was(O) presented(O) with(O) an(O) award(O) for(O) young(O) people(O) 's(O) literature(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, organization, country, event, location, literary_genre, book, award, person, writer, poem\nGIVEN SENTENCE: At the National Book Award s ceremony in November 2014 , Handler made a controversial remark after author Jacqueline Woodson was presented with an award for young people 's literature .\n","prediction_output":null,"prediction_outputs":null,"group":"130","words":["At","the","National","Book","Award","s","ceremony","in","November","2014",",","Handler","made","a","controversial","remark","after","author","Jacqueline","Woodson","was","presented","with","an","award","for","young","people","'s","literature","."],"labels":["O","O","B-award","I-award","I-award","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["magazine","organization","country","event","location","literary_genre","book","award","person","writer","poem"]}
{"id":"132.S","dataset":"crossner_literature","split":"dev","instance":{"id":"132.S","prompt_labels":"Some(O) of(O) these(O) friends(O) include(O) :(O) David(B-writer) Amram(I-writer) ,(O) Bob(B-writer) Kaufman(I-writer) ;(O) Diane(B-writer) di(I-writer) Prima(I-writer) ;(O) Jim(B-writer) Cohn(I-writer) ;(O) poets(O) associated(O) with(O) the(O) Black(B-organization) Mountain(I-organization) College(I-organization) such(O) as(O) Charles(B-writer) Olson(I-writer) ,(O) Robert(B-writer) Creeley(I-writer) ,(O) and(O) Denise(B-writer) Levertov(I-writer) ;(O) poets(O) associated(O) with(O) the(O) New(B-organization) York(I-organization) School(I-organization) such(O) as(O) Frank(B-writer) O(I-writer) 'Hara(I-writer) and(O) Kenneth(B-writer) Koch(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, book, poem, magazine, event, person, literary_genre, organization, award, location, writer\nGIVEN SENTENCE: Some of these friends include : David Amram , Bob Kaufman ; Diane di Prima ; Jim Cohn ; poets associated with the Black Mountain College such as Charles Olson , Robert Creeley , and Denise Levertov ; poets associated with the New York School such as Frank O 'Hara and Kenneth Koch .\n","prediction_output":null,"prediction_outputs":null,"group":"132","words":["Some","of","these","friends","include",":","David","Amram",",","Bob","Kaufman",";","Diane","di","Prima",";","Jim","Cohn",";","poets","associated","with","the","Black","Mountain","College","such","as","Charles","Olson",",","Robert","Creeley",",","and","Denise","Levertov",";","poets","associated","with","the","New","York","School","such","as","Frank","O","'Hara","and","Kenneth","Koch","."],"labels":["O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","B-writer","I-writer","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["country","book","poem","magazine","event","person","literary_genre","organization","award","location","writer"]}
{"id":"133.S","dataset":"crossner_literature","split":"dev","instance":{"id":"133.S","prompt_labels":"Again(O) ,(O) in(O) the(O) English(B-event) Renaissance(I-event) fantasy(I-event) Armor(B-book) of(I-book) Light(I-book) by(O) Melissa(B-writer) Scott(I-writer) and(O) Lisa(B-writer) A.(I-writer) Barnett(I-writer) ,(O) the(O) magic(O) used(O) in(O) the(O) book(O) ,(O) by(O) Dr.(B-person) John(I-person) Dee(I-person) and(O) others(O) ,(O) actually(O) was(O) practiced(O) in(O) the(O) Renaissance(B-event) ;(O) positing(O) a(O) secret(O) history(O) of(O) effective(O) magic(O) makes(O) this(O) an(O) alternate(B-literary_genre) history(I-literary_genre) with(O) a(O) POD(O) ,(O) Sir(B-person) Philip(I-person) Sidney(I-person) '(O) s(O) surviving(O) the(O) Battle(B-event) of(I-event) Zutphen(I-event) in(O) 1586(O) ,(O) and(O) shortly(O) thereafter(O) saving(O) the(O) life(O) of(O) Christopher(B-person) Marlowe(I-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, person, event, book, country, writer, organization, magazine, award, location, poem\nGIVEN SENTENCE: Again , in the English Renaissance fantasy Armor of Light by Melissa Scott and Lisa A. Barnett , the magic used in the book , by Dr. John Dee and others , actually was practiced in the Renaissance ; positing a secret history of effective magic makes this an alternate history with a POD , Sir Philip Sidney ' s surviving the Battle of Zutphen in 1586 , and shortly thereafter saving the life of Christopher Marlowe .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Again",",","in","the","English","Renaissance","fantasy","Armor","of","Light","by","Melissa","Scott","and","Lisa","A.","Barnett",",","the","magic","used","in","the","book",",","by","Dr.","John","Dee","and","others",",","actually","was","practiced","in","the","Renaissance",";","positing","a","secret","history","of","effective","magic","makes","this","an","alternate","history","with","a","POD",",","Sir","Philip","Sidney","'","s","surviving","the","Battle","of","Zutphen","in","1586",",","and","shortly","thereafter","saving","the","life","of","Christopher","Marlowe","."],"labels":["O","O","O","O","B-event","I-event","I-event","B-book","I-book","I-book","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","B-person","I-person","I-person","O","O","O","O","O","O","O","O","B-event","O","O","O","O","O","O","O","O","O","O","O","B-literary_genre","I-literary_genre","O","O","O","O","B-person","I-person","I-person","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","person","event","book","country","writer","organization","magazine","award","location","poem"]}
{"id":"134.S","dataset":"crossner_literature","split":"dev","instance":{"id":"134.S","prompt_labels":"Disraeli(B-writer) 's(O) early(O) silver(B-literary_genre) fork(I-literary_genre) novels(I-literary_genre) Vivian(B-book) Grey(I-book) ((O) 1826(O) )(O) and(O) The(B-book) Young(I-book) Duke(I-book) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, award, poem, literary_genre, book, magazine, event, person, location, country, writer\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"136.S","dataset":"crossner_literature","split":"dev","instance":{"id":"136.S","prompt_labels":"Investigative(O) journalist(O) Michael(B-writer) Specter(I-writer) ,(O) in(O) an(O) article(O) in(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) on(O) 25(O) August(O) 2014(O) entitled(O) Seeds(O) of(O) Doubt(O) ,(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: poem, magazine, book, event, organization, country, person, award, location, literary_genre, writer\nGIVEN SENTENCE: Investigative journalist Michael Specter , in an article in The New Yorker on 25 August 2014 entitled Seeds of Doubt ,\n","prediction_output":null,"prediction_outputs":null,"group":"136","words":["Investigative","journalist","Michael","Specter",",","in","an","article","in","The","New","Yorker","on","25","August","2014","entitled","Seeds","of","Doubt",","],"labels":["O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["poem","magazine","book","event","organization","country","person","award","location","literary_genre","writer"]}
{"id":"142.S","dataset":"crossner_literature","split":"dev","instance":{"id":"142.S","prompt_labels":"Lerner(B-writer) and(O) Loewe(B-writer) 's(O) run(O) of(O) success(O) continued(O) with(O) their(O) next(O) project(O) ,(O) a(O) film(O) adaptation(O) of(O) stories(O) from(O) Colette(B-writer) ,(O) the(O) Academy(B-award) Awards(I-award) -winning(O) film(O) musical(O) Gigi(O) ,(O) starring(O) Leslie(B-person) Caron(I-person) ,(O) Louis(B-person) Jourdan(I-person) and(O) Maurice(B-person) Chevalier(I-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, event, writer, award, poem, magazine, location, organization, person, literary_genre, country\nGIVEN SENTENCE: Lerner and Loewe 's run of success continued with their next project , a film adaptation of stories from Colette , the Academy Awards -winning film musical Gigi , starring Leslie Caron , Louis Jourdan and Maurice Chevalier .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["Lerner","and","Loewe","'s","run","of","success","continued","with","their","next","project",",","a","film","adaptation","of","stories","from","Colette",",","the","Academy","Awards","-winning","film","musical","Gigi",",","starring","Leslie","Caron",",","Louis","Jourdan","and","Maurice","Chevalier","."],"labels":["B-writer","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","O","O","B-award","I-award","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O"],"target_index":null,"target_label":null},"label_list":["book","event","writer","award","poem","magazine","location","organization","person","literary_genre","country"]}
{"id":"143.S","dataset":"crossner_literature","split":"dev","instance":{"id":"143.S","prompt_labels":"For(O) example(O) ,(O) Susanna(B-writer) Moodie(I-writer) and(O) Catharine(B-writer) Parr(I-writer) Traill(I-writer) ,(O) English(O) sisters(O) who(O) adopted(O) the(O) country(O) as(O) their(O) own(O) ,(O) moved(O) to(O) Upper(B-country) Canada(I-country) in(O) 1832(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: poem, literary_genre, magazine, award, event, person, location, writer, book, country, organization\nGIVEN SENTENCE: For example , Susanna Moodie and Catharine Parr Traill , English sisters who adopted the country as their own , moved to Upper Canada in 1832 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["For","example",",","Susanna","Moodie","and","Catharine","Parr","Traill",",","English","sisters","who","adopted","the","country","as","their","own",",","moved","to","Upper","Canada","in","1832","."],"labels":["O","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O"],"target_index":null,"target_label":null},"label_list":["poem","literary_genre","magazine","award","event","person","location","writer","book","country","organization"]}
{"id":"144.S","dataset":"crossner_literature","split":"dev","instance":{"id":"144.S","prompt_labels":"In(O) a(O) review(O) in(O) The(B-magazine) Dial(I-magazine) ,(O) T.(B-writer) S.(I-writer) Eliot(I-writer) said(O) of(O) Ulysses(B-book) :(O) I(O) hold(O) this(O) book(O) to(O) be(O) the(O) most(O) important(O) expression(O) which(O) the(O) present(O) age(O) has(O) found(O) ;(O) it(O) is(O) a(O) book(O) to(O) which(O) we(O) are(O) all(O) indebted(O) ,(O) and(O) from(O) which(O) none(O) of(O) us(O) can(O) escape(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, location, literary_genre, book, event, award, person, organization, country, poem, writer\nGIVEN SENTENCE: In a review in The Dial , T. S. Eliot said of Ulysses : I hold this book to be the most important expression which the present age has found ; it is a book to which we are all indebted , and from which none of us can escape .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["In","a","review","in","The","Dial",",","T.","S.","Eliot","said","of","Ulysses",":","I","hold","this","book","to","be","the","most","important","expression","which","the","present","age","has","found",";","it","is","a","book","to","which","we","are","all","indebted",",","and","from","which","none","of","us","can","escape","."],"labels":["O","O","O","O","B-magazine","I-magazine","O","B-writer","I-writer","I-writer","O","O","B-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["magazine","location","literary_genre","book","event","award","person","organization","country","poem","writer"]}
{"id":"145.S","dataset":"crossner_literature","split":"dev","instance":{"id":"145.S","prompt_labels":"Spengler(B-person) spent(O) his(O) final(O) years(O) in(O) Munich(B-location) ,(O) listening(O) to(O) Ludwig(B-person) van(I-person) Beethoven(I-person) ,(O) reading(O) Molière(B-writer) and(O) Shakespeare(B-writer) ,(O) buying(O) several(O) thousand(O) books(O) ,(O) and(O) collecting(O) ancient(O) Turkey(B-country) ,(O) Persia(B-country) n(O) and(O) India(B-country) n(O) weapons(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, poem, location, event, organization, country, writer, book, person, magazine, literary_genre\nGIVEN SENTENCE: Spengler spent his final years in Munich , listening to Ludwig van Beethoven , reading Molière and Shakespeare , buying several thousand books , and collecting ancient Turkey , Persia n and India n weapons .\n","prediction_output":null,"prediction_outputs":null,"group":"145","words":["Spengler","spent","his","final","years","in","Munich",",","listening","to","Ludwig","van","Beethoven",",","reading","Molière","and","Shakespeare",",","buying","several","thousand","books",",","and","collecting","ancient","Turkey",",","Persia","n","and","India","n","weapons","."],"labels":["B-person","O","O","O","O","O","B-location","O","O","O","B-person","I-person","I-person","O","O","B-writer","O","B-writer","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","O","B-country","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","poem","location","event","organization","country","writer","book","person","magazine","literary_genre"]}
{"id":"146.S","dataset":"crossner_literature","split":"dev","instance":{"id":"146.S","prompt_labels":"Novelist(O) James(B-writer) Joyce(I-writer) noted(O) that(O) the(O) TRUE(O) symbol(O) of(O) the(O) British(B-country) Empire(I-country) is(O) Robinson(B-book) Crusoe(I-book) ,(O) to(O) whom(O) he(O) ascribed(O) stereotypical(O) and(O) somewhat(O) hostile(O) English(O) racial(O) characteristics(O) :(O) He(O) is(O) the(O) TRUE(O) prototype(O) of(O) the(O) British(O) colonist(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, book, writer, poem, event, organization, magazine, country, award, person, literary_genre\nGIVEN SENTENCE: Novelist James Joyce noted that the TRUE symbol of the British Empire is Robinson Crusoe , to whom he ascribed stereotypical and somewhat hostile English racial characteristics : He is the TRUE prototype of the British colonist .\n","prediction_output":null,"prediction_outputs":null,"group":"146","words":["Novelist","James","Joyce","noted","that","the","TRUE","symbol","of","the","British","Empire","is","Robinson","Crusoe",",","to","whom","he","ascribed","stereotypical","and","somewhat","hostile","English","racial","characteristics",":","He","is","the","TRUE","prototype","of","the","British","colonist","."],"labels":["O","B-writer","I-writer","O","O","O","O","O","O","O","B-country","I-country","O","B-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","book","writer","poem","event","organization","magazine","country","award","person","literary_genre"]}
{"id":"147.S","dataset":"crossner_literature","split":"dev","instance":{"id":"147.S","prompt_labels":"Thompson(B-writer) remains(O) best(O) known(O) for(O) Fear(B-book) and(I-book) Loathing(I-book) in(I-book) Las(I-book) Vegas(I-book) ((O) 1971(O) )(O) ,(O) a(O) book(O) first(O) serialized(O) in(O) Rolling(B-magazine) Stone(I-magazine) in(O) which(O) he(O) grapples(O) with(O) the(O) implications(O) of(O) what(O) he(O) considered(O) the(O) failure(O) of(O) the(O) 1960s(B-event) counterculture(I-event) movement(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: writer, country, award, event, organization, poem, magazine, person, book, literary_genre, location\nGIVEN SENTENCE: Thompson remains best known for Fear and Loathing in Las Vegas ( 1971 ) , a book first serialized in Rolling Stone in which he grapples with the implications of what he considered the failure of the 1960s counterculture movement .\n","prediction_output":null,"prediction_outputs":null,"group":"147","words":["Thompson","remains","best","known","for","Fear","and","Loathing","in","Las","Vegas","(","1971",")",",","a","book","first","serialized","in","Rolling","Stone","in","which","he","grapples","with","the","implications","of","what","he","considered","the","failure","of","the","1960s","counterculture","movement","."],"labels":["B-writer","O","O","O","O","B-book","I-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["writer","country","award","event","organization","poem","magazine","person","book","literary_genre","location"]}
{"id":"149.S","dataset":"crossner_literature","split":"dev","instance":{"id":"149.S","prompt_labels":"Out(O) of(O) public(O) office(O) for(O) the(O) first(O) time(O) since(O) the(O) 1960s(O) ,(O) Bush(B-person) became(O) chairman(O) on(O) the(O) Executive(O) Committee(O) of(O) the(O) First(B-organization) International(I-organization) Bank(I-organization) in(O) Houston.(B-location) continued(O) his(O) membership(O) in(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) ,(O) and(O) joined(O) the(O) Trilateral(B-organization) Commission(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, award, organization, book, literary_genre, location, country, event, magazine, poem, writer\nGIVEN SENTENCE: Out of public office for the first time since the 1960s , Bush became chairman on the Executive Committee of the First International Bank in Houston. continued his membership in the Council on Foreign Relations , and joined the Trilateral Commission .\n","prediction_output":null,"prediction_outputs":null,"group":"149","words":["Out","of","public","office","for","the","first","time","since","the","1960s",",","Bush","became","chairman","on","the","Executive","Committee","of","the","First","International","Bank","in","Houston.","continued","his","membership","in","the","Council","on","Foreign","Relations",",","and","joined","the","Trilateral","Commission","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["person","award","organization","book","literary_genre","location","country","event","magazine","poem","writer"]}
{"id":"152.S","dataset":"crossner_literature","split":"dev","instance":{"id":"152.S","prompt_labels":"Elkin(B-writer) won(O) the(O) National(B-award) Book(I-award) Critics(I-award) Circle(I-award) Award(I-award) on(O) two(O) occasions(O) :(O) for(O) George(B-book) Mills(I-book) in(O) 1982(O) and(O) for(O) Mrs.(B-book) Ted(I-book) Bliss(I-book) ,(O) his(O) last(O) novel(B-literary_genre) ,(O) in(O) 1995(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, award, book, writer, literary_genre, country, location, person, poem, magazine, event\nGIVEN SENTENCE: Elkin won the National Book Critics Circle Award on two occasions : for George Mills in 1982 and for Mrs. Ted Bliss , his last novel , in 1995 .\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["Elkin","won","the","National","Book","Critics","Circle","Award","on","two","occasions",":","for","George","Mills","in","1982","and","for","Mrs.","Ted","Bliss",",","his","last","novel",",","in","1995","."],"labels":["B-writer","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","B-literary_genre","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","award","book","writer","literary_genre","country","location","person","poem","magazine","event"]}
{"id":"153.S","dataset":"crossner_literature","split":"dev","instance":{"id":"153.S","prompt_labels":"In(O) November(O) 1924(O) he(O) was(O) awarded(O) the(O) Nobel(B-award) Prize(I-award) for(I-award) Literature(I-award) over(O) rivals(O) Thomas(B-writer) Mann(I-writer) ,(O) George(B-writer) Bernard(I-writer) Shaw(I-writer) and(O) Thomas(B-writer) Hardy(I-writer) ,(O) after(O) he(O) had(O) been(O) nominated(O) by(O) Anders(B-writer) Österling(I-writer) ,(O) member(O) of(O) the(O) Swedish(B-organization) Academy(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, writer, book, award, poem, country, literary_genre, person, location, organization, magazine\nGIVEN SENTENCE: In November 1924 he was awarded the Nobel Prize for Literature over rivals Thomas Mann , George Bernard Shaw and Thomas Hardy , after he had been nominated by Anders Österling , member of the Swedish Academy .\n","prediction_output":null,"prediction_outputs":null,"group":"153","words":["In","November","1924","he","was","awarded","the","Nobel","Prize","for","Literature","over","rivals","Thomas","Mann",",","George","Bernard","Shaw","and","Thomas","Hardy",",","after","he","had","been","nominated","by","Anders","Österling",",","member","of","the","Swedish","Academy","."],"labels":["O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","B-writer","I-writer","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["event","writer","book","award","poem","country","literary_genre","person","location","organization","magazine"]}
{"id":"154.S","dataset":"crossner_literature","split":"dev","instance":{"id":"154.S","prompt_labels":"Many(O) old(O) and(O) new(O) friends(O) and(O) family(O) showed(O) up(O) to(O) support(O) the(O) Pranksters(O) on(O) this(O) tour(O) ,(O) which(O) took(O) them(O) from(O) Seattle(B-location) 's(O) Bumbershoot(B-event) all(O) along(O) the(O) West(B-location) Coast(I-location) ,(O) including(O) a(O) sold-out(O) two-night(O) run(O) at(O) The(B-location) Fillmore(I-location) in(O) San(B-location) Francisco(I-location) to(O) Boulder(B-location) ,(O) Colorado(B-location) ,(O) where(O) they(O) coaxed(O) the(O) Beat(O) Generation(O) poet(O) Allen(B-writer) Ginsberg(I-writer) into(O) performing(O) with(O) them(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, literary_genre, award, book, writer, organization, country, magazine, event, location, poem\nGIVEN SENTENCE: Many old and new friends and family showed up to support the Pranksters on this tour , which took them from Seattle 's Bumbershoot all along the West Coast , including a sold-out two-night run at The Fillmore in San Francisco to Boulder , Colorado , where they coaxed the Beat Generation poet Allen Ginsberg into performing with them .\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["Many","old","and","new","friends","and","family","showed","up","to","support","the","Pranksters","on","this","tour",",","which","took","them","from","Seattle","'s","Bumbershoot","all","along","the","West","Coast",",","including","a","sold-out","two-night","run","at","The","Fillmore","in","San","Francisco","to","Boulder",",","Colorado",",","where","they","coaxed","the","Beat","Generation","poet","Allen","Ginsberg","into","performing","with","them","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","O","B-event","O","O","O","B-location","I-location","O","O","O","O","O","O","O","B-location","I-location","O","B-location","I-location","O","B-location","O","B-location","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","literary_genre","award","book","writer","organization","country","magazine","event","location","poem"]}
{"id":"157.S","dataset":"crossner_literature","split":"dev","instance":{"id":"157.S","prompt_labels":"In(O) 1987(O) Allan(B-person) Gotthelf(I-person) ,(O) George(B-person) Walsh(I-person) and(O) David(B-person) Kelley(I-person) co-founded(O) the(O) Ayn(B-organization) Rand(I-organization) Society(I-organization) ,(O) a(O) group(O) affiliated(O) with(O) the(O) American(B-organization) Philosophical(I-organization) Association(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, location, writer, person, award, book, poem, event, literary_genre, magazine\nGIVEN SENTENCE: In 1987 Allan Gotthelf , George Walsh and David Kelley co-founded the Ayn Rand Society , a group affiliated with the American Philosophical Association .\n","prediction_output":null,"prediction_outputs":null,"group":"157","words":["In","1987","Allan","Gotthelf",",","George","Walsh","and","David","Kelley","co-founded","the","Ayn","Rand","Society",",","a","group","affiliated","with","the","American","Philosophical","Association","."],"labels":["O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["organization","country","location","writer","person","award","book","poem","event","literary_genre","magazine"]}
{"id":"159.S","dataset":"crossner_literature","split":"dev","instance":{"id":"159.S","prompt_labels":"In(O) 2000(O) ,(O) Anderson(B-writer) starred(O) in(O) the(O) film(O) The(O) House(O) of(O) Mirth(O) with(O) Eric(B-person) Stoltz(I-person) -(O) Terence(B-person) Davies(I-person) '(O) adaptation(O) of(O) the(O) Edith(B-writer) Wharton(I-writer) novel(B-literary_genre) of(O) the(O) The(B-book) House(I-book) of(I-book) Mirth(I-book) -(O) for(O) which(O) she(O) won(O) critical(O) acclaim(O) and(O) awards(O) such(O) as(O) the(O) British(B-award) Independent(I-award) Film(I-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) ,(O) Village(B-award) Voice(I-award) Film(I-award) Poll(I-award) Best(I-award) Lead(I-award) Performance(I-award) ,(O) and(O) a(O) nomination(O) for(O) the(O) National(B-award) Society(I-award) of(I-award) Film(I-award) Critics(I-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, literary_genre, award, location, writer, person, book, event, country, poem, magazine\nGIVEN SENTENCE: In 2000 , Anderson starred in the film The House of Mirth with Eric Stoltz - Terence Davies ' adaptation of the Edith Wharton novel of the The House of Mirth - for which she won critical acclaim and awards such as the British Independent Film Award for Best Actress , Village Voice Film Poll Best Lead Performance , and a nomination for the National Society of Film Critics Award for Best Actress .\n","prediction_output":null,"prediction_outputs":null,"group":"159","words":["In","2000",",","Anderson","starred","in","the","film","The","House","of","Mirth","with","Eric","Stoltz","-","Terence","Davies","'","adaptation","of","the","Edith","Wharton","novel","of","the","The","House","of","Mirth","-","for","which","she","won","critical","acclaim","and","awards","such","as","the","British","Independent","Film","Award","for","Best","Actress",",","Village","Voice","Film","Poll","Best","Lead","Performance",",","and","a","nomination","for","the","National","Society","of","Film","Critics","Award","for","Best","Actress","."],"labels":["O","O","O","B-writer","O","O","O","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","O","O","O","B-writer","I-writer","B-literary_genre","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["organization","literary_genre","award","location","writer","person","book","event","country","poem","magazine"]}
{"id":"161.S","dataset":"crossner_literature","split":"dev","instance":{"id":"161.S","prompt_labels":"Gordon(B-person) continued(O) her(O) stage(O) acting(O) career(O) in(O) the(O) 1950s(O) ,(O) and(O) was(O) nominated(O) for(O) a(O) 1956(O) Tony(B-award) Award(I-award) ,(O) for(O) Tony(B-award) Award(I-award) for(I-award) Best(I-award) Performance(I-award) by(O) a(O) Leading(O) Actress(O) in(O) a(O) Play(O) ,(O) for(O) her(O) portrayal(O) of(O) Dolly(B-person) Levi(I-person) in(O) Thornton(B-writer) Wilder(I-writer) '(O) s(O) The(B-book) Matchmaker(I-book) ,(O) a(O) role(O) she(O) also(O) played(O) in(O) London(B-location) ,(O) Edinburgh(B-location) and(O) Berlin(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, poem, organization, literary_genre, location, event, book, magazine, award, country, writer\nGIVEN SENTENCE: Gordon continued her stage acting career in the 1950s , and was nominated for a 1956 Tony Award , for Tony Award for Best Performance by a Leading Actress in a Play , for her portrayal of Dolly Levi in Thornton Wilder ' s The Matchmaker , a role she also played in London , Edinburgh and Berlin .\n","prediction_output":null,"prediction_outputs":null,"group":"161","words":["Gordon","continued","her","stage","acting","career","in","the","1950s",",","and","was","nominated","for","a","1956","Tony","Award",",","for","Tony","Award","for","Best","Performance","by","a","Leading","Actress","in","a","Play",",","for","her","portrayal","of","Dolly","Levi","in","Thornton","Wilder","'","s","The","Matchmaker",",","a","role","she","also","played","in","London",",","Edinburgh","and","Berlin","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","B-writer","I-writer","O","O","B-book","I-book","O","O","O","O","O","O","O","B-location","O","B-location","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["person","poem","organization","literary_genre","location","event","book","magazine","award","country","writer"]}
{"id":"162.S","dataset":"crossner_literature","split":"dev","instance":{"id":"162.S","prompt_labels":"On(O) February(O) 2(O) ,(O) 1966(O) ,(O) he(O) made(O) his(O) Broadway(B-organization) debut(O) as(O) Harry(B-person) Roat(I-person) ,(I-person) Jr(I-person) in(O) Frederick(B-writer) Knott(I-writer) '(O) s(O) Wait(B-book) Until(I-book) Dark(I-book) at(O) the(O) Ethel(B-location) Barrymore(I-location) Theatre(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, literary_genre, person, poem, award, country, book, location, magazine, organization, writer\nGIVEN SENTENCE: On February 2 , 1966 , he made his Broadway debut as Harry Roat , Jr in Frederick Knott ' s Wait Until Dark at the Ethel Barrymore Theatre .\n","prediction_output":null,"prediction_outputs":null,"group":"162","words":["On","February","2",",","1966",",","he","made","his","Broadway","debut","as","Harry","Roat",",","Jr","in","Frederick","Knott","'","s","Wait","Until","Dark","at","the","Ethel","Barrymore","Theatre","."],"labels":["O","O","O","O","O","O","O","O","O","B-organization","O","O","B-person","I-person","I-person","I-person","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","O","B-location","I-location","I-location","O"],"target_index":null,"target_label":null},"label_list":["event","literary_genre","person","poem","award","country","book","location","magazine","organization","writer"]}
{"id":"164.S","dataset":"crossner_literature","split":"dev","instance":{"id":"164.S","prompt_labels":"In(O) 2005(O) ,(O) Arkham(B-organization) House(I-organization) was(O) awarded(O) the(O) World(B-award) Fantasy(I-award) Award(I-award) for(I-award) Small(I-award) Press(I-award) Achievements(I-award) -(O) the(O) trophy(O) at(O) that(O) time(O) was(O) a(O) bust(O) of(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, person, award, poem, writer, organization, country, book, event, literary_genre, magazine\nGIVEN SENTENCE: In 2005 , Arkham House was awarded the World Fantasy Award for Small Press Achievements - the trophy at that time was a bust of H. P. Lovecraft .\n","prediction_output":null,"prediction_outputs":null,"group":"164","words":["In","2005",",","Arkham","House","was","awarded","the","World","Fantasy","Award","for","Small","Press","Achievements","-","the","trophy","at","that","time","was","a","bust","of","H.","P.","Lovecraft","."],"labels":["O","O","O","B-organization","I-organization","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["location","person","award","poem","writer","organization","country","book","event","literary_genre","magazine"]}
{"id":"165.S","dataset":"crossner_literature","split":"dev","instance":{"id":"165.S","prompt_labels":"In(O) addition(O) to(O) receiving(O) a(O) star(O) on(O) the(O) Hollywood(B-location) Walk(I-location) of(I-location) Fame(I-location) ,(O) media(O) appearances(O) included(O) write-ups(O) in(O) CCM(B-magazine) Magazine(I-magazine) ,(O) and(O) a(O) performance(O) on(O) The(O) View(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, magazine, writer, country, literary_genre, organization, book, location, person, poem, award\nGIVEN SENTENCE: In addition to receiving a star on the Hollywood Walk of Fame , media appearances included write-ups in CCM Magazine , and a performance on The View .\n","prediction_output":null,"prediction_outputs":null,"group":"165","words":["In","addition","to","receiving","a","star","on","the","Hollywood","Walk","of","Fame",",","media","appearances","included","write-ups","in","CCM","Magazine",",","and","a","performance","on","The","View","."],"labels":["O","O","O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","O","O","O","O","B-magazine","I-magazine","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","magazine","writer","country","literary_genre","organization","book","location","person","poem","award"]}
{"id":"167.S","dataset":"crossner_literature","split":"dev","instance":{"id":"167.S","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(B-writer) Conrad(I-writer) '(O) s(O) Heart(B-book) of(I-book) Darkness(I-book) and(O) Lord(B-book) Jim(I-book) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, location, magazine, writer, literary_genre, organization, country, award, person, poem, event\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":null},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"169.S","dataset":"crossner_literature","split":"dev","instance":{"id":"169.S","prompt_labels":"It(O) is(O) based(O) on(O) H.(B-writer) P.(I-writer) Lovecraft(I-writer) '(O) s(O) Cthulhu(O) Mythos(O) ,(O) particularly(O) At(B-book) the(I-book) Mountains(I-book) of(I-book) Madness(I-book) ,(O) and(O) is(O) a(O) follow-up(O) to(O) Infogrames(B-organization) '(O) earlier(O) Shadow(O) of(O) the(O) Comet(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, book, literary_genre, organization, writer, person, poem, award, magazine, location, country\nGIVEN SENTENCE: It is based on H. P. Lovecraft ' s Cthulhu Mythos , particularly At the Mountains of Madness , and is a follow-up to Infogrames ' earlier Shadow of the Comet .\n","prediction_output":null,"prediction_outputs":null,"group":"169","words":["It","is","based","on","H.","P.","Lovecraft","'","s","Cthulhu","Mythos",",","particularly","At","the","Mountains","of","Madness",",","and","is","a","follow-up","to","Infogrames","'","earlier","Shadow","of","the","Comet","."],"labels":["O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","O","B-book","I-book","I-book","I-book","I-book","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","book","literary_genre","organization","writer","person","poem","award","magazine","location","country"]}
{"id":"171.S","dataset":"crossner_literature","split":"dev","instance":{"id":"171.S","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(B-writer) Tagore(I-writer) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(B-country) to(O) include(O) complete(O) India(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, book, event, writer, poem, literary_genre, award, organization, location, person, magazine\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"172.S","dataset":"crossner_literature","split":"dev","instance":{"id":"172.S","prompt_labels":"In(O) 1857(O) ,(O) Dickens(B-writer) hired(O) professional(O) actresses(O) for(O) the(O) play(O) The(B-book) Frozen(I-book) Deep(I-book) ,(O) written(O) by(O) him(O) and(O) his(O) protégé(O) ,(O) Wilkie(B-writer) Collins(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, writer, literary_genre, organization, person, book, location, magazine, poem, event, award\nGIVEN SENTENCE: In 1857 , Dickens hired professional actresses for the play The Frozen Deep , written by him and his protégé , Wilkie Collins .\n","prediction_output":null,"prediction_outputs":null,"group":"172","words":["In","1857",",","Dickens","hired","professional","actresses","for","the","play","The","Frozen","Deep",",","written","by","him","and","his","protégé",",","Wilkie","Collins","."],"labels":["O","O","O","B-writer","O","O","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["country","writer","literary_genre","organization","person","book","location","magazine","poem","event","award"]}
{"id":"173.S","dataset":"crossner_literature","split":"dev","instance":{"id":"173.S","prompt_labels":"A(O) documentary(O) film(O) about(O) Rivers(O) ,(O) Joan(O) Rivers(O) :(O) A(O) Piece(O) of(O) Work(O) ,(O) premiered(O) at(O) the(O) San(B-event) Francisco(I-event) International(I-event) Film(I-event) Festival(I-event) on(O) May(O) 6(O) ,(O) 2010(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, organization, location, country, award, poem, writer, literary_genre, magazine, event, person\nGIVEN SENTENCE: A documentary film about Rivers , Joan Rivers : A Piece of Work , premiered at the San Francisco International Film Festival on May 6 , 2010 .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["A","documentary","film","about","Rivers",",","Joan","Rivers",":","A","Piece","of","Work",",","premiered","at","the","San","Francisco","International","Film","Festival","on","May","6",",","2010","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["book","organization","location","country","award","poem","writer","literary_genre","magazine","event","person"]}
{"id":"176.S","dataset":"crossner_literature","split":"dev","instance":{"id":"176.S","prompt_labels":"Satirical(B-literary_genre) poets(O) outside(O) England(B-country) include(O) Poland(B-country) '(O) s(O) Ignacy(B-writer) Krasicki(I-writer) ,(O) Azerbaijan(B-country) '(O) s(O) Mirza(B-writer) Alakbar(I-writer) Sabir(I-writer) and(O) Portugal(B-country) '(O) s(O) Manuel(B-writer) Maria(I-writer) Barbosa(I-writer) du(I-writer) Bocage(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, literary_genre, organization, country, award, writer, person, location, poem, event, book\nGIVEN SENTENCE: Satirical poets outside England include Poland ' s Ignacy Krasicki , Azerbaijan ' s Mirza Alakbar Sabir and Portugal ' s Manuel Maria Barbosa du Bocage .\n","prediction_output":null,"prediction_outputs":null,"group":"176","words":["Satirical","poets","outside","England","include","Poland","'","s","Ignacy","Krasicki",",","Azerbaijan","'","s","Mirza","Alakbar","Sabir","and","Portugal","'","s","Manuel","Maria","Barbosa","du","Bocage","."],"labels":["B-literary_genre","O","O","B-country","O","B-country","O","O","B-writer","I-writer","O","B-country","O","O","B-writer","I-writer","I-writer","O","B-country","O","O","B-writer","I-writer","I-writer","I-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["magazine","literary_genre","organization","country","award","writer","person","location","poem","event","book"]}
{"id":"178.S","dataset":"crossner_literature","split":"dev","instance":{"id":"178.S","prompt_labels":"Guillaume(B-writer) Apollinaire(I-writer) ,(O) André(B-writer) Salmon(I-writer) and(O) Max(B-writer) Jacob(I-writer) sought(O) him(O) out(O) in(O) his(O) truncated(O) apartment(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, location, book, magazine, person, writer, poem, event, award, literary_genre, country\nGIVEN SENTENCE: Guillaume Apollinaire , André Salmon and Max Jacob sought him out in his truncated apartment .\n","prediction_output":null,"prediction_outputs":null,"group":"178","words":["Guillaume","Apollinaire",",","André","Salmon","and","Max","Jacob","sought","him","out","in","his","truncated","apartment","."],"labels":["B-writer","I-writer","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","location","book","magazine","person","writer","poem","event","award","literary_genre","country"]}
{"id":"179.S","dataset":"crossner_literature","split":"dev","instance":{"id":"179.S","prompt_labels":"It(O) has(O) been(O) credited(O) by(O) American(O) poets(O) like(O) W.(B-writer) S.(I-writer) Merwin(I-writer) ,(O) and(O) American(O) scholars(O) like(O) Clare(B-writer) Cavanagh(I-writer) ,(O) with(O) having(O) a(O) profound(O) impact(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: writer, magazine, person, location, event, poem, award, literary_genre, book, organization, country\nGIVEN SENTENCE: It has been credited by American poets like W. S. Merwin , and American scholars like Clare Cavanagh , with having a profound impact .\n","prediction_output":null,"prediction_outputs":null,"group":"179","words":["It","has","been","credited","by","American","poets","like","W.","S.","Merwin",",","and","American","scholars","like","Clare","Cavanagh",",","with","having","a","profound","impact","."],"labels":["O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["writer","magazine","person","location","event","poem","award","literary_genre","book","organization","country"]}
{"id":"181.S","dataset":"crossner_literature","split":"dev","instance":{"id":"181.S","prompt_labels":"Like(O) his(O) contemporaries(O) Algernon(B-writer) Blackwood(I-writer) and(O) Arthur(B-writer) Machen(I-writer) ,(O) Rohmer(B-writer) claimed(O) membership(O) to(O) one(O) of(O) the(O) factions(O) of(O) the(O) qabbalistic(O) Hermetic(B-organization) Order(I-organization) of(I-organization) the(I-organization) Golden(I-organization) Dawn(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: writer, award, organization, literary_genre, event, magazine, book, poem, location, country, person\nGIVEN SENTENCE: Like his contemporaries Algernon Blackwood and Arthur Machen , Rohmer claimed membership to one of the factions of the qabbalistic Hermetic Order of the Golden Dawn .\n","prediction_output":null,"prediction_outputs":null,"group":"181","words":["Like","his","contemporaries","Algernon","Blackwood","and","Arthur","Machen",",","Rohmer","claimed","membership","to","one","of","the","factions","of","the","qabbalistic","Hermetic","Order","of","the","Golden","Dawn","."],"labels":["O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["writer","award","organization","literary_genre","event","magazine","book","poem","location","country","person"]}
{"id":"183.S","dataset":"crossner_literature","split":"dev","instance":{"id":"183.S","prompt_labels":"The(O) Pulitzer(B-award) Prize(I-award) -winning(O) The(B-book) Grapes(I-book) of(I-book) Wrath(I-book) ((O) 1939(O) )(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, magazine, literary_genre, award, person, writer, poem, location, book, country, organization\nGIVEN SENTENCE: The Pulitzer Prize -winning The Grapes of Wrath ( 1939 )\n","prediction_output":null,"prediction_outputs":null,"group":"183","words":["The","Pulitzer","Prize","-winning","The","Grapes","of","Wrath","(","1939",")"],"labels":["O","B-award","I-award","O","B-book","I-book","I-book","I-book","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","magazine","literary_genre","award","person","writer","poem","location","book","country","organization"]}
{"id":"186.S","dataset":"crossner_literature","split":"dev","instance":{"id":"186.S","prompt_labels":"Thereafter(O) ,(O) the(O) first(O) piece(O) to(O) provide(O) substantial(O) information(O) about(O) Pynchon(B-writer) 's(O) personal(O) life(O) was(O) a(O) biographical(O) account(O) written(O) by(O) a(O) former(O) Cornell(B-organization) University(I-organization) friend(O) ,(O) Jules(B-writer) Siegel(I-writer) ,(O) and(O) published(O) in(O) Playboy(B-magazine) magazine(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: book, magazine, event, poem, literary_genre, location, award, writer, country, person, organization\nGIVEN SENTENCE: Thereafter , the first piece to provide substantial information about Pynchon 's personal life was a biographical account written by a former Cornell University friend , Jules Siegel , and published in Playboy magazine .\n","prediction_output":null,"prediction_outputs":null,"group":"186","words":["Thereafter",",","the","first","piece","to","provide","substantial","information","about","Pynchon","'s","personal","life","was","a","biographical","account","written","by","a","former","Cornell","University","friend",",","Jules","Siegel",",","and","published","in","Playboy","magazine","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-writer","I-writer","O","O","O","O","B-magazine","O","O"],"target_index":null,"target_label":null},"label_list":["book","magazine","event","poem","literary_genre","location","award","writer","country","person","organization"]}
{"id":"187.S","dataset":"crossner_literature","split":"dev","instance":{"id":"187.S","prompt_labels":"H.(B-writer) P.(I-writer) Lovecraft(I-writer) stated(O) that(O) in(O) sheer(O) daemonic(O) strangeness(O) and(O) fertility(O) of(O) conception(O) ,(O) Clark(B-writer) Ashton(I-writer) Smith(I-writer) is(O) perhaps(O) unexcelled(O) ,(O) and(O) Ray(B-writer) Bradbury(I-writer) said(O) that(O) Smith(B-writer) filled(O) my(O) mind(O) with(O) incredible(O) worlds(O) ,(O) impossibly(O) beautiful(O) cities(O) ,(O) and(O) still(O) more(O) fantastic(O) creatures(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, person, award, book, poem, event, literary_genre, writer, country, location, organization\nGIVEN SENTENCE: H. P. Lovecraft stated that in sheer daemonic strangeness and fertility of conception , Clark Ashton Smith is perhaps unexcelled , and Ray Bradbury said that Smith filled my mind with incredible worlds , impossibly beautiful cities , and still more fantastic creatures .\n","prediction_output":null,"prediction_outputs":null,"group":"187","words":["H.","P.","Lovecraft","stated","that","in","sheer","daemonic","strangeness","and","fertility","of","conception",",","Clark","Ashton","Smith","is","perhaps","unexcelled",",","and","Ray","Bradbury","said","that","Smith","filled","my","mind","with","incredible","worlds",",","impossibly","beautiful","cities",",","and","still","more","fantastic","creatures","."],"labels":["B-writer","I-writer","I-writer","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","I-writer","O","O","O","O","O","B-writer","I-writer","O","O","B-writer","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["magazine","person","award","book","poem","event","literary_genre","writer","country","location","organization"]}
{"id":"188.S","dataset":"crossner_literature","split":"dev","instance":{"id":"188.S","prompt_labels":"In(O) September(O) 2006(O) Kenneth(B-person) Branagh(I-person) announced(O) at(O) the(O) Venice(B-event) Film(I-event) Festival(I-event) his(O) new(O) film(O) of(O) the(O) play(O) ,(O) with(O) the(O) screenplay(O) by(O) Nobel(B-award) laureate(O) Harold(B-writer) Pinter(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, magazine, poem, writer, organization, person, book, event, literary_genre, country, location\nGIVEN SENTENCE: In September 2006 Kenneth Branagh announced at the Venice Film Festival his new film of the play , with the screenplay by Nobel laureate Harold Pinter .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["In","September","2006","Kenneth","Branagh","announced","at","the","Venice","Film","Festival","his","new","film","of","the","play",",","with","the","screenplay","by","Nobel","laureate","Harold","Pinter","."],"labels":["O","O","O","B-person","I-person","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O","B-award","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["award","magazine","poem","writer","organization","person","book","event","literary_genre","country","location"]}
{"id":"190.S","dataset":"crossner_literature","split":"dev","instance":{"id":"190.S","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(B-poem) Virgin(I-poem) Carrying(I-poem) a(I-poem) Lantern(I-poem) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, magazine, country, literary_genre, book, person, writer, poem, organization, location, event\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":null},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"191.S","dataset":"crossner_literature","split":"dev","instance":{"id":"191.S","prompt_labels":"Of(O) Things(O) to(O) Come(O) ,(O) The(B-magazine) New(I-magazine) York(I-magazine) Times(I-magazine) Book(I-magazine) Review(I-magazine) ,(O) October(O) 26(O) ,(O) 1975(O) Theodore(B-writer) Sturgeon(I-writer) praised(O) The(B-book) Dispossessed(I-book) as(O) a(O) beautifully(O) written(O) ,(O) beautifully(O) composed(O) book(O) ,(O) saying(O) it(O) performs(O) one(O) of(O) science(B-literary_genre) fiction(I-literary_genre) 's(O) prime(O) functions(O) ,(O) which(O) is(O) to(O) create(O) another(O) kind(O) of(O) social(O) system(O) to(O) see(O) how(O) it(O) would(O) work(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, location, event, magazine, organization, country, poem, award, person, writer, book\nGIVEN SENTENCE: Of Things to Come , The New York Times Book Review , October 26 , 1975 Theodore Sturgeon praised The Dispossessed as a beautifully written , beautifully composed book , saying it performs one of science fiction 's prime functions , which is to create another kind of social system to see how it would work .\n","prediction_output":null,"prediction_outputs":null,"group":"191","words":["Of","Things","to","Come",",","The","New","York","Times","Book","Review",",","October","26",",","1975","Theodore","Sturgeon","praised","The","Dispossessed","as","a","beautifully","written",",","beautifully","composed","book",",","saying","it","performs","one","of","science","fiction","'s","prime","functions",",","which","is","to","create","another","kind","of","social","system","to","see","how","it","would","work","."],"labels":["O","O","O","O","O","B-magazine","I-magazine","I-magazine","I-magazine","I-magazine","I-magazine","O","O","O","O","O","B-writer","I-writer","O","B-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-literary_genre","I-literary_genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","location","event","magazine","organization","country","poem","award","person","writer","book"]}
{"id":"193.S","dataset":"crossner_literature","split":"dev","instance":{"id":"193.S","prompt_labels":"In(O) view(O) of(O) the(O) success(O) of(O) her(O) novels(B-literary_genre) ,(O) particularly(O) Jane(B-book) Eyre(I-book) ,(O) Brontë(B-writer) was(O) persuaded(O) by(O) her(O) publisher(O) to(O) make(O) occasional(O) visits(O) to(O) London(B-location) ,(O) where(O) she(O) revealed(O) her(O) TRUE(O) identity(O) and(O) began(O) to(O) move(O) in(O) more(O) exalted(O) social(O) circles(O) ,(O) becoming(O) friends(O) with(O) Harriet(B-writer) Martineau(I-writer) and(O) Elizabeth(B-writer) Gaskell(I-writer) ,(O) and(O) acquainted(O) with(O) William(B-writer) Makepeace(I-writer) Thackeray(I-writer) and(O) G.H.(B-writer) Lewes(I-writer) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: literary_genre, magazine, writer, poem, event, person, country, location, award, book, organization\nGIVEN SENTENCE: In view of the success of her novels , particularly Jane Eyre , Brontë was persuaded by her publisher to make occasional visits to London , where she revealed her TRUE identity and began to move in more exalted social circles , becoming friends with Harriet Martineau and Elizabeth Gaskell , and acquainted with William Makepeace Thackeray and G.H. Lewes .\n","prediction_output":null,"prediction_outputs":null,"group":"193","words":["In","view","of","the","success","of","her","novels",",","particularly","Jane","Eyre",",","Brontë","was","persuaded","by","her","publisher","to","make","occasional","visits","to","London",",","where","she","revealed","her","TRUE","identity","and","began","to","move","in","more","exalted","social","circles",",","becoming","friends","with","Harriet","Martineau","and","Elizabeth","Gaskell",",","and","acquainted","with","William","Makepeace","Thackeray","and","G.H.","Lewes","."],"labels":["O","O","O","O","O","O","O","B-literary_genre","O","O","B-book","I-book","O","B-writer","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","B-writer","I-writer","O","O","O","O","B-writer","I-writer","I-writer","O","B-writer","I-writer","O"],"target_index":null,"target_label":null},"label_list":["literary_genre","magazine","writer","poem","event","person","country","location","award","book","organization"]}
{"id":"195.S","dataset":"crossner_literature","split":"dev","instance":{"id":"195.S","prompt_labels":"Big(B-person) Brother(I-person) is(O) a(O) fictional(O) character(O) and(O) symbol(O) in(O) George(B-writer) Orwell(I-writer) '(O) s(O) dystopian(B-literary_genre) novel(I-literary_genre) Nineteen(B-book) Eighty-Four(I-book) ,(O) published(O) in(O) 1949(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, book, writer, country, literary_genre, location, organization, event, person, award, poem\nGIVEN SENTENCE: Big Brother is a fictional character and symbol in George Orwell ' s dystopian novel Nineteen Eighty-Four , published in 1949 .\n","prediction_output":null,"prediction_outputs":null,"group":"195","words":["Big","Brother","is","a","fictional","character","and","symbol","in","George","Orwell","'","s","dystopian","novel","Nineteen","Eighty-Four",",","published","in","1949","."],"labels":["B-person","I-person","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["magazine","book","writer","country","literary_genre","location","organization","event","person","award","poem"]}
{"id":"196.S","dataset":"crossner_literature","split":"dev","instance":{"id":"196.S","prompt_labels":"In(O) May(O) 1999(O) ,(O) after(O) the(O) Council(B-organization) of(I-organization) Fashion(I-organization) Designers(I-organization) of(I-organization) America(I-organization) recognized(O) Cher(B-writer) with(O) an(O) award(O) for(O) her(O) influence(O) on(O) fashion(O) ,(O) Robin(B-writer) Givhan(I-writer) of(O) the(O) Los(B-organization) Angeles(I-organization) Times(I-organization) called(O) her(O) a(O) fashion(O) visionary(O) for(O) striking(O) just(O) the(O) right(O) note(O) of(O) contemporary(O) wretched(O) excess(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, person, magazine, writer, country, event, literary_genre, book, award, location, poem\nGIVEN SENTENCE: In May 1999 , after the Council of Fashion Designers of America recognized Cher with an award for her influence on fashion , Robin Givhan of the Los Angeles Times called her a fashion visionary for striking just the right note of contemporary wretched excess .\n","prediction_output":null,"prediction_outputs":null,"group":"196","words":["In","May","1999",",","after","the","Council","of","Fashion","Designers","of","America","recognized","Cher","with","an","award","for","her","influence","on","fashion",",","Robin","Givhan","of","the","Los","Angeles","Times","called","her","a","fashion","visionary","for","striking","just","the","right","note","of","contemporary","wretched","excess","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-writer","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","person","magazine","writer","country","event","literary_genre","book","award","location","poem"]}
{"id":"197.S","dataset":"crossner_literature","split":"dev","instance":{"id":"197.S","prompt_labels":"Adams(B-writer) 's(O) posthumously(O) published(O) work(O) ,(O) The(B-book) Salmon(I-book) of(I-book) Doubt(I-book) ,(O) features(O) several(O) articles(O) by(O) him(O) on(O) the(O) subject(O) of(O) technology(O) ,(O) including(O) reprints(O) of(O) articles(O) that(O) originally(O) ran(O) in(O) MacUser(B-magazine) magazine(O) ,(O) and(O) in(O) The(B-organization) Independent(I-organization) on(I-organization) Sunday(I-organization) newspaper(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, poem, award, literary_genre, location, writer, magazine, organization, event, country, book\nGIVEN SENTENCE: Adams 's posthumously published work , The Salmon of Doubt , features several articles by him on the subject of technology , including reprints of articles that originally ran in MacUser magazine , and in The Independent on Sunday newspaper .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Adams","'s","posthumously","published","work",",","The","Salmon","of","Doubt",",","features","several","articles","by","him","on","the","subject","of","technology",",","including","reprints","of","articles","that","originally","ran","in","MacUser","magazine",",","and","in","The","Independent","on","Sunday","newspaper","."],"labels":["B-writer","O","O","O","O","O","B-book","I-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-magazine","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O"],"target_index":null,"target_label":null},"label_list":["person","poem","award","literary_genre","location","writer","magazine","organization","event","country","book"]}
{"id":"198.S","dataset":"crossner_literature","split":"dev","instance":{"id":"198.S","prompt_labels":"When(O) Martin(B-writer) Gardner(I-writer) retired(O) from(O) writing(O) his(O) Mathematical(B-book) Games(I-book) column(O) for(O) Scientific(B-magazine) American(I-magazine) magazine(O) ,(O) Hofstadter(B-writer) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(B-book) Themas(I-book) ((O) an(O) anagram(O) of(O) Mathematical(B-book) Games(I-book) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: magazine, event, literary_genre, person, location, country, poem, award, writer, book, organization\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":null},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"2.S","dataset":"crossner_music","split":"dev","instance":{"id":"2.S","prompt_labels":"During(O) the(O) 1990s(O) ,(O) many(O) releases(O) included(O) recordings(O) of(O) classical(O) compositions(O) :(O) Pictures(B-song) at(I-song) an(I-song) Exhibition(I-song) ((O) on(O) Turn(B-album) of(I-album) the(I-album) Tides(I-album) )(O) ,(O) Largo(B-song) ((O) from(O) Xerxes(O) )(O) ((O) on(O) Tyranny(B-album) of(I-album) Beauty(I-album) )(O) ,(O) Symphony(B-song) in(I-song) A(I-song) Minor(I-song) ((O) by(O) J.(B-musical_artist) S.(I-musical_artist) Bach(I-musical_artist) )(O) ,(O) and(O) Concerto(B-song) in(I-song) A(I-song) Major(I-song) /(I-song) Adagio(I-song) ((O) by(O) Wolfgang(B-musical_artist) Amadeus(I-musical_artist) Mozart(I-musical_artist) )(O) ((O) both(O) on(O) Ambient(B-album) Monkeys(I-album) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, person, album, song, musical_instrument, event, country, band, award, musical_artist, location, organization\nGIVEN SENTENCE: During the 1990s , many releases included recordings of classical compositions : Pictures at an Exhibition ( on Turn of the Tides ) , Largo ( from Xerxes ) ( on Tyranny of Beauty ) , Symphony in A Minor ( by J. S. Bach ) , and Concerto in A Major / Adagio ( by Wolfgang Amadeus Mozart ) ( both on Ambient Monkeys ) .\n","prediction_output":null,"prediction_outputs":null,"group":"2","words":["During","the","1990s",",","many","releases","included","recordings","of","classical","compositions",":","Pictures","at","an","Exhibition","(","on","Turn","of","the","Tides",")",",","Largo","(","from","Xerxes",")","(","on","Tyranny","of","Beauty",")",",","Symphony","in","A","Minor","(","by","J.","S.","Bach",")",",","and","Concerto","in","A","Major","/","Adagio","(","by","Wolfgang","Amadeus","Mozart",")","(","both","on","Ambient","Monkeys",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","O","O","B-album","I-album","I-album","I-album","O","O","B-song","O","O","O","O","O","O","B-album","I-album","I-album","O","O","B-song","I-song","I-song","I-song","O","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song","O","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","B-album","I-album","O","O"],"target_index":null,"target_label":null},"label_list":["music_genre","person","album","song","musical_instrument","event","country","band","award","musical_artist","location","organization"]}
{"id":"5.S","dataset":"crossner_music","split":"dev","instance":{"id":"5.S","prompt_labels":"His(O) style(O) incorporates(O) elements(O) of(O) Rock(B-music_genre) music(I-music_genre) ,(O) blues(B-music_genre) ,(O) Soul(B-music_genre) music(I-music_genre) ,(O) R(B-music_genre) &(I-music_genre) B(I-music_genre) ,(O) funk(B-music_genre) ,(O) jazz(B-music_genre) ,(O) reggae(B-music_genre) ,(O) hard(B-music_genre) rock(I-music_genre) ,(O) Psychedelic(B-music_genre) rock(I-music_genre) ,(O) Pop(B-music_genre) music(I-music_genre) ,(O) Folk(B-music_genre) music(I-music_genre) ,(O) and(O) ballads(B-music_genre) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, organization, location, award, band, musical_artist, musical_instrument, music_genre, country, album, event, song\nGIVEN SENTENCE: His style incorporates elements of Rock music , blues , Soul music , R & B , funk , jazz , reggae , hard rock , Psychedelic rock , Pop music , Folk music , and ballads .\n","prediction_output":null,"prediction_outputs":null,"group":"5","words":["His","style","incorporates","elements","of","Rock","music",",","blues",",","Soul","music",",","R","&","B",",","funk",",","jazz",",","reggae",",","hard","rock",",","Psychedelic","rock",",","Pop","music",",","Folk","music",",","and","ballads","."],"labels":["O","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","O","B-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","O","B-music_genre","O"],"target_index":null,"target_label":null},"label_list":["person","organization","location","award","band","musical_artist","musical_instrument","music_genre","country","album","event","song"]}
{"id":"8.S","dataset":"crossner_music","split":"dev","instance":{"id":"8.S","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, musical_artist, country, person, band, event, album, song, location, musical_instrument, organization, music_genre\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":null},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"9.S","dataset":"crossner_music","split":"dev","instance":{"id":"9.S","prompt_labels":"Ernest(B-musical_artist) Jennings(I-musical_artist) Ford(I-musical_artist) ((O) February(O) 13(O) ,(O) 1919(O) -(O) October(O) 17(O) ,(O) 1991(O) )(O) ,(O) known(O) professionally(O) as(O) Tennessee(B-musical_artist) Ernie(I-musical_artist) Ford(I-musical_artist) ,(O) was(O) an(O) American(O) singer(O) and(O) television(O) host(O) who(O) enjoyed(O) success(O) in(O) the(O) Country(B-music_genre) music(I-music_genre) ,(O) Pop(B-music_genre) music(I-music_genre) ,(O) and(O) Gospel(B-music_genre) music(I-music_genre) musical(O) genres(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, location, musical_artist, musical_instrument, song, album, music_genre, organization, band, award, country, person\nGIVEN SENTENCE: Ernest Jennings Ford ( February 13 , 1919 - October 17 , 1991 ) , known professionally as Tennessee Ernie Ford , was an American singer and television host who enjoyed success in the Country music , Pop music , and Gospel music musical genres .\n","prediction_output":null,"prediction_outputs":null,"group":"9","words":["Ernest","Jennings","Ford","(","February","13",",","1919","-","October","17",",","1991",")",",","known","professionally","as","Tennessee","Ernie","Ford",",","was","an","American","singer","and","television","host","who","enjoyed","success","in","the","Country","music",",","Pop","music",",","and","Gospel","music","musical","genres","."],"labels":["B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","O","B-music_genre","I-music_genre","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","location","musical_artist","musical_instrument","song","album","music_genre","organization","band","award","country","person"]}
{"id":"11.S","dataset":"crossner_music","split":"dev","instance":{"id":"11.S","prompt_labels":"Some(O) of(O) his(O) most(O) celebrated(O) designs(O) adorned(O) the(O) sleeves(O) of(O) albums(O) such(O) as(O) Midnight(B-album) Blue(I-album) ,(O) Out(B-album) to(I-album) Lunch(I-album) !(I-album) ,(O) Unity(B-album) ,(O) Somethin(B-album) '(I-album) Else(I-album) ,(O) Let(B-album) Freedom(I-album) Ring(I-album) ,(O) Hub-Tones(B-album) ,(O) No(B-album) Room(I-album) for(I-album) Squares(I-album) ,(O) Cool(B-album) Struttin(I-album) '(I-album) ,(O) and(O) The(B-album) Sidewinder(I-album) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, location, album, musical_instrument, country, music_genre, event, song, band, musical_artist, person, organization\nGIVEN SENTENCE: Some of his most celebrated designs adorned the sleeves of albums such as Midnight Blue , Out to Lunch ! , Unity , Somethin ' Else , Let Freedom Ring , Hub-Tones , No Room for Squares , Cool Struttin ' , and The Sidewinder .\n","prediction_output":null,"prediction_outputs":null,"group":"11","words":["Some","of","his","most","celebrated","designs","adorned","the","sleeves","of","albums","such","as","Midnight","Blue",",","Out","to","Lunch","!",",","Unity",",","Somethin","'","Else",",","Let","Freedom","Ring",",","Hub-Tones",",","No","Room","for","Squares",",","Cool","Struttin","'",",","and","The","Sidewinder","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","B-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","I-album","O","O","B-album","I-album","O"],"target_index":null,"target_label":null},"label_list":["award","location","album","musical_instrument","country","music_genre","event","song","band","musical_artist","person","organization"]}
{"id":"13.S","dataset":"crossner_music","split":"dev","instance":{"id":"13.S","prompt_labels":"Although(O) his(O) bandmate(O) Martin(B-musical_artist) Gore(I-musical_artist) continues(O) to(O) be(O) the(O) main(O) songwriter(O) for(O) Depeche(B-band) Mode(I-band) ,(O) Gahan(B-musical_artist) has(O) contributed(O) a(O) number(O) of(O) songs(O) to(O) the(O) albums(O) Playing(B-album) the(I-album) Angel(I-album) ((O) 2005(O) )(O) ,(O) Sounds(B-album) of(I-album) the(I-album) Universe(I-album) ((O) 2009(O) )(O) ,(O) Delta(B-album) Machine(I-album) ((O) 2013(O) )(O) and(O) Spirit(B-album) ((O) 2017(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, music_genre, song, event, musical_instrument, organization, location, musical_artist, award, band, person, album\nGIVEN SENTENCE: Although his bandmate Martin Gore continues to be the main songwriter for Depeche Mode , Gahan has contributed a number of songs to the albums Playing the Angel ( 2005 ) , Sounds of the Universe ( 2009 ) , Delta Machine ( 2013 ) and Spirit ( 2017 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["Although","his","bandmate","Martin","Gore","continues","to","be","the","main","songwriter","for","Depeche","Mode",",","Gahan","has","contributed","a","number","of","songs","to","the","albums","Playing","the","Angel","(","2005",")",",","Sounds","of","the","Universe","(","2009",")",",","Delta","Machine","(","2013",")","and","Spirit","(","2017",")","."],"labels":["O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-band","I-band","O","B-musical_artist","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","B-album","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","music_genre","song","event","musical_instrument","organization","location","musical_artist","award","band","person","album"]}
{"id":"15.S","dataset":"crossner_music","split":"dev","instance":{"id":"15.S","prompt_labels":"The(O) best-selling(O) album(O) in(O) the(O) band(O) 's(O) catalog(O) ,(O) I(O) Against(B-album) I(O) is(O) an(O) album(O) that(O) mixes(O) American(O) hardcore(B-music_genre) punk(I-music_genre) with(O) funk(B-music_genre) ,(O) Soul(B-music_genre) music(I-music_genre) ,(O) reggae(B-music_genre) and(O) Heavy(B-music_genre) metal(I-music_genre) music(I-music_genre) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, song, country, organization, musical_artist, music_genre, location, person, award, musical_instrument, album, event\nGIVEN SENTENCE: The best-selling album in the band 's catalog , I Against I is an album that mixes American hardcore punk with funk , Soul music , reggae and Heavy metal music .\n","prediction_output":null,"prediction_outputs":null,"group":"15","words":["The","best-selling","album","in","the","band","'s","catalog",",","I","Against","I","is","an","album","that","mixes","American","hardcore","punk","with","funk",",","Soul","music",",","reggae","and","Heavy","metal","music","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-album","O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","I-music_genre","I-music_genre","O"],"target_index":null,"target_label":null},"label_list":["band","song","country","organization","musical_artist","music_genre","location","person","award","musical_instrument","album","event"]}
{"id":"19.S","dataset":"crossner_music","split":"dev","instance":{"id":"19.S","prompt_labels":"The(O) film(O) was(O) nominated(O) for(O) the(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) as(O) well(O) as(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) ((O) Carroll(B-person) Clark(I-person) and(O) Van(B-person) Nest(I-person) Polglase(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) ((O) Irving(B-musical_artist) Berlin(I-musical_artist) for(O) Cheek(B-song) to(I-song) Cheek(I-song) )(O) ,(O) and(O) Dance(B-award) Direction(I-award) ((O) Hermes(B-person) Pan(I-person) for(O) Piccolino(O) and(O) Top(O) Hat(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, person, musical_artist, country, award, event, location, band, music_genre, musical_instrument, album, song\nGIVEN SENTENCE: The film was nominated for the Academy Awards for Academy Award for Best Picture , as well as Academy Award for Best Production Design ( Carroll Clark and Van Nest Polglase ) , Academy Award for Best Original Song ( Irving Berlin for Cheek to Cheek ) , and Dance Direction ( Hermes Pan for Piccolino and Top Hat ) .\n","prediction_output":null,"prediction_outputs":null,"group":"19","words":["The","film","was","nominated","for","the","Academy","Awards","for","Academy","Award","for","Best","Picture",",","as","well","as","Academy","Award","for","Best","Production","Design","(","Carroll","Clark","and","Van","Nest","Polglase",")",",","Academy","Award","for","Best","Original","Song","(","Irving","Berlin","for","Cheek","to","Cheek",")",",","and","Dance","Direction","(","Hermes","Pan","for","Piccolino","and","Top","Hat",")","."],"labels":["O","O","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","B-person","I-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-musical_artist","I-musical_artist","O","B-song","I-song","I-song","O","O","O","B-award","I-award","O","B-person","I-person","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","person","musical_artist","country","award","event","location","band","music_genre","musical_instrument","album","song"]}
{"id":"20.S","dataset":"crossner_music","split":"dev","instance":{"id":"20.S","prompt_labels":"It(O) received(O) 14(O) nominations(O) at(O) the(O) 89th(B-award) Academy(I-award) Awards(I-award) ,(O) tying(O) the(O) record(O) for(O) most(O) nominations(O) with(O) All(O) About(O) Eve(O) ((O) 1950(O) )(O) and(O) Titanic(O) ((O) 1997(O) )(O) ,(O) and(O) won(O) the(O) awards(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) ,(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, award, band, location, song, music_genre, event, album, musical_artist, organization, musical_instrument, country\nGIVEN SENTENCE: It received 14 nominations at the 89th Academy Awards , tying the record for most nominations with All About Eve ( 1950 ) and Titanic ( 1997 ) , and won the awards for Academy Award for Best Director , Academy Award for Best Actress , Academy Award for Best Cinematography , Academy Award for Best Original Score , Academy Award for Best Original Song , and Academy Award for Best Production Design .\n","prediction_output":null,"prediction_outputs":null,"group":"20","words":["It","received","14","nominations","at","the","89th","Academy","Awards",",","tying","the","record","for","most","nominations","with","All","About","Eve","(","1950",")","and","Titanic","(","1997",")",",","and","won","the","awards","for","Academy","Award","for","Best","Director",",","Academy","Award","for","Best","Actress",",","Academy","Award","for","Best","Cinematography",",","Academy","Award","for","Best","Original","Score",",","Academy","Award","for","Best","Original","Song",",","and","Academy","Award","for","Best","Production","Design","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["person","award","band","location","song","music_genre","event","album","musical_artist","organization","musical_instrument","country"]}
{"id":"21.S","dataset":"crossner_music","split":"dev","instance":{"id":"21.S","prompt_labels":"Western(B-music_genre) music(I-music_genre) artists(O) such(O) as(O) Michael(B-musical_artist) Martin(I-musical_artist) Murphey(I-musical_artist) ,(O) and(O) artists(O) within(O) the(O) aforementioned(O) styles(O) and(O) genres(O) ,(O) have(O) seen(O) continued(O) success(O) throughout(O) their(O) respective(O) fields(O) ,(O) including(O) the(O) likes(O) of(O) The(B-band) Great(I-band) Divide(I-band) ,(O) Lorenzo(B-musical_artist) Antonio(I-musical_artist) ,(O) Sparx(B-band) ,(O) Pat(B-musical_artist) Green(I-musical_artist) ,(O) and(O) Jack(B-musical_artist) Ingram(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, music_genre, musical_artist, award, person, event, country, organization, song, album, location, musical_instrument\nGIVEN SENTENCE: Western music artists such as Michael Martin Murphey , and artists within the aforementioned styles and genres , have seen continued success throughout their respective fields , including the likes of The Great Divide , Lorenzo Antonio , Sparx , Pat Green , and Jack Ingram .\n","prediction_output":null,"prediction_outputs":null,"group":"21","words":["Western","music","artists","such","as","Michael","Martin","Murphey",",","and","artists","within","the","aforementioned","styles","and","genres",",","have","seen","continued","success","throughout","their","respective","fields",",","including","the","likes","of","The","Great","Divide",",","Lorenzo","Antonio",",","Sparx",",","Pat","Green",",","and","Jack","Ingram","."],"labels":["B-music_genre","I-music_genre","O","O","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","B-band","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["band","music_genre","musical_artist","award","person","event","country","organization","song","album","location","musical_instrument"]}
{"id":"22.S","dataset":"crossner_music","split":"dev","instance":{"id":"22.S","prompt_labels":"The(O) band(O) have(O) received(O) seven(O) Grammy(B-award) Award(I-award) s(O) ,(O) four(O) Brit(B-award) Awards(I-award) ,(O) an(O) Academy(B-award) Award(I-award) ((O) for(O) Best(B-award) Original(I-award) Song(I-award) Score(I-award) for(O) the(O) 1970(O) film(O) Let(O) It(O) Be(O) )(O) and(O) fifteen(O) Ivor(B-award) Novello(I-award) Awards(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, person, song, country, musical_instrument, award, band, musical_artist, organization, album, event, music_genre\nGIVEN SENTENCE: The band have received seven Grammy Award s , four Brit Awards , an Academy Award ( for Best Original Song Score for the 1970 film Let It Be ) and fifteen Ivor Novello Awards .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["The","band","have","received","seven","Grammy","Award","s",",","four","Brit","Awards",",","an","Academy","Award","(","for","Best","Original","Song","Score","for","the","1970","film","Let","It","Be",")","and","fifteen","Ivor","Novello","Awards","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["location","person","song","country","musical_instrument","award","band","musical_artist","organization","album","event","music_genre"]}
{"id":"23.S","dataset":"crossner_music","split":"dev","instance":{"id":"23.S","prompt_labels":"She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(O) comedy(O) Roman(O) Holiday(O) ((O) 1953(O) )(O) ,(O) alongside(O) Gregory(B-person) Peck(I-person) ,(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award) ,(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award) ,(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, band, music_genre, country, location, musical_instrument, award, person, song, musical_artist, album, event\nGIVEN SENTENCE: She rose to stardom in the romantic comedy Roman Holiday ( 1953 ) , alongside Gregory Peck , for which she was the first actress to win an Academy Awards , a Golden Globe Awards , and a British Academy Film Awards for a single performance .\n","prediction_output":null,"prediction_outputs":null,"group":"23","words":["She","rose","to","stardom","in","the","romantic","comedy","Roman","Holiday","(","1953",")",",","alongside","Gregory","Peck",",","for","which","she","was","the","first","actress","to","win","an","Academy","Awards",",","a","Golden","Globe","Awards",",","and","a","British","Academy","Film","Awards","for","a","single","performance","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","band","music_genre","country","location","musical_instrument","award","person","song","musical_artist","album","event"]}
{"id":"26.S","dataset":"crossner_music","split":"dev","instance":{"id":"26.S","prompt_labels":"Special(O) guests(O) were(O) Pete(B-musical_artist) Seeger(I-musical_artist) ,(O) Bonnie(B-musical_artist) Raitt(I-musical_artist) ,(O) David(B-musical_artist) Bromberg(I-musical_artist) and(O) Jerry(B-musical_artist) Jeff(I-musical_artist) Walker(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, band, musical_artist, music_genre, organization, musical_instrument, song, award, location, album, person, country\nGIVEN SENTENCE: Special guests were Pete Seeger , Bonnie Raitt , David Bromberg and Jerry Jeff Walker .\n","prediction_output":null,"prediction_outputs":null,"group":"26","words":["Special","guests","were","Pete","Seeger",",","Bonnie","Raitt",",","David","Bromberg","and","Jerry","Jeff","Walker","."],"labels":["O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["event","band","musical_artist","music_genre","organization","musical_instrument","song","award","location","album","person","country"]}
{"id":"27.S","dataset":"crossner_music","split":"dev","instance":{"id":"27.S","prompt_labels":"Under(O) the(O) current(O) voting(O) system(O) ,(O) in(O) place(O) since(O) 2016(O) ,(O) the(O) highest-scoring(O) winner(O) is(O) Salvador(B-musical_artist) Sobral(I-musical_artist) of(O) Portugal(B-country) who(O) won(O) the(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2017(I-event) in(O) Kiev(B-location) ,(O) Ukraine(B-country) ,(O) with(O) 758(O) points(O) ;(O) under(O) the(O) previous(O) system(O) ,(O) the(O) highest-scoring(O) winner(O) was(O) Alexander(B-musical_artist) Rybak(I-musical_artist) of(O) Norway(B-country) with(O) 387(O) points(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2009(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, event, musical_instrument, music_genre, song, award, person, organization, country, musical_artist, album, location\nGIVEN SENTENCE: Under the current voting system , in place since 2016 , the highest-scoring winner is Salvador Sobral of Portugal who won the Eurovision Song Contest 2017 in Kiev , Ukraine , with 758 points ; under the previous system , the highest-scoring winner was Alexander Rybak of Norway with 387 points in Eurovision Song Contest 2009 .\n","prediction_output":null,"prediction_outputs":null,"group":"27","words":["Under","the","current","voting","system",",","in","place","since","2016",",","the","highest-scoring","winner","is","Salvador","Sobral","of","Portugal","who","won","the","Eurovision","Song","Contest","2017","in","Kiev",",","Ukraine",",","with","758","points",";","under","the","previous","system",",","the","highest-scoring","winner","was","Alexander","Rybak","of","Norway","with","387","points","in","Eurovision","Song","Contest","2009","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-country","O","O","O","B-event","I-event","I-event","I-event","O","B-location","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-country","O","O","O","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["band","event","musical_instrument","music_genre","song","award","person","organization","country","musical_artist","album","location"]}
{"id":"30.S","dataset":"crossner_music","split":"dev","instance":{"id":"30.S","prompt_labels":"Some(O) modern(O) artists(O) that(O) primarily(O) or(O) entirely(O) produce(O) country(B-music_genre) pop(I-music_genre) music(I-music_genre) include(O) Kacey(B-musical_artist) Musgraves(I-musical_artist) ,(O) Maren(B-musical_artist) Morris(I-musical_artist) ,(O) Kelsea(B-musical_artist) Ballerini(I-musical_artist) ,(O) Sam(B-musical_artist) Hunt(I-musical_artist) ,(O) Kane(B-musical_artist) Brown(I-musical_artist) ,(O) Chris(B-musical_artist) Lane(I-musical_artist) ,(O) and(O) Dan(B-band) +(I-band) Shay(I-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, song, album, musical_instrument, country, organization, band, award, musical_artist, person, location, event\nGIVEN SENTENCE: Some modern artists that primarily or entirely produce country pop music include Kacey Musgraves , Maren Morris , Kelsea Ballerini , Sam Hunt , Kane Brown , Chris Lane , and Dan + Shay .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["Some","modern","artists","that","primarily","or","entirely","produce","country","pop","music","include","Kacey","Musgraves",",","Maren","Morris",",","Kelsea","Ballerini",",","Sam","Hunt",",","Kane","Brown",",","Chris","Lane",",","and","Dan","+","Shay","."],"labels":["O","O","O","O","O","O","O","O","B-music_genre","I-music_genre","I-music_genre","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-band","I-band","I-band","O"],"target_index":null,"target_label":null},"label_list":["music_genre","song","album","musical_instrument","country","organization","band","award","musical_artist","person","location","event"]}
{"id":"31.S","dataset":"crossner_music","split":"dev","instance":{"id":"31.S","prompt_labels":"In(O) the(O) summer(O) of(O) 2004(O) ,(O) Diab(B-musical_artist) ,(O) having(O) left(O) Alam(B-organization) El(I-organization) Phan(I-organization) ,(O) released(O) his(O) first(O) album(O) with(O) Rotana(B-organization) Records(I-organization) ,(O) Leily(B-album) Nahary(I-album) ,(O) which(O) he(O) followed(O) up(O) with(O) the(O) hugely(O) successful(O) Kammel(B-album) Kalamak(I-album) ((O) 2005(O) )(O) ,(O) and(O) El(B-album) Lilady(I-album) ((O) 2007(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, band, music_genre, country, award, organization, song, album, musical_instrument, person, event, musical_artist\nGIVEN SENTENCE: In the summer of 2004 , Diab , having left Alam El Phan , released his first album with Rotana Records , Leily Nahary , which he followed up with the hugely successful Kammel Kalamak ( 2005 ) , and El Lilady ( 2007 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"31","words":["In","the","summer","of","2004",",","Diab",",","having","left","Alam","El","Phan",",","released","his","first","album","with","Rotana","Records",",","Leily","Nahary",",","which","he","followed","up","with","the","hugely","successful","Kammel","Kalamak","(","2005",")",",","and","El","Lilady","(","2007",")","."],"labels":["O","O","O","O","O","O","B-musical_artist","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","O","B-album","I-album","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O","B-album","I-album","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","band","music_genre","country","award","organization","song","album","musical_instrument","person","event","musical_artist"]}
{"id":"32.S","dataset":"crossner_music","split":"dev","instance":{"id":"32.S","prompt_labels":"Four(O) singles(O) -(O) Until(B-song) It(I-song) Sleeps(I-song) ,(O) Hero(B-song) of(I-song) the(I-song) Day(I-song) ,(O) Mama(B-song) Said(I-song) ,(O) and(O) King(B-song) Nothing(I-song) -(O) were(O) released(O) as(O) part(O) of(O) the(O) marketing(O) campaign(O) for(O) the(O) album(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, song, musical_instrument, album, person, musical_artist, location, country, event, award, band, music_genre\nGIVEN SENTENCE: Four singles - Until It Sleeps , Hero of the Day , Mama Said , and King Nothing - were released as part of the marketing campaign for the album .\n","prediction_output":null,"prediction_outputs":null,"group":"32","words":["Four","singles","-","Until","It","Sleeps",",","Hero","of","the","Day",",","Mama","Said",",","and","King","Nothing","-","were","released","as","part","of","the","marketing","campaign","for","the","album","."],"labels":["O","O","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","O","O","B-song","I-song","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","song","musical_instrument","album","person","musical_artist","location","country","event","award","band","music_genre"]}
{"id":"37.S","dataset":"crossner_music","split":"dev","instance":{"id":"37.S","prompt_labels":"Several(O) albums(O) that(O) continued(O) this(O) style(O) ,(O) which(O) had(O) come(O) to(O) be(O) known(O) as(O) technical(B-music_genre) thrash(I-music_genre) metal(I-music_genre) ,(O) were(O) released(O) in(O) 1991(O) ,(O) such(O) as(O) Overkill(B-band) 's(O) Horrorscope(B-album) ,(O) Heathen(B-band) '(O) s(O) Victims(B-album) of(I-album) Deception(I-album) ,(O) Dark(B-band) Angel(I-band) '(O) s(O) Time(B-album) Does(I-album) Not(I-album) Heal(I-album) ,(O) Sepultura(B-band) 's(O) Arise(B-album) ,(O) and(O) Coroner(B-band) 's(O) Mental(B-album) Vortex(I-album) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, musical_instrument, location, musical_artist, band, music_genre, person, organization, award, song, country, album\nGIVEN SENTENCE: Several albums that continued this style , which had come to be known as technical thrash metal , were released in 1991 , such as Overkill 's Horrorscope , Heathen ' s Victims of Deception , Dark Angel ' s Time Does Not Heal , Sepultura 's Arise , and Coroner 's Mental Vortex .\n","prediction_output":null,"prediction_outputs":null,"group":"37","words":["Several","albums","that","continued","this","style",",","which","had","come","to","be","known","as","technical","thrash","metal",",","were","released","in","1991",",","such","as","Overkill","'s","Horrorscope",",","Heathen","'","s","Victims","of","Deception",",","Dark","Angel","'","s","Time","Does","Not","Heal",",","Sepultura","'s","Arise",",","and","Coroner","'s","Mental","Vortex","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music_genre","I-music_genre","I-music_genre","O","O","O","O","O","O","O","O","B-band","O","B-album","O","B-band","O","O","B-album","I-album","I-album","O","B-band","I-band","O","O","B-album","I-album","I-album","I-album","O","B-band","O","B-album","O","O","B-band","O","B-album","I-album","O"],"target_index":null,"target_label":null},"label_list":["event","musical_instrument","location","musical_artist","band","music_genre","person","organization","award","song","country","album"]}
{"id":"38.S","dataset":"crossner_music","split":"dev","instance":{"id":"38.S","prompt_labels":"Burton(B-person) 's(O) work(O) on(O) Sweeney(O) Todd(O) won(O) the(O) National(B-award) Board(I-award) of(I-award) Review(I-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) ,(O) and(O) won(O) an(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, music_genre, person, musical_artist, organization, country, event, album, award, musical_instrument, song, location\nGIVEN SENTENCE: Burton 's work on Sweeney Todd won the National Board of Review Award for Best Director , and won an Academy Awards for Academy Award for Best Production Design .\n","prediction_output":null,"prediction_outputs":null,"group":"38","words":["Burton","'s","work","on","Sweeney","Todd","won","the","National","Board","of","Review","Award","for","Best","Director",",","and","won","an","Academy","Awards","for","Academy","Award","for","Best","Production","Design","."],"labels":["B-person","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["band","music_genre","person","musical_artist","organization","country","event","album","award","musical_instrument","song","location"]}
{"id":"39.S","dataset":"crossner_music","split":"dev","instance":{"id":"39.S","prompt_labels":"It(O) received(O) a(O) total(O) of(O) 13(O) Academy(B-award) Awards(I-award) nominations(O) ,(O) including(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) -(O) a(O) record(O) for(O) any(O) film(O) released(O) by(O) Walt(B-organization) Disney(I-organization) Studios(I-organization) -(O) and(O) won(O) five(O) :(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) for(O) Andrews(B-person) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Film(I-award) Editing(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Visual(I-award) Effects(I-award) ,(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) for(O) Chim(B-song) Chim(I-song) Cher-ee(I-song) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, musical_artist, organization, location, song, award, event, country, band, person, album, musical_instrument\nGIVEN SENTENCE: It received a total of 13 Academy Awards nominations , including Academy Award for Best Picture - a record for any film released by Walt Disney Studios - and won five : Academy Award for Best Actress for Andrews , Academy Award for Best Film Editing , Academy Award for Best Original Score , Academy Award for Best Visual Effects , and Academy Award for Best Original Song for Chim Chim Cher-ee .\n","prediction_output":null,"prediction_outputs":null,"group":"39","words":["It","received","a","total","of","13","Academy","Awards","nominations",",","including","Academy","Award","for","Best","Picture","-","a","record","for","any","film","released","by","Walt","Disney","Studios","-","and","won","five",":","Academy","Award","for","Best","Actress","for","Andrews",",","Academy","Award","for","Best","Film","Editing",",","Academy","Award","for","Best","Original","Score",",","Academy","Award","for","Best","Visual","Effects",",","and","Academy","Award","for","Best","Original","Song","for","Chim","Chim","Cher-ee","."],"labels":["O","O","O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-person","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-song","I-song","I-song","O"],"target_index":null,"target_label":null},"label_list":["music_genre","musical_artist","organization","location","song","award","event","country","band","person","album","musical_instrument"]}
{"id":"40.S","dataset":"crossner_music","split":"dev","instance":{"id":"40.S","prompt_labels":"Notable(O) rockabilly(B-music_genre) revivalists(O) and(O) psychobilly(B-music_genre) performers(O) from(O) the(O) 1990s(O) and(O) first(O) decade(O) of(O) the(O) 21st(O) century(O) include(O) Scott(B-musical_artist) Owen(I-musical_artist) ((O) from(O) the(O) Australian(O) band(O) The(B-band) Living(I-band) End(I-band) )(O) ,(O) Jimbo(B-musical_artist) Wallace(I-musical_artist) ((O) from(O) the(O) US(B-country) band(O) Reverend(B-band) Horton(I-band) Heat(I-band) )(O) ,(O) Kim(B-musical_artist) Nekroman(I-musical_artist) ((O) Nekromantix(B-band) )(O) ,(O) Patricia(B-musical_artist) Day(I-musical_artist) ((O) HorrorPops(B-band) )(O) ,(O) Geoff(B-musical_artist) Kresge(I-musical_artist) ((O) Tiger(B-band) Army(I-band) ,(O) ex-(O) AFI(B-band) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, country, location, musical_artist, album, award, band, song, musical_instrument, organization, music_genre, person\nGIVEN SENTENCE: Notable rockabilly revivalists and psychobilly performers from the 1990s and first decade of the 21st century include Scott Owen ( from the Australian band The Living End ) , Jimbo Wallace ( from the US band Reverend Horton Heat ) , Kim Nekroman ( Nekromantix ) , Patricia Day ( HorrorPops ) , Geoff Kresge ( Tiger Army , ex- AFI ) .\n","prediction_output":null,"prediction_outputs":null,"group":"40","words":["Notable","rockabilly","revivalists","and","psychobilly","performers","from","the","1990s","and","first","decade","of","the","21st","century","include","Scott","Owen","(","from","the","Australian","band","The","Living","End",")",",","Jimbo","Wallace","(","from","the","US","band","Reverend","Horton","Heat",")",",","Kim","Nekroman","(","Nekromantix",")",",","Patricia","Day","(","HorrorPops",")",",","Geoff","Kresge","(","Tiger","Army",",","ex-","AFI",")","."],"labels":["O","B-music_genre","O","O","B-music_genre","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","B-band","I-band","I-band","O","O","B-musical_artist","I-musical_artist","O","O","O","B-country","O","B-band","I-band","I-band","O","O","B-musical_artist","I-musical_artist","O","B-band","O","O","B-musical_artist","I-musical_artist","O","B-band","O","O","B-musical_artist","I-musical_artist","O","B-band","I-band","O","O","B-band","O","O"],"target_index":null,"target_label":null},"label_list":["event","country","location","musical_artist","album","award","band","song","musical_instrument","organization","music_genre","person"]}
{"id":"41.S","dataset":"crossner_music","split":"dev","instance":{"id":"41.S","prompt_labels":"In(O) 2009(O) ,(O) Paltrow(B-musical_artist) received(O) a(O) Grammy(B-award) Award(I-award) nomination(O) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Spoken(I-award) Word(I-award) Album(I-award) for(I-award) Children(I-award) for(O) the(O) children(O) 's(O) audiobook(O) Brown(O) Bear(O) and(O) Friends(O) and(O) won(O) the(O) Primetime(B-award) Emmy(I-award) Award(I-award) for(I-award) Outstanding(I-award) Guest(I-award) Actress(I-award) in(I-award) a(I-award) Comedy(I-award) Series(I-award) for(O) her(O) guest(O) role(O) as(O) Holly(B-person) Holliday(I-person) on(O) the(O) Fox(O) musical(O) comedy-drama(O) television(O) series(O) Glee(O) in(O) 2011(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, event, organization, person, band, musical_artist, country, location, award, album, music_genre, musical_instrument\nGIVEN SENTENCE: In 2009 , Paltrow received a Grammy Award nomination for Grammy Award for Best Spoken Word Album for Children for the children 's audiobook Brown Bear and Friends and won the Primetime Emmy Award for Outstanding Guest Actress in a Comedy Series for her guest role as Holly Holliday on the Fox musical comedy-drama television series Glee in 2011 .\n","prediction_output":null,"prediction_outputs":null,"group":"41","words":["In","2009",",","Paltrow","received","a","Grammy","Award","nomination","for","Grammy","Award","for","Best","Spoken","Word","Album","for","Children","for","the","children","'s","audiobook","Brown","Bear","and","Friends","and","won","the","Primetime","Emmy","Award","for","Outstanding","Guest","Actress","in","a","Comedy","Series","for","her","guest","role","as","Holly","Holliday","on","the","Fox","musical","comedy-drama","television","series","Glee","in","2011","."],"labels":["O","O","O","B-musical_artist","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["song","event","organization","person","band","musical_artist","country","location","award","album","music_genre","musical_instrument"]}
{"id":"42.S","dataset":"crossner_music","split":"dev","instance":{"id":"42.S","prompt_labels":"In(O) 1956(O) ,(O) the(O) arrival(O) of(O) rockabilly(O) was(O) underlined(O) by(O) the(O) success(O) of(O) songs(O) like(O) Folsom(B-song) Prison(I-song) Blues(I-song) by(O) Johnny(B-musical_artist) Cash(I-musical_artist) ,(O) Blue(B-song) Suede(I-song) Shoes(I-song) by(O) Perkins(B-musical_artist) and(O) the(O) No.(O) 1(O) hit(O) Heartbreak(B-song) Hotel(I-song) by(O) Presley(B-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: album, location, song, award, person, event, music_genre, musical_artist, musical_instrument, country, band, organization\nGIVEN SENTENCE: In 1956 , the arrival of rockabilly was underlined by the success of songs like Folsom Prison Blues by Johnny Cash , Blue Suede Shoes by Perkins and the No. 1 hit Heartbreak Hotel by Presley .\n","prediction_output":null,"prediction_outputs":null,"group":"42","words":["In","1956",",","the","arrival","of","rockabilly","was","underlined","by","the","success","of","songs","like","Folsom","Prison","Blues","by","Johnny","Cash",",","Blue","Suede","Shoes","by","Perkins","and","the","No.","1","hit","Heartbreak","Hotel","by","Presley","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-song","I-song","I-song","O","B-musical_artist","I-musical_artist","O","B-song","I-song","I-song","O","B-musical_artist","O","O","O","O","O","B-song","I-song","O","B-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["album","location","song","award","person","event","music_genre","musical_artist","musical_instrument","country","band","organization"]}
{"id":"43.S","dataset":"crossner_music","split":"dev","instance":{"id":"43.S","prompt_labels":"Olympia(B-album) 71(I-album) ,(O) Olympia(B-album) 74(I-album) ,(O) and(O) Olympia(B-album) 77(I-album) are(O) live(O) albums(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, band, award, album, music_genre, song, person, organization, musical_instrument, location, musical_artist, country\nGIVEN SENTENCE: Olympia 71 , Olympia 74 , and Olympia 77 are live albums .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Olympia","71",",","Olympia","74",",","and","Olympia","77","are","live","albums","."],"labels":["B-album","I-album","O","B-album","I-album","O","O","B-album","I-album","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","band","award","album","music_genre","song","person","organization","musical_instrument","location","musical_artist","country"]}
{"id":"44.S","dataset":"crossner_music","split":"dev","instance":{"id":"44.S","prompt_labels":"There(O) are(O) many(O) kinds(O) of(O) bubens(B-musical_instrument) ,(O) including(O) def(B-musical_instrument) ,(O) daf(B-musical_instrument) ,(O) or(O) qaval(B-musical_instrument) ((O) Azerbaijan(B-country) )(O) ,(O) daf(B-musical_instrument) or(O) khaval(B-musical_instrument) ((O) Armenia(B-country) )(O) ,(O) daira(B-musical_instrument) ((O) Georgia(B-country) )(O) ,(O) doira(B-musical_instrument) ((O) Uzbekistan(B-country) and(O) Tajikistan(B-country) )(O) ,(O) daire(B-musical_instrument) or(O) def(B-musical_instrument) ((O) Iran(B-country) )(O) ,(O) bendeir(B-musical_instrument) ((O) Arab(O) countries(O) )(O) ,(O) pandero(B-musical_instrument) ((O) Spain(B-country) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, musical_artist, country, award, album, organization, location, band, musical_instrument, event, person, song\nGIVEN SENTENCE: There are many kinds of bubens , including def , daf , or qaval ( Azerbaijan ) , daf or khaval ( Armenia ) , daira ( Georgia ) , doira ( Uzbekistan and Tajikistan ) , daire or def ( Iran ) , bendeir ( Arab countries ) , pandero ( Spain ) .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["There","are","many","kinds","of","bubens",",","including","def",",","daf",",","or","qaval","(","Azerbaijan",")",",","daf","or","khaval","(","Armenia",")",",","daira","(","Georgia",")",",","doira","(","Uzbekistan","and","Tajikistan",")",",","daire","or","def","(","Iran",")",",","bendeir","(","Arab","countries",")",",","pandero","(","Spain",")","."],"labels":["O","O","O","O","O","B-musical_instrument","O","O","B-musical_instrument","O","B-musical_instrument","O","O","B-musical_instrument","O","B-country","O","O","B-musical_instrument","O","B-musical_instrument","O","B-country","O","O","B-musical_instrument","O","B-country","O","O","B-musical_instrument","O","B-country","O","B-country","O","O","B-musical_instrument","O","B-musical_instrument","O","B-country","O","O","B-musical_instrument","O","O","O","O","O","B-musical_instrument","O","B-country","O","O"],"target_index":null,"target_label":null},"label_list":["music_genre","musical_artist","country","award","album","organization","location","band","musical_instrument","event","person","song"]}
{"id":"45.S","dataset":"crossner_music","split":"dev","instance":{"id":"45.S","prompt_labels":"The(O) venue(O) hosted(O) Badminton(B-event) at(I-event) the(I-event) 2012(I-event) Summer(I-event) Olympics(I-event) and(O) Gymnastics(B-event) at(I-event) the(I-event) 2012(I-event) Summer(I-event) Olympics(I-event) at(O) the(O) 2012(B-event) Summer(I-event) Olympics(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, music_genre, person, award, event, band, song, musical_instrument, organization, musical_artist, album, country\nGIVEN SENTENCE: The venue hosted Badminton at the 2012 Summer Olympics and Gymnastics at the 2012 Summer Olympics at the 2012 Summer Olympics .\n","prediction_output":null,"prediction_outputs":null,"group":"45","words":["The","venue","hosted","Badminton","at","the","2012","Summer","Olympics","and","Gymnastics","at","the","2012","Summer","Olympics","at","the","2012","Summer","Olympics","."],"labels":["O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","I-event","I-event","O","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["location","music_genre","person","award","event","band","song","musical_instrument","organization","musical_artist","album","country"]}
{"id":"47.S","dataset":"crossner_music","split":"dev","instance":{"id":"47.S","prompt_labels":"One(O) of(O) the(O) main(O) differences(O) between(O) American(O) and(O) European(O) pop(B-music_genre) is(O) that(O) Europop(B-music_genre) is(O) generally(O) more(O) Dance(B-music_genre) music(I-music_genre) and(O) Trance(B-music_genre) music(I-music_genre) oriented(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, musical_artist, location, album, musical_instrument, award, song, band, country, organization, person, event\nGIVEN SENTENCE: One of the main differences between American and European pop is that Europop is generally more Dance music and Trance music oriented .\n","prediction_output":null,"prediction_outputs":null,"group":"47","words":["One","of","the","main","differences","between","American","and","European","pop","is","that","Europop","is","generally","more","Dance","music","and","Trance","music","oriented","."],"labels":["O","O","O","O","O","O","O","O","O","B-music_genre","O","O","B-music_genre","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","O"],"target_index":null,"target_label":null},"label_list":["music_genre","musical_artist","location","album","musical_instrument","award","song","band","country","organization","person","event"]}
{"id":"50.S","dataset":"crossner_music","split":"dev","instance":{"id":"50.S","prompt_labels":"Castellano(B-musical_artist) switched(O) to(O) rhythm(B-musical_instrument) guitar(I-musical_instrument) and(O) keyboards(B-musical_instrument) ((O) Castellano(B-musical_artist) also(O) filled(O) in(O) on(O) lead(O) guitar(B-musical_instrument) and(O) vocals(O) for(O) an(O) ailing(O) Buck(B-musical_artist) Dharma(I-musical_artist) in(O) two(O) shows(O) in(O) 2005(O) )(O) ,(O) and(O) the(O) position(O) of(O) bassist(O) was(O) taken(O) up(O) by(O) Rudy(B-musical_artist) Sarzo(I-musical_artist) ((O) previously(O) a(O) member(O) of(O) Quiet(B-band) Riot(I-band) ,(O) Whitesnake(B-band) ,(O) Ozzy(B-musical_artist) Osbourne(I-musical_artist) and(O) Dio(B-musical_artist) )(O) ,(O) with(O) the(O) band(O) employing(O) Danny(B-musical_artist) Miranda(I-musical_artist) and(O) Jon(B-musical_artist) Rogers(I-musical_artist) as(O) guest(O) bassists(O) to(O) fill(O) in(O) when(O) Sarzo(B-musical_artist) was(O) unavailable(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, event, musical_artist, location, award, music_genre, band, musical_instrument, organization, song, album\nGIVEN SENTENCE: Castellano switched to rhythm guitar and keyboards ( Castellano also filled in on lead guitar and vocals for an ailing Buck Dharma in two shows in 2005 ) , and the position of bassist was taken up by Rudy Sarzo ( previously a member of Quiet Riot , Whitesnake , Ozzy Osbourne and Dio ) , with the band employing Danny Miranda and Jon Rogers as guest bassists to fill in when Sarzo was unavailable .\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["Castellano","switched","to","rhythm","guitar","and","keyboards","(","Castellano","also","filled","in","on","lead","guitar","and","vocals","for","an","ailing","Buck","Dharma","in","two","shows","in","2005",")",",","and","the","position","of","bassist","was","taken","up","by","Rudy","Sarzo","(","previously","a","member","of","Quiet","Riot",",","Whitesnake",",","Ozzy","Osbourne","and","Dio",")",",","with","the","band","employing","Danny","Miranda","and","Jon","Rogers","as","guest","bassists","to","fill","in","when","Sarzo","was","unavailable","."],"labels":["B-musical_artist","O","O","B-musical_instrument","I-musical_instrument","O","B-musical_instrument","O","B-musical_artist","O","O","O","O","O","B-musical_instrument","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","B-band","I-band","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","country","event","musical_artist","location","award","music_genre","band","musical_instrument","organization","song","album"]}
{"id":"51.S","dataset":"crossner_music","split":"dev","instance":{"id":"51.S","prompt_labels":"This(O) album(O) featured(O) vocal(O) contributions(O) by(O) Vicotnik(B-musical_artist) of(O) Ved(B-band) Buens(I-band) Ende(I-band) and(O) Dødheimsgard(B-band) and(O) Aldrahn(B-musical_artist) of(O) Dødheimsgard(B-band) and(O) Zyklon-B(B-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_instrument, country, organization, song, event, album, music_genre, band, location, award, musical_artist, person\nGIVEN SENTENCE: This album featured vocal contributions by Vicotnik of Ved Buens Ende and Dødheimsgard and Aldrahn of Dødheimsgard and Zyklon-B .\n","prediction_output":null,"prediction_outputs":null,"group":"51","words":["This","album","featured","vocal","contributions","by","Vicotnik","of","Ved","Buens","Ende","and","Dødheimsgard","and","Aldrahn","of","Dødheimsgard","and","Zyklon-B","."],"labels":["O","O","O","O","O","O","B-musical_artist","O","B-band","I-band","I-band","O","B-band","O","B-musical_artist","O","B-band","O","B-band","O"],"target_index":null,"target_label":null},"label_list":["musical_instrument","country","organization","song","event","album","music_genre","band","location","award","musical_artist","person"]}
{"id":"55.S","dataset":"crossner_music","split":"dev","instance":{"id":"55.S","prompt_labels":"The(O) film(O) won(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) ((O) James(B-person) Cagney(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Sound(I-award) Mixing(I-award) ((O) Nathan(B-musical_artist) Levinson(I-musical_artist) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, album, music_genre, location, person, musical_artist, band, event, musical_instrument, award, country, organization\nGIVEN SENTENCE: The film won Academy Awards for Academy Award for Best Actor ( James Cagney ) , Academy Award for Best Original Score and Academy Award for Best Sound Mixing ( Nathan Levinson ) .\n","prediction_output":null,"prediction_outputs":null,"group":"55","words":["The","film","won","Academy","Awards","for","Academy","Award","for","Best","Actor","(","James","Cagney",")",",","Academy","Award","for","Best","Original","Score","and","Academy","Award","for","Best","Sound","Mixing","(","Nathan","Levinson",")","."],"labels":["O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-musical_artist","I-musical_artist","O","O"],"target_index":null,"target_label":null},"label_list":["song","album","music_genre","location","person","musical_artist","band","event","musical_instrument","award","country","organization"]}
{"id":"59.S","dataset":"crossner_music","split":"dev","instance":{"id":"59.S","prompt_labels":"Since(O) TG(B-band) has(O) permanently(O) disbanded(O) following(O) the(O) death(O) of(O) Christopherson(B-musical_artist) ,(O) the(O) label(O) 's(O) plan(O) is(O) to(O) re-release(O) the(O) original(O) TG(B-band) albums(O) ((O) The(B-album) Second(I-album) Annual(I-album) Report(I-album) ,(O) D.o.A(B-album) :(I-album) The(I-album) Third(I-album) and(I-album) Final(I-album) Report(I-album) ,(O) 20(B-album) Jazz(I-album) Funk(I-album) Greats(I-album) ,(O) Heathen(B-album) Earth(I-album) and(O) Greatest(B-album) Hits(I-album) )(O) on(O) the(O) label(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, event, award, location, musical_artist, band, person, song, album, musical_instrument, organization, music_genre\nGIVEN SENTENCE: Since TG has permanently disbanded following the death of Christopherson , the label 's plan is to re-release the original TG albums ( The Second Annual Report , D.o.A : The Third and Final Report , 20 Jazz Funk Greats , Heathen Earth and Greatest Hits ) on the label .\n","prediction_output":null,"prediction_outputs":null,"group":"59","words":["Since","TG","has","permanently","disbanded","following","the","death","of","Christopherson",",","the","label","'s","plan","is","to","re-release","the","original","TG","albums","(","The","Second","Annual","Report",",","D.o.A",":","The","Third","and","Final","Report",",","20","Jazz","Funk","Greats",",","Heathen","Earth","and","Greatest","Hits",")","on","the","label","."],"labels":["O","B-band","O","O","O","O","O","O","O","B-musical_artist","O","O","O","O","O","O","O","O","O","O","B-band","O","O","B-album","I-album","I-album","I-album","O","B-album","I-album","I-album","I-album","I-album","I-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","I-album","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","event","award","location","musical_artist","band","person","song","album","musical_instrument","organization","music_genre"]}
{"id":"60.S","dataset":"crossner_music","split":"dev","instance":{"id":"60.S","prompt_labels":"Boogie(B-band) Down(I-band) and(O) KRS(B-musical_artist) retorted(O) angrily(O) with(O) songs(O) such(O) as(O) The(B-song) Bridge(I-song) is(I-song) Over(I-song) and(O) South(B-song) Bronx(I-song) ,(O) which(O) started(O) one(O) of(O) the(O) first(O) notable(O) hip(B-music_genre) hop(I-music_genre) wars(O) as(O) MC(B-musical_artist) Shan(I-musical_artist) ,(O) Marley(B-musical_artist) Marl(I-musical_artist) ,(O) Roxanne(B-musical_artist) Shanté(I-musical_artist) and(O) Blaq(B-musical_artist) Poet(I-musical_artist) all(O) released(O) songs(O) featuring(O) verses(O) personally(O) attacking(O) KRS(B-musical_artist) and(O) Scott(B-musical_artist) La(I-musical_artist) Rock(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, person, album, song, award, musical_artist, country, music_genre, event, organization, musical_instrument, band\nGIVEN SENTENCE: Boogie Down and KRS retorted angrily with songs such as The Bridge is Over and South Bronx , which started one of the first notable hip hop wars as MC Shan , Marley Marl , Roxanne Shanté and Blaq Poet all released songs featuring verses personally attacking KRS and Scott La Rock .\n","prediction_output":null,"prediction_outputs":null,"group":"60","words":["Boogie","Down","and","KRS","retorted","angrily","with","songs","such","as","The","Bridge","is","Over","and","South","Bronx",",","which","started","one","of","the","first","notable","hip","hop","wars","as","MC","Shan",",","Marley","Marl",",","Roxanne","Shanté","and","Blaq","Poet","all","released","songs","featuring","verses","personally","attacking","KRS","and","Scott","La","Rock","."],"labels":["B-band","I-band","O","B-musical_artist","O","O","O","O","O","O","B-song","I-song","I-song","I-song","O","B-song","I-song","O","O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["location","person","album","song","award","musical_artist","country","music_genre","event","organization","musical_instrument","band"]}
{"id":"61.S","dataset":"crossner_music","split":"dev","instance":{"id":"61.S","prompt_labels":"Other(O) top-10(O) entries(O) from(O) 2015(O) like(O) Mark(B-musical_artist) Ronson(I-musical_artist) '(O) s(O) disco(B-song) groove-infused(I-song) Uptown(B-song) Funk(I-song) ,(O) Maroon(B-band) 5(I-band) '(O) s(O) Sugar(B-song) ,(O) the(B-band) Weeknd(I-band) '(O) s(O) Can(B-song) 't(I-song) Feel(I-song) My(I-song) Face(I-song) and(O) Jason(B-musical_artist) Derulo(I-musical_artist) '(O) s(O) Want(B-song) to(I-song) Want(I-song) Me(I-song) also(O) ascended(O) the(O) charts(O) and(O) have(O) a(O) strong(O) disco(B-music_genre) influence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, music_genre, country, organization, event, location, person, album, award, musical_instrument, band, musical_artist\nGIVEN SENTENCE: Other top-10 entries from 2015 like Mark Ronson ' s disco groove-infused Uptown Funk , Maroon 5 ' s Sugar , the Weeknd ' s Can 't Feel My Face and Jason Derulo ' s Want to Want Me also ascended the charts and have a strong disco influence .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Other","top-10","entries","from","2015","like","Mark","Ronson","'","s","disco","groove-infused","Uptown","Funk",",","Maroon","5","'","s","Sugar",",","the","Weeknd","'","s","Can","'t","Feel","My","Face","and","Jason","Derulo","'","s","Want","to","Want","Me","also","ascended","the","charts","and","have","a","strong","disco","influence","."],"labels":["O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","B-song","I-song","B-song","I-song","O","B-band","I-band","O","O","B-song","O","B-band","I-band","O","O","B-song","I-song","I-song","I-song","I-song","O","B-musical_artist","I-musical_artist","O","O","B-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","B-music_genre","O","O"],"target_index":null,"target_label":null},"label_list":["song","music_genre","country","organization","event","location","person","album","award","musical_instrument","band","musical_artist"]}
{"id":"63.S","dataset":"crossner_music","split":"dev","instance":{"id":"63.S","prompt_labels":"In(O) December(O) 2011(O) the(O) band(O) announced(O) they(O) would(O) be(O) performing(O) Tellin(B-album) '(I-album) Stories(I-album) in(O) its(O) entirety(O) at(O) London(B-location) 's(O) HMV(B-location) Hammersmith(I-location) Apollo(I-location) ,(O) O2(B-location) Apollo(I-location) Manchester(I-location) and(O) Glasgow(B-location) 's(O) Barrowland(B-location) Ballroom(I-location) in(O) June(O) 2012(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, music_genre, musical_instrument, award, person, location, musical_artist, event, organization, album, band, song\nGIVEN SENTENCE: In December 2011 the band announced they would be performing Tellin ' Stories in its entirety at London 's HMV Hammersmith Apollo , O2 Apollo Manchester and Glasgow 's Barrowland Ballroom in June 2012 .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","December","2011","the","band","announced","they","would","be","performing","Tellin","'","Stories","in","its","entirety","at","London","'s","HMV","Hammersmith","Apollo",",","O2","Apollo","Manchester","and","Glasgow","'s","Barrowland","Ballroom","in","June","2012","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","B-location","O","B-location","I-location","I-location","O","B-location","I-location","I-location","O","B-location","O","B-location","I-location","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","music_genre","musical_instrument","award","person","location","musical_artist","event","organization","album","band","song"]}
{"id":"65.S","dataset":"crossner_music","split":"dev","instance":{"id":"65.S","prompt_labels":"The(O) Eurasian(B-organization) Economic(I-organization) Union(I-organization) ,(O) the(O) Gulf(B-organization) Cooperation(I-organization) Council(I-organization) ,(O) CARICOM(B-organization) and(O) the(O) European(B-organization) Union(I-organization) are(O) current(O) examples(O) of(O) single(O) markets(O) ,(O) although(O) the(O) Gulf(B-organization) Cooperation(I-organization) Council(I-organization) '(O) s(O) single(O) market(O) has(O) been(O) described(O) as(O) malfunctioning(O) in(O) 2014(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: album, award, musical_instrument, song, music_genre, organization, person, musical_artist, location, event, band, country\nGIVEN SENTENCE: The Eurasian Economic Union , the Gulf Cooperation Council , CARICOM and the European Union are current examples of single markets , although the Gulf Cooperation Council ' s single market has been described as malfunctioning in 2014 .\n","prediction_output":null,"prediction_outputs":null,"group":"65","words":["The","Eurasian","Economic","Union",",","the","Gulf","Cooperation","Council",",","CARICOM","and","the","European","Union","are","current","examples","of","single","markets",",","although","the","Gulf","Cooperation","Council","'","s","single","market","has","been","described","as","malfunctioning","in","2014","."],"labels":["O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["album","award","musical_instrument","song","music_genre","organization","person","musical_artist","location","event","band","country"]}
{"id":"67.S","dataset":"crossner_music","split":"dev","instance":{"id":"67.S","prompt_labels":"In(O) 1990(O) ,(O) he(O) appeared(O) on(O) Kool(B-song) Thing(I-song) ,(O) a(O) song(O) by(O) the(O) alternative(B-music_genre) rock(I-music_genre) band(O) Sonic(B-band) Youth(I-band) ,(O) and(O) along(O) with(O) Flavor(B-musical_artist) Flav(I-musical_artist) ,(O) he(O) sang(O) on(O) George(B-musical_artist) Clinton(I-musical_artist) '(O) s(O) song(O) Tweakin(B-song) '(O) ,(O) which(O) appears(O) on(O) his(O) 1989(O) album(O) The(B-album) Cinderella(I-album) Theory(I-album) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, music_genre, award, location, musical_instrument, band, album, event, song, country, musical_artist, organization\nGIVEN SENTENCE: In 1990 , he appeared on Kool Thing , a song by the alternative rock band Sonic Youth , and along with Flavor Flav , he sang on George Clinton ' s song Tweakin ' , which appears on his 1989 album The Cinderella Theory .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["In","1990",",","he","appeared","on","Kool","Thing",",","a","song","by","the","alternative","rock","band","Sonic","Youth",",","and","along","with","Flavor","Flav",",","he","sang","on","George","Clinton","'","s","song","Tweakin","'",",","which","appears","on","his","1989","album","The","Cinderella","Theory","."],"labels":["O","O","O","O","O","O","B-song","I-song","O","O","O","O","O","B-music_genre","I-music_genre","O","B-band","I-band","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","B-song","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O"],"target_index":null,"target_label":null},"label_list":["person","music_genre","award","location","musical_instrument","band","album","event","song","country","musical_artist","organization"]}
{"id":"68.S","dataset":"crossner_music","split":"dev","instance":{"id":"68.S","prompt_labels":"They(O) also(O) visited(O) South(B-location) America(I-location) for(O) the(O) second(O) time(O) ((O) the(O) first(O) time(O) being(O) in(O) 1999(O) )(O) ,(O) arriving(O) at(O) Chile(B-country) ,(O) Argentina(B-country) ,(O) and(O) Brazil(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, song, musical_artist, event, person, music_genre, location, musical_instrument, country, album, award, band\nGIVEN SENTENCE: They also visited South America for the second time ( the first time being in 1999 ) , arriving at Chile , Argentina , and Brazil .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["They","also","visited","South","America","for","the","second","time","(","the","first","time","being","in","1999",")",",","arriving","at","Chile",",","Argentina",",","and","Brazil","."],"labels":["O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["organization","song","musical_artist","event","person","music_genre","location","musical_instrument","country","album","award","band"]}
{"id":"72.S","dataset":"crossner_music","split":"dev","instance":{"id":"72.S","prompt_labels":"They(O) were(O) accompanied(O) by(O) a(O) varying(O) number(O) of(O) session(O) musicians(O) and(O) some(O) relatively(O) consistent(O) band(O) members(O) such(O) as(O) guitarist(O) Ian(B-musical_artist) Bairnson(I-musical_artist) ,(O) arranger(O) Andrew(B-musical_artist) Powell(I-musical_artist) ,(O) bassist(O) and(O) vocalist(O) David(B-musical_artist) Paton(I-musical_artist) ,(O) drummer(O) Stuart(B-musical_artist) Elliott(I-musical_artist) ,(O) and(O) vocalists(O) Lenny(B-musical_artist) Zakatek(I-musical_artist) and(O) Chris(B-musical_artist) Rainbow(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: album, location, event, musical_artist, musical_instrument, music_genre, award, person, song, band, organization, country\nGIVEN SENTENCE: They were accompanied by a varying number of session musicians and some relatively consistent band members such as guitarist Ian Bairnson , arranger Andrew Powell , bassist and vocalist David Paton , drummer Stuart Elliott , and vocalists Lenny Zakatek and Chris Rainbow .\n","prediction_output":null,"prediction_outputs":null,"group":"72","words":["They","were","accompanied","by","a","varying","number","of","session","musicians","and","some","relatively","consistent","band","members","such","as","guitarist","Ian","Bairnson",",","arranger","Andrew","Powell",",","bassist","and","vocalist","David","Paton",",","drummer","Stuart","Elliott",",","and","vocalists","Lenny","Zakatek","and","Chris","Rainbow","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["album","location","event","musical_artist","musical_instrument","music_genre","award","person","song","band","organization","country"]}
{"id":"73.S","dataset":"crossner_music","split":"dev","instance":{"id":"73.S","prompt_labels":"His(O) 13(O) Grammy(B-award) Award(I-award) nominations(O) have(O) resulted(O) in(O) 2(O) awards(O) won(O) ,(O) along(O) with(O) Billboard(B-award) Music(I-award) Award(I-award) s(O) ,(O) Country(B-award) Music(I-award) Association(I-award) Awards(I-award) ,(O) and(O) many(O) others(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_instrument, musical_artist, album, award, event, band, music_genre, organization, location, country, song, person\nGIVEN SENTENCE: His 13 Grammy Award nominations have resulted in 2 awards won , along with Billboard Music Award s , Country Music Association Awards , and many others .\n","prediction_output":null,"prediction_outputs":null,"group":"73","words":["His","13","Grammy","Award","nominations","have","resulted","in","2","awards","won",",","along","with","Billboard","Music","Award","s",",","Country","Music","Association","Awards",",","and","many","others","."],"labels":["O","O","B-award","I-award","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["musical_instrument","musical_artist","album","award","event","band","music_genre","organization","location","country","song","person"]}
{"id":"77.S","dataset":"crossner_music","split":"dev","instance":{"id":"77.S","prompt_labels":"Schmidt(B-person) was(O) born(O) in(O) Pozsony(B-location) ((O) known(O) in(O) German(O) as(O) Pressburg(B-location) )(O) ,(O) in(O) the(O) Hungary(B-country) part(O) of(O) the(O) Austria-Hungary(B-location) ((O) the(O) city(O) is(O) now(O) Bratislava(B-location) ,(O) capital(O) of(O) Slovakia(B-country) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, musical_artist, person, song, award, organization, event, musical_instrument, band, location, country, album\nGIVEN SENTENCE: Schmidt was born in Pozsony ( known in German as Pressburg ) , in the Hungary part of the Austria-Hungary ( the city is now Bratislava , capital of Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"77","words":["Schmidt","was","born","in","Pozsony","(","known","in","German","as","Pressburg",")",",","in","the","Hungary","part","of","the","Austria-Hungary","(","the","city","is","now","Bratislava",",","capital","of","Slovakia",")","."],"labels":["B-person","O","O","O","B-location","O","O","O","O","O","B-location","O","O","O","O","B-country","O","O","O","B-location","O","O","O","O","O","B-location","O","O","O","B-country","O","O"],"target_index":null,"target_label":null},"label_list":["music_genre","musical_artist","person","song","award","organization","event","musical_instrument","band","location","country","album"]}
{"id":"78.S","dataset":"crossner_music","split":"dev","instance":{"id":"78.S","prompt_labels":"In(O) 2005(O) Jamieson(B-musical_artist) won(O) Best(O) Male(O) Performer(O) in(O) the(O) second(B-award) annual(I-award) Jack(I-award) Awards(I-award) ,(O) Jamieson(B-musical_artist) showcased(O) the(O) sounds(O) of(O) Grinspoon(B-band) to(O) millions(O) of(O) viewers(O) in(O) March(O) 2006(O) ,(O) playing(O) live(O) at(O) Melbourne(B-location) Cricket(I-location) Ground(I-location) as(O) part(O) of(O) the(O) closing(O) ceremony(O) of(O) the(O) 2006(B-event) Commonwealth(I-event) Games(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: album, person, musical_instrument, organization, musical_artist, award, country, song, event, band, music_genre, location\nGIVEN SENTENCE: In 2005 Jamieson won Best Male Performer in the second annual Jack Awards , Jamieson showcased the sounds of Grinspoon to millions of viewers in March 2006 , playing live at Melbourne Cricket Ground as part of the closing ceremony of the 2006 Commonwealth Games .\n","prediction_output":null,"prediction_outputs":null,"group":"78","words":["In","2005","Jamieson","won","Best","Male","Performer","in","the","second","annual","Jack","Awards",",","Jamieson","showcased","the","sounds","of","Grinspoon","to","millions","of","viewers","in","March","2006",",","playing","live","at","Melbourne","Cricket","Ground","as","part","of","the","closing","ceremony","of","the","2006","Commonwealth","Games","."],"labels":["O","O","B-musical_artist","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","B-musical_artist","O","O","O","O","B-band","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["album","person","musical_instrument","organization","musical_artist","award","country","song","event","band","music_genre","location"]}
{"id":"79.S","dataset":"crossner_music","split":"dev","instance":{"id":"79.S","prompt_labels":"Funds(O) raised(O) by(O) the(O) project(O) will(O) go(O) to(O) Amazon(B-organization) Watch(I-organization) and(O) Extinction(B-organization) Rebellion(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, band, event, musical_instrument, country, album, person, musical_artist, music_genre, location, organization, award\nGIVEN SENTENCE: Funds raised by the project will go to Amazon Watch and Extinction Rebellion .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Funds","raised","by","the","project","will","go","to","Amazon","Watch","and","Extinction","Rebellion","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["song","band","event","musical_instrument","country","album","person","musical_artist","music_genre","location","organization","award"]}
{"id":"80.S","dataset":"crossner_music","split":"dev","instance":{"id":"80.S","prompt_labels":"This(O) is(O) the(O) method(O) used(O) by(O) Bands(B-organization) of(I-organization) America(I-organization) ,(O) the(O) Indiana(B-organization) State(I-organization) School(I-organization) Music(I-organization) Association(I-organization) ,(O) Kentucky(B-organization) Music(I-organization) Educators(I-organization) Association(I-organization) and(O) the(O) University(B-organization) Interscholastic(I-organization) League(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, musical_artist, event, album, location, musical_instrument, music_genre, band, award, country, organization, song\nGIVEN SENTENCE: This is the method used by Bands of America , the Indiana State School Music Association , Kentucky Music Educators Association and the University Interscholastic League .\n","prediction_output":null,"prediction_outputs":null,"group":"80","words":["This","is","the","method","used","by","Bands","of","America",",","the","Indiana","State","School","Music","Association",",","Kentucky","Music","Educators","Association","and","the","University","Interscholastic","League","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["person","musical_artist","event","album","location","musical_instrument","music_genre","band","award","country","organization","song"]}
{"id":"81.S","dataset":"crossner_music","split":"dev","instance":{"id":"81.S","prompt_labels":"Featuring(O) LaLonde(B-musical_artist) and(O) Alexander(B-musical_artist) ,(O) Primus(B-band) recorded(O) the(O) live(O) album(O) Suck(B-album) on(I-album) This(I-album) in(O) 1989(O) ,(O) followed(O) by(O) four(O) studio(O) albums(O) :(O) Frizzle(B-album) Fry(I-album) ,(O) Sailing(B-album) the(I-album) Seas(I-album) of(I-album) Cheese(I-album) ,(O) Pork(B-album) Soda(I-album) ,(O) and(O) Tales(B-album) from(I-album) the(I-album) Punchbowl(I-album) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, award, music_genre, album, musical_artist, organization, location, event, band, country, person, musical_instrument\nGIVEN SENTENCE: Featuring LaLonde and Alexander , Primus recorded the live album Suck on This in 1989 , followed by four studio albums : Frizzle Fry , Sailing the Seas of Cheese , Pork Soda , and Tales from the Punchbowl .\n","prediction_output":null,"prediction_outputs":null,"group":"81","words":["Featuring","LaLonde","and","Alexander",",","Primus","recorded","the","live","album","Suck","on","This","in","1989",",","followed","by","four","studio","albums",":","Frizzle","Fry",",","Sailing","the","Seas","of","Cheese",",","Pork","Soda",",","and","Tales","from","the","Punchbowl","."],"labels":["O","B-musical_artist","O","B-musical_artist","O","B-band","O","O","O","O","B-album","I-album","I-album","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","I-album","O","B-album","I-album","O","O","B-album","I-album","I-album","I-album","O"],"target_index":null,"target_label":null},"label_list":["song","award","music_genre","album","musical_artist","organization","location","event","band","country","person","musical_instrument"]}
{"id":"82.S","dataset":"crossner_music","split":"dev","instance":{"id":"82.S","prompt_labels":"In(O) 1977(O) Summer(O) ,(O) Moroder(B-musical_artist) and(O) Bellotte(B-musical_artist) further(O) released(O) I(B-song) Feel(I-song) Love(I-song) ,(O) as(O) the(O) B-side(O) of(O) Can(B-song) 't(I-song) We(I-song) Just(I-song) Sit(I-song) Down(I-song) ((O) And(B-song) Talk(I-song) It(I-song) Over(I-song) )(O) ,(O) which(O) revolutionized(O) dance(O) music(O) with(O) its(O) mostly(O) Electronic(B-music_genre) music(I-music_genre) production(O) and(O) was(O) a(O) massive(O) worldwide(O) success(O) ,(O) spawning(O) the(O) Hi-NRG(B-music_genre) subgenre(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, album, award, musical_instrument, person, country, music_genre, organization, musical_artist, song, event, band\nGIVEN SENTENCE: In 1977 Summer , Moroder and Bellotte further released I Feel Love , as the B-side of Can 't We Just Sit Down ( And Talk It Over ) , which revolutionized dance music with its mostly Electronic music production and was a massive worldwide success , spawning the Hi-NRG subgenre .\n","prediction_output":null,"prediction_outputs":null,"group":"82","words":["In","1977","Summer",",","Moroder","and","Bellotte","further","released","I","Feel","Love",",","as","the","B-side","of","Can","'t","We","Just","Sit","Down","(","And","Talk","It","Over",")",",","which","revolutionized","dance","music","with","its","mostly","Electronic","music","production","and","was","a","massive","worldwide","success",",","spawning","the","Hi-NRG","subgenre","."],"labels":["O","O","O","O","B-musical_artist","O","B-musical_artist","O","O","B-song","I-song","I-song","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","O","O","O","O","B-music_genre","O","O"],"target_index":null,"target_label":null},"label_list":["location","album","award","musical_instrument","person","country","music_genre","organization","musical_artist","song","event","band"]}
{"id":"84.S","dataset":"crossner_music","split":"dev","instance":{"id":"84.S","prompt_labels":"Other(O) acts(O) who(O) became(O) prominent(O) in(O) the(O) alt-country(B-music_genre) genre(I-music_genre) during(O) the(O) 1990s(O) and(O) 2000s(O) included(O) The(B-band) Bottle(I-band) Rockets(I-band) ,(O) The(B-band) Handsome(I-band) Family(I-band) ,(O) Blue(B-band) Mountain(I-band) ,(O) Robbie(B-band) Fulks(I-band) ,(O) Blood(B-band) Oranges(I-band) ,(O) Bright(B-band) Eyes(I-band) ,(O) Drive-By(B-band) Truckers(I-band) ,(O) Old(B-band) 97(I-band) 's(I-band) ,(O) Old(B-band) Crow(I-band) Medicine(I-band) Show(I-band) ,(O) Nickel(B-band) Creek(I-band) ,(O) Neko(B-musical_artist) Case(I-musical_artist) ,(O) and(O) Whiskeytown(B-band) ,(O) whose(O) lead(O) singer(O) Ryan(B-musical_artist) Adams(I-musical_artist) later(O) had(O) a(O) successful(O) solo-career(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, award, album, band, person, musical_instrument, song, event, country, musical_artist, music_genre, organization\nGIVEN SENTENCE: Other acts who became prominent in the alt-country genre during the 1990s and 2000s included The Bottle Rockets , The Handsome Family , Blue Mountain , Robbie Fulks , Blood Oranges , Bright Eyes , Drive-By Truckers , Old 97 's , Old Crow Medicine Show , Nickel Creek , Neko Case , and Whiskeytown , whose lead singer Ryan Adams later had a successful solo-career .\n","prediction_output":null,"prediction_outputs":null,"group":"84","words":["Other","acts","who","became","prominent","in","the","alt-country","genre","during","the","1990s","and","2000s","included","The","Bottle","Rockets",",","The","Handsome","Family",",","Blue","Mountain",",","Robbie","Fulks",",","Blood","Oranges",",","Bright","Eyes",",","Drive-By","Truckers",",","Old","97","'s",",","Old","Crow","Medicine","Show",",","Nickel","Creek",",","Neko","Case",",","and","Whiskeytown",",","whose","lead","singer","Ryan","Adams","later","had","a","successful","solo-career","."],"labels":["O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","I-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","O","B-musical_artist","I-musical_artist","O","O","B-band","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","award","album","band","person","musical_instrument","song","event","country","musical_artist","music_genre","organization"]}
{"id":"85.S","dataset":"crossner_music","split":"dev","instance":{"id":"85.S","prompt_labels":"The(O) West(O) Side(O) sound(O) had(O) strong(O) rhythmic(O) support(O) from(O) a(O) rhythm(B-musical_instrument) guitar(I-musical_instrument) ,(O) bass(B-musical_instrument) guitar(I-musical_instrument) and(O) drums(B-musical_instrument) and(O) as(O) perfected(O) by(O) Guy(B-band) ,(O) Freddie(B-musical_artist) King(I-musical_artist) ,(O) Magic(B-musical_artist) Slim(I-musical_artist) and(O) Luther(B-musical_artist) Allison(I-musical_artist) was(O) dominated(O) by(O) amplified(O) electric(B-musical_instrument) lead(I-musical_instrument) guitar(I-musical_instrument) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, band, musical_artist, person, musical_instrument, award, event, location, album, song, country, organization\nGIVEN SENTENCE: The West Side sound had strong rhythmic support from a rhythm guitar , bass guitar and drums and as perfected by Guy , Freddie King , Magic Slim and Luther Allison was dominated by amplified electric lead guitar .\n","prediction_output":null,"prediction_outputs":null,"group":"85","words":["The","West","Side","sound","had","strong","rhythmic","support","from","a","rhythm","guitar",",","bass","guitar","and","drums","and","as","perfected","by","Guy",",","Freddie","King",",","Magic","Slim","and","Luther","Allison","was","dominated","by","amplified","electric","lead","guitar","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-musical_instrument","I-musical_instrument","O","B-musical_instrument","I-musical_instrument","O","B-musical_instrument","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","B-musical_instrument","I-musical_instrument","I-musical_instrument","O"],"target_index":null,"target_label":null},"label_list":["music_genre","band","musical_artist","person","musical_instrument","award","event","location","album","song","country","organization"]}
{"id":"90.S","dataset":"crossner_music","split":"dev","instance":{"id":"90.S","prompt_labels":"Electropop(B-music_genre) pioneers(O) Haruomi(B-musical_artist) Hosono(I-musical_artist) and(O) Ryuichi(B-musical_artist) Sakamoto(I-musical_artist) of(O) the(O) Yellow(B-band) Magic(I-band) Orchestra(I-band) produced(O) a(O) 1978(O) Electronic(B-music_genre) music(I-music_genre) album(O) ,(O) Cochin(B-album) Moon(I-album) ,(O) based(O) on(O) an(O) experimental(O) fusion(O) of(O) electronic(B-music_genre) music(I-music_genre) and(O) Bollywood-inspired(B-music_genre) Indian(I-music_genre) music(I-music_genre) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, organization, person, band, event, music_genre, location, award, musical_artist, musical_instrument, album, song\nGIVEN SENTENCE: Electropop pioneers Haruomi Hosono and Ryuichi Sakamoto of the Yellow Magic Orchestra produced a 1978 Electronic music album , Cochin Moon , based on an experimental fusion of electronic music and Bollywood-inspired Indian music .\n","prediction_output":null,"prediction_outputs":null,"group":"90","words":["Electropop","pioneers","Haruomi","Hosono","and","Ryuichi","Sakamoto","of","the","Yellow","Magic","Orchestra","produced","a","1978","Electronic","music","album",",","Cochin","Moon",",","based","on","an","experimental","fusion","of","electronic","music","and","Bollywood-inspired","Indian","music","."],"labels":["B-music_genre","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-band","I-band","I-band","O","O","O","B-music_genre","I-music_genre","O","O","B-album","I-album","O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","I-music_genre","O"],"target_index":null,"target_label":null},"label_list":["country","organization","person","band","event","music_genre","location","award","musical_artist","musical_instrument","album","song"]}
{"id":"91.S","dataset":"crossner_music","split":"dev","instance":{"id":"91.S","prompt_labels":"Black(B-album) Holes(I-album) and(I-album) Revelations(I-album) ((O) 2006(O) )(O) incorporated(O) Electronic(B-music_genre) music(I-music_genre) and(O) Pop(B-music_genre) music(I-music_genre) elements(O) ,(O) displayed(O) in(O) singles(O) such(O) as(O) Supermassive(B-song) Black(I-song) Hole(I-song) ,(O) Their(O) seventh(O) album(O) ,(O) Drones(B-album) ((O) 2015(O) )(O) ,(O) was(O) a(O) concept(O) album(O) about(O) drone(B-album) warfare(I-album) and(O) returned(O) to(O) a(O) harder(O) rock(B-music_genre) sound(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_instrument, organization, country, location, event, musical_artist, band, album, award, song, person, music_genre\nGIVEN SENTENCE: Black Holes and Revelations ( 2006 ) incorporated Electronic music and Pop music elements , displayed in singles such as Supermassive Black Hole , Their seventh album , Drones ( 2015 ) , was a concept album about drone warfare and returned to a harder rock sound .\n","prediction_output":null,"prediction_outputs":null,"group":"91","words":["Black","Holes","and","Revelations","(","2006",")","incorporated","Electronic","music","and","Pop","music","elements",",","displayed","in","singles","such","as","Supermassive","Black","Hole",",","Their","seventh","album",",","Drones","(","2015",")",",","was","a","concept","album","about","drone","warfare","and","returned","to","a","harder","rock","sound","."],"labels":["B-album","I-album","I-album","I-album","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","O","O","O","O","O","O","B-song","I-song","I-song","O","O","O","O","O","B-album","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O","B-music_genre","O","O"],"target_index":null,"target_label":null},"label_list":["musical_instrument","organization","country","location","event","musical_artist","band","album","award","song","person","music_genre"]}
{"id":"92.S","dataset":"crossner_music","split":"dev","instance":{"id":"92.S","prompt_labels":"The(B-band) 5th(I-band) Dimension(I-band) is(O) an(O) United(B-country) States(I-country) popular(B-music_genre) music(I-music_genre) vocal(O) group(O) ,(O) whose(O) repertoire(O) includes(O) Pop(B-music_genre) music(I-music_genre) ,(O) Rhythm(B-music_genre) and(I-music_genre) blues(I-music_genre) ,(O) Soul(B-music_genre) music(I-music_genre) ,(O) jazz(B-music_genre) ,(O) light(B-music_genre) opera(I-music_genre) ,(O) and(O) Broadway(B-music_genre) -(O) the(O) melange(O) was(O) coined(O) as(O) Champagne(B-music_genre) Soul(I-music_genre) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, musical_instrument, song, country, band, musical_artist, person, event, album, music_genre, award, location\nGIVEN SENTENCE: The 5th Dimension is an United States popular music vocal group , whose repertoire includes Pop music , Rhythm and blues , Soul music , jazz , light opera , and Broadway - the melange was coined as Champagne Soul .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["The","5th","Dimension","is","an","United","States","popular","music","vocal","group",",","whose","repertoire","includes","Pop","music",",","Rhythm","and","blues",",","Soul","music",",","jazz",",","light","opera",",","and","Broadway","-","the","melange","was","coined","as","Champagne","Soul","."],"labels":["B-band","I-band","I-band","O","O","B-country","I-country","B-music_genre","I-music_genre","O","O","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","I-music_genre","O","O","B-music_genre","O","O","O","O","O","O","B-music_genre","I-music_genre","O"],"target_index":null,"target_label":null},"label_list":["organization","musical_instrument","song","country","band","musical_artist","person","event","album","music_genre","award","location"]}
{"id":"98.S","dataset":"crossner_music","split":"dev","instance":{"id":"98.S","prompt_labels":"Lynn(B-musical_artist) has(O) received(O) numerous(O) awards(O) and(O) other(O) accolades(O) for(O) her(O) groundbreaking(O) role(O) in(O) country(B-music_genre) music(I-music_genre) ,(O) including(O) awards(O) from(O) both(O) the(O) Country(B-organization) Music(I-organization) Association(I-organization) and(O) Academy(B-organization) of(I-organization) Country(I-organization) Music(I-organization) as(O) a(O) duet(O) partner(O) and(O) an(O) individual(O) artist(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, song, band, music_genre, album, musical_artist, location, country, musical_instrument, event, person, organization\nGIVEN SENTENCE: Lynn has received numerous awards and other accolades for her groundbreaking role in country music , including awards from both the Country Music Association and Academy of Country Music as a duet partner and an individual artist .\n","prediction_output":null,"prediction_outputs":null,"group":"98","words":["Lynn","has","received","numerous","awards","and","other","accolades","for","her","groundbreaking","role","in","country","music",",","including","awards","from","both","the","Country","Music","Association","and","Academy","of","Country","Music","as","a","duet","partner","and","an","individual","artist","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","song","band","music_genre","album","musical_artist","location","country","musical_instrument","event","person","organization"]}
{"id":"100.S","dataset":"crossner_music","split":"dev","instance":{"id":"100.S","prompt_labels":"Taylor(B-musical_artist) Momsen(I-musical_artist) ,(O) Marcus(B-band) Durant(I-band) ,(O) Brandi(B-musical_artist) Carlile(I-musical_artist) and(O) Taylor(B-musical_artist) Hawkins(I-musical_artist) contributed(O) vocals(O) to(O) Soundgarden(B-band) ,(O) who(O) performed(O) Rusty(B-song) Cage(I-song) ,(O) Flower(B-song) ,(O) Outshined(B-song) ,(O) Drawing(B-song) Flies(I-song) ,(O) Loud(B-song) Love(I-song) ,(O) I(B-song) Awake(I-song) ,(O) The(B-song) Day(I-song) I(I-song) Tried(I-song) to(I-song) Live(I-song) and(O) Black(B-song) Hole(I-song) Sun(I-song) ,(O) making(O) this(O) their(O) only(O) performance(O) since(O) Cornell(B-musical_artist) 's(O) death(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, album, musical_artist, country, organization, event, music_genre, song, location, band, musical_instrument, award\nGIVEN SENTENCE: Taylor Momsen , Marcus Durant , Brandi Carlile and Taylor Hawkins contributed vocals to Soundgarden , who performed Rusty Cage , Flower , Outshined , Drawing Flies , Loud Love , I Awake , The Day I Tried to Live and Black Hole Sun , making this their only performance since Cornell 's death .\n","prediction_output":null,"prediction_outputs":null,"group":"100","words":["Taylor","Momsen",",","Marcus","Durant",",","Brandi","Carlile","and","Taylor","Hawkins","contributed","vocals","to","Soundgarden",",","who","performed","Rusty","Cage",",","Flower",",","Outshined",",","Drawing","Flies",",","Loud","Love",",","I","Awake",",","The","Day","I","Tried","to","Live","and","Black","Hole","Sun",",","making","this","their","only","performance","since","Cornell","'s","death","."],"labels":["B-musical_artist","I-musical_artist","O","B-band","I-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","B-band","O","O","O","B-song","I-song","O","B-song","O","B-song","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","O","O","O","O","O","O","O","B-musical_artist","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","album","musical_artist","country","organization","event","music_genre","song","location","band","musical_instrument","award"]}
{"id":"101.S","dataset":"crossner_music","split":"dev","instance":{"id":"101.S","prompt_labels":"The(O) film(O) received(O) several(O) Golden(B-award) Globe(I-award) Awards(I-award) and(O) Academy(B-award) Awards(I-award) nominations(O) ,(O) and(O) earned(O) Kidman(O) a(O) fourth(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) nomination(O) ,(O) as(O) part(O) of(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Award(I-award) for(I-award) Outstanding(I-award) Performance(I-award) by(I-award) a(I-award) Cast(I-award) in(I-award) a(I-award) Motion(I-award) Picture(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, band, person, event, album, organization, song, country, location, award, musical_instrument, musical_artist\nGIVEN SENTENCE: The film received several Golden Globe Awards and Academy Awards nominations , and earned Kidman a fourth Screen Actors Guild Award nomination , as part of the Screen Actors Guild Award for Outstanding Performance by a Cast in a Motion Picture .\n","prediction_output":null,"prediction_outputs":null,"group":"101","words":["The","film","received","several","Golden","Globe","Awards","and","Academy","Awards","nominations",",","and","earned","Kidman","a","fourth","Screen","Actors","Guild","Award","nomination",",","as","part","of","the","Screen","Actors","Guild","Award","for","Outstanding","Performance","by","a","Cast","in","a","Motion","Picture","."],"labels":["O","O","O","O","B-award","I-award","I-award","O","B-award","I-award","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["music_genre","band","person","event","album","organization","song","country","location","award","musical_instrument","musical_artist"]}
{"id":"103.S","dataset":"crossner_music","split":"dev","instance":{"id":"103.S","prompt_labels":"New(B-location) York(I-location) 's(O) rock(B-music_genre) scene(O) includes(O) clubs(O) such(O) as(O) Irving(B-location) Plaza(I-location) ,(O) while(O) the(O) city(O) 's(O) avant-garde(O) downtown(O) scene(O) includes(O) The(B-location) Kitchen(I-location) ,(O) Roulette(B-location) ,(O) and(O) Knitting(B-location) Factory(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, music_genre, musical_artist, award, organization, album, location, country, band, musical_instrument, song, event\nGIVEN SENTENCE: New York 's rock scene includes clubs such as Irving Plaza , while the city 's avant-garde downtown scene includes The Kitchen , Roulette , and Knitting Factory .\n","prediction_output":null,"prediction_outputs":null,"group":"103","words":["New","York","'s","rock","scene","includes","clubs","such","as","Irving","Plaza",",","while","the","city","'s","avant-garde","downtown","scene","includes","The","Kitchen",",","Roulette",",","and","Knitting","Factory","."],"labels":["B-location","I-location","O","B-music_genre","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","O","B-location","I-location","O"],"target_index":null,"target_label":null},"label_list":["person","music_genre","musical_artist","award","organization","album","location","country","band","musical_instrument","song","event"]}
{"id":"109.S","dataset":"crossner_music","split":"dev","instance":{"id":"109.S","prompt_labels":"First(O) ,(O) they(O) played(O) a(O) series(O) of(O) concerts(O) at(O) the(O) Glór(B-location) Theatre(I-location) in(O) Ennis(B-location) ,(O) County(B-location) Clare(B-location) ((O) on(O) 23(O) &(O) amp(O) ;(O) 24(O) January(O) 2004(O) )(O) and(O) at(O) Vicar(B-location) Street(I-location) in(O) Dublin(B-location) ((O) on(O) 30(O) &(O) amp(O) ;(O) 31(O) January(O) and(O) on(O) 4(O) &(O) amp(O) ;(O) 5(O) ,(O) 11(O) &(O) amp(O) ;(O) 12(O) February(O) 2004(O) )(O) ,(O) which(O) were(O) recorded(O) and(O) from(O) which(O) selected(O) material(O) was(O) released(O) on(O) the(O) CD(O) Live(B-album) 2004(I-album) and(O) its(O) associated(O) DVD(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_instrument, country, event, award, musical_artist, band, song, location, organization, person, music_genre, album\nGIVEN SENTENCE: First , they played a series of concerts at the Glór Theatre in Ennis , County Clare ( on 23 & amp ; 24 January 2004 ) and at Vicar Street in Dublin ( on 30 & amp ; 31 January and on 4 & amp ; 5 , 11 & amp ; 12 February 2004 ) , which were recorded and from which selected material was released on the CD Live 2004 and its associated DVD .\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["First",",","they","played","a","series","of","concerts","at","the","Glór","Theatre","in","Ennis",",","County","Clare","(","on","23","&","amp",";","24","January","2004",")","and","at","Vicar","Street","in","Dublin","(","on","30","&","amp",";","31","January","and","on","4","&","amp",";","5",",","11","&","amp",";","12","February","2004",")",",","which","were","recorded","and","from","which","selected","material","was","released","on","the","CD","Live","2004","and","its","associated","DVD","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","B-location","B-location","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["musical_instrument","country","event","award","musical_artist","band","song","location","organization","person","music_genre","album"]}
{"id":"111.S","dataset":"crossner_music","split":"dev","instance":{"id":"111.S","prompt_labels":"British(O) genres(O) such(O) as(O) Lovers(B-music_genre) rock(I-music_genre) ,(O) Ragga(B-music_genre) jungle(I-music_genre) and(O) grime(B-music_genre) are(O) also(O) influenced(O) by(O) Jamaican(O) music(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, person, organization, location, band, musical_instrument, album, music_genre, event, award, country, musical_artist\nGIVEN SENTENCE: British genres such as Lovers rock , Ragga jungle and grime are also influenced by Jamaican music .\n","prediction_output":null,"prediction_outputs":null,"group":"111","words":["British","genres","such","as","Lovers","rock",",","Ragga","jungle","and","grime","are","also","influenced","by","Jamaican","music","."],"labels":["O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["song","person","organization","location","band","musical_instrument","album","music_genre","event","award","country","musical_artist"]}
{"id":"112.S","dataset":"crossner_music","split":"dev","instance":{"id":"112.S","prompt_labels":"some(O) of(O) his(O) performances(O) will(O) finish(O) without(O) some(O) blues(B-music_genre) and(O) Tejano(B-music_genre) music(I-music_genre) tunes(O) playing(O) as(O) well(O) as(O) Surf(B-music_genre) music(I-music_genre) instrumentals(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, music_genre, band, location, album, award, musical_artist, person, event, organization, song, musical_instrument\nGIVEN SENTENCE: some of his performances will finish without some blues and Tejano music tunes playing as well as Surf music instrumentals .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["some","of","his","performances","will","finish","without","some","blues","and","Tejano","music","tunes","playing","as","well","as","Surf","music","instrumentals","."],"labels":["O","O","O","O","O","O","O","O","B-music_genre","O","B-music_genre","I-music_genre","O","O","O","O","O","B-music_genre","I-music_genre","O","O"],"target_index":null,"target_label":null},"label_list":["country","music_genre","band","location","album","award","musical_artist","person","event","organization","song","musical_instrument"]}
{"id":"113.S","dataset":"crossner_music","split":"dev","instance":{"id":"113.S","prompt_labels":"They(O) have(O) won(O) two(O) Grammy(B-award) Award(I-award) s(O) ,(O) six(O) American(B-award) Music(I-award) Awards(I-award) ,(O) two(O) Billboard(B-award) Music(I-award) Award(I-award) ,(O) four(O) MTV(B-award) Video(I-award) Music(I-award) Award(I-award) s(O) ,(O) 10(O) MTV(B-award) Europe(I-award) Music(I-award) Award(I-award) and(O) three(O) World(B-award) Music(I-award) Awards(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, song, person, organization, music_genre, musical_instrument, band, location, award, event, musical_artist, album\nGIVEN SENTENCE: They have won two Grammy Award s , six American Music Awards , two Billboard Music Award , four MTV Video Music Award s , 10 MTV Europe Music Award and three World Music Awards .\n","prediction_output":null,"prediction_outputs":null,"group":"113","words":["They","have","won","two","Grammy","Award","s",",","six","American","Music","Awards",",","two","Billboard","Music","Award",",","four","MTV","Video","Music","Award","s",",","10","MTV","Europe","Music","Award","and","three","World","Music","Awards","."],"labels":["O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["country","song","person","organization","music_genre","musical_instrument","band","location","award","event","musical_artist","album"]}
{"id":"120.S","dataset":"crossner_music","split":"dev","instance":{"id":"120.S","prompt_labels":"Spears(O) has(O) earned(O) numerous(O) awards(O) and(O) accolades(O) ,(O) including(O) a(O) Grammy(B-award) Award(I-award) ;(O) seven(O) Guinness(B-award) World(I-award) Records(I-award) ;(O) six(O) MTV(B-award) Video(I-award) Music(I-award) Awards(I-award) ,(O) including(O) the(O) Michael(B-award) Jackson(I-award) Video(I-award) Vanguard(I-award) Award(I-award) ;(O) seven(O) Billboard(B-award) Music(I-award) Awards(I-award) ,(O) including(O) the(O) Millennium(B-award) Award(I-award) ;(O) the(O) inaugural(B-award) Radio(I-award) Disney(I-award) Icon(I-award) Award(I-award) ;(O) the(O) GLAAD(B-award) Media(I-award) Award(I-award) '(O) s(O) Vanguard(B-award) Award(I-award) and(O) a(O) star(O) on(O) the(O) Hollywood(B-location) Walk(I-location) of(I-location) Fame(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, country, person, award, music_genre, band, location, musical_instrument, musical_artist, organization, song, album\nGIVEN SENTENCE: Spears has earned numerous awards and accolades , including a Grammy Award ; seven Guinness World Records ; six MTV Video Music Awards , including the Michael Jackson Video Vanguard Award ; seven Billboard Music Awards , including the Millennium Award ; the inaugural Radio Disney Icon Award ; the GLAAD Media Award ' s Vanguard Award and a star on the Hollywood Walk of Fame .\n","prediction_output":null,"prediction_outputs":null,"group":"120","words":["Spears","has","earned","numerous","awards","and","accolades",",","including","a","Grammy","Award",";","seven","Guinness","World","Records",";","six","MTV","Video","Music","Awards",",","including","the","Michael","Jackson","Video","Vanguard","Award",";","seven","Billboard","Music","Awards",",","including","the","Millennium","Award",";","the","inaugural","Radio","Disney","Icon","Award",";","the","GLAAD","Media","Award","'","s","Vanguard","Award","and","a","star","on","the","Hollywood","Walk","of","Fame","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","O","O","O","O","O","B-location","I-location","I-location","I-location","O"],"target_index":null,"target_label":null},"label_list":["event","country","person","award","music_genre","band","location","musical_instrument","musical_artist","organization","song","album"]}
{"id":"121.S","dataset":"crossner_music","split":"dev","instance":{"id":"121.S","prompt_labels":"The(O) venue(O) was(O) the(O) site(O) of(O) several(O) Commonwealth(O) Games(O) sports(O) in(O) 1978(B-event) Commonwealth(I-event) Games(I-event) ,(O) and(O) part(O) of(O) Universiade(B-event) ((O) the(O) World(B-event) University(I-event) Games(I-event) )(O) in(O) 1983(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_artist, location, event, organization, award, music_genre, song, album, band, country, person, musical_instrument\nGIVEN SENTENCE: The venue was the site of several Commonwealth Games sports in 1978 Commonwealth Games , and part of Universiade ( the World University Games ) in 1983 .\n","prediction_output":null,"prediction_outputs":null,"group":"121","words":["The","venue","was","the","site","of","several","Commonwealth","Games","sports","in","1978","Commonwealth","Games",",","and","part","of","Universiade","(","the","World","University","Games",")","in","1983","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","B-event","O","O","B-event","I-event","I-event","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["musical_artist","location","event","organization","award","music_genre","song","album","band","country","person","musical_instrument"]}
{"id":"122.S","dataset":"crossner_music","split":"dev","instance":{"id":"122.S","prompt_labels":"Kraftwerk(B-musical_artist) 's(O) musical(O) style(O) and(O) image(O) can(O) be(O) heard(O) and(O) seen(O) in(O) 1980s(O) synthpop(B-music_genre) groups(O) such(O) as(O) Gary(B-musical_artist) Numan(I-musical_artist) ,(O) Ultravox(B-band) ,(O) John(B-musical_artist) Foxx(I-musical_artist) ,(O) Orchestral(B-band) Manoeuvres(I-band) in(I-band) the(I-band) Dark(I-band) ,(O) Human(B-band) League(I-band) ,(O) Depeche(B-band) Mode(I-band) ,(O) Visage(B-band) ,(O) and(O) Soft(B-band) Cell(I-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_instrument, event, music_genre, band, organization, person, country, location, album, musical_artist, song, award\nGIVEN SENTENCE: Kraftwerk 's musical style and image can be heard and seen in 1980s synthpop groups such as Gary Numan , Ultravox , John Foxx , Orchestral Manoeuvres in the Dark , Human League , Depeche Mode , Visage , and Soft Cell .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Kraftwerk","'s","musical","style","and","image","can","be","heard","and","seen","in","1980s","synthpop","groups","such","as","Gary","Numan",",","Ultravox",",","John","Foxx",",","Orchestral","Manoeuvres","in","the","Dark",",","Human","League",",","Depeche","Mode",",","Visage",",","and","Soft","Cell","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","B-music_genre","O","O","O","B-musical_artist","I-musical_artist","O","B-band","O","B-musical_artist","I-musical_artist","O","B-band","I-band","I-band","I-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","O","O","B-band","I-band","O"],"target_index":null,"target_label":null},"label_list":["musical_instrument","event","music_genre","band","organization","person","country","location","album","musical_artist","song","award"]}
{"id":"123.S","dataset":"crossner_music","split":"dev","instance":{"id":"123.S","prompt_labels":"Styles(O) like(O) Rock(B-music_genre) music(I-music_genre) ,(O) Heavy(B-music_genre) metal(I-music_genre) music(I-music_genre) ,(O) Pop(B-music_genre) rock(I-music_genre) ,(O) Folk(B-music_genre) rock(I-music_genre) ,(O) Neo-Romantic(B-music_genre) ,(O) Pop(B-music_genre) and(O) some(O) experimental(O) styles(O) ((O) e.g.(O) Cantorock(B-music_genre) )(O) were(O) introduced(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, organization, country, music_genre, song, musical_artist, album, event, person, musical_instrument, award, band\nGIVEN SENTENCE: Styles like Rock music , Heavy metal music , Pop rock , Folk rock , Neo-Romantic , Pop and some experimental styles ( e.g. Cantorock ) were introduced .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Styles","like","Rock","music",",","Heavy","metal","music",",","Pop","rock",",","Folk","rock",",","Neo-Romantic",",","Pop","and","some","experimental","styles","(","e.g.","Cantorock",")","were","introduced","."],"labels":["O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","O","O","O","O","O","O","B-music_genre","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","organization","country","music_genre","song","musical_artist","album","event","person","musical_instrument","award","band"]}
{"id":"124.S","dataset":"crossner_music","split":"dev","instance":{"id":"124.S","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(B-music_genre) metal(I-music_genre) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(B-band) ,(O) Aborted(B-band) ,(O) Exhumed(B-band) ,(O) Dying(B-band) Fetus(I-band) ,(O) Cannibal(B-band) Corpse(I-band) ,(O) and(O) Deicide(B-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_artist, event, location, award, album, song, music_genre, organization, musical_instrument, band, country, person\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":null},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"125.S","dataset":"crossner_music","split":"dev","instance":{"id":"125.S","prompt_labels":"Rodgers(B-musical_artist) was(O) the(O) first(O) person(O) to(O) win(O) what(O) is(O) considered(O) the(O) top(O) American(O) entertainment(O) awards(O) in(O) television(O) ,(O) recording(O) ,(O) movies(O) ,(O) and(O) Broadway(B-organization) -(O) an(O) Emmy(B-award) Award(I-award) ,(O) a(O) Grammy(B-award) Award(I-award) ,(O) an(O) Academy(B-award) Awards(I-award) ,(O) and(O) a(O) Tony(B-award) Award(I-award) -(O) now(O) known(O) collectively(O) as(O) an(O) EGOT(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: album, song, award, musical_instrument, organization, musical_artist, location, band, music_genre, country, event, person\nGIVEN SENTENCE: Rodgers was the first person to win what is considered the top American entertainment awards in television , recording , movies , and Broadway - an Emmy Award , a Grammy Award , an Academy Awards , and a Tony Award - now known collectively as an EGOT .\n","prediction_output":null,"prediction_outputs":null,"group":"125","words":["Rodgers","was","the","first","person","to","win","what","is","considered","the","top","American","entertainment","awards","in","television",",","recording",",","movies",",","and","Broadway","-","an","Emmy","Award",",","a","Grammy","Award",",","an","Academy","Awards",",","and","a","Tony","Award","-","now","known","collectively","as","an","EGOT","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","O","O","O","B-award","I-award","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["album","song","award","musical_instrument","organization","musical_artist","location","band","music_genre","country","event","person"]}
{"id":"126.S","dataset":"crossner_music","split":"dev","instance":{"id":"126.S","prompt_labels":"During(O) his(O) musical(O) career(O) ,(O) Tankian(B-musical_artist) has(O) released(O) five(O) albums(O) with(O) System(B-band) of(I-band) a(I-band) Down(I-band) ,(O) one(O) with(O) Arto(B-musical_artist) Tunçboyacıyan(I-musical_artist) ((O) Serart(B-album) )(O) ,(O) as(O) well(O) as(O) the(O) five(O) solo(O) albums(O) Elect(B-album) the(I-album) Dead(I-album) ,(O) Imperfect(B-album) Harmonies(I-album) ,(O) Harakiri(B-album) ,(O) Orca(B-album) Symphony(I-album) No.(I-album) 1(I-album) ,(O) and(O) Jazz-Iz-Christ(B-album) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, award, location, country, album, music_genre, organization, musical_instrument, band, song, person, musical_artist\nGIVEN SENTENCE: During his musical career , Tankian has released five albums with System of a Down , one with Arto Tunçboyacıyan ( Serart ) , as well as the five solo albums Elect the Dead , Imperfect Harmonies , Harakiri , Orca Symphony No. 1 , and Jazz-Iz-Christ .\n","prediction_output":null,"prediction_outputs":null,"group":"126","words":["During","his","musical","career",",","Tankian","has","released","five","albums","with","System","of","a","Down",",","one","with","Arto","Tunçboyacıyan","(","Serart",")",",","as","well","as","the","five","solo","albums","Elect","the","Dead",",","Imperfect","Harmonies",",","Harakiri",",","Orca","Symphony","No.","1",",","and","Jazz-Iz-Christ","."],"labels":["O","O","O","O","O","B-musical_artist","O","O","O","O","O","B-band","I-band","I-band","I-band","O","O","O","B-musical_artist","I-musical_artist","O","B-album","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","B-album","I-album","O","B-album","O","B-album","I-album","I-album","I-album","O","O","B-album","O"],"target_index":null,"target_label":null},"label_list":["event","award","location","country","album","music_genre","organization","musical_instrument","band","song","person","musical_artist"]}
{"id":"128.S","dataset":"crossner_music","split":"dev","instance":{"id":"128.S","prompt_labels":"They(O) restarted(O) to(O) perform(O) live(O) regularly(O) ,(O) touring(O) the(O) world(O) with(O) rapturous(O) feedbacks(O) :(O) they(O) brought(O) their(O) distinguishable(O) sound(O) in(O) great(O) venues(O) such(O) as(O) the(O) Kings(B-location) Place(I-location) in(O) London(B-location) ,(O) the(O) Soma(B-event) Festival(I-event) in(O) Belfast(B-location) ,(O) the(O) Bolshoi(B-location) Theatre(I-location) in(O) Moscow(B-location) and(O) the(O) Star(B-location) Pine(I-location) 's(I-location) cafe(I-location) in(O) Tokyo(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, band, organization, location, musical_instrument, person, event, music_genre, musical_artist, album, award, country\nGIVEN SENTENCE: They restarted to perform live regularly , touring the world with rapturous feedbacks : they brought their distinguishable sound in great venues such as the Kings Place in London , the Soma Festival in Belfast , the Bolshoi Theatre in Moscow and the Star Pine 's cafe in Tokyo .\n","prediction_output":null,"prediction_outputs":null,"group":"128","words":["They","restarted","to","perform","live","regularly",",","touring","the","world","with","rapturous","feedbacks",":","they","brought","their","distinguishable","sound","in","great","venues","such","as","the","Kings","Place","in","London",",","the","Soma","Festival","in","Belfast",",","the","Bolshoi","Theatre","in","Moscow","and","the","Star","Pine","'s","cafe","in","Tokyo","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","O","B-event","I-event","O","B-location","O","O","B-location","I-location","O","B-location","O","O","B-location","I-location","I-location","I-location","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["song","band","organization","location","musical_instrument","person","event","music_genre","musical_artist","album","award","country"]}
{"id":"129.S","dataset":"crossner_music","split":"dev","instance":{"id":"129.S","prompt_labels":"The(O) Hall(O) is(O) flanked(O) by(O) The(O) Royal(B-location) Lyceum(I-location) Theatre(I-location) on(O) the(O) right(O) and(O) The(O) Traverse(B-location) Theatre(I-location) on(O) the(O) left(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_instrument, album, award, musical_artist, event, person, music_genre, song, organization, location, country, band\nGIVEN SENTENCE: The Hall is flanked by The Royal Lyceum Theatre on the right and The Traverse Theatre on the left .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["The","Hall","is","flanked","by","The","Royal","Lyceum","Theatre","on","the","right","and","The","Traverse","Theatre","on","the","left","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","O","O","O","O","O","B-location","I-location","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["musical_instrument","album","award","musical_artist","event","person","music_genre","song","organization","location","country","band"]}
{"id":"133.S","dataset":"crossner_music","split":"dev","instance":{"id":"133.S","prompt_labels":"In(O) 2006(O) ,(O) the(O) Doha(B-organization) Asian(I-organization) Games(I-organization) Organising(I-organization) Committee(I-organization) has(O) named(O) Gary(B-musical_artist) Valenciano(I-musical_artist) the(O) official(O) performer(O) of(O) the(O) 2006(B-event) Asian(I-event) Games(I-event) '(O) theme(O) song(O) ,(O) Side(B-song) By(I-song) Side(I-song) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, song, band, event, country, musical_artist, music_genre, location, person, album, musical_instrument, award\nGIVEN SENTENCE: In 2006 , the Doha Asian Games Organising Committee has named Gary Valenciano the official performer of the 2006 Asian Games ' theme song , Side By Side .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["In","2006",",","the","Doha","Asian","Games","Organising","Committee","has","named","Gary","Valenciano","the","official","performer","of","the","2006","Asian","Games","'","theme","song",",","Side","By","Side","."],"labels":["O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","B-song","I-song","I-song","O"],"target_index":null,"target_label":null},"label_list":["organization","song","band","event","country","musical_artist","music_genre","location","person","album","musical_instrument","award"]}
{"id":"134.S","dataset":"crossner_music","split":"dev","instance":{"id":"134.S","prompt_labels":"DC(B-band) Talk(I-band) ((O) stylized(O) as(O) dc(B-band) Talk(I-band) )(O) is(O) a(O) Christian(B-music_genre) hip(I-music_genre) hop(I-music_genre) and(O) Christian(B-music_genre) rock(I-music_genre) trio(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, music_genre, event, person, organization, album, song, award, musical_instrument, band, country, musical_artist\nGIVEN SENTENCE: DC Talk ( stylized as dc Talk ) is a Christian hip hop and Christian rock trio .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["DC","Talk","(","stylized","as","dc","Talk",")","is","a","Christian","hip","hop","and","Christian","rock","trio","."],"labels":["B-band","I-band","O","O","O","B-band","I-band","O","O","O","B-music_genre","I-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","O"],"target_index":null,"target_label":null},"label_list":["location","music_genre","event","person","organization","album","song","award","musical_instrument","band","country","musical_artist"]}
{"id":"140.S","dataset":"crossner_music","split":"dev","instance":{"id":"140.S","prompt_labels":"Black(B-music_genre) metal(I-music_genre) album(O) covers(O) are(O) typically(O) dark(O) and(O) tend(O) to(O) be(O) atmospheric(O) or(O) provocative(O) ;(O) some(O) feature(O) natural(O) or(O) fantasy(O) landscapes(O) ((O) for(O) example(O) Burzum(B-band) '(O) s(O) Filosofem(B-album) and(O) Emperor(B-band) 's(O) In(B-album) the(I-album) Nightside(I-album) Eclipse(I-album) )(O) while(O) others(O) are(O) violent(O) ,(O) sexually(O) transgressive(O) ,(O) sacrilegious(O) ,(O) or(O) iconoclastic(O) ((O) for(O) example(O) Marduk(B-band) '(O) s(O) Fuck(B-album) Me(I-album) Jesus(I-album) and(O) Dimmu(B-band) Borgir(I-band) '(O) s(O) In(B-album) Sorte(I-album) Diaboli(I-album) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, song, album, organization, band, person, music_genre, country, musical_instrument, location, musical_artist, event\nGIVEN SENTENCE: Black metal album covers are typically dark and tend to be atmospheric or provocative ; some feature natural or fantasy landscapes ( for example Burzum ' s Filosofem and Emperor 's In the Nightside Eclipse ) while others are violent , sexually transgressive , sacrilegious , or iconoclastic ( for example Marduk ' s Fuck Me Jesus and Dimmu Borgir ' s In Sorte Diaboli ) .\n","prediction_output":null,"prediction_outputs":null,"group":"140","words":["Black","metal","album","covers","are","typically","dark","and","tend","to","be","atmospheric","or","provocative",";","some","feature","natural","or","fantasy","landscapes","(","for","example","Burzum","'","s","Filosofem","and","Emperor","'s","In","the","Nightside","Eclipse",")","while","others","are","violent",",","sexually","transgressive",",","sacrilegious",",","or","iconoclastic","(","for","example","Marduk","'","s","Fuck","Me","Jesus","and","Dimmu","Borgir","'","s","In","Sorte","Diaboli",")","."],"labels":["B-music_genre","I-music_genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","O","B-album","O","B-band","O","B-album","I-album","I-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","O","B-album","I-album","I-album","O","B-band","I-band","O","O","B-album","I-album","I-album","O","O"],"target_index":null,"target_label":null},"label_list":["award","song","album","organization","band","person","music_genre","country","musical_instrument","location","musical_artist","event"]}
{"id":"141.S","dataset":"crossner_music","split":"dev","instance":{"id":"141.S","prompt_labels":"Parliament-Funkadelic(B-band) 's(O) musical(O) influence(O) can(O) also(O) be(O) heard(O) in(O) rhythm(B-music_genre) and(I-music_genre) blues(I-music_genre) ,(O) Soul(B-music_genre) music(I-music_genre) ,(O) electronica(B-music_genre) ,(O) Gospel(B-music_genre) music(I-music_genre) ,(O) jazz(B-music_genre) ,(O) and(O) New(B-music_genre) wave(I-music_genre) music(I-music_genre) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, musical_instrument, organization, award, musical_artist, event, song, album, person, music_genre, country, band\nGIVEN SENTENCE: Parliament-Funkadelic 's musical influence can also be heard in rhythm and blues , Soul music , electronica , Gospel music , jazz , and New wave music .\n","prediction_output":null,"prediction_outputs":null,"group":"141","words":["Parliament-Funkadelic","'s","musical","influence","can","also","be","heard","in","rhythm","and","blues",",","Soul","music",",","electronica",",","Gospel","music",",","jazz",",","and","New","wave","music","."],"labels":["B-band","O","O","O","O","O","O","O","O","B-music_genre","I-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","O","O","B-music_genre","I-music_genre","I-music_genre","O"],"target_index":null,"target_label":null},"label_list":["location","musical_instrument","organization","award","musical_artist","event","song","album","person","music_genre","country","band"]}
{"id":"142.S","dataset":"crossner_music","split":"dev","instance":{"id":"142.S","prompt_labels":"The(O) set(O) includes(O) the(O) first(O) round(O) of(O) the(O) remastered(O) series(O) plus(O) the(O) long-awaited(O) remastered(O) versions(O) of(O) On(B-album) Your(I-album) Feet(I-album) or(I-album) on(I-album) Your(I-album) Knees(I-album) ((O) 1975(O) )(O) ,(O) Mirrors(B-album) ,(O) Cultösaurus(B-album) Erectus(I-album) ,(O) Fire(B-album) Of(I-album) Unknown(I-album) Origin(I-album) ,(O) Extraterrestrial(B-album) Live(I-album) ,(O) The(B-album) Revölution(I-album) by(I-album) Night(I-album) ,(O) Club(B-album) Ninja(I-album) and(O) Imaginos(B-album) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_artist, location, country, award, song, organization, band, event, musical_instrument, album, music_genre, person\nGIVEN SENTENCE: The set includes the first round of the remastered series plus the long-awaited remastered versions of On Your Feet or on Your Knees ( 1975 ) , Mirrors , Cultösaurus Erectus , Fire Of Unknown Origin , Extraterrestrial Live , The Revölution by Night , Club Ninja and Imaginos .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["The","set","includes","the","first","round","of","the","remastered","series","plus","the","long-awaited","remastered","versions","of","On","Your","Feet","or","on","Your","Knees","(","1975",")",",","Mirrors",",","Cultösaurus","Erectus",",","Fire","Of","Unknown","Origin",",","Extraterrestrial","Live",",","The","Revölution","by","Night",",","Club","Ninja","and","Imaginos","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","I-album","O","O","O","O","B-album","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","O","B-album","O"],"target_index":null,"target_label":null},"label_list":["musical_artist","location","country","award","song","organization","band","event","musical_instrument","album","music_genre","person"]}
{"id":"143.S","dataset":"crossner_music","split":"dev","instance":{"id":"143.S","prompt_labels":"In(O) 1994(O) ,(O) Yauch(B-musical_artist) and(O) activist(O) Erin(B-musical_artist) Potts(I-musical_artist) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(B-band) ,(O) Mike(B-musical_artist) Mills(I-musical_artist) and(O) Michael(B-musical_artist) Stipe(I-musical_artist) of(O) R.E.M.(B-band) ,(O) Rage(B-band) Against(I-band) the(I-band) Machine(I-band) ,(O) The(B-band) Smashing(I-band) Pumpkins(I-band) ,(O) and(O) U2(B-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, musical_instrument, event, album, organization, song, musical_artist, location, country, award, person, music_genre\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":null},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"145.S","dataset":"crossner_music","split":"dev","instance":{"id":"145.S","prompt_labels":"UK(B-country) Christmas(B-event) hit(O) singles(O) ;(O) Merry(B-song) Xmas(I-song) Everybody(I-song) by(O) Slade(B-band) ,(O) I(B-song) Wish(I-song) It(I-song) Could(I-song) Be(I-song) Christmas(I-song) Everyday(I-song) by(O) Wizzard(B-band) and(O) Lonely(B-song) This(I-song) Christmas(I-song) by(O) Mud(B-band) ,(O) all(O) of(O) which(O) have(O) remained(O) hugely(O) popular(O) ..(O) 14(O) December(O) 2012(O) PRS(B-organization) press(O) release(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, event, band, music_genre, country, organization, musical_artist, album, location, award, person, musical_instrument\nGIVEN SENTENCE: UK Christmas hit singles ; Merry Xmas Everybody by Slade , I Wish It Could Be Christmas Everyday by Wizzard and Lonely This Christmas by Mud , all of which have remained hugely popular .. 14 December 2012 PRS press release .\n","prediction_output":null,"prediction_outputs":null,"group":"145","words":["UK","Christmas","hit","singles",";","Merry","Xmas","Everybody","by","Slade",",","I","Wish","It","Could","Be","Christmas","Everyday","by","Wizzard","and","Lonely","This","Christmas","by","Mud",",","all","of","which","have","remained","hugely","popular","..","14","December","2012","PRS","press","release","."],"labels":["B-country","B-event","O","O","O","B-song","I-song","I-song","O","B-band","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-band","O","B-song","I-song","I-song","O","B-band","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O"],"target_index":null,"target_label":null},"label_list":["song","event","band","music_genre","country","organization","musical_artist","album","location","award","person","musical_instrument"]}
{"id":"148.S","dataset":"crossner_music","split":"dev","instance":{"id":"148.S","prompt_labels":"In(O) the(O) 1990s(O) ,(O) country(B-music_genre) music(I-music_genre) became(O) a(O) worldwide(O) phenomenon(O) thanks(O) to(O) Garth(B-musical_artist) Brooks(I-musical_artist) ,(O) Other(O) artists(O) that(O) experienced(O) success(O) during(O) this(O) time(O) included(O) Clint(B-musical_artist) Black(I-musical_artist) ,(O) Sammy(B-musical_artist) Kershaw(I-musical_artist) ,(O) Aaron(B-musical_artist) Tippin(I-musical_artist) ,(O) Travis(B-musical_artist) Tritt(I-musical_artist) ,(O) Alan(B-musical_artist) Jackson(I-musical_artist) and(O) the(O) newly(O) formed(O) duo(O) of(O) Brooks(B-band) &(I-band) amp(I-band) ;(I-band) Dunn(I-band) ;(O) George(B-musical_artist) Strait(I-musical_artist) ,(O) whose(O) career(O) began(O) in(O) the(O) 1980s(O) ,(O) also(O) continued(O) to(O) have(O) widespread(O) success(O) in(O) this(O) decade(O) and(O) beyond(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: song, location, band, musical_instrument, country, musical_artist, award, person, music_genre, organization, album, event\nGIVEN SENTENCE: In the 1990s , country music became a worldwide phenomenon thanks to Garth Brooks , Other artists that experienced success during this time included Clint Black , Sammy Kershaw , Aaron Tippin , Travis Tritt , Alan Jackson and the newly formed duo of Brooks & amp ; Dunn ; George Strait , whose career began in the 1980s , also continued to have widespread success in this decade and beyond .\n","prediction_output":null,"prediction_outputs":null,"group":"148","words":["In","the","1990s",",","country","music","became","a","worldwide","phenomenon","thanks","to","Garth","Brooks",",","Other","artists","that","experienced","success","during","this","time","included","Clint","Black",",","Sammy","Kershaw",",","Aaron","Tippin",",","Travis","Tritt",",","Alan","Jackson","and","the","newly","formed","duo","of","Brooks","&","amp",";","Dunn",";","George","Strait",",","whose","career","began","in","the","1980s",",","also","continued","to","have","widespread","success","in","this","decade","and","beyond","."],"labels":["O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","B-band","I-band","I-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["song","location","band","musical_instrument","country","musical_artist","award","person","music_genre","organization","album","event"]}
{"id":"149.S","dataset":"crossner_music","split":"dev","instance":{"id":"149.S","prompt_labels":"Sidney(B-musical_artist) Simien(I-musical_artist) ((O) April(O) 9(O) ,(O) 1938(O) -(O) February(O) 25(O) ,(O) 1998(O) )(O) ,(O) known(O) as(O) Rockin(B-musical_artist) '(I-musical_artist) Sidney(I-musical_artist) and(O) Count(B-musical_artist) Rockin(I-musical_artist) '(I-musical_artist) Sidney(I-musical_artist) ,(O) was(O) an(O) American(O) Rhythm(B-music_genre) and(I-music_genre) blues(I-music_genre) ,(O) zydeco(B-music_genre) ,(O) and(O) Soul(B-music_genre) music(I-music_genre) musician(O) who(O) began(O) recording(O) in(O) the(O) late(O) 1950s(O) and(O) continued(O) performing(O) until(O) his(O) death(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, location, event, musical_instrument, album, musical_artist, song, music_genre, award, band, person\nGIVEN SENTENCE: Sidney Simien ( April 9 , 1938 - February 25 , 1998 ) , known as Rockin ' Sidney and Count Rockin ' Sidney , was an American Rhythm and blues , zydeco , and Soul music musician who began recording in the late 1950s and continued performing until his death .\n","prediction_output":null,"prediction_outputs":null,"group":"149","words":["Sidney","Simien","(","April","9",",","1938","-","February","25",",","1998",")",",","known","as","Rockin","'","Sidney","and","Count","Rockin","'","Sidney",",","was","an","American","Rhythm","and","blues",",","zydeco",",","and","Soul","music","musician","who","began","recording","in","the","late","1950s","and","continued","performing","until","his","death","."],"labels":["B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","B-music_genre","I-music_genre","I-music_genre","O","B-music_genre","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","country","location","event","musical_instrument","album","musical_artist","song","music_genre","award","band","person"]}
{"id":"152.S","dataset":"crossner_music","split":"dev","instance":{"id":"152.S","prompt_labels":"The(O) Academy(O) sought(O) to(O) promote(O) country(B-music_genre) /(I-music_genre) western(I-music_genre) music(I-music_genre) in(O) the(O) western(O) states(O) ;(O) this(O) was(O) in(O) contrast(O) to(O) the(O) Country(B-organization) Music(I-organization) Association(I-organization) ,(O) based(O) in(O) Nashville(B-location) ,(O) Tennessee(B-location) ((O) then(O) the(O) center(O) of(O) the(O) pop-oriented(O) Nashville(B-music_genre) sound(I-music_genre) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, event, music_genre, musical_artist, album, song, award, organization, country, band, location, musical_instrument\nGIVEN SENTENCE: The Academy sought to promote country / western music in the western states ; this was in contrast to the Country Music Association , based in Nashville , Tennessee ( then the center of the pop-oriented Nashville sound ) .\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["The","Academy","sought","to","promote","country","/","western","music","in","the","western","states",";","this","was","in","contrast","to","the","Country","Music","Association",",","based","in","Nashville",",","Tennessee","(","then","the","center","of","the","pop-oriented","Nashville","sound",")","."],"labels":["O","O","O","O","O","B-music_genre","I-music_genre","I-music_genre","I-music_genre","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","B-location","O","B-location","O","O","O","O","O","O","O","B-music_genre","I-music_genre","O","O"],"target_index":null,"target_label":null},"label_list":["person","event","music_genre","musical_artist","album","song","award","organization","country","band","location","musical_instrument"]}
{"id":"153.S","dataset":"crossner_music","split":"dev","instance":{"id":"153.S","prompt_labels":"Muggs(B-musical_artist) released(O) Soul(O) Assassins(O) :(O) Chapter(O) 1(O) featuring(O) contributions(O) from(O) Dr.(B-musical_artist) Dre(I-musical_artist) ,(O) KRS-One(B-musical_artist) ,(O) Wyclef(B-musical_artist) Jean(I-musical_artist) and(O) Mobb(B-band) Deep(I-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, event, musical_instrument, music_genre, location, song, award, musical_artist, album, organization, person, country\nGIVEN SENTENCE: Muggs released Soul Assassins : Chapter 1 featuring contributions from Dr. Dre , KRS-One , Wyclef Jean and Mobb Deep .\n","prediction_output":null,"prediction_outputs":null,"group":"153","words":["Muggs","released","Soul","Assassins",":","Chapter","1","featuring","contributions","from","Dr.","Dre",",","KRS-One",",","Wyclef","Jean","and","Mobb","Deep","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","I-band","O"],"target_index":null,"target_label":null},"label_list":["band","event","musical_instrument","music_genre","location","song","award","musical_artist","album","organization","person","country"]}
{"id":"154.S","dataset":"crossner_music","split":"dev","instance":{"id":"154.S","prompt_labels":"In(O) recognition(O) of(O) her(O) film(O) career(O) ,(O) she(O) received(O) BAFTA(B-award) 's(I-award) Lifetime(I-award) Achievement(I-award) Award(I-award) ,(O) the(O) Golden(B-award) Globe(I-award) Cecil(I-award) B.(I-award) DeMille(I-award) Award(I-award) ,(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Life(I-award) Achievement(I-award) Award(I-award) ,(O) and(O) the(O) Special(B-award) Tony(I-award) Award(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_artist, person, country, award, song, musical_instrument, band, event, music_genre, album, organization, location\nGIVEN SENTENCE: In recognition of her film career , she received BAFTA 's Lifetime Achievement Award , the Golden Globe Cecil B. DeMille Award , the Screen Actors Guild Life Achievement Award , and the Special Tony Award .\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["In","recognition","of","her","film","career",",","she","received","BAFTA","'s","Lifetime","Achievement","Award",",","the","Golden","Globe","Cecil","B.","DeMille","Award",",","the","Screen","Actors","Guild","Life","Achievement","Award",",","and","the","Special","Tony","Award","."],"labels":["O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["musical_artist","person","country","award","song","musical_instrument","band","event","music_genre","album","organization","location"]}
{"id":"155.S","dataset":"crossner_music","split":"dev","instance":{"id":"155.S","prompt_labels":"It(O) also(O) produced(O) the(O) Top(O) 5(O) single(O) Rage(B-song) Hard(I-song) ((O) #(O) 1(O) in(O) Germany(B-country) )(O) ,(O) Top(O) 20(O) single(O) Warriors(B-song) of(I-song) the(I-song) Wasteland(I-song) and(O) Top(O) 30(O) single(O) Watching(B-song) the(I-song) Wildlife(I-song) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, organization, country, location, person, music_genre, album, musical_artist, song, musical_instrument, award, event\nGIVEN SENTENCE: It also produced the Top 5 single Rage Hard ( # 1 in Germany ) , Top 20 single Warriors of the Wasteland and Top 30 single Watching the Wildlife .\n","prediction_output":null,"prediction_outputs":null,"group":"155","words":["It","also","produced","the","Top","5","single","Rage","Hard","(","#","1","in","Germany",")",",","Top","20","single","Warriors","of","the","Wasteland","and","Top","30","single","Watching","the","Wildlife","."],"labels":["O","O","O","O","O","O","O","B-song","I-song","O","O","O","O","B-country","O","O","O","O","O","B-song","I-song","I-song","I-song","O","O","O","O","B-song","I-song","I-song","O"],"target_index":null,"target_label":null},"label_list":["band","organization","country","location","person","music_genre","album","musical_artist","song","musical_instrument","award","event"]}
{"id":"157.S","dataset":"crossner_music","split":"dev","instance":{"id":"157.S","prompt_labels":"In(O) the(O) 2010s(O) ,(O) the(O) alt-country(B-music_genre) genre(I-music_genre) saw(O) an(O) increase(O) in(O) its(O) critical(O) and(O) commercial(O) popularity(O) ,(O) owing(O) to(O) the(O) success(O) of(O) artists(O) such(O) as(O) The(B-band) Civil(I-band) Wars(I-band) ,(O) Chris(B-musical_artist) Stapleton(I-musical_artist) ,(O) Sturgill(B-musical_artist) Simpson(I-musical_artist) ,(O) Jason(B-musical_artist) Isbell(I-musical_artist) ,(O) Lydia(B-band) Loveless(I-band) and(O) Margo(B-musical_artist) Price(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_artist, person, musical_instrument, music_genre, organization, event, award, album, country, band, location, song\nGIVEN SENTENCE: In the 2010s , the alt-country genre saw an increase in its critical and commercial popularity , owing to the success of artists such as The Civil Wars , Chris Stapleton , Sturgill Simpson , Jason Isbell , Lydia Loveless and Margo Price .\n","prediction_output":null,"prediction_outputs":null,"group":"157","words":["In","the","2010s",",","the","alt-country","genre","saw","an","increase","in","its","critical","and","commercial","popularity",",","owing","to","the","success","of","artists","such","as","The","Civil","Wars",",","Chris","Stapleton",",","Sturgill","Simpson",",","Jason","Isbell",",","Lydia","Loveless","and","Margo","Price","."],"labels":["O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","I-band","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["musical_artist","person","musical_instrument","music_genre","organization","event","award","album","country","band","location","song"]}
{"id":"158.S","dataset":"crossner_music","split":"dev","instance":{"id":"158.S","prompt_labels":"At(O) the(O) 51st(B-award) Academy(I-award) Awards(I-award) ,(O) it(O) was(O) nominated(O) for(O) nine(O) Academy(B-award) Awards(I-award) ,(O) and(O) won(O) five(O) :(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) for(O) Cimino(B-person) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Supporting(I-award) Actor(I-award) for(O) Walken(B-person) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Sound(I-award) Mixing(I-award) ,(O) and(O) Best(B-award) Film(I-award) Editing(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, musical_artist, music_genre, event, person, album, award, band, musical_instrument, location, song, country\nGIVEN SENTENCE: At the 51st Academy Awards , it was nominated for nine Academy Awards , and won five : Academy Award for Best Picture , Academy Award for Best Director for Cimino , Academy Award for Best Supporting Actor for Walken , Academy Award for Best Sound Mixing , and Best Film Editing .\n","prediction_output":null,"prediction_outputs":null,"group":"158","words":["At","the","51st","Academy","Awards",",","it","was","nominated","for","nine","Academy","Awards",",","and","won","five",":","Academy","Award","for","Best","Picture",",","Academy","Award","for","Best","Director","for","Cimino",",","Academy","Award","for","Best","Supporting","Actor","for","Walken",",","Academy","Award","for","Best","Sound","Mixing",",","and","Best","Film","Editing","."],"labels":["O","O","B-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-person","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["organization","musical_artist","music_genre","event","person","album","award","band","musical_instrument","location","song","country"]}
{"id":"159.S","dataset":"crossner_music","split":"dev","instance":{"id":"159.S","prompt_labels":"Biafra(B-musical_artist) was(O) also(O) working(O) with(O) a(O) band(O) known(O) as(O) Jello(B-band) Biafra(I-band) and(I-band) the(I-band) Guantanamo(I-band) School(I-band) of(I-band) Medicine(I-band) ,(O) which(O) included(O) Ralph(B-musical_artist) Spight(I-musical_artist) of(O) Victims(B-band) Family(I-band) on(O) guitar(B-musical_instrument) and(O) Billy(B-musical_artist) Gould(I-musical_artist) of(O) Faith(B-band) No(I-band) More(I-band) on(O) bass(B-musical_instrument) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, song, person, musical_artist, event, location, organization, album, music_genre, country, band, musical_instrument\nGIVEN SENTENCE: Biafra was also working with a band known as Jello Biafra and the Guantanamo School of Medicine , which included Ralph Spight of Victims Family on guitar and Billy Gould of Faith No More on bass .\n","prediction_output":null,"prediction_outputs":null,"group":"159","words":["Biafra","was","also","working","with","a","band","known","as","Jello","Biafra","and","the","Guantanamo","School","of","Medicine",",","which","included","Ralph","Spight","of","Victims","Family","on","guitar","and","Billy","Gould","of","Faith","No","More","on","bass","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","B-band","I-band","I-band","I-band","I-band","I-band","I-band","I-band","O","O","O","B-musical_artist","I-musical_artist","O","B-band","I-band","O","B-musical_instrument","O","B-musical_artist","I-musical_artist","O","B-band","I-band","I-band","O","B-musical_instrument","O"],"target_index":null,"target_label":null},"label_list":["award","song","person","musical_artist","event","location","organization","album","music_genre","country","band","musical_instrument"]}
{"id":"161.S","dataset":"crossner_music","split":"dev","instance":{"id":"161.S","prompt_labels":"The(O) three(O) venues(O) regarded(O) as(O) the(O) most(O) important(O) in(O) this(O) decade(O) were(O) the(O) Golden(B-location) Torch(I-location) in(O) Tunstall(B-location) ,(O) Stoke-on-Trent(B-location) ((O) 1971(O) to(O) 1972(O) )(O) ,(O) Blackpool(B-location) Mecca(I-location) ((O) 1971(O) to(O) 1979(O) )(O) and(O) Wigan(B-location) Casino(I-location) ((O) 1973(O) to(O) 1981(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, award, music_genre, musical_artist, person, band, musical_instrument, album, song, country, organization, location\nGIVEN SENTENCE: The three venues regarded as the most important in this decade were the Golden Torch in Tunstall , Stoke-on-Trent ( 1971 to 1972 ) , Blackpool Mecca ( 1971 to 1979 ) and Wigan Casino ( 1973 to 1981 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"161","words":["The","three","venues","regarded","as","the","most","important","in","this","decade","were","the","Golden","Torch","in","Tunstall",",","Stoke-on-Trent","(","1971","to","1972",")",",","Blackpool","Mecca","(","1971","to","1979",")","and","Wigan","Casino","(","1973","to","1981",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","B-location","O","B-location","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","award","music_genre","musical_artist","person","band","musical_instrument","album","song","country","organization","location"]}
{"id":"163.S","dataset":"crossner_music","split":"dev","instance":{"id":"163.S","prompt_labels":"Minogue(B-musical_artist) has(O) sold(O) 70(O) million(O) records(O) worldwide(O) and(O) has(O) earned(O) numerous(O) awards(O) and(O) accolades(O) ,(O) including(O) a(O) Grammy(B-award) Award(I-award) ,(O) three(O) Brit(B-award) Awards(I-award) ,(O) 17(O) ARIA(B-award) Music(I-award) Awards(I-award) ,(O) two(O) MTV(B-award) Europe(I-award) Music(I-award) Award(I-award) and(O) two(O) MTV(B-award) Video(I-award) Music(I-award) Award(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_instrument, location, album, organization, musical_artist, event, award, band, music_genre, song, country, person\nGIVEN SENTENCE: Minogue has sold 70 million records worldwide and has earned numerous awards and accolades , including a Grammy Award , three Brit Awards , 17 ARIA Music Awards , two MTV Europe Music Award and two MTV Video Music Award .\n","prediction_output":null,"prediction_outputs":null,"group":"163","words":["Minogue","has","sold","70","million","records","worldwide","and","has","earned","numerous","awards","and","accolades",",","including","a","Grammy","Award",",","three","Brit","Awards",",","17","ARIA","Music","Awards",",","two","MTV","Europe","Music","Award","and","two","MTV","Video","Music","Award","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["musical_instrument","location","album","organization","musical_artist","event","award","band","music_genre","song","country","person"]}
{"id":"164.S","dataset":"crossner_music","split":"dev","instance":{"id":"164.S","prompt_labels":"The(O) festival(O) features(O) bands(O) from(O) different(O) places(O) in(O) Argentina(B-country) ,(O) as(O) well(O) as(O) international(O) artists(O) from(O) Brazil(B-country) ,(O) Uruguay(B-country) ,(O) Chile(B-country) ,(O) Peru(B-country) and(O) the(O) United(B-country) States(I-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, band, album, person, location, song, musical_instrument, musical_artist, music_genre, award, event\nGIVEN SENTENCE: The festival features bands from different places in Argentina , as well as international artists from Brazil , Uruguay , Chile , Peru and the United States .\n","prediction_output":null,"prediction_outputs":null,"group":"164","words":["The","festival","features","bands","from","different","places","in","Argentina",",","as","well","as","international","artists","from","Brazil",",","Uruguay",",","Chile",",","Peru","and","the","United","States","."],"labels":["O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O","B-country","O","O","B-country","I-country","O"],"target_index":null,"target_label":null},"label_list":["organization","country","band","album","person","location","song","musical_instrument","musical_artist","music_genre","award","event"]}
{"id":"170.S","dataset":"crossner_music","split":"dev","instance":{"id":"170.S","prompt_labels":"Some(O) of(O) the(O) early(O) stars(O) on(O) the(O) Opry(B-location) were(O) Uncle(B-musical_artist) Dave(I-musical_artist) Macon(I-musical_artist) ,(O) Roy(B-musical_artist) Acuff(I-musical_artist) and(O) African(O) American(O) harmonica(B-musical_instrument) player(O) DeFord(B-musical_artist) Bailey(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: album, country, location, song, musical_artist, award, band, music_genre, organization, person, musical_instrument, event\nGIVEN SENTENCE: Some of the early stars on the Opry were Uncle Dave Macon , Roy Acuff and African American harmonica player DeFord Bailey .\n","prediction_output":null,"prediction_outputs":null,"group":"170","words":["Some","of","the","early","stars","on","the","Opry","were","Uncle","Dave","Macon",",","Roy","Acuff","and","African","American","harmonica","player","DeFord","Bailey","."],"labels":["O","O","O","O","O","O","O","B-location","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","B-musical_instrument","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["album","country","location","song","musical_artist","award","band","music_genre","organization","person","musical_instrument","event"]}
{"id":"172.S","dataset":"crossner_music","split":"dev","instance":{"id":"172.S","prompt_labels":"Bands(O) like(O) Flogging(B-band) Molly(I-band) ,(O) Black(B-band) 47(I-band) ,(O) Dropkick(B-band) Murphys(I-band) ,(O) The(B-band) Young(I-band) Dubliners(I-band) ,(O) The(B-band) Tossers(I-band) introduced(O) a(O) hybrid(O) of(O) Celtic(B-music_genre) rock(I-music_genre) ,(O) Punk(B-music_genre) rock(I-music_genre) ,(O) reggae(B-music_genre) ,(O) Hardcore(B-music_genre) punk(I-music_genre) and(O) other(O) elements(O) in(O) the(O) 1990s(O) that(O) has(O) become(O) popular(O) with(O) Irish-American(O) youth(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_artist, country, event, musical_instrument, person, band, album, song, location, organization, music_genre, award\nGIVEN SENTENCE: Bands like Flogging Molly , Black 47 , Dropkick Murphys , The Young Dubliners , The Tossers introduced a hybrid of Celtic rock , Punk rock , reggae , Hardcore punk and other elements in the 1990s that has become popular with Irish-American youth .\n","prediction_output":null,"prediction_outputs":null,"group":"172","words":["Bands","like","Flogging","Molly",",","Black","47",",","Dropkick","Murphys",",","The","Young","Dubliners",",","The","Tossers","introduced","a","hybrid","of","Celtic","rock",",","Punk","rock",",","reggae",",","Hardcore","punk","and","other","elements","in","the","1990s","that","has","become","popular","with","Irish-American","youth","."],"labels":["O","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","O","B-band","I-band","I-band","O","B-band","I-band","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","I-music_genre","O","B-music_genre","O","B-music_genre","I-music_genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["musical_artist","country","event","musical_instrument","person","band","album","song","location","organization","music_genre","award"]}
{"id":"173.S","dataset":"crossner_music","split":"dev","instance":{"id":"173.S","prompt_labels":"Their(O) eighth(O) album(O) ,(O) Hesitation(B-album) Marks(I-album) ((O) 2013(O) )(O) ,(O) was(O) followed(O) by(O) a(O) trilogy(O) consisting(O) of(O) the(O) EPs(O) Not(B-album) the(I-album) Actual(I-album) Events(I-album) ((O) 2016(O) )(O) and(O) Add(B-album) Violence(I-album) ((O) 2017(O) )(O) and(O) their(O) ninth(O) album(O) Bad(B-album) Witch(I-album) ((O) 2018(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, music_genre, musical_artist, band, event, song, location, album, award, country, musical_instrument, person\nGIVEN SENTENCE: Their eighth album , Hesitation Marks ( 2013 ) , was followed by a trilogy consisting of the EPs Not the Actual Events ( 2016 ) and Add Violence ( 2017 ) and their ninth album Bad Witch ( 2018 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["Their","eighth","album",",","Hesitation","Marks","(","2013",")",",","was","followed","by","a","trilogy","consisting","of","the","EPs","Not","the","Actual","Events","(","2016",")","and","Add","Violence","(","2017",")","and","their","ninth","album","Bad","Witch","(","2018",")","."],"labels":["O","O","O","O","B-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","music_genre","musical_artist","band","event","song","location","album","award","country","musical_instrument","person"]}
{"id":"174.S","dataset":"crossner_music","split":"dev","instance":{"id":"174.S","prompt_labels":"He(O) has(O) appeared(O) as(O) a(O) featured(O) artist(O) on(O) many(O) other(O) songs(O) and(O) albums(O) ,(O) having(O) collaborated(O) with(O) artists(O) such(O) as(O) Janet(B-musical_artist) Jackson(I-musical_artist) ,(O) Kool(B-musical_artist) Moe(I-musical_artist) Dee(I-musical_artist) ,(O) The(B-band) Dope(I-band) Poet(I-band) Society(I-band) ,(O) Run-D.M.C.(B-band) ,(O) Ice(B-musical_artist) Cube(I-musical_artist) ,(O) Boom(B-band) Boom(I-band) Satellites(I-band) ,(O) Rage(B-band) Against(I-band) the(I-band) Machine(I-band) ,(O) Anthrax(B-band) ,(O) John(B-musical_artist) Mellencamp(I-musical_artist) and(O) many(O) others(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, album, country, person, music_genre, location, organization, song, award, musical_artist, musical_instrument, band\nGIVEN SENTENCE: He has appeared as a featured artist on many other songs and albums , having collaborated with artists such as Janet Jackson , Kool Moe Dee , The Dope Poet Society , Run-D.M.C. , Ice Cube , Boom Boom Satellites , Rage Against the Machine , Anthrax , John Mellencamp and many others .\n","prediction_output":null,"prediction_outputs":null,"group":"174","words":["He","has","appeared","as","a","featured","artist","on","many","other","songs","and","albums",",","having","collaborated","with","artists","such","as","Janet","Jackson",",","Kool","Moe","Dee",",","The","Dope","Poet","Society",",","Run-D.M.C.",",","Ice","Cube",",","Boom","Boom","Satellites",",","Rage","Against","the","Machine",",","Anthrax",",","John","Mellencamp","and","many","others","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-band","I-band","I-band","I-band","O","B-band","O","B-musical_artist","I-musical_artist","O","B-band","I-band","I-band","O","B-band","I-band","I-band","I-band","O","B-band","O","B-musical_artist","I-musical_artist","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","album","country","person","music_genre","location","organization","song","award","musical_artist","musical_instrument","band"]}
{"id":"176.S","dataset":"crossner_music","split":"dev","instance":{"id":"176.S","prompt_labels":"Besides(O) fronting(O) his(O) own(O) band(O) and(O) rap(B-music_genre) projects(O) ,(O) Ice-T(B-musical_artist) has(O) also(O) collaborated(O) with(O) other(O) hard(B-music_genre) rock(I-music_genre) and(O) metal(B-music_genre) bands(O) ,(O) such(O) as(O) Icepick(B-band) ,(O) Motörhead(B-band) ,(O) Slayer(B-band) ,(O) Pro-Pain(B-band) ,(O) and(O) Six(B-band) Feet(I-band) Under(I-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, band, award, musical_artist, album, organization, musical_instrument, person, country, location, music_genre, song\nGIVEN SENTENCE: Besides fronting his own band and rap projects , Ice-T has also collaborated with other hard rock and metal bands , such as Icepick , Motörhead , Slayer , Pro-Pain , and Six Feet Under .\n","prediction_output":null,"prediction_outputs":null,"group":"176","words":["Besides","fronting","his","own","band","and","rap","projects",",","Ice-T","has","also","collaborated","with","other","hard","rock","and","metal","bands",",","such","as","Icepick",",","Motörhead",",","Slayer",",","Pro-Pain",",","and","Six","Feet","Under","."],"labels":["O","O","O","O","O","O","B-music_genre","O","O","B-musical_artist","O","O","O","O","O","B-music_genre","I-music_genre","O","B-music_genre","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","O","O","B-band","I-band","I-band","O"],"target_index":null,"target_label":null},"label_list":["event","band","award","musical_artist","album","organization","musical_instrument","person","country","location","music_genre","song"]}
{"id":"180.S","dataset":"crossner_music","split":"dev","instance":{"id":"180.S","prompt_labels":"Alexander(B-musical_artist) von(I-musical_artist) Meilenwald(I-musical_artist) from(O) German(B-country) band(O) Nagelfar(B-band) considers(O) Ungod(B-band) '(O) s(O) 1993(O) debut(O) Circle(B-album) of(I-album) the(I-album) Seven(I-album) Infernal(I-album) Pacts(I-album) ,(O) Desaster(B-band) '(O) s(O) 1994(O) demo(O) Lost(B-album) in(I-album) the(I-album) Ages(I-album) ,(O) Tha-Norr(B-band) '(O) s(O) 1995(O) album(O) Wolfenzeitalter(B-album) ,(O) Lunar(B-band) Aurora(I-band) '(O) s(O) 1996(O) debut(O) Weltengänger(B-album) and(O) Katharsis(B-band) '(O) s(O) 2000(O) debut(O) 666(B-album) Alexander(B-musical_artist) von(I-musical_artist) Meilenwald(I-musical_artist) :(O) 5(O) Klassiker(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: music_genre, band, country, musical_instrument, song, location, event, person, album, award, musical_artist, organization\nGIVEN SENTENCE: Alexander von Meilenwald from German band Nagelfar considers Ungod ' s 1993 debut Circle of the Seven Infernal Pacts , Desaster ' s 1994 demo Lost in the Ages , Tha-Norr ' s 1995 album Wolfenzeitalter , Lunar Aurora ' s 1996 debut Weltengänger and Katharsis ' s 2000 debut 666 Alexander von Meilenwald : 5 Klassiker .\n","prediction_output":null,"prediction_outputs":null,"group":"180","words":["Alexander","von","Meilenwald","from","German","band","Nagelfar","considers","Ungod","'","s","1993","debut","Circle","of","the","Seven","Infernal","Pacts",",","Desaster","'","s","1994","demo","Lost","in","the","Ages",",","Tha-Norr","'","s","1995","album","Wolfenzeitalter",",","Lunar","Aurora","'","s","1996","debut","Weltengänger","and","Katharsis","'","s","2000","debut","666","Alexander","von","Meilenwald",":","5","Klassiker","."],"labels":["B-musical_artist","I-musical_artist","I-musical_artist","O","B-country","O","B-band","O","B-band","O","O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","O","B-band","O","O","O","O","B-album","I-album","I-album","I-album","O","B-band","O","O","O","O","B-album","O","B-band","I-band","O","O","O","O","B-album","O","B-band","O","O","O","O","B-album","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["music_genre","band","country","musical_instrument","song","location","event","person","album","award","musical_artist","organization"]}
{"id":"183.S","dataset":"crossner_music","split":"dev","instance":{"id":"183.S","prompt_labels":"In(O) February(O) 1984(O) ,(O) Queen(B-band) released(O) their(O) eleventh(O) studio(O) album(O) ,(O) The(B-album) Works(I-album) ,(O) which(O) included(O) the(O) successful(O) singles(O) Radio(B-song) Ga(I-song) Ga(I-song) ,(O) Hammer(B-song) to(I-song) Fall(I-song) and(O) I(B-song) Want(I-song) to(I-song) Break(I-song) Free(I-song) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, event, song, album, organization, band, award, person, music_genre, musical_artist, musical_instrument, country\nGIVEN SENTENCE: In February 1984 , Queen released their eleventh studio album , The Works , which included the successful singles Radio Ga Ga , Hammer to Fall and I Want to Break Free .\n","prediction_output":null,"prediction_outputs":null,"group":"183","words":["In","February","1984",",","Queen","released","their","eleventh","studio","album",",","The","Works",",","which","included","the","successful","singles","Radio","Ga","Ga",",","Hammer","to","Fall","and","I","Want","to","Break","Free","."],"labels":["O","O","O","O","B-band","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O","O","B-song","I-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":null},"label_list":["location","event","song","album","organization","band","award","person","music_genre","musical_artist","musical_instrument","country"]}
{"id":"187.S","dataset":"crossner_music","split":"dev","instance":{"id":"187.S","prompt_labels":"Fredriksson(B-musical_artist) returned(O) in(O) 2006(O) with(O) an(O) album(O) of(O) Swedish(O) cover(O) songs(O) ,(O) titled(O) Min(B-album) bäste(I-album) vän(I-album) ((O) My(B-album) Best(I-album) Friend(I-album) )(O) ,(O) while(O) Gessle(B-musical_artist) recorded(O) two(O) more(O) solo(O) albums(O) ,(O) En(B-album) händig(I-album) man(I-album) ((O) A(B-album) Handy(I-album) Man(I-album) )(O) ((O) 2007(O) )(O) and(O) Party(B-album) Crasher(I-album) ((O) 2008(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, song, music_genre, award, album, musical_instrument, event, country, band, musical_artist, location, organization\nGIVEN SENTENCE: Fredriksson returned in 2006 with an album of Swedish cover songs , titled Min bäste vän ( My Best Friend ) , while Gessle recorded two more solo albums , En händig man ( A Handy Man ) ( 2007 ) and Party Crasher ( 2008 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"187","words":["Fredriksson","returned","in","2006","with","an","album","of","Swedish","cover","songs",",","titled","Min","bäste","vän","(","My","Best","Friend",")",",","while","Gessle","recorded","two","more","solo","albums",",","En","händig","man","(","A","Handy","Man",")","(","2007",")","and","Party","Crasher","(","2008",")","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","O","O","B-musical_artist","O","O","O","O","O","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","O","O","O","O","B-album","I-album","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","song","music_genre","award","album","musical_instrument","event","country","band","musical_artist","location","organization"]}
{"id":"188.S","dataset":"crossner_music","split":"dev","instance":{"id":"188.S","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(B-musical_artist) D(I-musical_artist) and(O) LL(B-musical_artist) Cool(I-musical_artist) J(I-musical_artist) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical_artist) Thought(I-musical_artist) ,(O) Travie(B-musical_artist) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(B-musical_artist) Rock(I-musical_artist) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, person, organization, album, song, musical_artist, event, music_genre, location, award, country, musical_instrument\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"189.S","dataset":"crossner_music","split":"dev","instance":{"id":"189.S","prompt_labels":"Following(O) in(O) the(O) footsteps(O) of(O) Gene(B-musical_artist) Autry(I-musical_artist) ,(O) Lydia(B-musical_artist) Mendoza(I-musical_artist) ,(O) Roy(B-person) Rogers(I-person) ,(O) and(O) Patsy(B-musical_artist) Montana(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, organization, award, person, musical_artist, album, band, country, musical_instrument, song, event, music_genre\nGIVEN SENTENCE: Following in the footsteps of Gene Autry , Lydia Mendoza , Roy Rogers , and Patsy Montana .\n","prediction_output":null,"prediction_outputs":null,"group":"189","words":["Following","in","the","footsteps","of","Gene","Autry",",","Lydia","Mendoza",",","Roy","Rogers",",","and","Patsy","Montana","."],"labels":["O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-person","I-person","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":null},"label_list":["location","organization","award","person","musical_artist","album","band","country","musical_instrument","song","event","music_genre"]}
{"id":"190.S","dataset":"crossner_music","split":"dev","instance":{"id":"190.S","prompt_labels":"It(O) was(O) nominated(O) for(O) four(O) Academy(B-award) Awards(I-award) ,(O) including(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actor(I-award) ((O) De(B-person) Niro(I-person) )(O) ,(O) and(O) received(O) the(O) Palme(B-award) d(I-award) 'Or(I-award) at(O) the(O) 1976(B-event) Cannes(I-event) Film(I-event) Festival(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: band, person, musical_instrument, musical_artist, song, award, organization, location, event, album, country, music_genre\nGIVEN SENTENCE: It was nominated for four Academy Awards , including Academy Award for Best Picture and Academy Award for Best Actor ( De Niro ) , and received the Palme d 'Or at the 1976 Cannes Film Festival .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["It","was","nominated","for","four","Academy","Awards",",","including","Academy","Award","for","Best","Picture","and","Academy","Award","for","Best","Actor","(","De","Niro",")",",","and","received","the","Palme","d","'Or","at","the","1976","Cannes","Film","Festival","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","O","O","O","O","B-award","I-award","I-award","O","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["band","person","musical_instrument","musical_artist","song","award","organization","location","event","album","country","music_genre"]}
{"id":"191.S","dataset":"crossner_music","split":"dev","instance":{"id":"191.S","prompt_labels":"It(O) was(O) designed(O) by(O) Kenzo(B-person) Tange(I-person) and(O) built(O) between(O) 1961(O) and(O) 1964(O) to(O) house(O) Swimming(O) at(O) the(O) 1964(B-event) Summer(I-event) Olympics(I-event) and(O) Diving(O) at(O) the(O) 1964(B-event) Summer(I-event) Olympics(I-event) events(O) in(O) the(O) 1964(B-event) Summer(I-event) Olympics(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, album, event, country, song, band, organization, musical_instrument, award, musical_artist, music_genre, person\nGIVEN SENTENCE: It was designed by Kenzo Tange and built between 1961 and 1964 to house Swimming at the 1964 Summer Olympics and Diving at the 1964 Summer Olympics events in the 1964 Summer Olympics .\n","prediction_output":null,"prediction_outputs":null,"group":"191","words":["It","was","designed","by","Kenzo","Tange","and","built","between","1961","and","1964","to","house","Swimming","at","the","1964","Summer","Olympics","and","Diving","at","the","1964","Summer","Olympics","events","in","the","1964","Summer","Olympics","."],"labels":["O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","B-event","I-event","I-event","O","O","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["location","album","event","country","song","band","organization","musical_instrument","award","musical_artist","music_genre","person"]}
{"id":"194.S","dataset":"crossner_music","split":"dev","instance":{"id":"194.S","prompt_labels":"He(O) was(O) the(O) guitarist(O) for(O) the(O) 1980s(O) Hi-NRG(B-music_genre) ,(O) Synth-pop(B-music_genre) band(O) ,(O) Frankie(B-band) Goes(I-band) to(I-band) Hollywood(I-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: album, band, country, song, location, award, person, musical_artist, event, music_genre, musical_instrument, organization\nGIVEN SENTENCE: He was the guitarist for the 1980s Hi-NRG , Synth-pop band , Frankie Goes to Hollywood .\n","prediction_output":null,"prediction_outputs":null,"group":"194","words":["He","was","the","guitarist","for","the","1980s","Hi-NRG",",","Synth-pop","band",",","Frankie","Goes","to","Hollywood","."],"labels":["O","O","O","O","O","O","O","B-music_genre","O","B-music_genre","O","O","B-band","I-band","I-band","I-band","O"],"target_index":null,"target_label":null},"label_list":["album","band","country","song","location","award","person","musical_artist","event","music_genre","musical_instrument","organization"]}
{"id":"196.S","dataset":"crossner_music","split":"dev","instance":{"id":"196.S","prompt_labels":"In(O) July(O) 2010(O) ,(O) Dayne(B-musical_artist) released(O) Facing(B-song) a(I-song) Miracle(I-song) ,(O) the(O) official(O) theme(O) song(O) to(O) the(O) 2010(B-event) Gay(I-event) Games(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: musical_artist, event, music_genre, musical_instrument, person, organization, song, location, band, album, country, award\nGIVEN SENTENCE: In July 2010 , Dayne released Facing a Miracle , the official theme song to the 2010 Gay Games .\n","prediction_output":null,"prediction_outputs":null,"group":"196","words":["In","July","2010",",","Dayne","released","Facing","a","Miracle",",","the","official","theme","song","to","the","2010","Gay","Games","."],"labels":["O","O","O","O","B-musical_artist","O","B-song","I-song","I-song","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["musical_artist","event","music_genre","musical_instrument","person","organization","song","location","band","album","country","award"]}
{"id":"0.S","dataset":"crossner_politics","split":"dev","instance":{"id":"0.S","prompt_labels":"At(O) the(O) 2001(B-election) Italian(I-election) general(I-election) election(I-election) the(O) Greens(O) formed(O) a(O) joint(O) list(O) with(O) the(O) Italian(B-political_party) Democratic(I-political_party) Socialists(I-political_party) ((O) SDI(B-political_party) )(O) :(O) The(B-political_party) Sunflower(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, event, election, person, politician, political_party, organization, country\nGIVEN SENTENCE: At the 2001 Italian general election the Greens formed a joint list with the Italian Democratic Socialists ( SDI ) : The Sunflower .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["At","the","2001","Italian","general","election","the","Greens","formed","a","joint","list","with","the","Italian","Democratic","Socialists","(","SDI",")",":","The","Sunflower","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","B-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["location","event","election","person","politician","political_party","organization","country"]}
{"id":"1.S","dataset":"crossner_politics","split":"dev","instance":{"id":"1.S","prompt_labels":"For(O) the(O) 2009(B-election) European(I-election) Parliament(I-election) election(I-election) in(I-election) Italy(I-election) the(O) Greens(O) formed(O) a(O) joint(O) list(O) with(O) the(O) Movement(B-political_party) for(I-political_party) the(I-political_party) Left(I-political_party) ((O) MpS(B-political_party) )(O) -(O) a(O) moderate(O) split(O) from(O) the(O) PRC(B-political_party) -(O) ,(O) the(O) Socialist(B-political_party) Party(I-political_party) ((O) PS(B-political_party) )(O) -(O) successor(O) of(O) the(O) SDI(B-political_party) -(O) ,(O) SD(B-political_party) and(O) Unite(B-political_party) the(I-political_party) Left(I-political_party) ((O) UlS(B-political_party) )(O) :(O) Left(B-political_party) Ecology(I-political_party) Freedom(I-political_party) ((O) SL(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, location, person, political_party, politician, organization, election, event\nGIVEN SENTENCE: For the 2009 European Parliament election in Italy the Greens formed a joint list with the Movement for the Left ( MpS ) - a moderate split from the PRC - , the Socialist Party ( PS ) - successor of the SDI - , SD and Unite the Left ( UlS ) : Left Ecology Freedom ( SL ) .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["For","the","2009","European","Parliament","election","in","Italy","the","Greens","formed","a","joint","list","with","the","Movement","for","the","Left","(","MpS",")","-","a","moderate","split","from","the","PRC","-",",","the","Socialist","Party","(","PS",")","-","successor","of","the","SDI","-",",","SD","and","Unite","the","Left","(","UlS",")",":","Left","Ecology","Freedom","(","SL",")","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","O","O","O","B-political_party","I-political_party","O","B-political_party","O","O","O","O","O","B-political_party","O","O","B-political_party","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["country","location","person","political_party","politician","organization","election","event"]}
{"id":"2.S","dataset":"crossner_politics","split":"dev","instance":{"id":"2.S","prompt_labels":"Sitting(O) as(O) a(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) Member(O) of(O) Parliament(B-organization) ((O) MP(O) )(O) for(O) Niagara(O) Falls(O) ,(O) she(O) joined(O) the(O) Canadian(O) Cabinet(O) after(O) the(O) Liberals(O) defeated(O) the(O) Progressive(B-political_party) Conservative(I-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) government(O) of(O) John(B-politician) Diefenbaker(I-politician) in(O) the(O) 1963(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, political_party, country, person, event, organization, politician, election\nGIVEN SENTENCE: Sitting as a Liberal Party of Canada Member of Parliament ( MP ) for Niagara Falls , she joined the Canadian Cabinet after the Liberals defeated the Progressive Conservative Party of Canada government of John Diefenbaker in the 1963 Canadian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"2","words":["Sitting","as","a","Liberal","Party","of","Canada","Member","of","Parliament","(","MP",")","for","Niagara","Falls",",","she","joined","the","Canadian","Cabinet","after","the","Liberals","defeated","the","Progressive","Conservative","Party","of","Canada","government","of","John","Diefenbaker","in","the","1963","Canadian","federal","election","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-politician","I-politician","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["location","political_party","country","person","event","organization","politician","election"]}
{"id":"6.S","dataset":"crossner_politics","split":"dev","instance":{"id":"6.S","prompt_labels":"Their(O) destinies(O) are(O) all(O) altered(O) and(O) shaped(O) by(O) the(O) historical(O) event(O) ((O) for(O) example(O) :(O) Simard(B-politician) becomes(O) a(O) sovereigntist(O) and(O) will(O) leave(O) the(O) Quebec(B-political_party) Liberal(I-political_party) Party(I-political_party) for(O) the(O) Parti(B-political_party) Québécois(I-political_party) ;(O) Dumont(B-politician) will(O) also(O) slam(O) the(O) Liberal(O) door(O) to(O) later(O) help(O) create(O) and(O) finally(O) become(O) leader(O) of(O) the(O) Action(B-political_party) démocratique(I-political_party) du(I-political_party) Québec(I-political_party) ,(O) or(O) ADQ(B-political_party) ,(O) and(O) support(O) the(O) Yes(O) side(O) of(O) the(O) 1995(B-event) referendum(I-event) on(O) independence(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, political_party, politician, organization, election, person, event\nGIVEN SENTENCE: Their destinies are all altered and shaped by the historical event ( for example : Simard becomes a sovereigntist and will leave the Quebec Liberal Party for the Parti Québécois ; Dumont will also slam the Liberal door to later help create and finally become leader of the Action démocratique du Québec , or ADQ , and support the Yes side of the 1995 referendum on independence ) .\n","prediction_output":null,"prediction_outputs":null,"group":"6","words":["Their","destinies","are","all","altered","and","shaped","by","the","historical","event","(","for","example",":","Simard","becomes","a","sovereigntist","and","will","leave","the","Quebec","Liberal","Party","for","the","Parti","Québécois",";","Dumont","will","also","slam","the","Liberal","door","to","later","help","create","and","finally","become","leader","of","the","Action","démocratique","du","Québec",",","or","ADQ",",","and","support","the","Yes","side","of","the","1995","referendum","on","independence",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","O","O","O","O","O","O","O","O","B-event","I-event","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","country","political_party","politician","organization","election","person","event"]}
{"id":"7.S","dataset":"crossner_politics","split":"dev","instance":{"id":"7.S","prompt_labels":"Of(O) the(O) current(O) first(O) ministers(O) ,(O) four(O) are(O) from(O) a(O) Liberal(B-political_party) Party(I-political_party) ,(O) four(O) are(O) from(O) a(O) Progressive(B-political_party) Conservative(I-political_party) Party(I-political_party) ,(O) and(O) one(O) is(O) from(O) a(O) New(B-political_party) Democratic(I-political_party) Party(I-political_party) ;(O) three(O) others(O) are(O) from(O) local(O) parties(O) ((O) the(O) Coalition(B-political_party) Avenir(I-political_party) Québec(I-political_party) ,(O) the(O) Saskatchewan(B-political_party) Party(I-political_party) ,(O) and(O) the(O) United(B-political_party) Conservative(I-political_party) Party(I-political_party) )(O) and(O) two(O) are(O) non-partisan(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, political_party, country, politician, election, location, event, organization\nGIVEN SENTENCE: Of the current first ministers , four are from a Liberal Party , four are from a Progressive Conservative Party , and one is from a New Democratic Party ; three others are from local parties ( the Coalition Avenir Québec , the Saskatchewan Party , and the United Conservative Party ) and two are non-partisan .\n","prediction_output":null,"prediction_outputs":null,"group":"7","words":["Of","the","current","first","ministers",",","four","are","from","a","Liberal","Party",",","four","are","from","a","Progressive","Conservative","Party",",","and","one","is","from","a","New","Democratic","Party",";","three","others","are","from","local","parties","(","the","Coalition","Avenir","Québec",",","the","Saskatchewan","Party",",","and","the","United","Conservative","Party",")","and","two","are","non-partisan","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","political_party","country","politician","election","location","event","organization"]}
{"id":"9.S","dataset":"crossner_politics","split":"dev","instance":{"id":"9.S","prompt_labels":"He(O) stood(O) for(O) the(O) Green(B-political_party) party(I-political_party) in(O) Oxford(B-organization) West(I-organization) and(I-organization) Abingdon(I-organization) in(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) and(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) general(O) elections(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, political_party, organization, politician, event, location, person, country\nGIVEN SENTENCE: He stood for the Green party in Oxford West and Abingdon in the 1992 United Kingdom general election , 1997 United Kingdom general election , and 2001 United Kingdom general election general elections .\n","prediction_output":null,"prediction_outputs":null,"group":"9","words":["He","stood","for","the","Green","party","in","Oxford","West","and","Abingdon","in","the","1992","United","Kingdom","general","election",",","1997","United","Kingdom","general","election",",","and","2001","United","Kingdom","general","election","general","elections","."],"labels":["O","O","O","O","B-political_party","I-political_party","O","B-organization","I-organization","I-organization","I-organization","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O"],"target_index":null,"target_label":null},"label_list":["election","political_party","organization","politician","event","location","person","country"]}
{"id":"13.S","dataset":"crossner_politics","split":"dev","instance":{"id":"13.S","prompt_labels":"In(O) Australia(B-country) ,(O) a(O) number(O) of(O) single(O) issue(O) parties(O) have(O) been(O) elected(O) to(O) federal(O) and(O) state(O) parliaments(O) such(O) as(O) the(O) Animal(B-political_party) Justice(I-political_party) Party(I-political_party) ,(O) Dignity(B-political_party) for(I-political_party) Disability(I-political_party) ,(O) Australian(B-political_party) Motoring(I-political_party) Enthusiast(I-political_party) Party(I-political_party) and(O) the(O) Australian(B-political_party) Sex(I-political_party) Party(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, politician, organization, location, political_party, election, country, event\nGIVEN SENTENCE: In Australia , a number of single issue parties have been elected to federal and state parliaments such as the Animal Justice Party , Dignity for Disability , Australian Motoring Enthusiast Party and the Australian Sex Party .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","Australia",",","a","number","of","single","issue","parties","have","been","elected","to","federal","and","state","parliaments","such","as","the","Animal","Justice","Party",",","Dignity","for","Disability",",","Australian","Motoring","Enthusiast","Party","and","the","Australian","Sex","Party","."],"labels":["O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["person","politician","organization","location","political_party","election","country","event"]}
{"id":"14.S","dataset":"crossner_politics","split":"dev","instance":{"id":"14.S","prompt_labels":"In(O) the(O) United(B-country) States(I-country) ,(O) such(O) voter(O) turnout(O) organizations(O) include(O) the(O) League(B-organization) of(I-organization) Women(I-organization) Voters(I-organization) ,(O) Rock(B-organization) the(I-organization) Vote(I-organization) ,(O) The(B-organization) Voter(I-organization) Participation(I-organization) Center(I-organization) and(O) Vote.org(O) ,(O) which(O) attempt(O) to(O) motivate(O) potential(O) voters(O) to(O) register(O) and(O) to(O) vote(O) in(O) the(O) belief(O) that(O) failure(O) of(O) any(O) eligible(O) voter(O) to(O) vote(O) in(O) any(O) election(O) is(O) a(O) loss(O) to(O) society(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, country, politician, political_party, person, event, organization, location\nGIVEN SENTENCE: In the United States , such voter turnout organizations include the League of Women Voters , Rock the Vote , The Voter Participation Center and Vote.org , which attempt to motivate potential voters to register and to vote in the belief that failure of any eligible voter to vote in any election is a loss to society .\n","prediction_output":null,"prediction_outputs":null,"group":"14","words":["In","the","United","States",",","such","voter","turnout","organizations","include","the","League","of","Women","Voters",",","Rock","the","Vote",",","The","Voter","Participation","Center","and","Vote.org",",","which","attempt","to","motivate","potential","voters","to","register","and","to","vote","in","the","belief","that","failure","of","any","eligible","voter","to","vote","in","any","election","is","a","loss","to","society","."],"labels":["O","O","B-country","I-country","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["election","country","politician","political_party","person","event","organization","location"]}
{"id":"17.S","dataset":"crossner_politics","split":"dev","instance":{"id":"17.S","prompt_labels":"The(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) took(O) back(O) this(O) historically(O) New(B-political_party) Democratic(I-political_party) Party(I-political_party) ((O) NDP(B-political_party) )(O) seat(O) in(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, event, organization, politician, location, person, political_party, election\nGIVEN SENTENCE: The Conservative Party of Canada took back this historically New Democratic Party ( NDP ) seat in 2004 Canadian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"17","words":["The","Conservative","Party","of","Canada","took","back","this","historically","New","Democratic","Party","(","NDP",")","seat","in","2004","Canadian","federal","election","."],"labels":["O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["country","event","organization","politician","location","person","political_party","election"]}
{"id":"22.S","dataset":"crossner_politics","split":"dev","instance":{"id":"22.S","prompt_labels":"For(O) the(O) 2016(B-election) Belarusian(I-election) parliamentary(I-election) election(I-election) ,(O) the(O) party(O) formed(O) an(O) alliance(O) with(O) the(O) BPF(B-political_party) Party(I-political_party) ,(O) the(O) Belarusian(B-political_party) Christian(I-political_party) Democracy(I-political_party) ,(O) the(O) Social(B-political_party) Democratic(I-political_party) Party(I-political_party) ((O) Assembly(B-political_party) )(O) ,(O) the(O) '(B-political_party) Za(I-political_party) svabodu(I-political_party) '(I-political_party) movement(I-political_party) ,(O) the(O) Belarusian(B-political_party) Green(I-political_party) Party(I-political_party) ,(O) the(O) Belarusian(B-political_party) Liberal(I-political_party) Party(I-political_party) of(I-political_party) Freedom(I-political_party) and(I-political_party) Progress(I-political_party) ,(O) the(O) Trade(B-political_party) Union(I-political_party) of(I-political_party) Electric(I-political_party) Industry(I-political_party) and(O) independent(O) candidates(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, organization, politician, political_party, person, country, election, location\nGIVEN SENTENCE: For the 2016 Belarusian parliamentary election , the party formed an alliance with the BPF Party , the Belarusian Christian Democracy , the Social Democratic Party ( Assembly ) , the ' Za svabodu ' movement , the Belarusian Green Party , the Belarusian Liberal Party of Freedom and Progress , the Trade Union of Electric Industry and independent candidates .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["For","the","2016","Belarusian","parliamentary","election",",","the","party","formed","an","alliance","with","the","BPF","Party",",","the","Belarusian","Christian","Democracy",",","the","Social","Democratic","Party","(","Assembly",")",",","the","'","Za","svabodu","'","movement",",","the","Belarusian","Green","Party",",","the","Belarusian","Liberal","Party","of","Freedom","and","Progress",",","the","Trade","Union","of","Electric","Industry","and","independent","candidates","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","organization","politician","political_party","person","country","election","location"]}
{"id":"23.S","dataset":"crossner_politics","split":"dev","instance":{"id":"23.S","prompt_labels":"It(O) was(O) succeeded(O) in(O) the(O) Flemish(B-organization) Community(I-organization) of(O) Belgium(B-location) by(O) the(O) Open(B-political_party) Vlaamse(I-political_party) Liberalen(I-political_party) en(I-political_party) Democraten(I-political_party) ((O) VLD(B-political_party) )(O) and(O) in(O) the(O) French(B-country) Community(I-country) by(O) the(O) Liberal(B-political_party) Reformist(I-political_party) Party(I-political_party) ,(O) Parti(B-political_party) des(I-political_party) Réformes(I-political_party) et(I-political_party) des(I-political_party) Libertés(I-political_party) de(I-political_party) Wallonie(I-political_party) and(O) the(O) current-day(O) Mouvement(B-political_party) Réformateur(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, organization, politician, political_party, election, person, event\nGIVEN SENTENCE: It was succeeded in the Flemish Community of Belgium by the Open Vlaamse Liberalen en Democraten ( VLD ) and in the French Community by the Liberal Reformist Party , Parti des Réformes et des Libertés de Wallonie and the current-day Mouvement Réformateur .\n","prediction_output":null,"prediction_outputs":null,"group":"23","words":["It","was","succeeded","in","the","Flemish","Community","of","Belgium","by","the","Open","Vlaamse","Liberalen","en","Democraten","(","VLD",")","and","in","the","French","Community","by","the","Liberal","Reformist","Party",",","Parti","des","Réformes","et","des","Libertés","de","Wallonie","and","the","current-day","Mouvement","Réformateur","."],"labels":["O","O","O","O","O","B-organization","I-organization","O","B-location","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","B-country","I-country","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","B-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["location","country","organization","politician","political_party","election","person","event"]}
{"id":"24.S","dataset":"crossner_politics","split":"dev","instance":{"id":"24.S","prompt_labels":"In(O) March(O) 2002(O) the(O) PRL(B-political_party) merged(O) with(O) the(O) German-speaking(O) Partei(B-political_party) für(I-political_party) Freiheit(I-political_party) und(I-political_party) Fortschritt(I-political_party) ((O) PFF(B-political_party) )(O) of(O) the(O) East(B-political_party) Cantons(I-political_party) ,(O) the(O) Democratic(B-political_party) Front(I-political_party) of(I-political_party) Francophones(I-political_party) ((O) FDF(B-political_party) )(O) and(O) the(O) Mouvement(B-political_party) des(I-political_party) Citoyens(I-political_party) pour(I-political_party) le(I-political_party) Changement(I-political_party) ((O) MCC(B-political_party) )(O) into(O) the(O) Mouvement(B-political_party) Réformateur(I-political_party) ((O) MR(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, political_party, election, country, location, organization, event, person\nGIVEN SENTENCE: In March 2002 the PRL merged with the German-speaking Partei für Freiheit und Fortschritt ( PFF ) of the East Cantons , the Democratic Front of Francophones ( FDF ) and the Mouvement des Citoyens pour le Changement ( MCC ) into the Mouvement Réformateur ( MR ) .\n","prediction_output":null,"prediction_outputs":null,"group":"24","words":["In","March","2002","the","PRL","merged","with","the","German-speaking","Partei","für","Freiheit","und","Fortschritt","(","PFF",")","of","the","East","Cantons",",","the","Democratic","Front","of","Francophones","(","FDF",")","and","the","Mouvement","des","Citoyens","pour","le","Changement","(","MCC",")","into","the","Mouvement","Réformateur","(","MR",")","."],"labels":["O","O","O","O","B-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["politician","political_party","election","country","location","organization","event","person"]}
{"id":"25.S","dataset":"crossner_politics","split":"dev","instance":{"id":"25.S","prompt_labels":"When(O) the(O) seat(O) was(O) created(O) it(O) was(O) nominally(O) held(O) by(O) the(O) Democratic(B-political_party) Unionist(I-political_party) Party(I-political_party) ((O) DUP(B-political_party) )(O) ,(O) based(O) on(O) mapping(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) results(O) onto(O) the(O) new(O) boundaries(O) ,(O) but(O) this(O) was(O) because(O) the(O) Ulster(B-political_party) Unionist(I-political_party) Party(I-political_party) ((O) UUP(B-political_party) )(O) had(O) not(O) contested(O) the(O) equivalent(O) area(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, political_party, country, politician, organization, election, person, location\nGIVEN SENTENCE: When the seat was created it was nominally held by the Democratic Unionist Party ( DUP ) , based on mapping the 1992 United Kingdom general election results onto the new boundaries , but this was because the Ulster Unionist Party ( UUP ) had not contested the equivalent area .\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["When","the","seat","was","created","it","was","nominally","held","by","the","Democratic","Unionist","Party","(","DUP",")",",","based","on","mapping","the","1992","United","Kingdom","general","election","results","onto","the","new","boundaries",",","but","this","was","because","the","Ulster","Unionist","Party","(","UUP",")","had","not","contested","the","equivalent","area","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","political_party","country","politician","organization","election","person","location"]}
{"id":"26.S","dataset":"crossner_politics","split":"dev","instance":{"id":"26.S","prompt_labels":"The(O) American(B-organization) Conservative(I-organization) Union(I-organization) consistently(O) rated(O) Jones(B-politician) low(O) among(O) his(O) Republican(O) colleagues(O) for(O) support(O) of(O) the(O) conservative(O) political(O) platform(O) ,(O) though(O) he(O) received(O) higher(O) ratings(O) from(O) the(O) Conservative(B-organization) Review(I-organization) and(O) Club(B-organization) for(I-organization) Growth(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, event, political_party, country, politician, person, location, organization\nGIVEN SENTENCE: The American Conservative Union consistently rated Jones low among his Republican colleagues for support of the conservative political platform , though he received higher ratings from the Conservative Review and Club for Growth .\n","prediction_output":null,"prediction_outputs":null,"group":"26","words":["The","American","Conservative","Union","consistently","rated","Jones","low","among","his","Republican","colleagues","for","support","of","the","conservative","political","platform",",","though","he","received","higher","ratings","from","the","Conservative","Review","and","Club","for","Growth","."],"labels":["O","B-organization","I-organization","I-organization","O","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["election","event","political_party","country","politician","person","location","organization"]}
{"id":"31.S","dataset":"crossner_politics","split":"dev","instance":{"id":"31.S","prompt_labels":"Originally(O) a(O) member(O) of(O) the(O) Centre(B-political_party) of(I-political_party) Social(I-political_party) Democrats(I-political_party) ((O) CDS(B-political_party) )(O) ,(O) the(O) Christian(O) Democrat(O) component(O) of(O) the(O) Union(B-political_party) for(I-political_party) French(I-political_party) Democracy(I-political_party) ((O) UDF(B-political_party) )(O) party(O) ,(O) he(O) later(O) joined(O) the(O) Union(B-political_party) for(I-political_party) a(I-political_party) Popular(I-political_party) Movement(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, person, political_party, politician, location, country, event, organization\nGIVEN SENTENCE: Originally a member of the Centre of Social Democrats ( CDS ) , the Christian Democrat component of the Union for French Democracy ( UDF ) party , he later joined the Union for a Popular Movement .\n","prediction_output":null,"prediction_outputs":null,"group":"31","words":["Originally","a","member","of","the","Centre","of","Social","Democrats","(","CDS",")",",","the","Christian","Democrat","component","of","the","Union","for","French","Democracy","(","UDF",")","party",",","he","later","joined","the","Union","for","a","Popular","Movement","."],"labels":["O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["election","person","political_party","politician","location","country","event","organization"]}
{"id":"34.S","dataset":"crossner_politics","split":"dev","instance":{"id":"34.S","prompt_labels":"In(O) December(O) 2017(O) IdV(B-political_party) was(O) a(O) founding(O) member(O) of(O) the(O) Popular(B-political_party) Civic(I-political_party) List(I-political_party) ((O) CP(B-political_party) )(O) ,(O) a(O) centrist(O) electoral(O) list(O) within(O) the(O) centre-left(O) coalition(O) ,(O) along(O) with(O) Popular(B-political_party) Alternative(I-political_party) ((O) AP(B-political_party) )(O) ,(O) the(O) Centrists(B-political_party) for(I-political_party) Europe(I-political_party) ((O) CpE(B-political_party) )(O) ,(O) Solidary(B-political_party) Democracy(I-political_party) ((O) DemoS(B-political_party) )(O) ,(O) the(O) Union(B-political_party) for(I-political_party) Trentino(I-political_party) ((O) UpT(B-political_party) )(O) ,(O) Italy(B-political_party) is(I-political_party) Popular(I-political_party) ((O) IP(B-political_party) )(O) and(O) minor(O) parties(O) /(O) groups(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, person, event, location, politician, country, organization, political_party\nGIVEN SENTENCE: In December 2017 IdV was a founding member of the Popular Civic List ( CP ) , a centrist electoral list within the centre-left coalition , along with Popular Alternative ( AP ) , the Centrists for Europe ( CpE ) , Solidary Democracy ( DemoS ) , the Union for Trentino ( UpT ) , Italy is Popular ( IP ) and minor parties / groups .\n","prediction_output":null,"prediction_outputs":null,"group":"34","words":["In","December","2017","IdV","was","a","founding","member","of","the","Popular","Civic","List","(","CP",")",",","a","centrist","electoral","list","within","the","centre-left","coalition",",","along","with","Popular","Alternative","(","AP",")",",","the","Centrists","for","Europe","(","CpE",")",",","Solidary","Democracy","(","DemoS",")",",","the","Union","for","Trentino","(","UpT",")",",","Italy","is","Popular","(","IP",")","and","minor","parties","/","groups","."],"labels":["O","O","O","B-political_party","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","B-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["election","person","event","location","politician","country","organization","political_party"]}
{"id":"35.S","dataset":"crossner_politics","split":"dev","instance":{"id":"35.S","prompt_labels":"The(O) party(O) includes(O) former(O) Italian(B-political_party) Communist(I-political_party) Party(I-political_party) and(O) former(O) Lega(B-political_party) Nord(I-political_party) ,(O) as(O) well(O) as(O) former(O) Italian(B-political_party) Social(I-political_party) Movement(I-political_party) and(O) several(O) former(O) Christian(O) Democrats(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, election, event, country, person, organization, political_party, location\nGIVEN SENTENCE: The party includes former Italian Communist Party and former Lega Nord , as well as former Italian Social Movement and several former Christian Democrats .\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["The","party","includes","former","Italian","Communist","Party","and","former","Lega","Nord",",","as","well","as","former","Italian","Social","Movement","and","several","former","Christian","Democrats","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["politician","election","event","country","person","organization","political_party","location"]}
{"id":"38.S","dataset":"crossner_politics","split":"dev","instance":{"id":"38.S","prompt_labels":"Before(O) the(O) merger(O) of(O) the(O) Queensland(B-location) branches(O) of(O) the(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Australia(I-political_party) and(O) Nationals(O) as(O) the(O) Liberal(B-political_party) National(I-political_party) Party(I-political_party) of(I-political_party) Queensland(I-political_party) ,(O) the(O) National(O) Party(O) had(O) been(O) the(O) senior(O) partner(O) in(O) the(O) non-(O) Australian(B-political_party) Labor(I-political_party) Party(I-political_party) Coalition(O) since(O) 1924(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, event, election, organization, location, country, politician, political_party\nGIVEN SENTENCE: Before the merger of the Queensland branches of the Liberal Party of Australia and Nationals as the Liberal National Party of Queensland , the National Party had been the senior partner in the non- Australian Labor Party Coalition since 1924 .\n","prediction_output":null,"prediction_outputs":null,"group":"38","words":["Before","the","merger","of","the","Queensland","branches","of","the","Liberal","Party","of","Australia","and","Nationals","as","the","Liberal","National","Party","of","Queensland",",","the","National","Party","had","been","the","senior","partner","in","the","non-","Australian","Labor","Party","Coalition","since","1924","."],"labels":["O","O","O","O","O","B-location","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","event","election","organization","location","country","politician","political_party"]}
{"id":"40.S","dataset":"crossner_politics","split":"dev","instance":{"id":"40.S","prompt_labels":"The(O) Social(B-political_party) Democratic(I-political_party) and(I-political_party) Labour(I-political_party) Party(I-political_party) ((O) SDLP(B-political_party) )(O) stood(O) a(O) candidate(O) against(O) her(O) in(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) nationalist(O) vote(O) was(O) strongly(O) divided(O) ,(O) allowing(O) John(B-politician) Dunlop(I-politician) of(O) the(O) Vanguard(B-political_party) Progressive(I-political_party) Unionist(I-political_party) Party(I-political_party) to(O) win(O) with(O) the(O) support(O) of(O) the(O) UUP(B-political_party) and(O) the(O) Democratic(B-political_party) Unionist(I-political_party) Party(I-political_party) ((O) DUP(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, location, politician, election, political_party, person, country, event\nGIVEN SENTENCE: The Social Democratic and Labour Party ( SDLP ) stood a candidate against her in the February 1974 United Kingdom general election and the nationalist vote was strongly divided , allowing John Dunlop of the Vanguard Progressive Unionist Party to win with the support of the UUP and the Democratic Unionist Party ( DUP ) .\n","prediction_output":null,"prediction_outputs":null,"group":"40","words":["The","Social","Democratic","and","Labour","Party","(","SDLP",")","stood","a","candidate","against","her","in","the","February","1974","United","Kingdom","general","election","and","the","nationalist","vote","was","strongly","divided",",","allowing","John","Dunlop","of","the","Vanguard","Progressive","Unionist","Party","to","win","with","the","support","of","the","UUP","and","the","Democratic","Unionist","Party","(","DUP",")","."],"labels":["O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","B-political_party","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["organization","location","politician","election","political_party","person","country","event"]}
{"id":"41.S","dataset":"crossner_politics","split":"dev","instance":{"id":"41.S","prompt_labels":"In(O) 1990(B-election) Australian(I-election) federal(I-election) election(I-election) Caldicott(O) unsuccessfully(O) contested(O) the(O) House(B-organization) of(I-organization) Representatives(I-organization) New(I-organization) South(I-organization) Wales(I-organization) seat(O) of(O) Richmond(B-location) ,(O) a(O) seat(O) held(O) since(O) the(O) inaugural(O) 1901(B-election) Australian(I-election) federal(I-election) election(I-election) by(O) conservatives(O) ,(O) and(O) by(O) the(O) National(B-political_party) Party(I-political_party) of(I-political_party) Australia(I-political_party) since(O) it(O) first(O) contested(O) elections(O) at(O) the(O) 1922(B-election) Australian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, organization, person, country, election, location, politician, political_party\nGIVEN SENTENCE: In 1990 Australian federal election Caldicott unsuccessfully contested the House of Representatives New South Wales seat of Richmond , a seat held since the inaugural 1901 Australian federal election by conservatives , and by the National Party of Australia since it first contested elections at the 1922 Australian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"41","words":["In","1990","Australian","federal","election","Caldicott","unsuccessfully","contested","the","House","of","Representatives","New","South","Wales","seat","of","Richmond",",","a","seat","held","since","the","inaugural","1901","Australian","federal","election","by","conservatives",",","and","by","the","National","Party","of","Australia","since","it","first","contested","elections","at","the","1922","Australian","federal","election","."],"labels":["O","B-election","I-election","I-election","I-election","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["event","organization","person","country","election","location","politician","political_party"]}
{"id":"45.S","dataset":"crossner_politics","split":"dev","instance":{"id":"45.S","prompt_labels":"For(O) the(O) 2011(B-election) Peruvian(I-election) general(I-election) election(I-election) ,(O) the(O) party(O) joined(O) forces(O) with(O) We(B-political_party) Are(I-political_party) Peru(I-political_party) and(O) Possible(B-political_party) Peru(I-political_party) to(O) form(O) the(O) Peru(B-organization) Possible(I-organization) Alliance(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, location, event, organization, political_party, country, person, election\nGIVEN SENTENCE: For the 2011 Peruvian general election , the party joined forces with We Are Peru and Possible Peru to form the Peru Possible Alliance .\n","prediction_output":null,"prediction_outputs":null,"group":"45","words":["For","the","2011","Peruvian","general","election",",","the","party","joined","forces","with","We","Are","Peru","and","Possible","Peru","to","form","the","Peru","Possible","Alliance","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["politician","location","event","organization","political_party","country","person","election"]}
{"id":"47.S","dataset":"crossner_politics","split":"dev","instance":{"id":"47.S","prompt_labels":"Other(O) parties(O) such(O) as(O) the(O) Alliance(B-political_party) Party(I-political_party) of(I-political_party) Northern(I-political_party) Ireland(I-political_party) ,(O) Progressive(B-political_party) Unionist(I-political_party) Party(I-political_party) ,(O) Unionist(B-political_party) Party(I-political_party) of(I-political_party) Northern(I-political_party) Ireland(I-political_party) ,(O) Conservatives(B-political_party) and(I-political_party) the(I-political_party) Workers(I-political_party) '(I-political_party) Party(I-political_party) have(O) at(O) times(O) polled(O) significantly(O) ,(O) as(O) have(O) independent(O) candidates(O) ,(O) with(O) the(O) result(O) that(O) many(O) elections(O) have(O) been(O) won(O) on(O) comparatively(O) low(O) shares(O) of(O) the(O) vote(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, organization, location, election, event, politician, person, political_party\nGIVEN SENTENCE: Other parties such as the Alliance Party of Northern Ireland , Progressive Unionist Party , Unionist Party of Northern Ireland , Conservatives and the Workers ' Party have at times polled significantly , as have independent candidates , with the result that many elections have been won on comparatively low shares of the vote .\n","prediction_output":null,"prediction_outputs":null,"group":"47","words":["Other","parties","such","as","the","Alliance","Party","of","Northern","Ireland",",","Progressive","Unionist","Party",",","Unionist","Party","of","Northern","Ireland",",","Conservatives","and","the","Workers","'","Party","have","at","times","polled","significantly",",","as","have","independent","candidates",",","with","the","result","that","many","elections","have","been","won","on","comparatively","low","shares","of","the","vote","."],"labels":["O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","organization","location","election","event","politician","person","political_party"]}
{"id":"49.S","dataset":"crossner_politics","split":"dev","instance":{"id":"49.S","prompt_labels":"AP(B-political_party) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(B-political_party) Nord(I-political_party) in(O) Italy(B-country) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(B-location) Marino(I-location) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(B-political_party) Christian(I-political_party) Democratic(I-political_party) Party(I-political_party) ((O) PDCS(B-political_party) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(B-political_party) of(I-political_party) Socialists(I-political_party) and(I-political_party) Democrats(I-political_party) ((O) PSD(B-political_party) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, election, location, organization, person, politician, political_party, country\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"50.S","dataset":"crossner_politics","split":"dev","instance":{"id":"50.S","prompt_labels":"In(O) 1987(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) Adams(B-politician) narrowly(O) held(O) his(O) seat(O) ,(O) but(O) lost(O) it(O) in(O) the(O) 1992(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) amidst(O) a(O) strong(O) tactical(O) voting(O) campaign(O) in(O) favour(O) of(O) Joe(B-politician) Hendron(I-politician) of(O) the(O) Social(B-political_party) Democratic(I-political_party) and(I-political_party) Labour(I-political_party) Party(I-political_party) by(O) unionists(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, location, politician, event, election, organization, political_party, person\nGIVEN SENTENCE: In 1987 United Kingdom general election Adams narrowly held his seat , but lost it in the 1992 United Kingdom general election amidst a strong tactical voting campaign in favour of Joe Hendron of the Social Democratic and Labour Party by unionists\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["In","1987","United","Kingdom","general","election","Adams","narrowly","held","his","seat",",","but","lost","it","in","the","1992","United","Kingdom","general","election","amidst","a","strong","tactical","voting","campaign","in","favour","of","Joe","Hendron","of","the","Social","Democratic","and","Labour","Party","by","unionists"],"labels":["O","B-election","I-election","I-election","I-election","I-election","B-politician","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["country","location","politician","event","election","organization","political_party","person"]}
{"id":"51.S","dataset":"crossner_politics","split":"dev","instance":{"id":"51.S","prompt_labels":"In(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) Adams(B-politician) regained(O) the(O) seat(O) and(O) held(O) it(O) in(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 2005(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 2010(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, event, person, election, country, political_party, location, politician\nGIVEN SENTENCE: In 1997 United Kingdom general election Adams regained the seat and held it in 2001 United Kingdom general election , 2005 United Kingdom general election and 2010 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"51","words":["In","1997","United","Kingdom","general","election","Adams","regained","the","seat","and","held","it","in","2001","United","Kingdom","general","election",",","2005","United","Kingdom","general","election","and","2010","United","Kingdom","general","election","."],"labels":["O","B-election","I-election","I-election","I-election","I-election","B-politician","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["organization","event","person","election","country","political_party","location","politician"]}
{"id":"55.S","dataset":"crossner_politics","split":"dev","instance":{"id":"55.S","prompt_labels":"In(O) the(O) 1979(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) the(O) constituency(O) witnessed(O) a(O) very(O) close(O) three-way(O) fight(O) between(O) Peter(B-politician) Robinson(I-politician) of(O) the(O) Democratic(B-political_party) Unionist(I-political_party) Party(I-political_party) ,(O) William(B-politician) Craig(I-politician) for(O) the(O) UUP(B-political_party) and(O) Oliver(B-politician) Napier(I-politician) for(O) the(O) Alliance(B-political_party) Party(I-political_party) of(I-political_party) Northern(I-political_party) Ireland(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, politician, organization, country, location, event, political_party, person\nGIVEN SENTENCE: In the 1979 United Kingdom general election the constituency witnessed a very close three-way fight between Peter Robinson of the Democratic Unionist Party , William Craig for the UUP and Oliver Napier for the Alliance Party of Northern Ireland .\n","prediction_output":null,"prediction_outputs":null,"group":"55","words":["In","the","1979","United","Kingdom","general","election","the","constituency","witnessed","a","very","close","three-way","fight","between","Peter","Robinson","of","the","Democratic","Unionist","Party",",","William","Craig","for","the","UUP","and","Oliver","Napier","for","the","Alliance","Party","of","Northern","Ireland","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","B-politician","I-politician","O","O","B-political_party","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["election","politician","organization","country","location","event","political_party","person"]}
{"id":"59.S","dataset":"crossner_politics","split":"dev","instance":{"id":"59.S","prompt_labels":"It(O) was(O) widely(O) expected(O) that(O) a(O) coalition(O) between(O) supporters(O) of(O) the(O) Orange(B-political_party) Movement(I-political_party) would(O) form(O) Ukraine(B-country) 's(O) next(O) government(O) ,(O) but(O) after(O) three(O) months(O) of(O) negotiations(O) and(O) a(O) failure(O) to(O) reach(O) an(O) agreement(O) the(O) proposed(O) coalition(O) collapsed(O) following(O) the(O) decision(O) of(O) the(O) Socialist(B-political_party) Party(I-political_party) of(I-political_party) Ukraine(I-political_party) to(O) support(O) the(O) formation(O) of(O) the(O) anti-crisis(O) coalition(O) with(O) Party(B-political_party) of(I-political_party) Regions(I-political_party) and(O) the(O) Communist(B-political_party) Party(I-political_party) of(I-political_party) Ukraine(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, election, political_party, person, event, organization, politician, location\nGIVEN SENTENCE: It was widely expected that a coalition between supporters of the Orange Movement would form Ukraine 's next government , but after three months of negotiations and a failure to reach an agreement the proposed coalition collapsed following the decision of the Socialist Party of Ukraine to support the formation of the anti-crisis coalition with Party of Regions and the Communist Party of Ukraine .\n","prediction_output":null,"prediction_outputs":null,"group":"59","words":["It","was","widely","expected","that","a","coalition","between","supporters","of","the","Orange","Movement","would","form","Ukraine","'s","next","government",",","but","after","three","months","of","negotiations","and","a","failure","to","reach","an","agreement","the","proposed","coalition","collapsed","following","the","decision","of","the","Socialist","Party","of","Ukraine","to","support","the","formation","of","the","anti-crisis","coalition","with","Party","of","Regions","and","the","Communist","Party","of","Ukraine","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["country","election","political_party","person","event","organization","politician","location"]}
{"id":"61.S","dataset":"crossner_politics","split":"dev","instance":{"id":"61.S","prompt_labels":"The(O) UUP(B-political_party) had(O) their(O) best(O) result(O) in(O) the(O) election(O) ,(O) in(O) part(O) due(O) to(O) no(O) candidate(O) from(O) either(O) the(O) UK(B-political_party) Unionist(I-political_party) Party(I-political_party) or(O) Northern(B-political_party) Ireland(I-political_party) Unionist(I-political_party) Party(I-political_party) defending(O) one(O) of(O) the(O) seats(O) won(O) in(O) 1998(B-election) Northern(I-election) Ireland(I-election) Assembly(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, location, person, election, event, politician, political_party, country\nGIVEN SENTENCE: The UUP had their best result in the election , in part due to no candidate from either the UK Unionist Party or Northern Ireland Unionist Party defending one of the seats won in 1998 Northern Ireland Assembly election .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["The","UUP","had","their","best","result","in","the","election",",","in","part","due","to","no","candidate","from","either","the","UK","Unionist","Party","or","Northern","Ireland","Unionist","Party","defending","one","of","the","seats","won","in","1998","Northern","Ireland","Assembly","election","."],"labels":["O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["organization","location","person","election","event","politician","political_party","country"]}
{"id":"62.S","dataset":"crossner_politics","split":"dev","instance":{"id":"62.S","prompt_labels":"The(O) Member(O) of(O) Parliament(B-organization) since(O) 1997(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) is(O) Sir(B-politician) Jeffrey(I-politician) Donaldson(I-politician) who(O) was(O) elected(O) as(O) a(O) member(O) of(O) the(O) Ulster(B-political_party) Unionist(I-political_party) Party(I-political_party) but(O) switched(O) to(O) the(O) Democratic(B-political_party) Unionist(I-political_party) Party(I-political_party) in(O) 2004(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, political_party, politician, election, organization, country, event, location\nGIVEN SENTENCE: The Member of Parliament since 1997 United Kingdom general election is Sir Jeffrey Donaldson who was elected as a member of the Ulster Unionist Party but switched to the Democratic Unionist Party in 2004 .\n","prediction_output":null,"prediction_outputs":null,"group":"62","words":["The","Member","of","Parliament","since","1997","United","Kingdom","general","election","is","Sir","Jeffrey","Donaldson","who","was","elected","as","a","member","of","the","Ulster","Unionist","Party","but","switched","to","the","Democratic","Unionist","Party","in","2004","."],"labels":["O","O","O","B-organization","O","B-election","I-election","I-election","I-election","I-election","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","political_party","politician","election","organization","country","event","location"]}
{"id":"63.S","dataset":"crossner_politics","split":"dev","instance":{"id":"63.S","prompt_labels":"Farry(B-politician) was(O) elected(O) to(O) the(O) position(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) replacing(O) the(O) incumbent(O) Sylvia(B-politician) Hermon(I-politician) ,(O) who(O) had(O) held(O) the(O) position(O) since(O) being(O) elected(O) to(O) it(O) in(O) the(O) 2001(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) but(O) chose(O) not(O) to(O) contest(O) in(O) the(O) 2019(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, organization, election, event, politician, person, country, location\nGIVEN SENTENCE: Farry was elected to the position in the 2019 United Kingdom general election , replacing the incumbent Sylvia Hermon , who had held the position since being elected to it in the 2001 United Kingdom general election , but chose not to contest in the 2019 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["Farry","was","elected","to","the","position","in","the","2019","United","Kingdom","general","election",",","replacing","the","incumbent","Sylvia","Hermon",",","who","had","held","the","position","since","being","elected","to","it","in","the","2001","United","Kingdom","general","election",",","but","chose","not","to","contest","in","the","2019","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["political_party","organization","election","event","politician","person","country","location"]}
{"id":"65.S","dataset":"crossner_politics","split":"dev","instance":{"id":"65.S","prompt_labels":"Examples(O) of(O) regional(O) parties(O) that(O) do(O) not(O) generally(O) campaign(O) for(O) greater(O) autonomy(O) or(O) federalism(O) include(O) most(O) provincial(O) parties(O) in(O) Canada(B-country) ,(O) most(O) regional(O) and(O) minority(O) parties(O) in(O) Europe(B-location) ,(O) notably(O) including(O) the(O) Christian(B-political_party) Social(I-political_party) Union(I-political_party) in(I-political_party) Bavaria(I-political_party) in(O) Bavaria(B-location) ((O) Germany(B-country) )(O) ,(O) most(O) parties(O) in(O) Belgium(B-location) ,(O) most(O) parties(O) in(O) Northern(B-country) Ireland(I-country) ,(O) the(O) Istrian(B-political_party) Democratic(I-political_party) Assembly(I-political_party) in(O) Istria(B-location) and(O) the(O) Alliance(B-political_party) of(I-political_party) Primorje-Gorski(I-political_party) Kotar(I-political_party) in(O) Primorje-Gorski(B-location) Kotar(I-location) ((O) both(O) counties(O) of(O) Croatia(B-country) )(O) ,(O) and(O) most(O) political(O) parties(O) in(O) India(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, person, election, organization, political_party, event, politician\nGIVEN SENTENCE: Examples of regional parties that do not generally campaign for greater autonomy or federalism include most provincial parties in Canada , most regional and minority parties in Europe , notably including the Christian Social Union in Bavaria in Bavaria ( Germany ) , most parties in Belgium , most parties in Northern Ireland , the Istrian Democratic Assembly in Istria and the Alliance of Primorje-Gorski Kotar in Primorje-Gorski Kotar ( both counties of Croatia ) , and most political parties in India .\n","prediction_output":null,"prediction_outputs":null,"group":"65","words":["Examples","of","regional","parties","that","do","not","generally","campaign","for","greater","autonomy","or","federalism","include","most","provincial","parties","in","Canada",",","most","regional","and","minority","parties","in","Europe",",","notably","including","the","Christian","Social","Union","in","Bavaria","in","Bavaria","(","Germany",")",",","most","parties","in","Belgium",",","most","parties","in","Northern","Ireland",",","the","Istrian","Democratic","Assembly","in","Istria","and","the","Alliance","of","Primorje-Gorski","Kotar","in","Primorje-Gorski","Kotar","(","both","counties","of","Croatia",")",",","and","most","political","parties","in","India","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","B-location","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-location","O","B-country","O","O","O","O","O","B-location","O","O","O","O","B-country","I-country","O","O","B-political_party","I-political_party","I-political_party","O","B-location","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-location","I-location","O","O","O","O","B-country","O","O","O","O","O","O","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["location","country","person","election","organization","political_party","event","politician"]}
{"id":"67.S","dataset":"crossner_politics","split":"dev","instance":{"id":"67.S","prompt_labels":"Ayaan(B-politician) Hirsi(I-politician) Ali(I-politician) is(O) a(O) Fellow(O) with(O) the(O) Hoover(B-organization) Institution(I-organization) at(O) Stanford(B-organization) University(I-organization) ,(O) a(O) Fellow(O) with(O) the(O) Future(B-organization) of(I-organization) Diplomacy(I-organization) Project(I-organization) at(O) the(O) Belfer(B-organization) Center(I-organization) for(I-organization) Science(I-organization) and(I-organization) International(I-organization) Affairs(I-organization) at(O) The(O) Harvard(B-organization) Kennedy(I-organization) School(I-organization) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(B-organization) Enterprise(I-organization) Institute(I-organization) in(O) Washington(B-location) ,(I-location) D.C.(I-location) ,(O) and(O) a(O) member(O) of(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, person, location, politician, election, organization, political_party, country\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"68.S","dataset":"crossner_politics","split":"dev","instance":{"id":"68.S","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ,(O) the(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ,(O) the(O) New(B-political_party) Democratic(I-political_party) Party(I-political_party) and(O) the(O) Green(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(B-location) remaining(O) part(O) of(O) Canada(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, politician, event, political_party, country, person, election, organization\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"69.S","dataset":"crossner_politics","split":"dev","instance":{"id":"69.S","prompt_labels":"However(O) ,(O) with(O) the(O) onset(O) of(O) the(B-event) Troubles(I-event) ,(O) new(O) parties(O) emerged(O) that(O) appealed(O) to(O) the(O) party(O) 's(O) support(O) base(O) ,(O) including(O) the(O) Social(B-political_party) Democratic(I-political_party) and(I-political_party) Labour(I-political_party) Party(I-political_party) ((O) SDLP(B-political_party) )(O) ,(O) the(O) Alliance(B-political_party) Party(I-political_party) of(I-political_party) Northern(I-political_party) Ireland(I-political_party) and(O) the(O) Democratic(B-political_party) Unionist(I-political_party) Party(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, election, political_party, politician, country, organization, person, event\nGIVEN SENTENCE: However , with the onset of the Troubles , new parties emerged that appealed to the party 's support base , including the Social Democratic and Labour Party ( SDLP ) , the Alliance Party of Northern Ireland and the Democratic Unionist Party .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["However",",","with","the","onset","of","the","Troubles",",","new","parties","emerged","that","appealed","to","the","party","'s","support","base",",","including","the","Social","Democratic","and","Labour","Party","(","SDLP",")",",","the","Alliance","Party","of","Northern","Ireland","and","the","Democratic","Unionist","Party","."],"labels":["O","O","O","O","O","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["location","election","political_party","politician","country","organization","person","event"]}
{"id":"70.S","dataset":"crossner_politics","split":"dev","instance":{"id":"70.S","prompt_labels":"President(O) Kim(B-politician) Dae-jung(I-politician) '(O) s(O) National(B-political_party) Congress(I-political_party) for(I-political_party) New(I-political_party) Politics(I-political_party) ((O) NCNP(B-political_party) )(O) re-branded(O) itself(O) to(O) Millennium(B-political_party) Democratic(I-political_party) Party(I-political_party) ((O) MDP(B-political_party) )(O) in(O) 2000(O) ,(O) but(O) was(O) struggling(O) as(O) it(O) had(O) defeated(O) by(O) the(O) Liberty(B-political_party) Korea(I-political_party) Party(I-political_party) ((O) GNP(B-political_party) )(O) both(O) the(O) 2000(B-election) South(I-election) Korean(I-election) legislative(I-election) election(I-election) and(O) 2002(B-election) South(I-election) Korean(I-election) local(I-election) elections(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, political_party, organization, country, person, politician, event, location\nGIVEN SENTENCE: President Kim Dae-jung ' s National Congress for New Politics ( NCNP ) re-branded itself to Millennium Democratic Party ( MDP ) in 2000 , but was struggling as it had defeated by the Liberty Korea Party ( GNP ) both the 2000 South Korean legislative election and 2002 South Korean local elections .\n","prediction_output":null,"prediction_outputs":null,"group":"70","words":["President","Kim","Dae-jung","'","s","National","Congress","for","New","Politics","(","NCNP",")","re-branded","itself","to","Millennium","Democratic","Party","(","MDP",")","in","2000",",","but","was","struggling","as","it","had","defeated","by","the","Liberty","Korea","Party","(","GNP",")","both","the","2000","South","Korean","legislative","election","and","2002","South","Korean","local","elections","."],"labels":["O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["election","political_party","organization","country","person","politician","event","location"]}
{"id":"71.S","dataset":"crossner_politics","split":"dev","instance":{"id":"71.S","prompt_labels":"The(O) Freedom(B-political_party) Party(I-political_party) was(O) subsequently(O) expelled(O) from(O) the(O) Liberal(B-organization) International(I-organization) ,(O) and(O) the(O) remaining(O) liberals(O) seceded(O) to(O) found(O) the(O) Liberal(B-political_party) Forum(I-political_party) ((O) Liberales(B-political_party) Forum(I-political_party) ,(O) member(O) Liberal(B-organization) International(I-organization) ,(O) Alliance(B-political_party) of(I-political_party) Liberals(I-political_party) and(I-political_party) Democrats(I-political_party) for(I-political_party) Europe(I-political_party) Party(I-political_party) )(O) in(O) 1993(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, event, country, politician, person, location, election, organization\nGIVEN SENTENCE: The Freedom Party was subsequently expelled from the Liberal International , and the remaining liberals seceded to found the Liberal Forum ( Liberales Forum , member Liberal International , Alliance of Liberals and Democrats for Europe Party ) in 1993 .\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["The","Freedom","Party","was","subsequently","expelled","from","the","Liberal","International",",","and","the","remaining","liberals","seceded","to","found","the","Liberal","Forum","(","Liberales","Forum",",","member","Liberal","International",",","Alliance","of","Liberals","and","Democrats","for","Europe","Party",")","in","1993","."],"labels":["O","B-political_party","I-political_party","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-political_party","I-political_party","O","O","B-organization","I-organization","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","event","country","politician","person","location","election","organization"]}
{"id":"74.S","dataset":"crossner_politics","split":"dev","instance":{"id":"74.S","prompt_labels":"The(O) main(O) line(O) of(O) conflict(O) in(O) France(B-country) during(O) the(O) 19th(O) century(O) was(O) between(O) monarchists(O) ((O) mainly(O) Legitimists(O) and(O) Orléanist(O) s(O) ,(O) but(O) also(O) Bonapartism(O) )(O) and(O) republicans(O) ((O) Radical-Socialists(O) ,(O) Opportunist(B-organization) Republicans(I-organization) ,(O) and(O) later(O) socialists(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, location, event, election, politician, political_party, organization\nGIVEN SENTENCE: The main line of conflict in France during the 19th century was between monarchists ( mainly Legitimists and Orléanist s , but also Bonapartism ) and republicans ( Radical-Socialists , Opportunist Republicans , and later socialists ) .\n","prediction_output":null,"prediction_outputs":null,"group":"74","words":["The","main","line","of","conflict","in","France","during","the","19th","century","was","between","monarchists","(","mainly","Legitimists","and","Orléanist","s",",","but","also","Bonapartism",")","and","republicans","(","Radical-Socialists",",","Opportunist","Republicans",",","and","later","socialists",")","."],"labels":["O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","country","location","event","election","politician","political_party","organization"]}
{"id":"75.S","dataset":"crossner_politics","split":"dev","instance":{"id":"75.S","prompt_labels":"She(O) was(O) elected(O) to(O) the(O) Ontario(B-organization) legislature(I-organization) in(O) the(O) 1995(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) defeating(O) Ontario(B-political_party) Liberal(I-political_party) Party(I-political_party) Joe(B-politician) Dickson(I-politician) and(O) incumbent(O) Ontario(B-political_party) New(I-political_party) Democratic(I-political_party) Party(I-political_party) Jim(B-politician) Wiseman(I-politician) by(O) a(O) significant(O) margin(O) in(O) the(O) riding(O) of(O) Durham(B-location) West(I-location) ,(O) east(O) of(O) Toronto(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, person, organization, politician, location, political_party, election, event\nGIVEN SENTENCE: She was elected to the Ontario legislature in the 1995 Ontario general election , defeating Ontario Liberal Party Joe Dickson and incumbent Ontario New Democratic Party Jim Wiseman by a significant margin in the riding of Durham West , east of Toronto .\n","prediction_output":null,"prediction_outputs":null,"group":"75","words":["She","was","elected","to","the","Ontario","legislature","in","the","1995","Ontario","general","election",",","defeating","Ontario","Liberal","Party","Joe","Dickson","and","incumbent","Ontario","New","Democratic","Party","Jim","Wiseman","by","a","significant","margin","in","the","riding","of","Durham","West",",","east","of","Toronto","."],"labels":["O","O","O","O","O","B-organization","I-organization","O","O","B-election","I-election","I-election","I-election","O","O","B-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["country","person","organization","politician","location","political_party","election","event"]}
{"id":"77.S","dataset":"crossner_politics","split":"dev","instance":{"id":"77.S","prompt_labels":"In(O) recent(O) years(O) ,(O) the(O) Progressive(B-political_party) Conservative(I-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) has(O) had(O) the(O) most(O) success(O) in(O) the(O) city(O) :(O) its(O) members(O) were(O) elected(O) in(O) all(O) but(O) four(O) elections(O) since(O) 1953(O) :(O) 1974(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 1980(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, location, organization, political_party, event, election, politician, country\nGIVEN SENTENCE: In recent years , the Progressive Conservative Party of Canada has had the most success in the city : its members were elected in all but four elections since 1953 : 1974 Canadian federal election , 1980 Canadian federal election , 2004 Canadian federal election , and 2006 Canadian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"77","words":["In","recent","years",",","the","Progressive","Conservative","Party","of","Canada","has","had","the","most","success","in","the","city",":","its","members","were","elected","in","all","but","four","elections","since","1953",":","1974","Canadian","federal","election",",","1980","Canadian","federal","election",",","2004","Canadian","federal","election",",","and","2006","Canadian","federal","election","."],"labels":["O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["person","location","organization","political_party","event","election","politician","country"]}
{"id":"79.S","dataset":"crossner_politics","split":"dev","instance":{"id":"79.S","prompt_labels":"He(O) was(O) the(O) American(B-political_party) Independent(I-political_party) Party(I-political_party) vice(O) presidential(O) nominee(O) under(O) John(B-politician) G.(I-politician) Schmitz(I-politician) in(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) and(O) the(O) American(O) Party(O) presidential(O) nominee(O) in(O) 1976(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, politician, location, election, person, event, political_party, country\nGIVEN SENTENCE: He was the American Independent Party vice presidential nominee under John G. Schmitz in 1972 United States presidential election and the American Party presidential nominee in 1976 United States presidential election .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["He","was","the","American","Independent","Party","vice","presidential","nominee","under","John","G.","Schmitz","in","1972","United","States","presidential","election","and","the","American","Party","presidential","nominee","in","1976","United","States","presidential","election","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-politician","I-politician","I-politician","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["organization","politician","location","election","person","event","political_party","country"]}
{"id":"81.S","dataset":"crossner_politics","split":"dev","instance":{"id":"81.S","prompt_labels":"He(O) won(O) reelection(O) in(O) 1997(O) as(O) a(O) Reform(B-political_party) Party(I-political_party) Member(O) ,(O) in(O) 2000(O) as(O) a(O) member(O) of(O) the(O) Canadian(B-political_party) Alliance(I-political_party) and(O) in(O) 2004(O) as(O) a(O) member(O) of(O) the(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ,(O) until(O) Black(B-politician) defeated(O) him(O) in(O) the(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, event, politician, political_party, person, organization, election\nGIVEN SENTENCE: He won reelection in 1997 as a Reform Party Member , in 2000 as a member of the Canadian Alliance and in 2004 as a member of the Conservative Party of Canada , until Black defeated him in the 2006 Canadian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"81","words":["He","won","reelection","in","1997","as","a","Reform","Party","Member",",","in","2000","as","a","member","of","the","Canadian","Alliance","and","in","2004","as","a","member","of","the","Conservative","Party","of","Canada",",","until","Black","defeated","him","in","the","2006","Canadian","federal","election","."],"labels":["O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-politician","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["location","country","event","politician","political_party","person","organization","election"]}
{"id":"82.S","dataset":"crossner_politics","split":"dev","instance":{"id":"82.S","prompt_labels":"Kōmeitō(B-politician) did(O) quite(O) well(O) ,(O) and(O) in(O) 1993(O) ,(O) when(O) the(O) LDP(B-political_party) was(O) for(O) the(O) first(O) time(O) declared(O) an(O) opposition(O) party(O) ,(O) the(O) Kōmeitō(B-political_party) became(O) one(O) of(O) the(O) ruling(O) parties(O) ,(O) headed(O) by(O) the(O) liberal(O) Japan(B-political_party) New(I-political_party) Party(I-political_party) ,(O) but(O) which(O) also(O) included(O) the(O) Democratic(B-political_party) Socialist(I-political_party) Party(I-political_party) ,(O) Japan(B-political_party) Renewal(I-political_party) Party(I-political_party) ,(O) the(O) New(B-political_party) Party(I-political_party) Sakigake(I-political_party) ,(O) and(O) the(O) Japan(B-political_party) Socialist(I-political_party) Party(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, politician, organization, political_party, event, country, election, location\nGIVEN SENTENCE: Kōmeitō did quite well , and in 1993 , when the LDP was for the first time declared an opposition party , the Kōmeitō became one of the ruling parties , headed by the liberal Japan New Party , but which also included the Democratic Socialist Party , Japan Renewal Party , the New Party Sakigake , and the Japan Socialist Party .\n","prediction_output":null,"prediction_outputs":null,"group":"82","words":["Kōmeitō","did","quite","well",",","and","in","1993",",","when","the","LDP","was","for","the","first","time","declared","an","opposition","party",",","the","Kōmeitō","became","one","of","the","ruling","parties",",","headed","by","the","liberal","Japan","New","Party",",","but","which","also","included","the","Democratic","Socialist","Party",",","Japan","Renewal","Party",",","the","New","Party","Sakigake",",","and","the","Japan","Socialist","Party","."],"labels":["B-politician","O","O","O","O","O","O","O","O","O","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["person","politician","organization","political_party","event","country","election","location"]}
{"id":"84.S","dataset":"crossner_politics","split":"dev","instance":{"id":"84.S","prompt_labels":"Under(O) Terre(B-politician) 'Blanche(I-politician) ,(O) the(O) AWB(B-organization) swore(O) to(O) use(O) violence(O) to(O) preserve(O) minority(O) rule(O) ,(O) opposing(O) any(O) concessions(O) offered(O) to(O) the(O) African(B-political_party) National(I-political_party) Congress(I-political_party) -(O) an(O) organisation(O) AWB(B-organization) supporters(O) repeatedly(O) branded(O) as(O) Marxist(O) terrorist(O) s(O) Immediately(O) prior(O) to(O) South(B-country) Africa(I-country) 's(O) 1994(B-election) South(I-election) African(I-election) general(I-election) election(I-election) ,(O) Terre(B-politician) 'Blanche(I-politician) 's(O) followers(O) were(O) linked(O) to(O) a(O) number(O) of(O) bombings(O) and(O) assassinations(O) targeting(O) the(O) South(B-political_party) African(I-political_party) Communist(I-political_party) Party(I-political_party) ;(O) armed(O) AWB(B-organization) commandos(O) participated(O) in(O) the(O) crisis(O) in(O) Bophuthatswana(B-country) in(O) 1994(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, political_party, event, politician, person, location, election, country\nGIVEN SENTENCE: Under Terre 'Blanche , the AWB swore to use violence to preserve minority rule , opposing any concessions offered to the African National Congress - an organisation AWB supporters repeatedly branded as Marxist terrorist s Immediately prior to South Africa 's 1994 South African general election , Terre 'Blanche 's followers were linked to a number of bombings and assassinations targeting the South African Communist Party ; armed AWB commandos participated in the crisis in Bophuthatswana in 1994 .\n","prediction_output":null,"prediction_outputs":null,"group":"84","words":["Under","Terre","'Blanche",",","the","AWB","swore","to","use","violence","to","preserve","minority","rule",",","opposing","any","concessions","offered","to","the","African","National","Congress","-","an","organisation","AWB","supporters","repeatedly","branded","as","Marxist","terrorist","s","Immediately","prior","to","South","Africa","'s","1994","South","African","general","election",",","Terre","'Blanche","'s","followers","were","linked","to","a","number","of","bombings","and","assassinations","targeting","the","South","African","Communist","Party",";","armed","AWB","commandos","participated","in","the","crisis","in","Bophuthatswana","in","1994","."],"labels":["O","B-politician","I-politician","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","B-election","I-election","I-election","I-election","I-election","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-organization","O","O","O","O","O","O","B-country","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","political_party","event","politician","person","location","election","country"]}
{"id":"85.S","dataset":"crossner_politics","split":"dev","instance":{"id":"85.S","prompt_labels":"She(O) was(O) a(O) candidate(O) in(O) the(O) 1984(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1992(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ((O) 339(O) votes(O) )(O) ,(O) 1996(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) and(O) 2004(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, election, location, event, person, organization, country, political_party\nGIVEN SENTENCE: She was a candidate in the 1984 United States presidential election , 1992 United States presidential election ( 339 votes ) , 1996 United States presidential election , and 2004 United States presidential election .\n","prediction_output":null,"prediction_outputs":null,"group":"85","words":["She","was","a","candidate","in","the","1984","United","States","presidential","election",",","1992","United","States","presidential","election","(","339","votes",")",",","1996","United","States","presidential","election",",","and","2004","United","States","presidential","election","."],"labels":["O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["politician","election","location","event","person","organization","country","political_party"]}
{"id":"90.S","dataset":"crossner_politics","split":"dev","instance":{"id":"90.S","prompt_labels":"Other(O) political(O) parties(O) that(O) have(O) practiced(O) fusion(O) include(O) the(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) New(I-political_party) York(I-political_party) State(I-political_party) ,(O) the(O) Working(B-political_party) Families(I-political_party) Party(I-political_party) and(O) the(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) New(I-political_party) York(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, event, organization, political_party, politician, person, location, country\nGIVEN SENTENCE: Other political parties that have practiced fusion include the Conservative Party of New York State , the Working Families Party and the Liberal Party of New York .\n","prediction_output":null,"prediction_outputs":null,"group":"90","words":["Other","political","parties","that","have","practiced","fusion","include","the","Conservative","Party","of","New","York","State",",","the","Working","Families","Party","and","the","Liberal","Party","of","New","York","."],"labels":["O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["election","event","organization","political_party","politician","person","location","country"]}
{"id":"92.S","dataset":"crossner_politics","split":"dev","instance":{"id":"92.S","prompt_labels":"Supporters(O) of(O) the(O) campaign(O) included(O) Margo(B-person) Kingston(I-person) ((O) journalist(O) )(O) ,(O) John(B-politician) Valder(I-politician) ((O) previous(O) president(O) of(O) Howard(O) 's(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Australia(I-political_party) )(O) ,(O) Brian(B-person) Deegan(I-person) ((O) former(O) magistrate(O) ,(O) who(O) stood(O) against(O) Alexander(B-politician) Downer(I-politician) )(O) ,(O) Andrew(B-politician) Wilkie(I-politician) ((O) Australian(B-political_party) Greens(I-political_party) candidate(O) )(O) ,(O) Alex(B-person) Broun(I-person) playwright(O) and(O) Nicole(B-politician) Campbell(I-politician) ((O) Australian(B-political_party) Labor(I-political_party) Party(I-political_party) candidate(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, political_party, location, person, election, organization, politician, event\nGIVEN SENTENCE: Supporters of the campaign included Margo Kingston ( journalist ) , John Valder ( previous president of Howard 's Liberal Party of Australia ) , Brian Deegan ( former magistrate , who stood against Alexander Downer ) , Andrew Wilkie ( Australian Greens candidate ) , Alex Broun playwright and Nicole Campbell ( Australian Labor Party candidate ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Supporters","of","the","campaign","included","Margo","Kingston","(","journalist",")",",","John","Valder","(","previous","president","of","Howard","'s","Liberal","Party","of","Australia",")",",","Brian","Deegan","(","former","magistrate",",","who","stood","against","Alexander","Downer",")",",","Andrew","Wilkie","(","Australian","Greens","candidate",")",",","Alex","Broun","playwright","and","Nicole","Campbell","(","Australian","Labor","Party","candidate",")","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-person","I-person","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-politician","I-politician","O","B-political_party","I-political_party","O","O","O","B-person","I-person","O","O","B-politician","I-politician","O","B-political_party","I-political_party","I-political_party","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","political_party","location","person","election","organization","politician","event"]}
{"id":"96.S","dataset":"crossner_politics","split":"dev","instance":{"id":"96.S","prompt_labels":"Although(O) several(O) parties(O) are(O) typically(O) represented(O) in(O) parliament(O) ,(O) Canada(B-country) has(O) historically(O) had(O) two(O) dominant(O) political(O) parties(O) :(O) the(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) and(O) the(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ((O) preceded(O) by(O) the(O) Progressive(B-political_party) Conservative(I-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) and(O) the(O) Conservative(B-political_party) Party(I-political_party) ((O) 1867-1942(O) )(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, person, political_party, politician, election, location, country, event\nGIVEN SENTENCE: Although several parties are typically represented in parliament , Canada has historically had two dominant political parties : the Liberal Party of Canada and the Conservative Party of Canada ( preceded by the Progressive Conservative Party of Canada and the Conservative Party ( 1867-1942 ) ) .\n","prediction_output":null,"prediction_outputs":null,"group":"96","words":["Although","several","parties","are","typically","represented","in","parliament",",","Canada","has","historically","had","two","dominant","political","parties",":","the","Liberal","Party","of","Canada","and","the","Conservative","Party","of","Canada","(","preceded","by","the","Progressive","Conservative","Party","of","Canada","and","the","Conservative","Party","(","1867-1942",")",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","person","political_party","politician","election","location","country","event"]}
{"id":"99.S","dataset":"crossner_politics","split":"dev","instance":{"id":"99.S","prompt_labels":"Australia(B-country) has(O) a(O) de(O) facto(O) two-party(O) system(O) ,(O) with(O) the(O) Australian(B-political_party) Labor(I-political_party) Party(I-political_party) and(O) the(O) Coalition(O) of(O) the(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Australia(I-political_party) ,(O) National(B-political_party) Party(I-political_party) of(I-political_party) Australia(I-political_party) ,(O) the(O) Liberal(B-political_party) National(I-political_party) Party(I-political_party) of(I-political_party) Queensland(I-political_party) and(O) Country(B-political_party) Liberal(I-political_party) Party(I-political_party) dominating(O) Parliamentary(O) elections(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, event, location, person, political_party, politician, organization, election\nGIVEN SENTENCE: Australia has a de facto two-party system , with the Australian Labor Party and the Coalition of the Liberal Party of Australia , National Party of Australia , the Liberal National Party of Queensland and Country Liberal Party dominating Parliamentary elections .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Australia","has","a","de","facto","two-party","system",",","with","the","Australian","Labor","Party","and","the","Coalition","of","the","Liberal","Party","of","Australia",",","National","Party","of","Australia",",","the","Liberal","National","Party","of","Queensland","and","Country","Liberal","Party","dominating","Parliamentary","elections","."],"labels":["B-country","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["country","event","location","person","political_party","politician","organization","election"]}
{"id":"100.S","dataset":"crossner_politics","split":"dev","instance":{"id":"100.S","prompt_labels":"ALP(B-political_party) =(O) Australian(B-political_party) Labor(I-political_party) Party(I-political_party) ,(O) L(O) +(O) NP(O) =(O) grouping(O) of(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Australia(I-political_party) /(O) National(B-political_party) Party(I-political_party) of(I-political_party) Australia(I-political_party) /(O) Liberal(B-political_party) National(I-political_party) Party(I-political_party) of(I-political_party) Queensland(I-political_party) /(O) Country(B-political_party) Liberal(I-political_party) Party(I-political_party) Coalition(O) parties(O) ((O) and(O) predecessors(O) )(O) ,(O) Oth(O) =(O) other(O) parties(O) and(O) independents(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, person, country, election, politician, location, organization, political_party\nGIVEN SENTENCE: ALP = Australian Labor Party , L + NP = grouping of Liberal Party of Australia / National Party of Australia / Liberal National Party of Queensland / Country Liberal Party Coalition parties ( and predecessors ) , Oth = other parties and independents .\n","prediction_output":null,"prediction_outputs":null,"group":"100","words":["ALP","=","Australian","Labor","Party",",","L","+","NP","=","grouping","of","Liberal","Party","of","Australia","/","National","Party","of","Australia","/","Liberal","National","Party","of","Queensland","/","Country","Liberal","Party","Coalition","parties","(","and","predecessors",")",",","Oth","=","other","parties","and","independents","."],"labels":["B-political_party","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","person","country","election","politician","location","organization","political_party"]}
{"id":"101.S","dataset":"crossner_politics","split":"dev","instance":{"id":"101.S","prompt_labels":"The(O) five(O) largest(O) parties(O) in(O) the(O) election(O) were(O) the(O) National(B-political_party) Party(I-political_party) of(I-political_party) Indonesia(I-political_party) ((O) Partai(B-political_party) Nasional(I-political_party) Indonesia(I-political_party) )(O) ,(O) Masyumi(B-political_party) ,(O) Nahdlatul(B-political_party) Ulama(I-political_party) ,(O) the(O) Communist(B-political_party) Party(I-political_party) of(I-political_party) Indonesia(I-political_party) ((O) Partai(B-political_party) Komunis(I-political_party) Indonesia(I-political_party) ,(O) PKI(B-political_party) )(O) ,(O) and(O) the(O) Indonesian(B-political_party) Islamic(I-political_party) Union(I-political_party) Party(I-political_party) ((O) Partai(B-political_party) Sarekat(I-political_party) Islam(I-political_party) Indonesia(I-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, politician, election, event, organization, location, country, person\nGIVEN SENTENCE: The five largest parties in the election were the National Party of Indonesia ( Partai Nasional Indonesia ) , Masyumi , Nahdlatul Ulama , the Communist Party of Indonesia ( Partai Komunis Indonesia , PKI ) , and the Indonesian Islamic Union Party ( Partai Sarekat Islam Indonesia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"101","words":["The","five","largest","parties","in","the","election","were","the","National","Party","of","Indonesia","(","Partai","Nasional","Indonesia",")",",","Masyumi",",","Nahdlatul","Ulama",",","the","Communist","Party","of","Indonesia","(","Partai","Komunis","Indonesia",",","PKI",")",",","and","the","Indonesian","Islamic","Union","Party","(","Partai","Sarekat","Islam","Indonesia",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","O","B-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","politician","election","event","organization","location","country","person"]}
{"id":"103.S","dataset":"crossner_politics","split":"dev","instance":{"id":"103.S","prompt_labels":"There(O) are(O) numerous(O) other(O) groups(O) ,(O) including(O) communists(O) ,(O) European(B-political_party) Green(I-political_party) Party(I-political_party) ,(O) European(B-political_party) Free(I-political_party) Alliance(I-political_party) ,(O) conservatives(O) ,(O) Alliance(B-political_party) of(I-political_party) Liberals(I-political_party) and(I-political_party) Democrats(I-political_party) for(I-political_party) Europe(I-political_party) and(O) eurosceptics(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, event, organization, country, location, politician, election, political_party\nGIVEN SENTENCE: There are numerous other groups , including communists , European Green Party , European Free Alliance , conservatives , Alliance of Liberals and Democrats for Europe and eurosceptics .\n","prediction_output":null,"prediction_outputs":null,"group":"103","words":["There","are","numerous","other","groups",",","including","communists",",","European","Green","Party",",","European","Free","Alliance",",","conservatives",",","Alliance","of","Liberals","and","Democrats","for","Europe","and","eurosceptics","."],"labels":["O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","event","organization","country","location","politician","election","political_party"]}
{"id":"104.S","dataset":"crossner_politics","split":"dev","instance":{"id":"104.S","prompt_labels":"Those(O) were(O) the(O) Croatian(B-political_party) Democratic(I-political_party) Union(I-political_party) ,(O) the(O) Croatian(B-political_party) Peasant(I-political_party) Party(I-political_party) ,(O) the(O) Croatian(B-political_party) People(I-political_party) 's(I-political_party) Party(I-political_party) -(I-political_party) Liberal(I-political_party) Democrats(I-political_party) ,(O) the(O) Croatian(B-political_party) Social(I-political_party) Liberal(I-political_party) Party(I-political_party) ,(O) Social(B-political_party) Democratic(I-political_party) Party(I-political_party) of(I-political_party) Croatia(I-political_party) and(O) the(O) Bridge(B-political_party) of(I-political_party) Independent(I-political_party) Lists(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, event, location, election, country, politician, person, organization\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"105.S","dataset":"crossner_politics","split":"dev","instance":{"id":"105.S","prompt_labels":"Those(O) are(O) ((O) in(O) alphabetical(O) order(O) )(O) :(O) the(O) Alliance(B-political_party) of(I-political_party) Primorje-Gorski(I-political_party) Kotar(I-political_party) ((O) previously(O) known(O) as(O) the(O) Rijeka(B-political_party) Democratic(I-political_party) Alliance(I-political_party) )(O) ,(O) the(O) Croatian(B-political_party) Christian(I-political_party) Democratic(I-political_party) Union(I-political_party) ,(O) the(O) Croatian(B-political_party) Citizen(I-political_party) Party(I-political_party) ,(O) the(O) Croatian(B-political_party) Democratic(I-political_party) Alliance(I-political_party) of(I-political_party) Slavonia(I-political_party) and(I-political_party) Baranja(I-political_party) ,(O) the(O) Croatian(B-political_party) Democratic(I-political_party) Peasant(I-political_party) Party(I-political_party) ,(O) the(O) Croatian(B-political_party) Independent(I-political_party) Democrats(I-political_party) ,(O) the(O) Croatian(B-political_party) Party(I-political_party) of(I-political_party) Pensioners(I-political_party) ,(O) the(O) Croatian(B-political_party) Party(I-political_party) of(I-political_party) Rights(I-political_party) ,(O) the(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, country, organization, person, event, location, politician, election\nGIVEN SENTENCE: Those are ( in alphabetical order ) : the Alliance of Primorje-Gorski Kotar ( previously known as the Rijeka Democratic Alliance ) , the Croatian Christian Democratic Union , the Croatian Citizen Party , the Croatian Democratic Alliance of Slavonia and Baranja , the Croatian Democratic Peasant Party , the Croatian Independent Democrats , the Croatian Party of Pensioners , the Croatian Party of Rights , the .\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["Those","are","(","in","alphabetical","order",")",":","the","Alliance","of","Primorje-Gorski","Kotar","(","previously","known","as","the","Rijeka","Democratic","Alliance",")",",","the","Croatian","Christian","Democratic","Union",",","the","Croatian","Citizen","Party",",","the","Croatian","Democratic","Alliance","of","Slavonia","and","Baranja",",","the","Croatian","Democratic","Peasant","Party",",","the","Croatian","Independent","Democrats",",","the","Croatian","Party","of","Pensioners",",","the","Croatian","Party","of","Rights",",","the","."],"labels":["O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","country","organization","person","event","location","politician","election"]}
{"id":"106.S","dataset":"crossner_politics","split":"dev","instance":{"id":"106.S","prompt_labels":"Ante(B-politician) Starčević(I-politician) Croatian(B-political_party) Party(I-political_party) of(I-political_party) Rights(I-political_party) dr(I-political_party) ,(O) Dalmatian(B-political_party) Action(I-political_party) ,(O) the(O) Democratic(B-political_party) Centre(I-political_party) ,(O) the(O) Istrian(B-political_party) Democratic(I-political_party) Assembly(I-political_party) ,(O) the(O) Liberal(B-political_party) Party(I-political_party) ,(O) the(O) Party(B-political_party) of(I-political_party) Liberal(I-political_party) Democrats(I-political_party) ,(O) the(O) Serb(B-political_party) Democratic(I-political_party) Party(I-political_party) ,(O) the(O) Slavonia-Baranja(B-political_party) Croatian(I-political_party) Party(I-political_party) and(O) the(O) Social(B-political_party) Democratic(I-political_party) Action(I-political_party) of(I-political_party) Croatia(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, country, election, location, organization, political_party, event, person\nGIVEN SENTENCE: Ante Starčević Croatian Party of Rights dr , Dalmatian Action , the Democratic Centre , the Istrian Democratic Assembly , the Liberal Party , the Party of Liberal Democrats , the Serb Democratic Party , the Slavonia-Baranja Croatian Party and the Social Democratic Action of Croatia .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["Ante","Starčević","Croatian","Party","of","Rights","dr",",","Dalmatian","Action",",","the","Democratic","Centre",",","the","Istrian","Democratic","Assembly",",","the","Liberal","Party",",","the","Party","of","Liberal","Democrats",",","the","Serb","Democratic","Party",",","the","Slavonia-Baranja","Croatian","Party","and","the","Social","Democratic","Action","of","Croatia","."],"labels":["B-politician","I-politician","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","B-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["politician","country","election","location","organization","political_party","event","person"]}
{"id":"112.S","dataset":"crossner_politics","split":"dev","instance":{"id":"112.S","prompt_labels":"In(O) 2017(B-election) Czech(I-election) legislative(I-election) election(I-election) Koruna(B-politician) Česká(I-politician) together(O) with(O) Conservative(B-political_party) Party(I-political_party) and(O) Club(B-political_party) of(I-political_party) Committed(I-political_party) Non-Party(I-political_party) Members(I-political_party) agreed(O) on(O) joint(O) endorsement(O) of(O) TOP(B-political_party) 9(I-political_party) ,(O) while(O) TOP(O) 9(O) added(O) candidates(O) of(O) the(O) smaller(O) parties(O) on(O) their(O) list(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, election, politician, location, event, person, organization, country\nGIVEN SENTENCE: In 2017 Czech legislative election Koruna Česká together with Conservative Party and Club of Committed Non-Party Members agreed on joint endorsement of TOP 9 , while TOP 9 added candidates of the smaller parties on their list .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["In","2017","Czech","legislative","election","Koruna","Česká","together","with","Conservative","Party","and","Club","of","Committed","Non-Party","Members","agreed","on","joint","endorsement","of","TOP","9",",","while","TOP","9","added","candidates","of","the","smaller","parties","on","their","list","."],"labels":["O","B-election","I-election","I-election","I-election","B-politician","I-politician","O","O","B-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","election","politician","location","event","person","organization","country"]}
{"id":"113.S","dataset":"crossner_politics","split":"dev","instance":{"id":"113.S","prompt_labels":"During(O) this(O) period(O) ,(O) despite(O) no(O) longer(O) being(O) in(O) charge(O) of(O) external(O) affairs(O) ,(O) Ismail(B-person) expressed(O) strong(O) support(O) for(O) an(O) Association(B-organization) of(I-organization) Southeast(I-organization) Asia(I-organization) ,(O) telling(O) the(O) media(O) that(O) We(O) look(O) forward(O) to(O) a(O) regional(O) association(O) embracing(O) Thailand(B-country) ,(O) Burma(B-country) ,(O) Indonesia(B-country) ,(O) Singapore(B-country) ,(O) Malaysia(B-country) ,(O) Philippines(B-country) ,(O) Cambodia(B-country) ,(O) Laos(B-country) and(O) Vietnam(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, event, country, political_party, person, politician, election, organization\nGIVEN SENTENCE: During this period , despite no longer being in charge of external affairs , Ismail expressed strong support for an Association of Southeast Asia , telling the media that We look forward to a regional association embracing Thailand , Burma , Indonesia , Singapore , Malaysia , Philippines , Cambodia , Laos and Vietnam .\n","prediction_output":null,"prediction_outputs":null,"group":"113","words":["During","this","period",",","despite","no","longer","being","in","charge","of","external","affairs",",","Ismail","expressed","strong","support","for","an","Association","of","Southeast","Asia",",","telling","the","media","that","We","look","forward","to","a","regional","association","embracing","Thailand",",","Burma",",","Indonesia",",","Singapore",",","Malaysia",",","Philippines",",","Cambodia",",","Laos","and","Vietnam","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["location","event","country","political_party","person","politician","election","organization"]}
{"id":"118.S","dataset":"crossner_politics","split":"dev","instance":{"id":"118.S","prompt_labels":"Vice(O) presidents(O) Chen(B-politician) Cheng(I-politician) ,(O) Yen(B-politician) Chia-kan(I-politician) ,(O) and(O) Lien(B-politician) Chan(I-politician) all(O) served(O) as(O) premier(O) concurrently(O) as(O) vice(O) president(O) during(O) part(O) of(O) their(O) terms(O) ,(O) and(O) vice(O) president(O) Annette(B-politician) Lu(I-politician) has(O) at(O) times(O) been(O) mentioned(O) as(O) a(O) possible(O) candidate(O) for(O) premiership(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, organization, location, politician, election, political_party, event\nGIVEN SENTENCE: Vice presidents Chen Cheng , Yen Chia-kan , and Lien Chan all served as premier concurrently as vice president during part of their terms , and vice president Annette Lu has at times been mentioned as a possible candidate for premiership .\n","prediction_output":null,"prediction_outputs":null,"group":"118","words":["Vice","presidents","Chen","Cheng",",","Yen","Chia-kan",",","and","Lien","Chan","all","served","as","premier","concurrently","as","vice","president","during","part","of","their","terms",",","and","vice","president","Annette","Lu","has","at","times","been","mentioned","as","a","possible","candidate","for","premiership","."],"labels":["O","O","B-politician","I-politician","O","B-politician","I-politician","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","country","organization","location","politician","election","political_party","event"]}
{"id":"120.S","dataset":"crossner_politics","split":"dev","instance":{"id":"120.S","prompt_labels":"Malaya(B-country) united(O) with(O) Crown(B-country) Colony(I-country) of(I-country) North(I-country) Borneo(I-country) ,(O) Crown(B-country) Colony(I-country) of(I-country) Sarawak(I-country) ,(O) and(O) Colony(B-country) of(I-country) Singapore(I-country) on(O) 16(O) September(O) 1963(O) to(O) become(O) Malaysia(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, politician, country, political_party, person, event, location, organization\nGIVEN SENTENCE: Malaya united with Crown Colony of North Borneo , Crown Colony of Sarawak , and Colony of Singapore on 16 September 1963 to become Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"120","words":["Malaya","united","with","Crown","Colony","of","North","Borneo",",","Crown","Colony","of","Sarawak",",","and","Colony","of","Singapore","on","16","September","1963","to","become","Malaysia","."],"labels":["B-country","O","O","B-country","I-country","I-country","I-country","I-country","O","B-country","I-country","I-country","I-country","O","O","B-country","I-country","I-country","O","O","O","O","O","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["election","politician","country","political_party","person","event","location","organization"]}
{"id":"121.S","dataset":"crossner_politics","split":"dev","instance":{"id":"121.S","prompt_labels":"It(O) is(O) a(O) founding(O) member(O) of(O) ASEAN(B-organization) ,(O) EAS(B-organization) ,(O) Organisation(B-organization) of(I-organization) Islamic(I-organization) Cooperation(I-organization) and(O) a(O) member(O) of(O) Asia-Pacific(B-organization) Economic(I-organization) Cooperation(I-organization) ,(O) the(O) Commonwealth(B-organization) of(I-organization) Nations(I-organization) and(O) the(O) Non-Aligned(B-organization) Movement(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, location, person, politician, election, political_party, event, country\nGIVEN SENTENCE: It is a founding member of ASEAN , EAS , Organisation of Islamic Cooperation and a member of Asia-Pacific Economic Cooperation , the Commonwealth of Nations and the Non-Aligned Movement .\n","prediction_output":null,"prediction_outputs":null,"group":"121","words":["It","is","a","founding","member","of","ASEAN",",","EAS",",","Organisation","of","Islamic","Cooperation","and","a","member","of","Asia-Pacific","Economic","Cooperation",",","the","Commonwealth","of","Nations","and","the","Non-Aligned","Movement","."],"labels":["O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["organization","location","person","politician","election","political_party","event","country"]}
{"id":"122.S","dataset":"crossner_politics","split":"dev","instance":{"id":"122.S","prompt_labels":"Stanley(B-politician) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(B-politician) Lyulph(I-politician) Stanley(I-politician) )(O) contested(O) Oldham(B-location) ,(O) in(O) the(O) Liberal(B-political_party) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1880(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1885(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, person, organization, event, political_party, politician, election\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"123.S","dataset":"crossner_politics","split":"dev","instance":{"id":"123.S","prompt_labels":"Malagodi(B-politician) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(B-political_party) Social(I-political_party) Movement(I-political_party) ,(O) the(O) Monarchist(B-political_party) National(I-political_party) Party(I-political_party) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(B-election) Italian(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, politician, election, political_party, event, person, location\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"126.S","dataset":"crossner_politics","split":"dev","instance":{"id":"126.S","prompt_labels":"For(O) the(O) 2018(B-election) Pakistani(I-election) general(I-election) election(I-election) ,(O) PML-F(B-political_party) lead(O) a(O) new(O) coalition(O) named(O) Grand(B-political_party) Democratic(I-political_party) Alliance(I-political_party) with(O) Awami(B-political_party) Tahreek(I-political_party) ,(O) National(B-political_party) Peoples(I-political_party) Party(I-political_party) ,(O) Pakistan(B-political_party) Peoples(I-political_party) Party(I-political_party) Workers(I-political_party) and(O) Pakistan(B-political_party) Peoples(I-political_party) Muslim(I-political_party) League(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, location, event, person, politician, organization, election, country\nGIVEN SENTENCE: For the 2018 Pakistani general election , PML-F lead a new coalition named Grand Democratic Alliance with Awami Tahreek , National Peoples Party , Pakistan Peoples Party Workers and Pakistan Peoples Muslim League .\n","prediction_output":null,"prediction_outputs":null,"group":"126","words":["For","the","2018","Pakistani","general","election",",","PML-F","lead","a","new","coalition","named","Grand","Democratic","Alliance","with","Awami","Tahreek",",","National","Peoples","Party",",","Pakistan","Peoples","Party","Workers","and","Pakistan","Peoples","Muslim","League","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","B-political_party","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["political_party","location","event","person","politician","organization","election","country"]}
{"id":"128.S","dataset":"crossner_politics","split":"dev","instance":{"id":"128.S","prompt_labels":"The(O) Progressive(B-political_party) Conservative(I-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) government(O) of(O) the(O) time(O) ,(O) headed(O) by(O) Prime(O) Minister(O) John(B-politician) Diefenbaker(I-politician) ,(O) did(O) not(O) accept(O) the(O) invitation(O) to(O) establish(O) a(O) new(O) Canadian(O) flag(O) ,(O) so(O) Pearson(B-politician) made(O) it(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) policy(O) in(O) 1961(O) ,(O) and(O) part(O) of(O) the(O) party(O) 's(O) election(O) platform(O) in(O) the(O) 1962(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 1963(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, political_party, politician, event, organization, location, election\nGIVEN SENTENCE: The Progressive Conservative Party of Canada government of the time , headed by Prime Minister John Diefenbaker , did not accept the invitation to establish a new Canadian flag , so Pearson made it Liberal Party of Canada policy in 1961 , and part of the party 's election platform in the 1962 Canadian federal election and 1963 Canadian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"128","words":["The","Progressive","Conservative","Party","of","Canada","government","of","the","time",",","headed","by","Prime","Minister","John","Diefenbaker",",","did","not","accept","the","invitation","to","establish","a","new","Canadian","flag",",","so","Pearson","made","it","Liberal","Party","of","Canada","policy","in","1961",",","and","part","of","the","party","'s","election","platform","in","the","1962","Canadian","federal","election","and","1963","Canadian","federal","election","."],"labels":["O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["person","country","political_party","politician","event","organization","location","election"]}
{"id":"130.S","dataset":"crossner_politics","split":"dev","instance":{"id":"130.S","prompt_labels":"He(O) contested(O) Cardiff(B-politician) North(I-politician) in(O) October(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1979(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) for(O) the(O) Liberals(B-political_party) ,(O) before(O) fighting(O) Cardiff(B-politician) Central(I-politician) in(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1987(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) for(O) the(O) SDP-Liberal(B-political_party) Alliance(I-political_party) ,(O) but(O) was(O) unsuccessful(O) on(O) each(O) occasion(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, political_party, person, event, election, politician, location\nGIVEN SENTENCE: He contested Cardiff North in October 1974 United Kingdom general election and 1979 United Kingdom general election for the Liberals , before fighting Cardiff Central in 1983 United Kingdom general election and 1987 United Kingdom general election for the SDP-Liberal Alliance , but was unsuccessful on each occasion .\n","prediction_output":null,"prediction_outputs":null,"group":"130","words":["He","contested","Cardiff","North","in","October","1974","United","Kingdom","general","election","and","1979","United","Kingdom","general","election","for","the","Liberals",",","before","fighting","Cardiff","Central","in","1983","United","Kingdom","general","election","and","1987","United","Kingdom","general","election","for","the","SDP-Liberal","Alliance",",","but","was","unsuccessful","on","each","occasion","."],"labels":["O","O","B-politician","I-politician","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-political_party","O","O","O","B-politician","I-politician","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","country","political_party","person","event","election","politician","location"]}
{"id":"132.S","dataset":"crossner_politics","split":"dev","instance":{"id":"132.S","prompt_labels":"She(O) was(O) re-elected(O) in(O) the(O) federal(O) general(O) elections(O) of(O) 1997(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2000(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) and(O) 2008(B-election) Canadian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, political_party, politician, organization, country, location, person, event\nGIVEN SENTENCE: She was re-elected in the federal general elections of 1997 Canadian federal election , 2000 Canadian federal election , 2004 Canadian federal election , 2006 Canadian federal election , and 2008 Canadian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"132","words":["She","was","re-elected","in","the","federal","general","elections","of","1997","Canadian","federal","election",",","2000","Canadian","federal","election",",","2004","Canadian","federal","election",",","2006","Canadian","federal","election",",","and","2008","Canadian","federal","election","."],"labels":["O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["election","political_party","politician","organization","country","location","person","event"]}
{"id":"138.S","dataset":"crossner_politics","split":"dev","instance":{"id":"138.S","prompt_labels":"However(O) ,(O) in(O) the(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) 2008(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) 2011(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) the(O) entire(O) region(O) ,(O) incrementally(O) swung(O) away(O) from(O) the(O) Liberals(B-political_party) to(O) support(O) the(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ,(O) including(O) in(O) London(B-location) ,(O) where(O) three-way(O) vote-splitting(O) resulted(O) in(O) two(O) ridings(O) switching(O) from(O) Liberal(B-political_party) to(O) Conservative(B-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, event, organization, location, political_party, person, country, politician\nGIVEN SENTENCE: However , in the 2004 Canadian federal election , 2006 Canadian federal election , 2008 Canadian federal election and 2011 Canadian federal election , the entire region , incrementally swung away from the Liberals to support the Conservative Party of Canada , including in London , where three-way vote-splitting resulted in two ridings switching from Liberal to Conservative .\n","prediction_output":null,"prediction_outputs":null,"group":"138","words":["However",",","in","the","2004","Canadian","federal","election",",","2006","Canadian","federal","election",",","2008","Canadian","federal","election","and","2011","Canadian","federal","election",",","the","entire","region",",","incrementally","swung","away","from","the","Liberals","to","support","the","Conservative","Party","of","Canada",",","including","in","London",",","where","three-way","vote-splitting","resulted","in","two","ridings","switching","from","Liberal","to","Conservative","."],"labels":["O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","B-political_party","O","B-political_party","O"],"target_index":null,"target_label":null},"label_list":["election","event","organization","location","political_party","person","country","politician"]}
{"id":"145.S","dataset":"crossner_politics","split":"dev","instance":{"id":"145.S","prompt_labels":"Christian(B-organization) Voice(I-organization) was(O) the(O) first(O) of(O) the(O) Christian(O) Right(O) groups(O) ,(O) pre-dating(O) the(O) Christian(B-organization) Coalition(I-organization) of(I-organization) America(I-organization) ,(O) American(B-organization) Coalition(I-organization) for(I-organization) Traditional(I-organization) Values(I-organization) ,(O) Concerned(B-organization) Women(I-organization) for(I-organization) America(I-organization) ,(O) Moral(B-organization) Majority(I-organization) ,(O) Family(B-organization) Research(I-organization) Council(I-organization) ,(O) and(O) other(O) Christian(O) political(O) groups(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, political_party, politician, event, election, person, location\nGIVEN SENTENCE: Christian Voice was the first of the Christian Right groups , pre-dating the Christian Coalition of America , American Coalition for Traditional Values , Concerned Women for America , Moral Majority , Family Research Council , and other Christian political groups .\n","prediction_output":null,"prediction_outputs":null,"group":"145","words":["Christian","Voice","was","the","first","of","the","Christian","Right","groups",",","pre-dating","the","Christian","Coalition","of","America",",","American","Coalition","for","Traditional","Values",",","Concerned","Women","for","America",",","Moral","Majority",",","Family","Research","Council",",","and","other","Christian","political","groups","."],"labels":["B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","country","political_party","politician","event","election","person","location"]}
{"id":"146.S","dataset":"crossner_politics","split":"dev","instance":{"id":"146.S","prompt_labels":"In(O) Kota(B-location) Kinabalu(I-location) ,(O) United(B-political_party) Pasokmomogun(I-political_party) Kadazandusun(I-political_party) Murut(I-political_party) Organisation(I-political_party) ((O) UPKO(B-political_party) )(O) led(O) by(O) its(O) Secretary-General(O) Datuk(O) Wilfred(B-politician) Madius(I-politician) Tangau(I-politician) ,(O) on(O) 23(O) September(O) 2008(O) ,(O) joined(O) its(O) 3(O) other(O) Barisan(B-political_party) Nasional(I-political_party) ((O) BN(B-political_party) )(O) counterparts(O) Malaysian(B-political_party) Chinese(I-political_party) Association(I-political_party) ,(O) Parti(B-political_party) Gerakan(I-political_party) Rakyat(I-political_party) Malaysia(I-political_party) and(O) Malaysian(B-political_party) Indian(I-political_party) Congress(I-political_party) ,(O) petitioning(O) Government(O) review(O) of(O) ISA(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, politician, event, country, location, political_party, election, person\nGIVEN SENTENCE: In Kota Kinabalu , United Pasokmomogun Kadazandusun Murut Organisation ( UPKO ) led by its Secretary-General Datuk Wilfred Madius Tangau , on 23 September 2008 , joined its 3 other Barisan Nasional ( BN ) counterparts Malaysian Chinese Association , Parti Gerakan Rakyat Malaysia and Malaysian Indian Congress , petitioning Government review of ISA .\n","prediction_output":null,"prediction_outputs":null,"group":"146","words":["In","Kota","Kinabalu",",","United","Pasokmomogun","Kadazandusun","Murut","Organisation","(","UPKO",")","led","by","its","Secretary-General","Datuk","Wilfred","Madius","Tangau",",","on","23","September","2008",",","joined","its","3","other","Barisan","Nasional","(","BN",")","counterparts","Malaysian","Chinese","Association",",","Parti","Gerakan","Rakyat","Malaysia","and","Malaysian","Indian","Congress",",","petitioning","Government","review","of","ISA","."],"labels":["O","B-location","I-location","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-political_party","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","politician","event","country","location","political_party","election","person"]}
{"id":"147.S","dataset":"crossner_politics","split":"dev","instance":{"id":"147.S","prompt_labels":"In(O) the(O) 1969(B-election) Malaysian(I-election) general(I-election) election(I-election) ,(O) MCA(B-political_party) lost(O) more(O) than(O) half(O) its(O) seats(O) to(O) the(O) new(O) ,(O) mainly(O) Chinese(O) Malaysian(O) ,(O) opposition(O) parties(O) Democratic(B-political_party) Action(I-political_party) Party(I-political_party) ((O) DAP(B-political_party) )(O) and(O) Parti(B-political_party) Gerakan(I-political_party) Rakyat(I-political_party) Malaysia(I-political_party) ((O) Gerakan(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, election, politician, political_party, location, person, organization, event\nGIVEN SENTENCE: In the 1969 Malaysian general election , MCA lost more than half its seats to the new , mainly Chinese Malaysian , opposition parties Democratic Action Party ( DAP ) and Parti Gerakan Rakyat Malaysia ( Gerakan ) .\n","prediction_output":null,"prediction_outputs":null,"group":"147","words":["In","the","1969","Malaysian","general","election",",","MCA","lost","more","than","half","its","seats","to","the","new",",","mainly","Chinese","Malaysian",",","opposition","parties","Democratic","Action","Party","(","DAP",")","and","Parti","Gerakan","Rakyat","Malaysia","(","Gerakan",")","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["country","election","politician","political_party","location","person","organization","event"]}
{"id":"149.S","dataset":"crossner_politics","split":"dev","instance":{"id":"149.S","prompt_labels":"Patteson(B-person) was(O) a(O) member(O) of(O) the(O) Board(O) of(O) Trustees(O) of(O) West(B-organization) Virginia(I-organization) Wesleyan(I-organization) ,(O) and(O) of(O) a(O) number(O) of(O) societies(O) :(O) Free(B-organization) mason(I-organization) s(O) ,(O) Knights(B-organization) Templar(I-organization) ,(O) Moose(B-organization) International(I-organization) ,(O) Lions(B-organization) Clubs(I-organization) International(I-organization) ,(O) Chamber(B-organization) of(I-organization) Commerce(I-organization) ,(O) American(B-organization) Legion(I-organization) ,(O) Sons(B-organization) of(I-organization) the(I-organization) American(I-organization) Revolution(I-organization) and(O) Benevolent(B-organization) and(I-organization) Protective(I-organization) Order(I-organization) of(I-organization) Elks(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, political_party, politician, person, organization, country, event, location\nGIVEN SENTENCE: Patteson was a member of the Board of Trustees of West Virginia Wesleyan , and of a number of societies : Free mason s , Knights Templar , Moose International , Lions Clubs International , Chamber of Commerce , American Legion , Sons of the American Revolution and Benevolent and Protective Order of Elks .\n","prediction_output":null,"prediction_outputs":null,"group":"149","words":["Patteson","was","a","member","of","the","Board","of","Trustees","of","West","Virginia","Wesleyan",",","and","of","a","number","of","societies",":","Free","mason","s",",","Knights","Templar",",","Moose","International",",","Lions","Clubs","International",",","Chamber","of","Commerce",",","American","Legion",",","Sons","of","the","American","Revolution","and","Benevolent","and","Protective","Order","of","Elks","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["election","political_party","politician","person","organization","country","event","location"]}
{"id":"151.S","dataset":"crossner_politics","split":"dev","instance":{"id":"151.S","prompt_labels":"Before(O) the(O) 2000(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) West(B-location) Virginia(I-location) had(O) been(O) won(O) by(O) the(O) Democratic(O) nominee(O) every(O) time(O) since(O) 1932(O) ((O) except(O) for(O) the(O) Republican(O) landslides(O) of(O) 1956(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) 1972(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) and(O) 1984(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, election, event, country, organization, person, political_party, location\nGIVEN SENTENCE: Before the 2000 United States presidential election , West Virginia had been won by the Democratic nominee every time since 1932 ( except for the Republican landslides of 1956 United States presidential election , 1972 United States presidential election , and 1984 United States presidential election ) .\n","prediction_output":null,"prediction_outputs":null,"group":"151","words":["Before","the","2000","United","States","presidential","election",",","West","Virginia","had","been","won","by","the","Democratic","nominee","every","time","since","1932","(","except","for","the","Republican","landslides","of","1956","United","States","presidential","election",",","1972","United","States","presidential","election",",","and","1984","United","States","presidential","election",")","."],"labels":["O","O","B-election","I-election","I-election","I-election","I-election","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O"],"target_index":null,"target_label":null},"label_list":["politician","election","event","country","organization","person","political_party","location"]}
{"id":"152.S","dataset":"crossner_politics","split":"dev","instance":{"id":"152.S","prompt_labels":"Molloy(B-politician) ran(O) for(O) the(O) Canadian(B-organization) House(I-organization) of(I-organization) Commons(I-organization) in(O) the(O) 1921(B-election) Canadian(I-election) federal(I-election) election(I-election) as(O) a(O) candidate(O) of(O) the(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ,(O) and(O) lost(O) to(O) Progressive(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) candidate(O) Robert(B-politician) Alexander(I-politician) Hoey(I-politician) by(O) 1,397(O) votes(O) in(O) the(O) riding(O) of(O) Springfield(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, organization, event, politician, country, location, person, political_party\nGIVEN SENTENCE: Molloy ran for the Canadian House of Commons in the 1921 Canadian federal election as a candidate of the Liberal Party of Canada , and lost to Progressive Party of Canada candidate Robert Alexander Hoey by 1,397 votes in the riding of Springfield .\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["Molloy","ran","for","the","Canadian","House","of","Commons","in","the","1921","Canadian","federal","election","as","a","candidate","of","the","Liberal","Party","of","Canada",",","and","lost","to","Progressive","Party","of","Canada","candidate","Robert","Alexander","Hoey","by","1,397","votes","in","the","riding","of","Springfield","."],"labels":["B-politician","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["election","organization","event","politician","country","location","person","political_party"]}
{"id":"157.S","dataset":"crossner_politics","split":"dev","instance":{"id":"157.S","prompt_labels":"Despite(O) the(O) unsuccessful(O) attempt(O) at(O) the(O) 1987(B-election) Sarawak(I-election) state(I-election) election(I-election) ,(O) Abdul(B-politician) Rahman(I-politician) continued(O) his(O) struggle(O) with(O) his(O) allies(O) ,(O) Sarawak(B-location) Dayak(B-political_party) People(I-political_party) 's(I-political_party) Party(I-political_party) against(O) Taib(B-politician) 's(O) led(O) Sarawak(B-location) Barisan(B-political_party) Nasional(I-political_party) until(O) 1991(B-election) Sarawak(I-election) state(I-election) election(I-election) when(O) Taib(B-politician) 's(O) coalition(O) won(O) an(O) overwhelming(O) majority(O) of(O) 49(O) out(O) of(O) 56(O) seats(O) in(O) the(O) state(O) assembly(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, election, politician, political_party, event, location, person, country\nGIVEN SENTENCE: Despite the unsuccessful attempt at the 1987 Sarawak state election , Abdul Rahman continued his struggle with his allies , Sarawak Dayak People 's Party against Taib 's led Sarawak Barisan Nasional until 1991 Sarawak state election when Taib 's coalition won an overwhelming majority of 49 out of 56 seats in the state assembly .\n","prediction_output":null,"prediction_outputs":null,"group":"157","words":["Despite","the","unsuccessful","attempt","at","the","1987","Sarawak","state","election",",","Abdul","Rahman","continued","his","struggle","with","his","allies",",","Sarawak","Dayak","People","'s","Party","against","Taib","'s","led","Sarawak","Barisan","Nasional","until","1991","Sarawak","state","election","when","Taib","'s","coalition","won","an","overwhelming","majority","of","49","out","of","56","seats","in","the","state","assembly","."],"labels":["O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","B-politician","I-politician","O","O","O","O","O","O","O","B-location","B-political_party","I-political_party","I-political_party","I-political_party","O","B-politician","O","O","B-location","B-political_party","I-political_party","O","B-election","I-election","I-election","I-election","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","election","politician","political_party","event","location","person","country"]}
{"id":"158.S","dataset":"crossner_politics","split":"dev","instance":{"id":"158.S","prompt_labels":"In(O) British(B-location) Columbia(I-location) ,(O) the(O) British(B-political_party) Columbia(I-political_party) Social(I-political_party) Credit(I-political_party) Party(I-political_party) was(O) replaced(O) as(O) the(O) party(O) of(O) the(O) centre-right(O) by(O) the(O) British(B-political_party) Columbia(I-political_party) Liberal(I-political_party) Party(I-political_party) ,(O) and(O) in(O) Alberta(B-location) the(O) Alberta(B-political_party) Social(I-political_party) Credit(I-political_party) Party(I-political_party) were(O) completely(O) annihilated(O) by(O) the(O) more(O) moderate(O) Alberta(B-political_party) Progressive(I-political_party) Conservative(I-political_party) Party(I-political_party) ,(O) leaving(O) both(O) parties(O) as(O) marginal(O) political(O) forces(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, organization, election, politician, location, country, event, person\nGIVEN SENTENCE: In British Columbia , the British Columbia Social Credit Party was replaced as the party of the centre-right by the British Columbia Liberal Party , and in Alberta the Alberta Social Credit Party were completely annihilated by the more moderate Alberta Progressive Conservative Party , leaving both parties as marginal political forces .\n","prediction_output":null,"prediction_outputs":null,"group":"158","words":["In","British","Columbia",",","the","British","Columbia","Social","Credit","Party","was","replaced","as","the","party","of","the","centre-right","by","the","British","Columbia","Liberal","Party",",","and","in","Alberta","the","Alberta","Social","Credit","Party","were","completely","annihilated","by","the","more","moderate","Alberta","Progressive","Conservative","Party",",","leaving","both","parties","as","marginal","political","forces","."],"labels":["O","B-location","I-location","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","B-location","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","organization","election","politician","location","country","event","person"]}
{"id":"159.S","dataset":"crossner_politics","split":"dev","instance":{"id":"159.S","prompt_labels":"AD(B-political_party) members(O) were(O) mainly(O) former(O) Italian(B-political_party) Republican(I-political_party) Party(I-political_party) and(O) former(O) Italian(B-political_party) Socialist(I-political_party) Party(I-political_party) ,(O) was(O) a(O) former(O) member(O) of(O) the(O) Italian(B-political_party) Communist(I-political_party) Party(I-political_party) and(O) the(O) Democratic(B-political_party) Party(I-political_party) of(I-political_party) the(I-political_party) Left(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, person, organization, political_party, location, politician, event, country\nGIVEN SENTENCE: AD members were mainly former Italian Republican Party and former Italian Socialist Party , was a former member of the Italian Communist Party and the Democratic Party of the Left .\n","prediction_output":null,"prediction_outputs":null,"group":"159","words":["AD","members","were","mainly","former","Italian","Republican","Party","and","former","Italian","Socialist","Party",",","was","a","former","member","of","the","Italian","Communist","Party","and","the","Democratic","Party","of","the","Left","."],"labels":["B-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["election","person","organization","political_party","location","politician","event","country"]}
{"id":"160.S","dataset":"crossner_politics","split":"dev","instance":{"id":"160.S","prompt_labels":"The(O) party(O) ran(O) in(O) the(O) 1994(B-election) Italian(I-election) general(I-election) election(I-election) within(O) the(O) Alliance(B-political_party) of(I-political_party) Progressives(I-political_party) and(O) obtained(O) a(O) mere(O) 1.2(O) %(O) of(O) the(O) vote(O) ,(O) due(O) to(O) the(O) uneasy(O) alliance(O) with(O) the(O) traditional(O) left(O) and(O) the(O) competition(O) by(O) Silvio(B-politician) Berlusconi(I-politician) '(O) s(O) Forza(B-political_party) Italia(I-political_party) ,(O) which(O) embraced(O) most(O) of(O) AD(B-political_party) 's(O) policies(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, political_party, event, politician, location, country, organization, election\nGIVEN SENTENCE: The party ran in the 1994 Italian general election within the Alliance of Progressives and obtained a mere 1.2 % of the vote , due to the uneasy alliance with the traditional left and the competition by Silvio Berlusconi ' s Forza Italia , which embraced most of AD 's policies .\n","prediction_output":null,"prediction_outputs":null,"group":"160","words":["The","party","ran","in","the","1994","Italian","general","election","within","the","Alliance","of","Progressives","and","obtained","a","mere","1.2","%","of","the","vote",",","due","to","the","uneasy","alliance","with","the","traditional","left","and","the","competition","by","Silvio","Berlusconi","'","s","Forza","Italia",",","which","embraced","most","of","AD","'s","policies","."],"labels":["O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","O","O","O","O","O","B-political_party","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","political_party","event","politician","location","country","organization","election"]}
{"id":"163.S","dataset":"crossner_politics","split":"dev","instance":{"id":"163.S","prompt_labels":"The(O) Unionist(B-political_party) Party(I-political_party) ((O) ,(O) UP(B-political_party) )(O) was(O) a(O) pre-apartheid(O) South(O) African(O) political(O) party(O) ,(O) which(O) contested(O) elections(O) to(O) the(O) Union(B-country) of(I-country) South(I-country) Africa(I-country) parliament(O) from(O) the(O) 1910(B-election) South(I-election) African(I-election) general(I-election) election(I-election) until(O) its(O) merger(O) into(O) the(O) South(B-political_party) African(I-political_party) Party(I-political_party) just(O) before(O) the(O) 1921(B-election) South(I-election) African(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, event, election, organization, location, political_party, politician\nGIVEN SENTENCE: The Unionist Party ( , UP ) was a pre-apartheid South African political party , which contested elections to the Union of South Africa parliament from the 1910 South African general election until its merger into the South African Party just before the 1921 South African general election .\n","prediction_output":null,"prediction_outputs":null,"group":"163","words":["The","Unionist","Party","(",",","UP",")","was","a","pre-apartheid","South","African","political","party",",","which","contested","elections","to","the","Union","of","South","Africa","parliament","from","the","1910","South","African","general","election","until","its","merger","into","the","South","African","Party","just","before","the","1921","South","African","general","election","."],"labels":["O","B-political_party","I-political_party","O","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","I-country","I-country","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["person","country","event","election","organization","location","political_party","politician"]}
{"id":"164.S","dataset":"crossner_politics","split":"dev","instance":{"id":"164.S","prompt_labels":"The(O) Socialist(B-political_party) Party(I-political_party) of(I-political_party) the(I-political_party) United(I-political_party) States(I-political_party) ((O) SPUS(B-political_party) )(O) -(O) its(O) name(O) inspired(O) by(O) co-thinkers(O) in(O) the(O) Socialist(B-political_party) Party(I-political_party) of(I-political_party) Great(I-political_party) Britain(I-political_party) ((O) SPGB(B-political_party) )(O) and(O) the(O) original(O) ((O) non-WSM(O) )(O) Socialist(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ((O) SPC(B-political_party) )(O) -(O) was(O) established(O) on(O) July(O) 7(O) ,(O) 1916(O) by(O) 42(O) defecting(O) members(O) of(O) Local(B-location) Detroit(I-location) of(O) the(O) Socialist(B-political_party) Party(I-political_party) of(I-political_party) America(I-political_party) ((O) SPA(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, person, organization, country, location, election, political_party, event\nGIVEN SENTENCE: The Socialist Party of the United States ( SPUS ) - its name inspired by co-thinkers in the Socialist Party of Great Britain ( SPGB ) and the original ( non-WSM ) Socialist Party of Canada ( SPC ) - was established on July 7 , 1916 by 42 defecting members of Local Detroit of the Socialist Party of America ( SPA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"164","words":["The","Socialist","Party","of","the","United","States","(","SPUS",")","-","its","name","inspired","by","co-thinkers","in","the","Socialist","Party","of","Great","Britain","(","SPGB",")","and","the","original","(","non-WSM",")","Socialist","Party","of","Canada","(","SPC",")","-","was","established","on","July","7",",","1916","by","42","defecting","members","of","Local","Detroit","of","the","Socialist","Party","of","America","(","SPA",")","."],"labels":["O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["politician","person","organization","country","location","election","political_party","event"]}
{"id":"165.S","dataset":"crossner_politics","split":"dev","instance":{"id":"165.S","prompt_labels":"He(O) was(O) elected(O) as(O) a(O) Social(B-organization) Credit(I-organization) MLA(I-organization) in(O) Vancouver(B-location) South(I-location) in(O) 1975(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) ,(O) 1979(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) ,(O) 1983(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) and(O) 1986(B-election) British(I-election) Columbia(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, organization, location, politician, person, political_party, election, event\nGIVEN SENTENCE: He was elected as a Social Credit MLA in Vancouver South in 1975 British Columbia general election , 1979 British Columbia general election , 1983 British Columbia general election and 1986 British Columbia general election .\n","prediction_output":null,"prediction_outputs":null,"group":"165","words":["He","was","elected","as","a","Social","Credit","MLA","in","Vancouver","South","in","1975","British","Columbia","general","election",",","1979","British","Columbia","general","election",",","1983","British","Columbia","general","election","and","1986","British","Columbia","general","election","."],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["country","organization","location","politician","person","political_party","election","event"]}
{"id":"166.S","dataset":"crossner_politics","split":"dev","instance":{"id":"166.S","prompt_labels":"He(O) ran(O) as(O) the(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) candidate(O) for(O) the(O) riding(O) of(O) Vancouver(B-location) Quadra(I-location) in(O) the(O) 2004(B-election) Canadian(I-election) federal(I-election) election(I-election) and(O) again(O) in(O) 2006(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) losing(O) both(O) times(O) to(O) Liberal(O) Stephen(B-politician) Owen(I-politician) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, organization, politician, event, election, person, country, location\nGIVEN SENTENCE: He ran as the Conservative Party of Canada candidate for the riding of Vancouver Quadra in the 2004 Canadian federal election and again in 2006 Canadian federal election , losing both times to Liberal Stephen Owen .\n","prediction_output":null,"prediction_outputs":null,"group":"166","words":["He","ran","as","the","Conservative","Party","of","Canada","candidate","for","the","riding","of","Vancouver","Quadra","in","the","2004","Canadian","federal","election","and","again","in","2006","Canadian","federal","election",",","losing","both","times","to","Liberal","Stephen","Owen","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","B-location","I-location","O","O","B-election","I-election","I-election","I-election","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-politician","I-politician","O"],"target_index":null,"target_label":null},"label_list":["political_party","organization","politician","event","election","person","country","location"]}
{"id":"167.S","dataset":"crossner_politics","split":"dev","instance":{"id":"167.S","prompt_labels":"During(O) the(O) 2005(B-election) German(I-election) federal(I-election) election(I-election) campaign(O) ,(O) Angela(B-politician) Merkel(I-politician) ,(O) leader(O) of(O) the(O) Christian(B-political_party) Democratic(I-political_party) Union(I-political_party) of(I-political_party) Germany(I-political_party) /(O) Christian(B-political_party) Social(I-political_party) Union(I-political_party) in(I-political_party) Bavaria(I-political_party) ,(O) announced(O) that(O) Kirchhof(B-politician) would(O) serve(O) as(O) minister(O) of(O) finance(O) if(O) she(O) formed(O) a(O) government(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, politician, political_party, country, event, organization, location, person\nGIVEN SENTENCE: During the 2005 German federal election campaign , Angela Merkel , leader of the Christian Democratic Union of Germany / Christian Social Union in Bavaria , announced that Kirchhof would serve as minister of finance if she formed a government .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["During","the","2005","German","federal","election","campaign",",","Angela","Merkel",",","leader","of","the","Christian","Democratic","Union","of","Germany","/","Christian","Social","Union","in","Bavaria",",","announced","that","Kirchhof","would","serve","as","minister","of","finance","if","she","formed","a","government","."],"labels":["O","O","B-election","I-election","I-election","I-election","O","O","B-politician","I-politician","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","B-politician","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["election","politician","political_party","country","event","organization","location","person"]}
{"id":"168.S","dataset":"crossner_politics","split":"dev","instance":{"id":"168.S","prompt_labels":"Being(O) a(O) political(O) club(O) with(O) the(O) intent(O) of(O) assuring(O) a(O) strong(O) left-wing(O) presence(O) in(O) a(O) party(O) and(O) to(O) influence(O) it(O) ,(O) its(O) nature(O) is(O) notably(O) reminiscent(O) of(O) the(O) New(B-political_party) Democratic(I-political_party) Party(I-political_party) '(O) s(O) New(B-political_party) Politics(I-political_party) Initiative(I-political_party) or(O) ,(O) to(O) a(O) lesser(O) extent(O) ,(O) of(O) the(O) New(B-organization) Democratic(I-organization) Party(I-organization) Socialist(I-organization) Caucus(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, politician, political_party, election, country, event, organization, location\nGIVEN SENTENCE: Being a political club with the intent of assuring a strong left-wing presence in a party and to influence it , its nature is notably reminiscent of the New Democratic Party ' s New Politics Initiative or , to a lesser extent , of the New Democratic Party Socialist Caucus .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["Being","a","political","club","with","the","intent","of","assuring","a","strong","left-wing","presence","in","a","party","and","to","influence","it",",","its","nature","is","notably","reminiscent","of","the","New","Democratic","Party","'","s","New","Politics","Initiative","or",",","to","a","lesser","extent",",","of","the","New","Democratic","Party","Socialist","Caucus","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["person","politician","political_party","election","country","event","organization","location"]}
{"id":"170.S","dataset":"crossner_politics","split":"dev","instance":{"id":"170.S","prompt_labels":"The(O) seat(O) was(O) retained(O) in(O) elections(O) in(O) 1990(B-election) Costa(I-election) Rican(I-election) general(I-election) election(I-election) and(O) 1994(B-election) Costa(I-election) Rican(I-election) general(I-election) election(I-election) ,(O) but(O) a(O) loss(O) of(O) support(O) in(O) the(O) 1998(B-election) Costa(I-election) Rican(I-election) general(I-election) election(I-election) saw(O) its(O) share(O) of(O) the(O) vote(O) drop(O) to(O) 0.5(O) %(O) ,(O) resulting(O) in(O) it(O) losing(O) its(O) solitary(O) seat(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, organization, politician, event, location, election, political_party\nGIVEN SENTENCE: The seat was retained in elections in 1990 Costa Rican general election and 1994 Costa Rican general election , but a loss of support in the 1998 Costa Rican general election saw its share of the vote drop to 0.5 % , resulting in it losing its solitary seat .\n","prediction_output":null,"prediction_outputs":null,"group":"170","words":["The","seat","was","retained","in","elections","in","1990","Costa","Rican","general","election","and","1994","Costa","Rican","general","election",",","but","a","loss","of","support","in","the","1998","Costa","Rican","general","election","saw","its","share","of","the","vote","drop","to","0.5","%",",","resulting","in","it","losing","its","solitary","seat","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","country","organization","politician","event","location","election","political_party"]}
{"id":"171.S","dataset":"crossner_politics","split":"dev","instance":{"id":"171.S","prompt_labels":"Conversely(O) ,(O) many(O) Indo-Fijian(O) supporters(O) of(O) the(O) National(B-political_party) Federation(I-political_party) Party(I-political_party) ((O) NFP(B-political_party) )(O) in(O) the(O) 2001(B-election) Fijian(I-election) general(I-election) election(I-election) may(O) not(O) have(O) been(O) aware(O) that(O) votes(O) for(O) NFP(B-political_party) candidates(O) ,(O) all(O) of(O) whom(O) lost(O) ,(O) were(O) to(O) be(O) transferred(O) to(O) the(O) indigenous-dominated(O) Soqosoqo(B-political_party) Duavata(I-political_party) ni(I-political_party) Lewenivanua(I-political_party) ((O) SDL(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, politician, country, organization, location, election, person, event\nGIVEN SENTENCE: Conversely , many Indo-Fijian supporters of the National Federation Party ( NFP ) in the 2001 Fijian general election may not have been aware that votes for NFP candidates , all of whom lost , were to be transferred to the indigenous-dominated Soqosoqo Duavata ni Lewenivanua ( SDL ) .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["Conversely",",","many","Indo-Fijian","supporters","of","the","National","Federation","Party","(","NFP",")","in","the","2001","Fijian","general","election","may","not","have","been","aware","that","votes","for","NFP","candidates",",","all","of","whom","lost",",","were","to","be","transferred","to","the","indigenous-dominated","Soqosoqo","Duavata","ni","Lewenivanua","(","SDL",")","."],"labels":["O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","politician","country","organization","location","election","person","event"]}
{"id":"173.S","dataset":"crossner_politics","split":"dev","instance":{"id":"173.S","prompt_labels":"Palestinian(O) groups(O) that(O) have(O) been(O) involved(O) in(O) politically(O) motivated(O) violence(O) include(O) the(O) Palestinian(B-organization) Liberation(I-organization) Organization(I-organization) ((O) PLO(B-organization) )(O) ,(O) Fatah(B-political_party) ,(O) the(O) Popular(B-political_party) Front(I-political_party) for(I-political_party) the(I-political_party) Liberation(I-political_party) of(I-political_party) Palestine(I-political_party) ((O) PFLP(B-political_party) )(O) ,(O) the(O) Popular(B-organization) Front(I-organization) for(I-organization) the(I-organization) Liberation(I-organization) of(I-organization) Palestine(I-organization) -(I-organization) General(I-organization) Command(I-organization) ((O) PFLP-GC(B-organization) )(O) ,(O) the(O) Democratic(B-political_party) Front(I-political_party) for(I-political_party) the(I-political_party) Liberation(I-political_party) of(I-political_party) Palestine(I-political_party) ,(O) the(O) Abu(B-organization) Nidal(I-organization) Organization(I-organization) ,(O) the(O) Palestinian(B-organization) Islamic(I-organization) Jihad(I-organization) ,(O) and(O) Hamas(B-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, person, election, politician, political_party, country, organization, event\nGIVEN SENTENCE: Palestinian groups that have been involved in politically motivated violence include the Palestinian Liberation Organization ( PLO ) , Fatah , the Popular Front for the Liberation of Palestine ( PFLP ) , the Popular Front for the Liberation of Palestine - General Command ( PFLP-GC ) , the Democratic Front for the Liberation of Palestine , the Abu Nidal Organization , the Palestinian Islamic Jihad , and Hamas .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["Palestinian","groups","that","have","been","involved","in","politically","motivated","violence","include","the","Palestinian","Liberation","Organization","(","PLO",")",",","Fatah",",","the","Popular","Front","for","the","Liberation","of","Palestine","(","PFLP",")",",","the","Popular","Front","for","the","Liberation","of","Palestine","-","General","Command","(","PFLP-GC",")",",","the","Democratic","Front","for","the","Liberation","of","Palestine",",","the","Abu","Nidal","Organization",",","the","Palestinian","Islamic","Jihad",",","and","Hamas","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","B-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","O"],"target_index":null,"target_label":null},"label_list":["location","person","election","politician","political_party","country","organization","event"]}
{"id":"174.S","dataset":"crossner_politics","split":"dev","instance":{"id":"174.S","prompt_labels":"The(O) body(O) thus(O) oversaw(O) the(O) activities(O) of(O) the(O) Bulgarian(B-political_party) Communist(I-political_party) Party(I-political_party) ((O) BKP(B-political_party) )(O) ,(O) the(O) League(B-political_party) of(I-political_party) Communists(I-political_party) of(I-political_party) Yugoslavia(I-political_party) ((O) KPJ(B-political_party) )(O) ,(O) the(O) Communist(B-political_party) Party(I-political_party) of(I-political_party) Greece(I-political_party) ((O) KKE(B-political_party) )(O) ,(O) the(O) Communist(B-political_party) Party(I-political_party) of(I-political_party) Turkey(I-political_party) ((O) TKP(B-political_party) )(O) ,(O) and(O) ,(O) to(O) a(O) certain(O) measure(O) ,(O) those(O) of(O) the(O) Romanian(B-political_party) Communist(I-political_party) Party(I-political_party) ((O) PCdR(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: election, country, event, person, location, politician, political_party, organization\nGIVEN SENTENCE: The body thus oversaw the activities of the Bulgarian Communist Party ( BKP ) , the League of Communists of Yugoslavia ( KPJ ) , the Communist Party of Greece ( KKE ) , the Communist Party of Turkey ( TKP ) , and , to a certain measure , those of the Romanian Communist Party ( PCdR ) .\n","prediction_output":null,"prediction_outputs":null,"group":"174","words":["The","body","thus","oversaw","the","activities","of","the","Bulgarian","Communist","Party","(","BKP",")",",","the","League","of","Communists","of","Yugoslavia","(","KPJ",")",",","the","Communist","Party","of","Greece","(","KKE",")",",","the","Communist","Party","of","Turkey","(","TKP",")",",","and",",","to","a","certain","measure",",","those","of","the","Romanian","Communist","Party","(","PCdR",")","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["election","country","event","person","location","politician","political_party","organization"]}
{"id":"175.S","dataset":"crossner_politics","split":"dev","instance":{"id":"175.S","prompt_labels":"Page(B-political_party) 's(I-political_party) party(I-political_party) affiliation(O) remained(O) with(O) different(O) facets(O) of(O) the(O) Democratic(B-political_party) Party(I-political_party) ,(O) and(O) moved(O) over(O) time(O) from(O) the(O) Democratic-Republican(B-political_party) Party(I-political_party) to(O) the(O) Jacksonian(O) democracy(O) to(O) the(O) Democrats(O) to(O) the(O) Free(B-political_party) Soil(I-political_party) Party(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, location, person, political_party, country, event, election, politician\nGIVEN SENTENCE: Page 's party affiliation remained with different facets of the Democratic Party , and moved over time from the Democratic-Republican Party to the Jacksonian democracy to the Democrats to the Free Soil Party .\n","prediction_output":null,"prediction_outputs":null,"group":"175","words":["Page","'s","party","affiliation","remained","with","different","facets","of","the","Democratic","Party",",","and","moved","over","time","from","the","Democratic-Republican","Party","to","the","Jacksonian","democracy","to","the","Democrats","to","the","Free","Soil","Party","."],"labels":["B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":null},"label_list":["organization","location","person","political_party","country","event","election","politician"]}
{"id":"176.S","dataset":"crossner_politics","split":"dev","instance":{"id":"176.S","prompt_labels":"Williams(B-politician) stood(O) unsuccessfully(O) for(O) Labour(B-political_party) in(O) Coventry(B-location) at(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) s(O) ,(O) but(O) was(O) elected(O) to(O) the(O) National(B-organization) Executive(I-organization) Committee(I-organization) of(O) the(O) party(O) ,(O) serving(O) as(O) its(O) chair(O) in(O) 1925(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, location, country, person, politician, organization, event, election\nGIVEN SENTENCE: Williams stood unsuccessfully for Labour in Coventry at the 1923 United Kingdom general election and 1924 United Kingdom general election s , but was elected to the National Executive Committee of the party , serving as its chair in 1925 .\n","prediction_output":null,"prediction_outputs":null,"group":"176","words":["Williams","stood","unsuccessfully","for","Labour","in","Coventry","at","the","1923","United","Kingdom","general","election","and","1924","United","Kingdom","general","election","s",",","but","was","elected","to","the","National","Executive","Committee","of","the","party",",","serving","as","its","chair","in","1925","."],"labels":["B-politician","O","O","O","B-political_party","O","B-location","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","location","country","person","politician","organization","event","election"]}
{"id":"178.S","dataset":"crossner_politics","split":"dev","instance":{"id":"178.S","prompt_labels":"A(O) cash(O) book(O) kept(O) by(O) Flick(B-organization) company(I-organization) accountant(O) Rudolph(B-person) Diehl(I-person) listed(O) that(O) next(O) to(O) other(O) transfers(O) ,(O) 250,000(O) Deutschemark(O) was(O) transferred(O) to(O) Christian(B-political_party) Social(I-political_party) Union(I-political_party) in(I-political_party) Bavaria(I-political_party) chairman(O) Franz(B-politician) Josef(I-politician) Strauss(I-politician) and(O) 565,000(O) Deutschemark(O) were(O) transferred(O) to(O) Christian(B-political_party) Democratic(I-political_party) Union(I-political_party) of(I-political_party) Germany(I-political_party) chairman(O) Helmut(B-politician) Kohl(I-politician) ,(O) as(O) well(O) as(O) payments(O) to(O) FDP(B-political_party) and(O) Social(B-political_party) Democratic(I-political_party) Party(I-political_party) of(I-political_party) Germany(I-political_party) politicians(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, organization, political_party, person, election, politician, location, event\nGIVEN SENTENCE: A cash book kept by Flick company accountant Rudolph Diehl listed that next to other transfers , 250,000 Deutschemark was transferred to Christian Social Union in Bavaria chairman Franz Josef Strauss and 565,000 Deutschemark were transferred to Christian Democratic Union of Germany chairman Helmut Kohl , as well as payments to FDP and Social Democratic Party of Germany politicians .\n","prediction_output":null,"prediction_outputs":null,"group":"178","words":["A","cash","book","kept","by","Flick","company","accountant","Rudolph","Diehl","listed","that","next","to","other","transfers",",","250,000","Deutschemark","was","transferred","to","Christian","Social","Union","in","Bavaria","chairman","Franz","Josef","Strauss","and","565,000","Deutschemark","were","transferred","to","Christian","Democratic","Union","of","Germany","chairman","Helmut","Kohl",",","as","well","as","payments","to","FDP","and","Social","Democratic","Party","of","Germany","politicians","."],"labels":["O","O","O","O","O","B-organization","I-organization","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-politician","I-politician","I-politician","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-politician","I-politician","O","O","O","O","O","O","B-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["country","organization","political_party","person","election","politician","location","event"]}
{"id":"179.S","dataset":"crossner_politics","split":"dev","instance":{"id":"179.S","prompt_labels":"Two(O) years(O) of(O) proceedings(O) clarified(O) that(O) between(O) 1969(O) and(O) 1989(O) ,(O) politicians(O) of(O) all(O) major(O) parties(O) ((O) Christian(B-political_party) Democratic(I-political_party) Union(I-political_party) of(I-political_party) Germany(I-political_party) ,(O) Christian(B-political_party) Social(I-political_party) Union(I-political_party) in(I-political_party) Bavaria(I-political_party) ,(O) FDP(B-political_party) ,(O) and(O) Social(B-political_party) Democratic(I-political_party) Party(I-political_party) of(I-political_party) Germany(I-political_party) )(O) had(O) received(O) money(O) from(O) the(O) Flick(B-organization) company(I-organization) :(O) a(O) total(O) of(O) 25(O) million(O) Deutschemark(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, election, country, person, organization, event, location, politician\nGIVEN SENTENCE: Two years of proceedings clarified that between 1969 and 1989 , politicians of all major parties ( Christian Democratic Union of Germany , Christian Social Union in Bavaria , FDP , and Social Democratic Party of Germany ) had received money from the Flick company : a total of 25 million Deutschemark .\n","prediction_output":null,"prediction_outputs":null,"group":"179","words":["Two","years","of","proceedings","clarified","that","between","1969","and","1989",",","politicians","of","all","major","parties","(","Christian","Democratic","Union","of","Germany",",","Christian","Social","Union","in","Bavaria",",","FDP",",","and","Social","Democratic","Party","of","Germany",")","had","received","money","from","the","Flick","company",":","a","total","of","25","million","Deutschemark","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","election","country","person","organization","event","location","politician"]}
{"id":"182.S","dataset":"crossner_politics","split":"dev","instance":{"id":"182.S","prompt_labels":"President(O) John(B-politician) Adams(I-politician) ,(O) a(O) Federalist(B-political_party) Party(I-political_party) elected(O) two(O) years(O) prior(O) in(O) the(O) 1796(B-election) United(I-election) States(I-election) presidential(I-election) election(I-election) ,(O) remained(O) popular(O) during(O) a(O) time(O) of(O) national(O) economic(O) growth(O) ,(O) and(O) the(O) Federalists(O) made(O) a(O) modest(O) gain(O) of(O) three(O) seats(O) at(O) the(O) expense(O) of(O) the(O) opposition(O) Democratic-Republican(B-political_party) Party(I-political_party) ,(O) the(O) party(O) of(O) Vice(O) President(O) and(O) future(O) President(O) Thomas(B-politician) Jefferson(I-politician) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, country, political_party, organization, election, person, event, location\nGIVEN SENTENCE: President John Adams , a Federalist Party elected two years prior in the 1796 United States presidential election , remained popular during a time of national economic growth , and the Federalists made a modest gain of three seats at the expense of the opposition Democratic-Republican Party , the party of Vice President and future President Thomas Jefferson .\n","prediction_output":null,"prediction_outputs":null,"group":"182","words":["President","John","Adams",",","a","Federalist","Party","elected","two","years","prior","in","the","1796","United","States","presidential","election",",","remained","popular","during","a","time","of","national","economic","growth",",","and","the","Federalists","made","a","modest","gain","of","three","seats","at","the","expense","of","the","opposition","Democratic-Republican","Party",",","the","party","of","Vice","President","and","future","President","Thomas","Jefferson","."],"labels":["O","B-politician","I-politician","O","O","B-political_party","I-political_party","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","B-politician","I-politician","O"],"target_index":null,"target_label":null},"label_list":["politician","country","political_party","organization","election","person","event","location"]}
{"id":"183.S","dataset":"crossner_politics","split":"dev","instance":{"id":"183.S","prompt_labels":"She(O) was(O) the(O) lead(O) Senate(O) candidate(O) at(O) the(O) 2007(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) again(O) at(O) the(O) 2010(B-election) Australian(I-election) federal(I-election) election(I-election) ,(O) in(O) which(O) she(O) became(O) the(O) first(O) Greens(B-political_party) candidate(O) elected(O) in(O) Queensland(B-location) ,(O) and(O) the(O) 2019(B-election) Australian(I-election) federal(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, election, political_party, event, politician, organization, person, location\nGIVEN SENTENCE: She was the lead Senate candidate at the 2007 Australian federal election , again at the 2010 Australian federal election , in which she became the first Greens candidate elected in Queensland , and the 2019 Australian federal election .\n","prediction_output":null,"prediction_outputs":null,"group":"183","words":["She","was","the","lead","Senate","candidate","at","the","2007","Australian","federal","election",",","again","at","the","2010","Australian","federal","election",",","in","which","she","became","the","first","Greens","candidate","elected","in","Queensland",",","and","the","2019","Australian","federal","election","."],"labels":["O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","B-political_party","O","O","O","B-location","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["country","election","political_party","event","politician","organization","person","location"]}
{"id":"186.S","dataset":"crossner_politics","split":"dev","instance":{"id":"186.S","prompt_labels":"A(O) significant(O) number(O) of(O) Straight(B-organization) Left(I-organization) faction(O) members(O) had(O) developed(O) close(O) personal(O) friendships(O) with(O) members(O) of(O) fraternal(O) communist(O) parties(O) ,(O) particularly(O) the(O) Tudeh(B-political_party) Party(I-political_party) of(I-political_party) Iran(I-political_party) ,(O) Iraqi(B-political_party) Communist(I-political_party) Party(I-political_party) ,(O) South(O) African(O) and(O) Communist(B-political_party) Party(I-political_party) of(I-political_party) Greece(I-political_party) parties(O) ,(O) who(O) were(O) well(O) organised(O) on(O) most(O) British(O) University(O) campuses(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, organization, event, country, person, election, politician, location\nGIVEN SENTENCE: A significant number of Straight Left faction members had developed close personal friendships with members of fraternal communist parties , particularly the Tudeh Party of Iran , Iraqi Communist Party , South African and Communist Party of Greece parties , who were well organised on most British University campuses .\n","prediction_output":null,"prediction_outputs":null,"group":"186","words":["A","significant","number","of","Straight","Left","faction","members","had","developed","close","personal","friendships","with","members","of","fraternal","communist","parties",",","particularly","the","Tudeh","Party","of","Iran",",","Iraqi","Communist","Party",",","South","African","and","Communist","Party","of","Greece","parties",",","who","were","well","organised","on","most","British","University","campuses","."],"labels":["O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["political_party","organization","event","country","person","election","politician","location"]}
{"id":"188.S","dataset":"crossner_politics","split":"dev","instance":{"id":"188.S","prompt_labels":"He(O) was(O) voted(O) into(O) Parliament(O) with(O) the(O) Liberal(B-political_party) Democratic(I-political_party) Union(I-political_party) ,(O) in(O) the(O) 1956(B-election) Greek(I-election) legislative(I-election) election(I-election) s(O) ,(O) but(O) in(O) the(O) 1958(B-election) Greek(I-election) legislative(I-election) election(I-election) s(O) ,(O) as(O) head(O) of(O) the(O) Union(B-political_party) of(I-political_party) Populars(I-political_party) ,(O) he(O) failed(O) to(O) be(O) elected(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, country, event, location, person, politician, election, political_party\nGIVEN SENTENCE: He was voted into Parliament with the Liberal Democratic Union , in the 1956 Greek legislative election s , but in the 1958 Greek legislative election s , as head of the Union of Populars , he failed to be elected .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["He","was","voted","into","Parliament","with","the","Liberal","Democratic","Union",",","in","the","1956","Greek","legislative","election","s",",","but","in","the","1958","Greek","legislative","election","s",",","as","head","of","the","Union","of","Populars",",","he","failed","to","be","elected","."],"labels":["O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","country","event","location","person","politician","election","political_party"]}
{"id":"189.S","dataset":"crossner_politics","split":"dev","instance":{"id":"189.S","prompt_labels":"Other(O) groups(O) supporting(O) their(O) repeal(O) include(O) the(O) National(B-organization) Conference(I-organization) of(I-organization) Insurance(I-organization) Legislators(I-organization) ,(O) the(O) American(B-organization) Bar(I-organization) Association(I-organization) ,(O) the(O) American(B-organization) College(I-organization) of(I-organization) Emergency(I-organization) Physicians(I-organization) ,(O) Mothers(B-organization) Against(I-organization) Drunk(I-organization) Driving(I-organization) ,(O) the(O) National(B-organization) Commission(I-organization) Against(I-organization) Drunk(I-organization) Driving(I-organization) ,(O) and(O) the(O) American(B-organization) Medical(I-organization) Association(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, event, election, politician, organization, political_party, location, person\nGIVEN SENTENCE: Other groups supporting their repeal include the National Conference of Insurance Legislators , the American Bar Association , the American College of Emergency Physicians , Mothers Against Drunk Driving , the National Commission Against Drunk Driving , and the American Medical Association .\n","prediction_output":null,"prediction_outputs":null,"group":"189","words":["Other","groups","supporting","their","repeal","include","the","National","Conference","of","Insurance","Legislators",",","the","American","Bar","Association",",","the","American","College","of","Emergency","Physicians",",","Mothers","Against","Drunk","Driving",",","the","National","Commission","Against","Drunk","Driving",",","and","the","American","Medical","Association","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["country","event","election","politician","organization","political_party","location","person"]}
{"id":"190.S","dataset":"crossner_politics","split":"dev","instance":{"id":"190.S","prompt_labels":"Grande(B-person) was(O) elected(O) to(O) the(O) Ontario(B-organization) legislature(I-organization) in(O) the(O) 1975(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) and(O) re-elected(O) in(O) 1977(B-election) Ontario(I-election) general(I-election) election(I-election) ,(O) 1981(B-election) Ontario(I-election) general(I-election) election(I-election) and(O) 1985(B-election) Ontario(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: political_party, politician, election, organization, country, event, location, person\nGIVEN SENTENCE: Grande was elected to the Ontario legislature in the 1975 Ontario general election , and re-elected in 1977 Ontario general election , 1981 Ontario general election and 1985 Ontario general election .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Grande","was","elected","to","the","Ontario","legislature","in","the","1975","Ontario","general","election",",","and","re-elected","in","1977","Ontario","general","election",",","1981","Ontario","general","election","and","1985","Ontario","general","election","."],"labels":["B-person","O","O","O","O","B-organization","I-organization","O","O","B-election","I-election","I-election","I-election","O","O","O","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["political_party","politician","election","organization","country","event","location","person"]}
{"id":"195.S","dataset":"crossner_politics","split":"dev","instance":{"id":"195.S","prompt_labels":"In(O) Belgian(O) politics(O) ,(O) the(O) term(O) Jamaica(B-country) coalition(O) refers(O) to(O) a(O) coalition(O) of(O) Christian(O) democrats(O) ((O) Christen-Democratisch(B-political_party) en(I-political_party) Vlaams(I-political_party) and(O) Centre(B-political_party) démocrate(I-political_party) humaniste(I-political_party) )(O) ,(O) liberals(O) ((O) Open(B-political_party) Vlaamse(I-political_party) Liberalen(I-political_party) en(I-political_party) Democraten(I-political_party) and(O) Mouvement(B-political_party) Réformateur(I-political_party) )(O) and(O) greens(O) ((O) Groen(B-political_party) and(O) Ecolo(B-political_party) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, political_party, event, location, country, organization, election, person\nGIVEN SENTENCE: In Belgian politics , the term Jamaica coalition refers to a coalition of Christian democrats ( Christen-Democratisch en Vlaams and Centre démocrate humaniste ) , liberals ( Open Vlaamse Liberalen en Democraten and Mouvement Réformateur ) and greens ( Groen and Ecolo ) .\n","prediction_output":null,"prediction_outputs":null,"group":"195","words":["In","Belgian","politics",",","the","term","Jamaica","coalition","refers","to","a","coalition","of","Christian","democrats","(","Christen-Democratisch","en","Vlaams","and","Centre","démocrate","humaniste",")",",","liberals","(","Open","Vlaamse","Liberalen","en","Democraten","and","Mouvement","Réformateur",")","and","greens","(","Groen","and","Ecolo",")","."],"labels":["O","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","O","B-political_party","O","O"],"target_index":null,"target_label":null},"label_list":["politician","political_party","event","location","country","organization","election","person"]}
{"id":"196.S","dataset":"crossner_politics","split":"dev","instance":{"id":"196.S","prompt_labels":"The(O) same(O) boundaries(O) were(O) used(O) in(O) the(O) 1922(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1923(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1924(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1929(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1931(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1935(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) 1945(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, election, location, politician, event, country, organization, political_party\nGIVEN SENTENCE: The same boundaries were used in the 1922 United Kingdom general election , the 1923 United Kingdom general election , the 1924 United Kingdom general election , the 1929 United Kingdom general election , the 1931 United Kingdom general election , the 1935 United Kingdom general election and the 1945 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"196","words":["The","same","boundaries","were","used","in","the","1922","United","Kingdom","general","election",",","the","1923","United","Kingdom","general","election",",","the","1924","United","Kingdom","general","election",",","the","1929","United","Kingdom","general","election",",","the","1931","United","Kingdom","general","election",",","the","1935","United","Kingdom","general","election","and","the","1945","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["person","election","location","politician","event","country","organization","political_party"]}
{"id":"197.S","dataset":"crossner_politics","split":"dev","instance":{"id":"197.S","prompt_labels":"1885(O) boundaries(O) were(O) also(O) used(O) in(O) the(O) 1886(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1892(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1895(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1900(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1906(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) January(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) December(B-election) 1910(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: politician, location, organization, person, country, event, election, political_party\nGIVEN SENTENCE: 1885 boundaries were also used in the 1886 United Kingdom general election , the 1892 United Kingdom general election , the 1895 United Kingdom general election , the 1900 United Kingdom general election , the 1906 United Kingdom general election , the January 1910 United Kingdom general election and the December 1910 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["1885","boundaries","were","also","used","in","the","1886","United","Kingdom","general","election",",","the","1892","United","Kingdom","general","election",",","the","1895","United","Kingdom","general","election",",","the","1900","United","Kingdom","general","election",",","the","1906","United","Kingdom","general","election",",","the","January","1910","United","Kingdom","general","election","and","the","December","1910","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["politician","location","organization","person","country","event","election","political_party"]}
{"id":"198.S","dataset":"crossner_politics","split":"dev","instance":{"id":"198.S","prompt_labels":"East(B-location) Aberdeenshire(I-location) retained(O) the(O) same(O) boundaries(O) for(O) the(O) 1959(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1964(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1966(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) 1970(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) the(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) the(O) October(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, election, political_party, event, location, person, country, politician\nGIVEN SENTENCE: East Aberdeenshire retained the same boundaries for the 1959 United Kingdom general election , the 1964 United Kingdom general election , the 1966 United Kingdom general election , the 1970 United Kingdom general election , the February 1974 United Kingdom general election and the October 1974 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["East","Aberdeenshire","retained","the","same","boundaries","for","the","1959","United","Kingdom","general","election",",","the","1964","United","Kingdom","general","election",",","the","1966","United","Kingdom","general","election",",","the","1970","United","Kingdom","general","election",",","the","February","1974","United","Kingdom","general","election","and","the","October","1974","United","Kingdom","general","election","."],"labels":["B-location","I-location","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O","O","B-election","I-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":null},"label_list":["organization","election","political_party","event","location","person","country","politician"]}
{"id":"2.S","dataset":"crossner_science","split":"dev","instance":{"id":"2.S","prompt_labels":"Labeled(O) genomic(O) DNA(O) is(O) extracted(O) from(O) nuclei(O) and(O) fragmented(O) by(O) HaeIII(O) digestion(O) and(O) sonication(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: astronomical_object, discipline, scientist, event, protein, chemical_element, university, chemical_compound, country, location, person, award, organization, enzyme, theory, academic_journal\nGIVEN SENTENCE: Labeled genomic DNA is extracted from nuclei and fragmented by HaeIII digestion and sonication .\n","prediction_output":null,"prediction_outputs":null,"group":"2","words":["Labeled","genomic","DNA","is","extracted","from","nuclei","and","fragmented","by","HaeIII","digestion","and","sonication","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["astronomical_object","discipline","scientist","event","protein","chemical_element","university","chemical_compound","country","location","person","award","organization","enzyme","theory","academic_journal"]}
{"id":"3.S","dataset":"crossner_science","split":"dev","instance":{"id":"3.S","prompt_labels":"He(O) attended(O) the(O) U.S.(B-university) Air(I-university) Force(I-university) Institute(I-university) of(I-university) Technology(I-university) for(O) a(O) year(O) ,(O) earning(O) a(O) bachelor(O) 's(O) degree(O) in(O) aeromechanics(B-discipline) ,(O) and(O) received(O) his(O) test(O) pilot(O) training(O) at(O) Edwards(B-organization) Air(I-organization) Force(I-organization) Base(I-organization) in(O) California(B-location) before(O) his(O) assignment(O) as(O) a(O) test(O) pilot(O) at(O) Wright-Patterson(B-organization) Air(I-organization) Force(I-organization) Base(I-organization) in(O) Ohio(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, award, protein, scientist, theory, organization, astronomical_object, academic_journal, event, person, university, chemical_element, discipline, enzyme, country, location\nGIVEN SENTENCE: He attended the U.S. Air Force Institute of Technology for a year , earning a bachelor 's degree in aeromechanics , and received his test pilot training at Edwards Air Force Base in California before his assignment as a test pilot at Wright-Patterson Air Force Base in Ohio .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["He","attended","the","U.S.","Air","Force","Institute","of","Technology","for","a","year",",","earning","a","bachelor","'s","degree","in","aeromechanics",",","and","received","his","test","pilot","training","at","Edwards","Air","Force","Base","in","California","before","his","assignment","as","a","test","pilot","at","Wright-Patterson","Air","Force","Base","in","Ohio","."],"labels":["O","O","O","B-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","B-discipline","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-location","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","award","protein","scientist","theory","organization","astronomical_object","academic_journal","event","person","university","chemical_element","discipline","enzyme","country","location"]}
{"id":"7.S","dataset":"crossner_science","split":"dev","instance":{"id":"7.S","prompt_labels":"The(O) Olympic(B-location) golf(I-location) course(I-location) is(O) a(O) new(O) venue(O) built(O) for(O) the(O) Golf(O) at(O) the(O) 2016(B-event) Summer(I-event) Olympics(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, award, country, protein, enzyme, person, scientist, chemical_element, university, organization, academic_journal, theory, event, location, astronomical_object, discipline\nGIVEN SENTENCE: The Olympic golf course is a new venue built for the Golf at the 2016 Summer Olympics .\n","prediction_output":null,"prediction_outputs":null,"group":"7","words":["The","Olympic","golf","course","is","a","new","venue","built","for","the","Golf","at","the","2016","Summer","Olympics","."],"labels":["O","B-location","I-location","I-location","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","award","country","protein","enzyme","person","scientist","chemical_element","university","organization","academic_journal","theory","event","location","astronomical_object","discipline"]}
{"id":"8.S","dataset":"crossner_science","split":"dev","instance":{"id":"8.S","prompt_labels":"Removing(O) a(O) TAD(O) boundary(O) ((O) for(O) example(O) ,(O) using(O) CRISPR(O) to(O) delete(O) the(O) relevant(O) region(O) of(O) the(O) genome(O) )(O) can(O) allow(O) new(O) promoter-enhancer(O) contacts(O) to(O) form(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: enzyme, theory, chemical_compound, country, organization, chemical_element, protein, person, event, award, astronomical_object, scientist, university, location, academic_journal, discipline\nGIVEN SENTENCE: Removing a TAD boundary ( for example , using CRISPR to delete the relevant region of the genome ) can allow new promoter-enhancer contacts to form .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["Removing","a","TAD","boundary","(","for","example",",","using","CRISPR","to","delete","the","relevant","region","of","the","genome",")","can","allow","new","promoter-enhancer","contacts","to","form","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["enzyme","theory","chemical_compound","country","organization","chemical_element","protein","person","event","award","astronomical_object","scientist","university","location","academic_journal","discipline"]}
{"id":"10.S","dataset":"crossner_science","split":"dev","instance":{"id":"10.S","prompt_labels":"He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university) ,(O) is(O) the(O) Latin(O) American(O) co-chair(O) of(O) the(O) Inter-American(B-organization) Dialogue(I-organization) ,(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, protein, award, location, organization, scientist, astronomical_object, country, discipline, chemical_element, academic_journal, chemical_compound, enzyme, theory, person, university\nGIVEN SENTENCE: He is currently Director of the Yale Center for the Study of Globalization at Yale University , is the Latin American co-chair of the Inter-American Dialogue , and is on the board of directors of Citigroup .\n","prediction_output":null,"prediction_outputs":null,"group":"10","words":["He","is","currently","Director","of","the","Yale","Center","for","the","Study","of","Globalization","at","Yale","University",",","is","the","Latin","American","co-chair","of","the","Inter-American","Dialogue",",","and","is","on","the","board","of","directors","of","Citigroup","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-university","I-university","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","B-organization","O"],"target_index":null,"target_label":null},"label_list":["event","protein","award","location","organization","scientist","astronomical_object","country","discipline","chemical_element","academic_journal","chemical_compound","enzyme","theory","person","university"]}
{"id":"11.S","dataset":"crossner_science","split":"dev","instance":{"id":"11.S","prompt_labels":"Saturn(B-astronomical_object) is(O) usually(O) depicted(O) with(O) a(O) scythe(O) or(O) sickle(O) ,(O) and(O) the(O) planetary(O) symbol(O) has(O) apparently(O) evolved(O) from(O) a(O) picture(O) of(O) this(O) attribute(O) ,(O) in(O) Kamateros(O) ((O) 12th(O) century(O) )(O) shown(O) in(O) a(O) shape(O) similar(O) to(O) the(O) letter(O) eta(O) η(O) ,(O) with(O) the(O) horizontal(O) stroke(O) added(O) along(O) with(O) the(O) Christianization(O) of(O) the(O) other(O) symbols(O) in(O) the(O) early(O) 16th(O) century(O) ,(O) Saturn(B-astronomical_object) ((O) U(O) +(O) 2644(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, theory, academic_journal, chemical_compound, scientist, enzyme, location, organization, country, chemical_element, protein, event, astronomical_object, person, discipline, university\nGIVEN SENTENCE: Saturn is usually depicted with a scythe or sickle , and the planetary symbol has apparently evolved from a picture of this attribute , in Kamateros ( 12th century ) shown in a shape similar to the letter eta η , with the horizontal stroke added along with the Christianization of the other symbols in the early 16th century , Saturn ( U + 2644 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"11","words":["Saturn","is","usually","depicted","with","a","scythe","or","sickle",",","and","the","planetary","symbol","has","apparently","evolved","from","a","picture","of","this","attribute",",","in","Kamateros","(","12th","century",")","shown","in","a","shape","similar","to","the","letter","eta","η",",","with","the","horizontal","stroke","added","along","with","the","Christianization","of","the","other","symbols","in","the","early","16th","century",",","Saturn","(","U","+","2644",")","."],"labels":["B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","theory","academic_journal","chemical_compound","scientist","enzyme","location","organization","country","chemical_element","protein","event","astronomical_object","person","discipline","university"]}
{"id":"13.S","dataset":"crossner_science","split":"dev","instance":{"id":"13.S","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic_journal) Journal(I-academic_journal) of(I-academic_journal) Physics(I-academic_journal) ,(O) European(B-academic_journal) Journal(I-academic_journal) of(I-academic_journal) Physics(I-academic_journal) ,(O) Journal(B-academic_journal) of(I-academic_journal) Chemical(I-academic_journal) Education(I-academic_journal) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, enzyme, scientist, university, chemical_compound, award, chemical_element, astronomical_object, theory, location, protein, discipline, event, academic_journal, person, organization\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":null},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"14.S","dataset":"crossner_science","split":"dev","instance":{"id":"14.S","prompt_labels":"Most(O) of(O) the(O) outer(O) irregular(O) moon(O) s(O) of(O) Jupiter(B-astronomical_object) and(O) Saturn(B-astronomical_object) also(O) have(O) retrograde(O) orbits(O) ,(O) as(O) do(O) some(O) of(O) Uranus(B-astronomical_object) '(O) s(O) outer(O) moons(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, country, event, chemical_compound, theory, astronomical_object, university, scientist, person, organization, academic_journal, discipline, chemical_element, award, enzyme, protein\nGIVEN SENTENCE: Most of the outer irregular moon s of Jupiter and Saturn also have retrograde orbits , as do some of Uranus ' s outer moons .\n","prediction_output":null,"prediction_outputs":null,"group":"14","words":["Most","of","the","outer","irregular","moon","s","of","Jupiter","and","Saturn","also","have","retrograde","orbits",",","as","do","some","of","Uranus","'","s","outer","moons","."],"labels":["O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","country","event","chemical_compound","theory","astronomical_object","university","scientist","person","organization","academic_journal","discipline","chemical_element","award","enzyme","protein"]}
{"id":"15.S","dataset":"crossner_science","split":"dev","instance":{"id":"15.S","prompt_labels":"For(O) example(O) ,(O) that(O) ancestor(O) had(O) at(O) least(O) 7(O) Pax(O) genes(O) for(O) transcription(O) factor(O) s(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, event, location, chemical_element, academic_journal, theory, chemical_compound, astronomical_object, university, enzyme, person, country, scientist, organization, protein, discipline\nGIVEN SENTENCE: For example , that ancestor had at least 7 Pax genes for transcription factor s .\n","prediction_output":null,"prediction_outputs":null,"group":"15","words":["For","example",",","that","ancestor","had","at","least","7","Pax","genes","for","transcription","factor","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","event","location","chemical_element","academic_journal","theory","chemical_compound","astronomical_object","university","enzyme","person","country","scientist","organization","protein","discipline"]}
{"id":"16.S","dataset":"crossner_science","split":"dev","instance":{"id":"16.S","prompt_labels":"In(O) most(O) cases(O) ,(O) planets(O) named(O) with(O) Bayer(O) ,(O) Flamsteed(O) ,(O) and(O) or(O) Variable(O) star(O) designation(O) have(O) a(O) space(O) ,(O) but(O) usage(O) with(O) other(O) designations(O) varies(O) e.g.(O) WASP-12b(B-astronomical_object) but(O) HD(B-astronomical_object) 209458(I-astronomical_object) b(I-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: astronomical_object, award, university, person, chemical_compound, protein, scientist, enzyme, discipline, theory, academic_journal, location, organization, country, chemical_element, event\nGIVEN SENTENCE: In most cases , planets named with Bayer , Flamsteed , and or Variable star designation have a space , but usage with other designations varies e.g. WASP-12b but HD 209458 b .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["In","most","cases",",","planets","named","with","Bayer",",","Flamsteed",",","and","or","Variable","star","designation","have","a","space",",","but","usage","with","other","designations","varies","e.g.","WASP-12b","but","HD","209458","b","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","I-astronomical_object","I-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["astronomical_object","award","university","person","chemical_compound","protein","scientist","enzyme","discipline","theory","academic_journal","location","organization","country","chemical_element","event"]}
{"id":"17.S","dataset":"crossner_science","split":"dev","instance":{"id":"17.S","prompt_labels":"Schirra(B-person) was(O) a(O) 33rd(O) Degree(O) Mason(O) and(O) part(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization) ,(O) as(O) well(O) as(O) a(O) fellow(B-award) of(I-award) the(I-award) American(I-award) Astronautical(I-award) Society(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, country, award, chemical_element, event, organization, enzyme, astronomical_object, chemical_compound, academic_journal, location, university, discipline, scientist, person, protein\nGIVEN SENTENCE: Schirra was a 33rd Degree Mason and part of the American Institute of Aeronautics and Astronautics , as well as a fellow of the American Astronautical Society .\n","prediction_output":null,"prediction_outputs":null,"group":"17","words":["Schirra","was","a","33rd","Degree","Mason","and","part","of","the","American","Institute","of","Aeronautics","and","Astronautics",",","as","well","as","a","fellow","of","the","American","Astronautical","Society","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["theory","country","award","chemical_element","event","organization","enzyme","astronomical_object","chemical_compound","academic_journal","location","university","discipline","scientist","person","protein"]}
{"id":"20.S","dataset":"crossner_science","split":"dev","instance":{"id":"20.S","prompt_labels":"Generally(O) ,(O) Potassium(B-chemical_compound) cyanide(I-chemical_compound) or(O) its(O) less(O) toxic(O) surrogate(O) Zinc(B-chemical_compound) cyanide(I-chemical_compound) are(O) used(O) as(O) nucleophilic(B-chemical_compound) cyanide(I-chemical_compound) sources(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: scientist, academic_journal, chemical_element, location, enzyme, protein, organization, theory, astronomical_object, award, event, discipline, person, country, university, chemical_compound\nGIVEN SENTENCE: Generally , Potassium cyanide or its less toxic surrogate Zinc cyanide are used as nucleophilic cyanide sources .\n","prediction_output":null,"prediction_outputs":null,"group":"20","words":["Generally",",","Potassium","cyanide","or","its","less","toxic","surrogate","Zinc","cyanide","are","used","as","nucleophilic","cyanide","sources","."],"labels":["O","O","B-chemical_compound","I-chemical_compound","O","O","O","O","O","B-chemical_compound","I-chemical_compound","O","O","O","B-chemical_compound","I-chemical_compound","O","O"],"target_index":null,"target_label":null},"label_list":["scientist","academic_journal","chemical_element","location","enzyme","protein","organization","theory","astronomical_object","award","event","discipline","person","country","university","chemical_compound"]}
{"id":"27.S","dataset":"crossner_science","split":"dev","instance":{"id":"27.S","prompt_labels":"He(O) is(O) known(O) for(O) his(O) studies(O) on(O) DNA(O) and(O) RNA(B-enzyme) polymerase(I-enzyme) s(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, academic_journal, country, scientist, event, theory, astronomical_object, enzyme, organization, person, chemical_element, award, chemical_compound, protein, university, discipline\nGIVEN SENTENCE: He is known for his studies on DNA and RNA polymerase s .\n","prediction_output":null,"prediction_outputs":null,"group":"27","words":["He","is","known","for","his","studies","on","DNA","and","RNA","polymerase","s","."],"labels":["O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O","O"],"target_index":null,"target_label":null},"label_list":["location","academic_journal","country","scientist","event","theory","astronomical_object","enzyme","organization","person","chemical_element","award","chemical_compound","protein","university","discipline"]}
{"id":"28.S","dataset":"crossner_science","split":"dev","instance":{"id":"28.S","prompt_labels":"He(O) has(O) served(O) on(O) scientific(O) journal(O) editorial(O) boards(O) including(O) American(B-academic_journal) Scientist(I-academic_journal) ,(O) Physics(B-academic_journal) of(I-academic_journal) Fluids(I-academic_journal) ,(O) Journal(B-academic_journal) of(I-academic_journal) Fluid(I-academic_journal) Mechanics(I-academic_journal) ,(O) Physical(B-academic_journal) Review(I-academic_journal) E(I-academic_journal) ,(O) Physical(B-academic_journal) Review(I-academic_journal) Letters(I-academic_journal) ,(O) Journal(B-academic_journal) of(I-academic_journal) Theoretical(I-academic_journal) and(I-academic_journal) Computational(I-academic_journal) Fluid(I-academic_journal) Dynamics(I-academic_journal) ,(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_element, organization, academic_journal, person, theory, event, country, chemical_compound, astronomical_object, award, scientist, location, protein, discipline, enzyme, university\nGIVEN SENTENCE: He has served on scientific journal editorial boards including American Scientist , Physics of Fluids , Journal of Fluid Mechanics , Physical Review E , Physical Review Letters , Journal of Theoretical and Computational Fluid Dynamics ,\n","prediction_output":null,"prediction_outputs":null,"group":"28","words":["He","has","served","on","scientific","journal","editorial","boards","including","American","Scientist",",","Physics","of","Fluids",",","Journal","of","Fluid","Mechanics",",","Physical","Review","E",",","Physical","Review","Letters",",","Journal","of","Theoretical","and","Computational","Fluid","Dynamics",","],"labels":["O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O"],"target_index":null,"target_label":null},"label_list":["chemical_element","organization","academic_journal","person","theory","event","country","chemical_compound","astronomical_object","award","scientist","location","protein","discipline","enzyme","university"]}
{"id":"29.S","dataset":"crossner_science","split":"dev","instance":{"id":"29.S","prompt_labels":"This(O) led(O) to(O) a(O) vigorous(O) debate(O) between(O) the(O) biometricians(O) ,(O) who(O) supported(O) Galton(B-scientist) 's(O) ideas(O) ,(O) as(O) Walter(B-scientist) Weldon(I-scientist) ,(O) Arthur(B-scientist) Dukinfield(I-scientist) Darbishire(I-scientist) and(O) Karl(B-scientist) Pearson(I-scientist) ,(O) and(O) Mendelians(O) ,(O) who(O) supported(O) Bateson(B-scientist) 's(O) ((O) and(O) Mendel(B-scientist) 's(O) )(O) ideas(O) ,(O) such(O) as(O) Charles(B-scientist) Davenport(I-scientist) and(O) Wilhelm(B-scientist) Johannsen(I-scientist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: astronomical_object, scientist, discipline, chemical_compound, location, person, event, country, theory, award, organization, protein, academic_journal, university, chemical_element, enzyme\nGIVEN SENTENCE: This led to a vigorous debate between the biometricians , who supported Galton 's ideas , as Walter Weldon , Arthur Dukinfield Darbishire and Karl Pearson , and Mendelians , who supported Bateson 's ( and Mendel 's ) ideas , such as Charles Davenport and Wilhelm Johannsen .\n","prediction_output":null,"prediction_outputs":null,"group":"29","words":["This","led","to","a","vigorous","debate","between","the","biometricians",",","who","supported","Galton","'s","ideas",",","as","Walter","Weldon",",","Arthur","Dukinfield","Darbishire","and","Karl","Pearson",",","and","Mendelians",",","who","supported","Bateson","'s","(","and","Mendel","'s",")","ideas",",","such","as","Charles","Davenport","and","Wilhelm","Johannsen","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","O","B-scientist","O","O","O","B-scientist","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"target_index":null,"target_label":null},"label_list":["astronomical_object","scientist","discipline","chemical_compound","location","person","event","country","theory","award","organization","protein","academic_journal","university","chemical_element","enzyme"]}
{"id":"31.S","dataset":"crossner_science","split":"dev","instance":{"id":"31.S","prompt_labels":"Usually(O) ,(O) in(O) the(O) presence(O) of(O) NADPH(B-enzyme) dehydrogenase(I-enzyme) or(O) NADH(B-enzyme) dehydrogenase(I-enzyme) as(O) the(O) enzyme(O) ,(O) NADPH(B-chemical_compound) or(O) NADH(B-chemical_compound) is(O) the(O) reductant(O) that(O) converts(O) resazurin(O) to(O) resorufin(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_element, astronomical_object, theory, event, university, location, academic_journal, enzyme, chemical_compound, scientist, country, person, award, protein, discipline, organization\nGIVEN SENTENCE: Usually , in the presence of NADPH dehydrogenase or NADH dehydrogenase as the enzyme , NADPH or NADH is the reductant that converts resazurin to resorufin .\n","prediction_output":null,"prediction_outputs":null,"group":"31","words":["Usually",",","in","the","presence","of","NADPH","dehydrogenase","or","NADH","dehydrogenase","as","the","enzyme",",","NADPH","or","NADH","is","the","reductant","that","converts","resazurin","to","resorufin","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O","B-enzyme","I-enzyme","O","O","O","O","B-chemical_compound","O","B-chemical_compound","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["chemical_element","astronomical_object","theory","event","university","location","academic_journal","enzyme","chemical_compound","scientist","country","person","award","protein","discipline","organization"]}
{"id":"35.S","dataset":"crossner_science","split":"dev","instance":{"id":"35.S","prompt_labels":"The(O) album(O) was(O) nominated(O) at(O) the(O) 41st(B-award) Annual(I-award) Grammy(I-award) Awards(I-award) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Rap(I-award) Album(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: university, scientist, theory, chemical_element, chemical_compound, event, academic_journal, astronomical_object, location, award, country, enzyme, discipline, person, organization, protein\nGIVEN SENTENCE: The album was nominated at the 41st Annual Grammy Awards for Grammy Award for Best Rap Album .\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["The","album","was","nominated","at","the","41st","Annual","Grammy","Awards","for","Grammy","Award","for","Best","Rap","Album","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["university","scientist","theory","chemical_element","chemical_compound","event","academic_journal","astronomical_object","location","award","country","enzyme","discipline","person","organization","protein"]}
{"id":"39.S","dataset":"crossner_science","split":"dev","instance":{"id":"39.S","prompt_labels":"The(O) team(O) that(O) she(O) manages(O) has(O) specially(O) studied(O) the(O) role(O) of(O) Proinsulin(B-protein) /(O) insulin(B-protein) in(O) the(O) development(O) of(O) the(O) central(O) nervous(O) system(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, person, location, enzyme, country, chemical_element, theory, astronomical_object, scientist, organization, event, chemical_compound, academic_journal, university, award, discipline\nGIVEN SENTENCE: The team that she manages has specially studied the role of Proinsulin / insulin in the development of the central nervous system .\n","prediction_output":null,"prediction_outputs":null,"group":"39","words":["The","team","that","she","manages","has","specially","studied","the","role","of","Proinsulin","/","insulin","in","the","development","of","the","central","nervous","system","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-protein","O","B-protein","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["protein","person","location","enzyme","country","chemical_element","theory","astronomical_object","scientist","organization","event","chemical_compound","academic_journal","university","award","discipline"]}
{"id":"41.S","dataset":"crossner_science","split":"dev","instance":{"id":"41.S","prompt_labels":"Hamilton(B-person) was(O) a(O) visiting(O) professor(O) at(O) Harvard(B-university) University(I-university) and(O) later(O) spent(O) nine(O) months(O) with(O) the(O) Royal(B-organization) Society(I-organization) '(O) s(O) and(O) the(O) Royal(B-organization) Geographical(I-organization) Society(I-organization) '(O) s(O) Xavantina-Cachimbo(O) Expedition(O) as(O) a(O) visiting(O) professor(O) at(O) the(O) University(B-university) of(I-university) São(I-university) Paulo(I-university) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, theory, person, astronomical_object, award, event, organization, protein, location, country, academic_journal, enzyme, discipline, scientist, university, chemical_element\nGIVEN SENTENCE: Hamilton was a visiting professor at Harvard University and later spent nine months with the Royal Society ' s and the Royal Geographical Society ' s Xavantina-Cachimbo Expedition as a visiting professor at the University of São Paulo .\n","prediction_output":null,"prediction_outputs":null,"group":"41","words":["Hamilton","was","a","visiting","professor","at","Harvard","University","and","later","spent","nine","months","with","the","Royal","Society","'","s","and","the","Royal","Geographical","Society","'","s","Xavantina-Cachimbo","Expedition","as","a","visiting","professor","at","the","University","of","São","Paulo","."],"labels":["B-person","O","O","O","O","O","B-university","I-university","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","theory","person","astronomical_object","award","event","organization","protein","location","country","academic_journal","enzyme","discipline","scientist","university","chemical_element"]}
{"id":"42.S","dataset":"crossner_science","split":"dev","instance":{"id":"42.S","prompt_labels":"Michelson(B-scientist) was(O) a(O) member(O) of(O) the(O) Royal(B-organization) Society(I-organization) ,(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) American(B-organization) Physical(I-organization) Society(I-organization) and(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: astronomical_object, country, award, event, chemical_element, theory, academic_journal, discipline, enzyme, location, university, protein, scientist, organization, person, chemical_compound\nGIVEN SENTENCE: Michelson was a member of the Royal Society , the National Academy of Sciences , the American Physical Society and the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"42","words":["Michelson","was","a","member","of","the","Royal","Society",",","the","National","Academy","of","Sciences",",","the","American","Physical","Society","and","the","American","Association","for","the","Advancement","of","Science","."],"labels":["B-scientist","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["astronomical_object","country","award","event","chemical_element","theory","academic_journal","discipline","enzyme","location","university","protein","scientist","organization","person","chemical_compound"]}
{"id":"45.S","dataset":"crossner_science","split":"dev","instance":{"id":"45.S","prompt_labels":"The(O) Asian(B-organization) Football(I-organization) Confederation(I-organization) ,(O) Oceania(B-organization) Football(I-organization) Confederation(I-organization) and(O) CONCACAF(B-organization) ((O) the(O) governing(O) body(O) of(O) football(O) in(O) North(O) and(O) Central(O) America(B-country) and(O) the(O) Caribbean(B-location) )(O) use(O) blue(O) text(O) on(O) their(O) logos(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, astronomical_object, country, chemical_element, organization, protein, university, person, theory, discipline, chemical_compound, enzyme, event, award, scientist, academic_journal\nGIVEN SENTENCE: The Asian Football Confederation , Oceania Football Confederation and CONCACAF ( the governing body of football in North and Central America and the Caribbean ) use blue text on their logos .\n","prediction_output":null,"prediction_outputs":null,"group":"45","words":["The","Asian","Football","Confederation",",","Oceania","Football","Confederation","and","CONCACAF","(","the","governing","body","of","football","in","North","and","Central","America","and","the","Caribbean",")","use","blue","text","on","their","logos","."],"labels":["O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","O","O","O","O","B-country","O","O","B-location","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["location","astronomical_object","country","chemical_element","organization","protein","university","person","theory","discipline","chemical_compound","enzyme","event","award","scientist","academic_journal"]}
{"id":"46.S","dataset":"crossner_science","split":"dev","instance":{"id":"46.S","prompt_labels":"She(O) competed(O) in(O) the(O) 4(B-event) ×(I-event) 100(I-event) metres(I-event) relay(I-event) event(I-event) at(O) the(O) 2015(B-event) World(I-event) Championships(I-event) in(O) Athletics(O) in(O) Beijing(B-location) ,(O) China(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, country, astronomical_object, person, enzyme, protein, discipline, academic_journal, organization, chemical_element, theory, chemical_compound, university, location, scientist, award\nGIVEN SENTENCE: She competed in the 4 × 100 metres relay event at the 2015 World Championships in Athletics in Beijing , China .\n","prediction_output":null,"prediction_outputs":null,"group":"46","words":["She","competed","in","the","4","×","100","metres","relay","event","at","the","2015","World","Championships","in","Athletics","in","Beijing",",","China","."],"labels":["O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","O","O","B-event","I-event","I-event","O","O","O","B-location","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["event","country","astronomical_object","person","enzyme","protein","discipline","academic_journal","organization","chemical_element","theory","chemical_compound","university","location","scientist","award"]}
{"id":"47.S","dataset":"crossner_science","split":"dev","instance":{"id":"47.S","prompt_labels":"Tremaine(O) ,(O) along(O) with(O) Peter(B-scientist) Goldreich(I-scientist) ,(O) correctly(O) predicted(O) that(O) shepherd(B-astronomical_object) moon(I-astronomical_object) s(O) created(O) Saturn(B-astronomical_object) '(O) s(O) thin(O) F(O) ring(O) ,(O) as(O) well(O) as(O) the(O) thin(O) rings(O) of(O) Uranus(B-astronomical_object) in(O) 1979(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: scientist, academic_journal, theory, chemical_element, country, person, protein, location, discipline, organization, enzyme, chemical_compound, award, astronomical_object, event, university\nGIVEN SENTENCE: Tremaine , along with Peter Goldreich , correctly predicted that shepherd moon s created Saturn ' s thin F ring , as well as the thin rings of Uranus in 1979 .\n","prediction_output":null,"prediction_outputs":null,"group":"47","words":["Tremaine",",","along","with","Peter","Goldreich",",","correctly","predicted","that","shepherd","moon","s","created","Saturn","'","s","thin","F","ring",",","as","well","as","the","thin","rings","of","Uranus","in","1979","."],"labels":["O","O","O","O","B-scientist","I-scientist","O","O","O","O","B-astronomical_object","I-astronomical_object","O","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","O"],"target_index":null,"target_label":null},"label_list":["scientist","academic_journal","theory","chemical_element","country","person","protein","location","discipline","organization","enzyme","chemical_compound","award","astronomical_object","event","university"]}
{"id":"51.S","dataset":"crossner_science","split":"dev","instance":{"id":"51.S","prompt_labels":"Genes(O) related(O) to(O) the(O) proximal(O) area(O) are(O) HFE2(O) ,(O) TXNIP(O) ,(O) POLR3GL(O) ,(O) LIX1L(O) ,(O) RBM8A(O) ,(O) PEX11B(O) ,(O) ITGA10(O) ,(O) ANKRD35(O) ,(O) PIAS3(O) ,(O) NUDT17(O) ,(O) POLR3C(O) ,(O) RNF115(O) ,(O) CD160(O) ,(O) PDZK1(O) ,(O) and(O) GPR89A(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, discipline, chemical_compound, event, country, chemical_element, award, protein, person, scientist, university, location, enzyme, academic_journal, astronomical_object, organization\nGIVEN SENTENCE: Genes related to the proximal area are HFE2 , TXNIP , POLR3GL , LIX1L , RBM8A , PEX11B , ITGA10 , ANKRD35 , PIAS3 , NUDT17 , POLR3C , RNF115 , CD160 , PDZK1 , and GPR89A .\n","prediction_output":null,"prediction_outputs":null,"group":"51","words":["Genes","related","to","the","proximal","area","are","HFE2",",","TXNIP",",","POLR3GL",",","LIX1L",",","RBM8A",",","PEX11B",",","ITGA10",",","ANKRD35",",","PIAS3",",","NUDT17",",","POLR3C",",","RNF115",",","CD160",",","PDZK1",",","and","GPR89A","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["theory","discipline","chemical_compound","event","country","chemical_element","award","protein","person","scientist","university","location","enzyme","academic_journal","astronomical_object","organization"]}
{"id":"52.S","dataset":"crossner_science","split":"dev","instance":{"id":"52.S","prompt_labels":"From(O) 1884(O) to(O) 1888(O) he(O) studied(O) at(O) the(O) universities(O) of(O) Humboldt(B-university) University(I-university) of(I-university) Berlin(I-university) and(O) University(B-university) of(I-university) Strasbourg(I-university) ,(O) after(O) which(O) he(O) became(O) an(O) assistant(O) at(O) the(O) Academy(B-organization) of(I-organization) Münster(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, theory, enzyme, protein, astronomical_object, chemical_compound, discipline, event, university, scientist, award, person, location, organization, chemical_element, academic_journal\nGIVEN SENTENCE: From 1884 to 1888 he studied at the universities of Humboldt University of Berlin and University of Strasbourg , after which he became an assistant at the Academy of Münster .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["From","1884","to","1888","he","studied","at","the","universities","of","Humboldt","University","of","Berlin","and","University","of","Strasbourg",",","after","which","he","became","an","assistant","at","the","Academy","of","Münster","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["country","theory","enzyme","protein","astronomical_object","chemical_compound","discipline","event","university","scientist","award","person","location","organization","chemical_element","academic_journal"]}
{"id":"53.S","dataset":"crossner_science","split":"dev","instance":{"id":"53.S","prompt_labels":"The(O) effect(O) was(O) first(O) predicted(O) as(O) the(O) diffraction(O) of(O) electrons(O) from(O) a(O) standing(O) wave(O) of(O) light(O) by(O) Paul(B-scientist) Dirac(I-scientist) and(O) Pyotr(B-scientist) Kapitsa(I-scientist) ((O) or(O) Peter(B-scientist) Kapitza(I-scientist) )(O) in(O) 1933(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, academic_journal, person, scientist, discipline, chemical_compound, astronomical_object, enzyme, theory, country, protein, organization, university, event, location, chemical_element\nGIVEN SENTENCE: The effect was first predicted as the diffraction of electrons from a standing wave of light by Paul Dirac and Pyotr Kapitsa ( or Peter Kapitza ) in 1933 .\n","prediction_output":null,"prediction_outputs":null,"group":"53","words":["The","effect","was","first","predicted","as","the","diffraction","of","electrons","from","a","standing","wave","of","light","by","Paul","Dirac","and","Pyotr","Kapitsa","(","or","Peter","Kapitza",")","in","1933","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","academic_journal","person","scientist","discipline","chemical_compound","astronomical_object","enzyme","theory","country","protein","organization","university","event","location","chemical_element"]}
{"id":"55.S","dataset":"crossner_science","split":"dev","instance":{"id":"55.S","prompt_labels":"Not(O) only(O) were(O) these(O) initiators(O) the(O) first(O) to(O) achieve(O) relatively(O) high(O) molecular(O) weight(O) poly(O) ((O) 1-alkenes(B-chemical_compound) )(O) ((O) currently(O) the(O) most(O) widely(O) produced(O) thermoplastic(O) in(O) the(O) world(O) PE(B-chemical_compound) ((O) Polyethylene(B-chemical_compound) )(O) and(O) PP(B-chemical_compound) ((O) Polypropylene(B-chemical_compound) )(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: discipline, enzyme, organization, chemical_compound, chemical_element, university, academic_journal, country, scientist, person, award, location, protein, theory, event, astronomical_object\nGIVEN SENTENCE: Not only were these initiators the first to achieve relatively high molecular weight poly ( 1-alkenes ) ( currently the most widely produced thermoplastic in the world PE ( Polyethylene ) and PP ( Polypropylene )\n","prediction_output":null,"prediction_outputs":null,"group":"55","words":["Not","only","were","these","initiators","the","first","to","achieve","relatively","high","molecular","weight","poly","(","1-alkenes",")","(","currently","the","most","widely","produced","thermoplastic","in","the","world","PE","(","Polyethylene",")","and","PP","(","Polypropylene",")"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical_compound","O","O","O","O","O","O","O","O","O","O","O","B-chemical_compound","O","B-chemical_compound","O","O","B-chemical_compound","O","B-chemical_compound","O"],"target_index":null,"target_label":null},"label_list":["discipline","enzyme","organization","chemical_compound","chemical_element","university","academic_journal","country","scientist","person","award","location","protein","theory","event","astronomical_object"]}
{"id":"56.S","dataset":"crossner_science","split":"dev","instance":{"id":"56.S","prompt_labels":"UCSI(B-university) University(I-university) ,(I-university) Sarawak(I-university) Campus(I-university) ,(O) University(B-university) College(I-university) of(I-university) Technology(I-university) Sarawak(I-university) ((O) UCTS(B-university) )(O) Tunku(B-university) Abdul(I-university) Rahman(I-university) University(I-university) College(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) International(B-university) University(I-university) College(I-university) Of(I-university) Technology(I-university) Twintech(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) and(O) Open(B-university) University(I-university) Malaysia(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(B-location) Malaysia(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, award, university, enzyme, chemical_element, academic_journal, organization, event, theory, chemical_compound, location, discipline, protein, astronomical_object, person, scientist\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":null},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"57.S","dataset":"crossner_science","split":"dev","instance":{"id":"57.S","prompt_labels":"He(O) also(O) included(O) perturbations(O) due(O) to(O) the(O) other(O) planets(O) ((O) principally(O) Jupiter(B-astronomical_object) and(O) Venus(B-astronomical_object) )(O) and(O) also(O) accounted(O) for(O) the(O) more(O) difficult(O) problem(O) of(O) the(O) non-spherical(O) nature(O) of(O) the(O) Earth(B-astronomical_object) and(O) Moon(B-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, protein, country, theory, event, scientist, discipline, chemical_element, person, organization, academic_journal, location, enzyme, university, award, astronomical_object\nGIVEN SENTENCE: He also included perturbations due to the other planets ( principally Jupiter and Venus ) and also accounted for the more difficult problem of the non-spherical nature of the Earth and Moon .\n","prediction_output":null,"prediction_outputs":null,"group":"57","words":["He","also","included","perturbations","due","to","the","other","planets","(","principally","Jupiter","and","Venus",")","and","also","accounted","for","the","more","difficult","problem","of","the","non-spherical","nature","of","the","Earth","and","Moon","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","protein","country","theory","event","scientist","discipline","chemical_element","person","organization","academic_journal","location","enzyme","university","award","astronomical_object"]}
{"id":"58.S","dataset":"crossner_science","split":"dev","instance":{"id":"58.S","prompt_labels":"Thompson(B-scientist) endowed(O) the(O) Rumford(B-award) medal(I-award) s(O) of(O) the(O) Royal(B-organization) Society(I-organization) and(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) and(O) endowed(O) a(O) professorship(O) at(O) Harvard(B-university) University(I-university) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: discipline, astronomical_object, person, protein, location, scientist, university, organization, chemical_compound, country, enzyme, award, theory, event, academic_journal, chemical_element\nGIVEN SENTENCE: Thompson endowed the Rumford medal s of the Royal Society and the American Academy of Arts and Sciences , and endowed a professorship at Harvard University .\n","prediction_output":null,"prediction_outputs":null,"group":"58","words":["Thompson","endowed","the","Rumford","medal","s","of","the","Royal","Society","and","the","American","Academy","of","Arts","and","Sciences",",","and","endowed","a","professorship","at","Harvard","University","."],"labels":["B-scientist","O","O","B-award","I-award","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","B-university","I-university","O"],"target_index":null,"target_label":null},"label_list":["discipline","astronomical_object","person","protein","location","scientist","university","organization","chemical_compound","country","enzyme","award","theory","event","academic_journal","chemical_element"]}
{"id":"61.S","dataset":"crossner_science","split":"dev","instance":{"id":"61.S","prompt_labels":"Robot(O) designer(O) Hans(B-scientist) Moravec(I-scientist) ,(O) cyberneticist(O) Kevin(B-scientist) Warwick(I-scientist) and(O) inventor(O) Ray(B-person) Kurzweil(I-person) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, person, university, award, astronomical_object, event, location, enzyme, academic_journal, chemical_element, chemical_compound, discipline, theory, scientist, protein, country\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"62.S","dataset":"crossner_science","split":"dev","instance":{"id":"62.S","prompt_labels":"Matjaž(B-scientist) Perc(I-scientist) is(O) editorial(O) board(O) member(O) at(O) Physical(B-academic_journal) Review(I-academic_journal) E(I-academic_journal) ,(O) New(B-academic_journal) Journal(I-academic_journal) of(I-academic_journal) Physics(I-academic_journal) ,(O) EPL(B-academic_journal) ,(O) European(B-academic_journal) Physical(I-academic_journal) Journal(I-academic_journal) B(I-academic_journal) ,(O) Advances(B-academic_journal) in(I-academic_journal) Complex(I-academic_journal) Systems(I-academic_journal) ,(O) Frontiers(B-academic_journal) in(I-academic_journal) Interdisciplinary(I-academic_journal) Physics(I-academic_journal) ,(O) International(B-academic_journal) Journal(I-academic_journal) of(I-academic_journal) Bifurcation(I-academic_journal) and(I-academic_journal) Chaos(I-academic_journal) ,(O) PLOS(B-academic_journal) ONE(I-academic_journal) ,(O) Scientific(B-academic_journal) Reports(I-academic_journal) ,(O) Royal(B-academic_journal) Society(I-academic_journal) Open(I-academic_journal) Science(I-academic_journal) ,(O) '(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_element, chemical_compound, university, enzyme, event, protein, organization, academic_journal, award, scientist, country, discipline, theory, location, person, astronomical_object\nGIVEN SENTENCE: Matjaž Perc is editorial board member at Physical Review E , New Journal of Physics , EPL , European Physical Journal B , Advances in Complex Systems , Frontiers in Interdisciplinary Physics , International Journal of Bifurcation and Chaos , PLOS ONE , Scientific Reports , Royal Society Open Science , ' .\n","prediction_output":null,"prediction_outputs":null,"group":"62","words":["Matjaž","Perc","is","editorial","board","member","at","Physical","Review","E",",","New","Journal","of","Physics",",","EPL",",","European","Physical","Journal","B",",","Advances","in","Complex","Systems",",","Frontiers","in","Interdisciplinary","Physics",",","International","Journal","of","Bifurcation","and","Chaos",",","PLOS","ONE",",","Scientific","Reports",",","Royal","Society","Open","Science",",","'","."],"labels":["B-scientist","I-scientist","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O","O"],"target_index":null,"target_label":null},"label_list":["chemical_element","chemical_compound","university","enzyme","event","protein","organization","academic_journal","award","scientist","country","discipline","theory","location","person","astronomical_object"]}
{"id":"68.S","dataset":"crossner_science","split":"dev","instance":{"id":"68.S","prompt_labels":"The(O) concept(O) that(O) the(O) composition(O) of(O) plant(O) communities(O) such(O) as(O) temperate(O) broadleaf(O) forest(O) changes(O) by(O) a(O) process(O) of(O) ecological(O) succession(O) was(O) developed(O) by(O) Henry(B-scientist) Chandler(I-scientist) Cowles(I-scientist) ,(O) Arthur(B-scientist) Tansley(I-scientist) and(O) Frederic(B-scientist) Clements(I-scientist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, chemical_element, scientist, university, astronomical_object, chemical_compound, organization, protein, country, enzyme, location, person, award, event, academic_journal, discipline\nGIVEN SENTENCE: The concept that the composition of plant communities such as temperate broadleaf forest changes by a process of ecological succession was developed by Henry Chandler Cowles , Arthur Tansley and Frederic Clements .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["The","concept","that","the","composition","of","plant","communities","such","as","temperate","broadleaf","forest","changes","by","a","process","of","ecological","succession","was","developed","by","Henry","Chandler","Cowles",",","Arthur","Tansley","and","Frederic","Clements","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"target_index":null,"target_label":null},"label_list":["theory","chemical_element","scientist","university","astronomical_object","chemical_compound","organization","protein","country","enzyme","location","person","award","event","academic_journal","discipline"]}
{"id":"70.S","dataset":"crossner_science","split":"dev","instance":{"id":"70.S","prompt_labels":"FastPP(O) can(O) be(O) used(O) on(O) unpurified(O) ,(O) complex(O) mixtures(O) of(O) proteins(O) and(O) proteins(O) fused(O) with(O) other(O) proteins(O) ,(O) such(O) as(O) Glutathione(B-protein) S-transferase(I-protein) or(O) Green(B-protein) fluorescent(I-protein) protein(I-protein) ,(O) as(O) long(O) as(O) the(O) sequence(O) that(O) is(O) the(O) target(O) of(O) the(O) western(O) blot(O) ,(O) e.g.(O) ,(O) His-tag(O) ,(O) is(O) directly(O) linked(O) to(O) the(O) protein(O) of(O) interest(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, location, academic_journal, country, award, theory, discipline, person, protein, enzyme, university, organization, event, scientist, astronomical_object, chemical_element\nGIVEN SENTENCE: FastPP can be used on unpurified , complex mixtures of proteins and proteins fused with other proteins , such as Glutathione S-transferase or Green fluorescent protein , as long as the sequence that is the target of the western blot , e.g. , His-tag , is directly linked to the protein of interest .\n","prediction_output":null,"prediction_outputs":null,"group":"70","words":["FastPP","can","be","used","on","unpurified",",","complex","mixtures","of","proteins","and","proteins","fused","with","other","proteins",",","such","as","Glutathione","S-transferase","or","Green","fluorescent","protein",",","as","long","as","the","sequence","that","is","the","target","of","the","western","blot",",","e.g.",",","His-tag",",","is","directly","linked","to","the","protein","of","interest","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","I-protein","O","B-protein","I-protein","I-protein","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","location","academic_journal","country","award","theory","discipline","person","protein","enzyme","university","organization","event","scientist","astronomical_object","chemical_element"]}
{"id":"71.S","dataset":"crossner_science","split":"dev","instance":{"id":"71.S","prompt_labels":"The(O) theory(O) has(O) been(O) published(O) in(O) three(O) peer-reviewed(O) journals(O) :(O) The(B-academic_journal) Quarterly(I-academic_journal) Review(I-academic_journal) of(I-academic_journal) Biology(I-academic_journal) ,(O) Evolutionary(B-academic_journal) Anthropology(I-academic_journal) and(O) the(O) Journal(B-academic_journal) of(I-academic_journal) Theoretical(I-academic_journal) Biology(I-academic_journal) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, protein, scientist, event, country, academic_journal, person, award, organization, university, location, discipline, chemical_element, theory, astronomical_object, enzyme\nGIVEN SENTENCE: The theory has been published in three peer-reviewed journals : The Quarterly Review of Biology , Evolutionary Anthropology and the Journal of Theoretical Biology .\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["The","theory","has","been","published","in","three","peer-reviewed","journals",":","The","Quarterly","Review","of","Biology",",","Evolutionary","Anthropology","and","the","Journal","of","Theoretical","Biology","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","protein","scientist","event","country","academic_journal","person","award","organization","university","location","discipline","chemical_element","theory","astronomical_object","enzyme"]}
{"id":"78.S","dataset":"crossner_science","split":"dev","instance":{"id":"78.S","prompt_labels":"He(O) was(O) member(O) of(O) the(O) Deutsche(B-university) Akademie(I-university) of(I-university) Munich(I-university) ,(O) Swiss(B-organization) Physical(I-organization) Society(I-organization) of(I-organization) Zürich(I-organization) ,(O) Royal(B-organization) Philosophical(I-organization) Society(I-organization) of(I-organization) Glasgow(I-organization) ,(O) Royal(B-organization) Irish(I-organization) Academy(I-organization) ,(O) Hungarian(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) Academy(B-organization) of(I-organization) Sciences(I-organization) of(I-organization) the(I-organization) U.S.S.R.(I-organization) ,(O) Optical(B-organization) Society(I-organization) of(I-organization) America(I-organization) and(O) Mineralogical(B-organization) Society(I-organization) of(I-organization) America(I-organization) ,(O) Romanian(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) Catgut(B-organization) Acoustical(I-organization) Society(I-organization) of(I-organization) America(I-organization) ,(O) and(O) Czechoslovak(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_element, event, award, discipline, chemical_compound, astronomical_object, country, university, enzyme, theory, scientist, protein, academic_journal, location, person, organization\nGIVEN SENTENCE: He was member of the Deutsche Akademie of Munich , Swiss Physical Society of Zürich , Royal Philosophical Society of Glasgow , Royal Irish Academy , Hungarian Academy of Sciences , Academy of Sciences of the U.S.S.R. , Optical Society of America and Mineralogical Society of America , Romanian Academy of Sciences , Catgut Acoustical Society of America , and Czechoslovak Academy of Sciences .\n","prediction_output":null,"prediction_outputs":null,"group":"78","words":["He","was","member","of","the","Deutsche","Akademie","of","Munich",",","Swiss","Physical","Society","of","Zürich",",","Royal","Philosophical","Society","of","Glasgow",",","Royal","Irish","Academy",",","Hungarian","Academy","of","Sciences",",","Academy","of","Sciences","of","the","U.S.S.R.",",","Optical","Society","of","America","and","Mineralogical","Society","of","America",",","Romanian","Academy","of","Sciences",",","Catgut","Acoustical","Society","of","America",",","and","Czechoslovak","Academy","of","Sciences","."],"labels":["O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["chemical_element","event","award","discipline","chemical_compound","astronomical_object","country","university","enzyme","theory","scientist","protein","academic_journal","location","person","organization"]}
{"id":"81.S","dataset":"crossner_science","split":"dev","instance":{"id":"81.S","prompt_labels":"ESA(B-organization) 's(O) Advanced(B-organization) Concepts(I-organization) Team(I-organization) has(O) also(O) demonstrated(O) theoretically(O) that(O) a(O) deflection(O) of(O) 99942(B-astronomical_object) Apophis(I-astronomical_object) could(O) be(O) achieved(O) by(O) sending(O) a(O) simple(O) spacecraft(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: discipline, chemical_compound, award, location, enzyme, organization, university, theory, protein, person, academic_journal, scientist, chemical_element, astronomical_object, country, event\nGIVEN SENTENCE: ESA 's Advanced Concepts Team has also demonstrated theoretically that a deflection of 99942 Apophis could be achieved by sending a simple spacecraft\n","prediction_output":null,"prediction_outputs":null,"group":"81","words":["ESA","'s","Advanced","Concepts","Team","has","also","demonstrated","theoretically","that","a","deflection","of","99942","Apophis","could","be","achieved","by","sending","a","simple","spacecraft"],"labels":["B-organization","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-astronomical_object","I-astronomical_object","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["discipline","chemical_compound","award","location","enzyme","organization","university","theory","protein","person","academic_journal","scientist","chemical_element","astronomical_object","country","event"]}
{"id":"83.S","dataset":"crossner_science","split":"dev","instance":{"id":"83.S","prompt_labels":"Other(O) higher(O) education(O) organizations(O) present(O) in(O) the(O) community(O) ,(O) but(O) not(O) offering(O) classes(O) locally(O) ,(O) include(O) the(O) Oak(B-organization) Ridge(I-organization) Institute(I-organization) for(I-organization) Science(I-organization) and(I-organization) Education(I-organization) ,(O) Oak(B-university) Ridge(I-university) Associated(I-university) Universities(I-university) ,(O) and(O) the(O) University(B-university) of(I-university) Tennessee(I-university) Forestry(B-organization) Stations(I-organization) and(O) Arboretum(B-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, award, academic_journal, event, theory, person, university, scientist, discipline, country, protein, chemical_compound, astronomical_object, chemical_element, enzyme, location\nGIVEN SENTENCE: Other higher education organizations present in the community , but not offering classes locally , include the Oak Ridge Institute for Science and Education , Oak Ridge Associated Universities , and the University of Tennessee Forestry Stations and Arboretum .\n","prediction_output":null,"prediction_outputs":null,"group":"83","words":["Other","higher","education","organizations","present","in","the","community",",","but","not","offering","classes","locally",",","include","the","Oak","Ridge","Institute","for","Science","and","Education",",","Oak","Ridge","Associated","Universities",",","and","the","University","of","Tennessee","Forestry","Stations","and","Arboretum","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-university","I-university","I-university","I-university","O","O","O","B-university","I-university","I-university","B-organization","I-organization","O","B-organization","O"],"target_index":null,"target_label":null},"label_list":["organization","award","academic_journal","event","theory","person","university","scientist","discipline","country","protein","chemical_compound","astronomical_object","chemical_element","enzyme","location"]}
{"id":"84.S","dataset":"crossner_science","split":"dev","instance":{"id":"84.S","prompt_labels":"In(O) the(O) first(O) half(O) of(O) the(O) 20th(O) century(O) ,(O) advances(O) in(O) electronics(O) enabled(O) investigation(O) of(O) the(O) electrical(O) properties(O) of(O) nerve(O) cells(O) ,(O) culminating(O) in(O) work(O) by(O) Alan(B-scientist) Hodgkin(I-scientist) ,(O) Andrew(B-scientist) Huxley(I-scientist) ,(O) and(O) others(O) on(O) the(O) biophysics(O) of(O) the(O) action(O) potential(O) ,(O) and(O) the(O) work(O) of(O) Bernard(B-scientist) Katz(I-scientist) and(O) others(O) on(O) the(O) electrochemistry(B-discipline) of(O) the(O) synapse(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, scientist, academic_journal, enzyme, protein, university, chemical_element, person, theory, country, event, discipline, award, chemical_compound, location, astronomical_object\nGIVEN SENTENCE: In the first half of the 20th century , advances in electronics enabled investigation of the electrical properties of nerve cells , culminating in work by Alan Hodgkin , Andrew Huxley , and others on the biophysics of the action potential , and the work of Bernard Katz and others on the electrochemistry of the synapse .\n","prediction_output":null,"prediction_outputs":null,"group":"84","words":["In","the","first","half","of","the","20th","century",",","advances","in","electronics","enabled","investigation","of","the","electrical","properties","of","nerve","cells",",","culminating","in","work","by","Alan","Hodgkin",",","Andrew","Huxley",",","and","others","on","the","biophysics","of","the","action","potential",",","and","the","work","of","Bernard","Katz","and","others","on","the","electrochemistry","of","the","synapse","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","B-discipline","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","scientist","academic_journal","enzyme","protein","university","chemical_element","person","theory","country","event","discipline","award","chemical_compound","location","astronomical_object"]}
{"id":"85.S","dataset":"crossner_science","split":"dev","instance":{"id":"85.S","prompt_labels":"Jupiter(B-astronomical_object) rarely(O) occults(O) Saturn(B-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, person, scientist, academic_journal, theory, chemical_compound, organization, country, enzyme, chemical_element, location, discipline, university, astronomical_object, award, event\nGIVEN SENTENCE: Jupiter rarely occults Saturn .\n","prediction_output":null,"prediction_outputs":null,"group":"85","words":["Jupiter","rarely","occults","Saturn","."],"labels":["B-astronomical_object","O","O","B-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["protein","person","scientist","academic_journal","theory","chemical_compound","organization","country","enzyme","chemical_element","location","discipline","university","astronomical_object","award","event"]}
{"id":"87.S","dataset":"crossner_science","split":"dev","instance":{"id":"87.S","prompt_labels":"He(O) is(O) known(O) for(O) his(O) studies(O) on(O) the(O) Pore-forming(B-protein) toxin(I-protein) and(O) T-cell(O) costimulatory(O) molecules(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, award, academic_journal, country, university, theory, enzyme, location, discipline, scientist, protein, person, chemical_compound, astronomical_object, chemical_element, organization\nGIVEN SENTENCE: He is known for his studies on the Pore-forming toxin and T-cell costimulatory molecules .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["He","is","known","for","his","studies","on","the","Pore-forming","toxin","and","T-cell","costimulatory","molecules","."],"labels":["O","O","O","O","O","O","O","O","B-protein","I-protein","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","award","academic_journal","country","university","theory","enzyme","location","discipline","scientist","protein","person","chemical_compound","astronomical_object","chemical_element","organization"]}
{"id":"88.S","dataset":"crossner_science","split":"dev","instance":{"id":"88.S","prompt_labels":"The(O) name(O) was(O) suggested(O) by(O) John(B-scientist) Herschel(I-scientist) ((O) son(O) of(O) William(B-scientist) Herschel(I-scientist) ,(O) discoverer(O) of(O) Mimas(B-astronomical_object) and(O) Enceladus(B-astronomical_object) )(O) in(O) his(O) 1847(O) publication(O) Results(O) of(O) Astronomical(O) Observations(O) made(O) at(O) the(O) Cape(B-location) of(I-location) Good(I-location) Hope(I-location) ,(O) in(O) which(O) he(O) advocated(O) naming(O) the(O) moons(O) of(O) Saturn(B-astronomical_object) after(O) the(O) Titans(B-astronomical_object) ,(O) brothers(O) and(O) sisters(O) of(O) the(O) Titan(B-person) Cronus(I-person) ((O) whom(O) the(O) Romans(O) equated(O) with(O) their(O) god(O) Saturn(B-astronomical_object) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, astronomical_object, theory, academic_journal, location, university, person, country, protein, organization, award, enzyme, discipline, chemical_element, event, scientist\nGIVEN SENTENCE: The name was suggested by John Herschel ( son of William Herschel , discoverer of Mimas and Enceladus ) in his 1847 publication Results of Astronomical Observations made at the Cape of Good Hope , in which he advocated naming the moons of Saturn after the Titans , brothers and sisters of the Titan Cronus ( whom the Romans equated with their god Saturn ) .\n","prediction_output":null,"prediction_outputs":null,"group":"88","words":["The","name","was","suggested","by","John","Herschel","(","son","of","William","Herschel",",","discoverer","of","Mimas","and","Enceladus",")","in","his","1847","publication","Results","of","Astronomical","Observations","made","at","the","Cape","of","Good","Hope",",","in","which","he","advocated","naming","the","moons","of","Saturn","after","the","Titans",",","brothers","and","sisters","of","the","Titan","Cronus","(","whom","the","Romans","equated","with","their","god","Saturn",")","."],"labels":["O","O","O","O","O","B-scientist","I-scientist","O","O","O","B-scientist","I-scientist","O","O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","B-astronomical_object","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","B-astronomical_object","O","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","astronomical_object","theory","academic_journal","location","university","person","country","protein","organization","award","enzyme","discipline","chemical_element","event","scientist"]}
{"id":"89.S","dataset":"crossner_science","split":"dev","instance":{"id":"89.S","prompt_labels":"The(O) testing(O) station(O) is(O) where(O) Rexer(B-scientist) ,(O) F.(B-scientist) Berkei(I-scientist) ,(O) W.(B-scientist) Borrmann(I-scientist) ,(O) W.(B-scientist) Czulius(I-scientist) ,(O) Kurt(B-scientist) Diebner(I-scientist) ,(O) Georg(B-scientist) Hartwig(I-scientist) ,(O) Karl-Heinz(B-scientist) Höcker(I-scientist) ,(O) Walter(B-scientist) Herrmann(I-scientist) ,(O) and(O) Heinz(B-scientist) Pose(I-scientist) ,(O) compared(O) the(O) effectiveness(O) of(O) neutron(O) production(O) in(O) a(O) paraffin-moderated(O) reactor(O) using(O) uranium(B-chemical_element) plates(O) ,(O) rods(O) ,(O) and(O) cubes(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: enzyme, chemical_compound, person, event, country, academic_journal, university, theory, scientist, protein, astronomical_object, organization, award, location, discipline, chemical_element\nGIVEN SENTENCE: The testing station is where Rexer , F. Berkei , W. Borrmann , W. Czulius , Kurt Diebner , Georg Hartwig , Karl-Heinz Höcker , Walter Herrmann , and Heinz Pose , compared the effectiveness of neutron production in a paraffin-moderated reactor using uranium plates , rods , and cubes .\n","prediction_output":null,"prediction_outputs":null,"group":"89","words":["The","testing","station","is","where","Rexer",",","F.","Berkei",",","W.","Borrmann",",","W.","Czulius",",","Kurt","Diebner",",","Georg","Hartwig",",","Karl-Heinz","Höcker",",","Walter","Herrmann",",","and","Heinz","Pose",",","compared","the","effectiveness","of","neutron","production","in","a","paraffin-moderated","reactor","using","uranium","plates",",","rods",",","and","cubes","."],"labels":["O","O","O","O","O","B-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical_element","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["enzyme","chemical_compound","person","event","country","academic_journal","university","theory","scientist","protein","astronomical_object","organization","award","location","discipline","chemical_element"]}
{"id":"94.S","dataset":"crossner_science","split":"dev","instance":{"id":"94.S","prompt_labels":"Some(O) ligninolytic(O) enzymes(O) include(O) Haem(B-enzyme) peroxidase(I-enzyme) such(O) as(O) lignin(B-enzyme) peroxidase(I-enzyme) s(O) ,(O) manganese(B-enzyme) peroxidase(I-enzyme) s(O) ,(O) versatile(B-enzyme) peroxidase(I-enzyme) s(O) ,(O) and(O) Dye(B-enzyme) decolorizing(I-enzyme) peroxidase(I-enzyme) as(O) well(O) as(O) copper-based(O) laccase(B-enzyme) s(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_element, theory, country, discipline, enzyme, person, location, organization, academic_journal, protein, scientist, chemical_compound, university, event, award, astronomical_object\nGIVEN SENTENCE: Some ligninolytic enzymes include Haem peroxidase such as lignin peroxidase s , manganese peroxidase s , versatile peroxidase s , and Dye decolorizing peroxidase as well as copper-based laccase s .\n","prediction_output":null,"prediction_outputs":null,"group":"94","words":["Some","ligninolytic","enzymes","include","Haem","peroxidase","such","as","lignin","peroxidase","s",",","manganese","peroxidase","s",",","versatile","peroxidase","s",",","and","Dye","decolorizing","peroxidase","as","well","as","copper-based","laccase","s","."],"labels":["O","O","O","O","B-enzyme","I-enzyme","O","O","B-enzyme","I-enzyme","O","O","B-enzyme","I-enzyme","O","O","B-enzyme","I-enzyme","O","O","O","B-enzyme","I-enzyme","I-enzyme","O","O","O","O","B-enzyme","O","O"],"target_index":null,"target_label":null},"label_list":["chemical_element","theory","country","discipline","enzyme","person","location","organization","academic_journal","protein","scientist","chemical_compound","university","event","award","astronomical_object"]}
{"id":"96.S","dataset":"crossner_science","split":"dev","instance":{"id":"96.S","prompt_labels":"Gas(O) giants(O) with(O) a(O) large(O) radius(O) and(O) very(O) low(O) density(O) are(O) sometimes(O) called(O) puffy(O) planets(O) COROT-1b(B-astronomical_object) ,(O) TrES-4(B-astronomical_object) ,(O) WASP-12b(B-astronomical_object) ,(O) WASP-17b(B-astronomical_object) ,(O) and(O) Kepler-7b(B-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_element, astronomical_object, organization, theory, event, chemical_compound, award, location, discipline, protein, person, academic_journal, university, enzyme, scientist, country\nGIVEN SENTENCE: Gas giants with a large radius and very low density are sometimes called puffy planets COROT-1b , TrES-4 , WASP-12b , WASP-17b , and Kepler-7b .\n","prediction_output":null,"prediction_outputs":null,"group":"96","words":["Gas","giants","with","a","large","radius","and","very","low","density","are","sometimes","called","puffy","planets","COROT-1b",",","TrES-4",",","WASP-12b",",","WASP-17b",",","and","Kepler-7b","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","B-astronomical_object","O","B-astronomical_object","O","O","B-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["chemical_element","astronomical_object","organization","theory","event","chemical_compound","award","location","discipline","protein","person","academic_journal","university","enzyme","scientist","country"]}
{"id":"97.S","dataset":"crossner_science","split":"dev","instance":{"id":"97.S","prompt_labels":"ATX-II(B-chemical_compound) slows(O) down(O) the(O) inactivation(O) of(O) different(O) Voltage-gated(O) ion(O) channel(O) ,(O) including(O) Nasubv(B-protein) /(I-protein) sub1.1(I-protein) and(O) Nasubv(B-protein) /(I-protein) sub1.2(I-protein) ,(O) thus(O) prolonging(O) action(O) potentials(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: academic_journal, country, discipline, location, person, organization, enzyme, protein, chemical_element, award, theory, event, scientist, astronomical_object, chemical_compound, university\nGIVEN SENTENCE: ATX-II slows down the inactivation of different Voltage-gated ion channel , including Nasubv / sub1.1 and Nasubv / sub1.2 , thus prolonging action potentials .\n","prediction_output":null,"prediction_outputs":null,"group":"97","words":["ATX-II","slows","down","the","inactivation","of","different","Voltage-gated","ion","channel",",","including","Nasubv","/","sub1.1","and","Nasubv","/","sub1.2",",","thus","prolonging","action","potentials","."],"labels":["B-chemical_compound","O","O","O","O","O","O","O","O","O","O","O","B-protein","I-protein","I-protein","O","B-protein","I-protein","I-protein","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["academic_journal","country","discipline","location","person","organization","enzyme","protein","chemical_element","award","theory","event","scientist","astronomical_object","chemical_compound","university"]}
{"id":"101.S","dataset":"crossner_science","split":"dev","instance":{"id":"101.S","prompt_labels":"Eggleton(B-scientist) is(O) the(O) author(O) and(O) coauthor(O) of(O) more(O) than(O) 480(O) journal(O) publications(O) ,(O) including(O) articles(O) in(O) Nature(B-academic_journal) Photonics(I-academic_journal) ,(O) Nature(B-academic_journal) Physics(I-academic_journal) ,(O) Nature(B-academic_journal) Communications(I-academic_journal) ,(O) Physical(B-academic_journal) Review(I-academic_journal) Letters(I-academic_journal) and(O) Optica(B-academic_journal) and(O) over(O) 200(O) invited(O) presentations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, organization, theory, university, country, chemical_element, academic_journal, chemical_compound, person, award, protein, location, enzyme, discipline, astronomical_object, scientist\nGIVEN SENTENCE: Eggleton is the author and coauthor of more than 480 journal publications , including articles in Nature Photonics , Nature Physics , Nature Communications , Physical Review Letters and Optica and over 200 invited presentations .\n","prediction_output":null,"prediction_outputs":null,"group":"101","words":["Eggleton","is","the","author","and","coauthor","of","more","than","480","journal","publications",",","including","articles","in","Nature","Photonics",",","Nature","Physics",",","Nature","Communications",",","Physical","Review","Letters","and","Optica","and","over","200","invited","presentations","."],"labels":["B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","organization","theory","university","country","chemical_element","academic_journal","chemical_compound","person","award","protein","location","enzyme","discipline","astronomical_object","scientist"]}
{"id":"102.S","dataset":"crossner_science","split":"dev","instance":{"id":"102.S","prompt_labels":"It(O) is(O) operated(O) by(O) the(O) National(B-organization) Centre(I-organization) for(I-organization) Radio(I-organization) Astrophysics(I-organization) ,(O) a(O) part(O) of(O) the(O) Tata(B-organization) Institute(I-organization) of(I-organization) Fundamental(I-organization) Research(I-organization) ,(O) Mumbai(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, academic_journal, astronomical_object, scientist, enzyme, discipline, event, organization, protein, country, university, theory, location, chemical_element, person, award\nGIVEN SENTENCE: It is operated by the National Centre for Radio Astrophysics , a part of the Tata Institute of Fundamental Research , Mumbai .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["It","is","operated","by","the","National","Centre","for","Radio","Astrophysics",",","a","part","of","the","Tata","Institute","of","Fundamental","Research",",","Mumbai","."],"labels":["O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","academic_journal","astronomical_object","scientist","enzyme","discipline","event","organization","protein","country","university","theory","location","chemical_element","person","award"]}
{"id":"103.S","dataset":"crossner_science","split":"dev","instance":{"id":"103.S","prompt_labels":"The(O) Council(B-organization) of(I-organization) Europe(I-organization) also(O) has(O) a(O) Congress(B-organization) of(I-organization) the(I-organization) Council(I-organization) of(I-organization) Europe(I-organization) ,(O) similar(O) to(O) the(O) EU(B-organization) 's(I-organization) Committee(I-organization) of(I-organization) the(I-organization) Regions(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, enzyme, chemical_compound, academic_journal, event, location, award, theory, university, scientist, discipline, astronomical_object, chemical_element, protein, organization, person\nGIVEN SENTENCE: The Council of Europe also has a Congress of the Council of Europe , similar to the EU 's Committee of the Regions .\n","prediction_output":null,"prediction_outputs":null,"group":"103","words":["The","Council","of","Europe","also","has","a","Congress","of","the","Council","of","Europe",",","similar","to","the","EU","'s","Committee","of","the","Regions","."],"labels":["O","B-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["country","enzyme","chemical_compound","academic_journal","event","location","award","theory","university","scientist","discipline","astronomical_object","chemical_element","protein","organization","person"]}
{"id":"106.S","dataset":"crossner_science","split":"dev","instance":{"id":"106.S","prompt_labels":"Cotton(B-scientist) served(O) on(O) various(O) editorial(O) boards(O) of(O) scientific(O) journals(O) ,(O) including(O) those(O) of(O) the(O) Journal(B-academic_journal) of(I-academic_journal) the(I-academic_journal) American(I-academic_journal) Chemical(I-academic_journal) Society(I-academic_journal) ,(O) Inorganic(B-academic_journal) Chemistry(I-academic_journal) ,(O) and(O) Organometallics(B-academic_journal) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, organization, chemical_element, academic_journal, event, enzyme, person, country, discipline, university, award, astronomical_object, chemical_compound, location, scientist, protein\nGIVEN SENTENCE: Cotton served on various editorial boards of scientific journals , including those of the Journal of the American Chemical Society , Inorganic Chemistry , and Organometallics .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["Cotton","served","on","various","editorial","boards","of","scientific","journals",",","including","those","of","the","Journal","of","the","American","Chemical","Society",",","Inorganic","Chemistry",",","and","Organometallics","."],"labels":["B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","O","B-academic_journal","O"],"target_index":null,"target_label":null},"label_list":["theory","organization","chemical_element","academic_journal","event","enzyme","person","country","discipline","university","award","astronomical_object","chemical_compound","location","scientist","protein"]}
{"id":"108.S","dataset":"crossner_science","split":"dev","instance":{"id":"108.S","prompt_labels":"The(O) pyrimidines(B-chemical_compound) ,(O) thymine(B-chemical_compound) ,(O) cytosine(B-chemical_compound) and(O) uracil(B-chemical_compound) ,(O) form(O) the(O) complementary(O) bases(O) to(O) the(O) purine(B-chemical_compound) bases(O) in(O) DNA(O) and(O) RNA(O) ,(O) and(O) are(O) also(O) components(O) of(O) Cytidine(B-chemical_compound) triphosphate(I-chemical_compound) ,(O) Uridine(B-chemical_compound) monophosphate(I-chemical_compound) ,(O) Uridine(B-chemical_compound) diphosphate(I-chemical_compound) and(O) Uridine(B-chemical_compound) triphosphate(I-chemical_compound) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, university, chemical_element, location, academic_journal, organization, award, country, discipline, event, scientist, person, astronomical_object, protein, chemical_compound, enzyme\nGIVEN SENTENCE: The pyrimidines , thymine , cytosine and uracil , form the complementary bases to the purine bases in DNA and RNA , and are also components of Cytidine triphosphate , Uridine monophosphate , Uridine diphosphate and Uridine triphosphate .\n","prediction_output":null,"prediction_outputs":null,"group":"108","words":["The","pyrimidines",",","thymine",",","cytosine","and","uracil",",","form","the","complementary","bases","to","the","purine","bases","in","DNA","and","RNA",",","and","are","also","components","of","Cytidine","triphosphate",",","Uridine","monophosphate",",","Uridine","diphosphate","and","Uridine","triphosphate","."],"labels":["O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","O","O","O","O","O","O","B-chemical_compound","O","O","O","O","O","O","O","O","O","O","O","B-chemical_compound","I-chemical_compound","O","B-chemical_compound","I-chemical_compound","O","B-chemical_compound","I-chemical_compound","O","B-chemical_compound","I-chemical_compound","O"],"target_index":null,"target_label":null},"label_list":["theory","university","chemical_element","location","academic_journal","organization","award","country","discipline","event","scientist","person","astronomical_object","protein","chemical_compound","enzyme"]}
{"id":"109.S","dataset":"crossner_science","split":"dev","instance":{"id":"109.S","prompt_labels":"He(O) has(O) received(O) Academy(B-award) Awards(I-award) ,(O) Grammy(B-award) Award(I-award) ,(O) and(O) Golden(B-award) Globe(I-award) Award(I-award) s(O) ,(O) and(O) he(O) is(O) an(O) inductee(O) to(O) the(O) Rock(B-organization) and(I-organization) Roll(I-organization) Hall(I-organization) of(I-organization) Fame(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, discipline, university, country, event, chemical_element, organization, award, academic_journal, theory, location, scientist, chemical_compound, person, enzyme, astronomical_object\nGIVEN SENTENCE: He has received Academy Awards , Grammy Award , and Golden Globe Award s , and he is an inductee to the Rock and Roll Hall of Fame .\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["He","has","received","Academy","Awards",",","Grammy","Award",",","and","Golden","Globe","Award","s",",","and","he","is","an","inductee","to","the","Rock","and","Roll","Hall","of","Fame","."],"labels":["O","O","O","B-award","I-award","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["protein","discipline","university","country","event","chemical_element","organization","award","academic_journal","theory","location","scientist","chemical_compound","person","enzyme","astronomical_object"]}
{"id":"110.S","dataset":"crossner_science","split":"dev","instance":{"id":"110.S","prompt_labels":"He(O) was(O) also(O) awarded(O) the(O) Eddington(B-award) Medal(I-award) of(O) the(O) Royal(B-organization) Astronomical(I-organization) Society(I-organization) in(O) 1969(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, enzyme, location, astronomical_object, country, scientist, organization, chemical_element, discipline, event, person, award, academic_journal, protein, university, chemical_compound\nGIVEN SENTENCE: He was also awarded the Eddington Medal of the Royal Astronomical Society in 1969 .\n","prediction_output":null,"prediction_outputs":null,"group":"110","words":["He","was","also","awarded","the","Eddington","Medal","of","the","Royal","Astronomical","Society","in","1969","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","B-organization","I-organization","I-organization","O","O","O"],"target_index":null,"target_label":null},"label_list":["theory","enzyme","location","astronomical_object","country","scientist","organization","chemical_element","discipline","event","person","award","academic_journal","protein","university","chemical_compound"]}
{"id":"113.S","dataset":"crossner_science","split":"dev","instance":{"id":"113.S","prompt_labels":"Major(O) species(O) assessors(O) include(O) BirdLife(B-organization) International(I-organization) ,(O) the(O) Institute(B-organization) of(I-organization) Zoology(I-organization) ((O) the(O) research(O) division(O) of(O) the(O) Zoological(B-organization) Society(I-organization) of(I-organization) London(I-organization) )(O) ,(O) the(O) World(B-organization) Conservation(I-organization) Monitoring(I-organization) Centre(I-organization) ,(O) and(O) many(O) Specialist(O) Groups(O) within(O) the(O) IUCN(B-organization) Species(I-organization) Survival(I-organization) Commission(I-organization) ((O) SSC(B-organization) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: enzyme, chemical_element, country, discipline, person, university, award, academic_journal, astronomical_object, protein, location, scientist, chemical_compound, organization, event, theory\nGIVEN SENTENCE: Major species assessors include BirdLife International , the Institute of Zoology ( the research division of the Zoological Society of London ) , the World Conservation Monitoring Centre , and many Specialist Groups within the IUCN Species Survival Commission ( SSC ) .\n","prediction_output":null,"prediction_outputs":null,"group":"113","words":["Major","species","assessors","include","BirdLife","International",",","the","Institute","of","Zoology","(","the","research","division","of","the","Zoological","Society","of","London",")",",","the","World","Conservation","Monitoring","Centre",",","and","many","Specialist","Groups","within","the","IUCN","Species","Survival","Commission","(","SSC",")","."],"labels":["O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":null},"label_list":["enzyme","chemical_element","country","discipline","person","university","award","academic_journal","astronomical_object","protein","location","scientist","chemical_compound","organization","event","theory"]}
{"id":"114.S","dataset":"crossner_science","split":"dev","instance":{"id":"114.S","prompt_labels":"Uranus(B-astronomical_object) is(O) similar(O) in(O) composition(O) to(O) Neptune(B-astronomical_object) ,(O) and(O) both(O) have(O) bulk(O) chemical(O) compositions(O) which(O) differ(O) from(O) that(O) of(O) the(O) larger(O) gas(O) giant(O) s(O) Jupiter(B-astronomical_object) and(O) Saturn(B-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, award, university, organization, person, protein, enzyme, scientist, chemical_element, astronomical_object, discipline, chemical_compound, theory, country, location, academic_journal\nGIVEN SENTENCE: Uranus is similar in composition to Neptune , and both have bulk chemical compositions which differ from that of the larger gas giant s Jupiter and Saturn .\n","prediction_output":null,"prediction_outputs":null,"group":"114","words":["Uranus","is","similar","in","composition","to","Neptune",",","and","both","have","bulk","chemical","compositions","which","differ","from","that","of","the","larger","gas","giant","s","Jupiter","and","Saturn","."],"labels":["B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["event","award","university","organization","person","protein","enzyme","scientist","chemical_element","astronomical_object","discipline","chemical_compound","theory","country","location","academic_journal"]}
{"id":"115.S","dataset":"crossner_science","split":"dev","instance":{"id":"115.S","prompt_labels":"In(O) 1999(O) ,(O) Haraway(B-scientist) received(O) the(O) Society(B-organization) for(I-organization) Social(I-organization) Studies(I-organization) of(I-organization) Science(I-organization) '(O) s(O) ((O) 4S(B-organization) )(O) Ludwik(B-award) Fleck(I-award) Prize(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, country, chemical_compound, discipline, chemical_element, academic_journal, person, university, location, organization, scientist, award, astronomical_object, enzyme, protein, theory\nGIVEN SENTENCE: In 1999 , Haraway received the Society for Social Studies of Science ' s ( 4S ) Ludwik Fleck Prize .\n","prediction_output":null,"prediction_outputs":null,"group":"115","words":["In","1999",",","Haraway","received","the","Society","for","Social","Studies","of","Science","'","s","(","4S",")","Ludwik","Fleck","Prize","."],"labels":["O","O","O","B-scientist","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-organization","O","B-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["event","country","chemical_compound","discipline","chemical_element","academic_journal","person","university","location","organization","scientist","award","astronomical_object","enzyme","protein","theory"]}
{"id":"116.S","dataset":"crossner_science","split":"dev","instance":{"id":"116.S","prompt_labels":"Knowles(B-person) collaborated(O) with(O) several(O) studio(O) personalities(O) ,(O) including(O) Jack(B-person) Splash(I-person) ,(O) Shea(B-person) Taylor(I-person) ,(O) Mr.(B-person) Familiar(I-person) ,(O) Lamont(B-person) Dozier(I-person) ,(O) production(O) teams(O) Soulshock(B-organization) &(I-organization) Karlin(I-organization) and(O) Bama(B-organization) Boyz(I-organization) ,(O) as(O) well(O) as(O) singers(O) and(O) rappers(O) Pharrell(B-person) Williams(I-person) ,(O) Bilal(B-person) ,(O) Q-Tip(B-person) and(O) Lil(B-person) Wayne(I-person) respectively(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: location, protein, chemical_element, chemical_compound, academic_journal, discipline, event, country, astronomical_object, scientist, person, organization, enzyme, university, theory, award\nGIVEN SENTENCE: Knowles collaborated with several studio personalities , including Jack Splash , Shea Taylor , Mr. Familiar , Lamont Dozier , production teams Soulshock & Karlin and Bama Boyz , as well as singers and rappers Pharrell Williams , Bilal , Q-Tip and Lil Wayne respectively .\n","prediction_output":null,"prediction_outputs":null,"group":"116","words":["Knowles","collaborated","with","several","studio","personalities",",","including","Jack","Splash",",","Shea","Taylor",",","Mr.","Familiar",",","Lamont","Dozier",",","production","teams","Soulshock","&","Karlin","and","Bama","Boyz",",","as","well","as","singers","and","rappers","Pharrell","Williams",",","Bilal",",","Q-Tip","and","Lil","Wayne","respectively","."],"labels":["B-person","O","O","O","O","O","O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","O","O","B-person","I-person","O","B-person","O","B-person","O","B-person","I-person","O","O"],"target_index":null,"target_label":null},"label_list":["location","protein","chemical_element","chemical_compound","academic_journal","discipline","event","country","astronomical_object","scientist","person","organization","enzyme","university","theory","award"]}
{"id":"119.S","dataset":"crossner_science","split":"dev","instance":{"id":"119.S","prompt_labels":"Thus(O) ,(O) Jupiter(B-astronomical_object) and(O) Saturn(B-astronomical_object) are(O) gas(O) giants(O) ,(O) and(O) Uranus(B-astronomical_object) and(O) Neptune(B-astronomical_object) are(O) ice(O) giant(O) s(O) ,(O) even(O) though(O) the(O) vast(O) majority(O) of(O) the(O) gas(O) and(O) ice(O) in(O) their(O) interiors(O) is(O) a(O) hot(O) ,(O) highly(O) dense(O) fluid(O) that(O) gets(O) denser(O) as(O) the(O) center(O) of(O) the(O) planet(O) is(O) approached(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, chemical_compound, scientist, academic_journal, event, astronomical_object, country, protein, award, enzyme, theory, university, chemical_element, location, organization, discipline\nGIVEN SENTENCE: Thus , Jupiter and Saturn are gas giants , and Uranus and Neptune are ice giant s , even though the vast majority of the gas and ice in their interiors is a hot , highly dense fluid that gets denser as the center of the planet is approached .\n","prediction_output":null,"prediction_outputs":null,"group":"119","words":["Thus",",","Jupiter","and","Saturn","are","gas","giants",",","and","Uranus","and","Neptune","are","ice","giant","s",",","even","though","the","vast","majority","of","the","gas","and","ice","in","their","interiors","is","a","hot",",","highly","dense","fluid","that","gets","denser","as","the","center","of","the","planet","is","approached","."],"labels":["O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","chemical_compound","scientist","academic_journal","event","astronomical_object","country","protein","award","enzyme","theory","university","chemical_element","location","organization","discipline"]}
{"id":"121.S","dataset":"crossner_science","split":"dev","instance":{"id":"121.S","prompt_labels":"This(O) subcategory(O) includes(O) Pluto(B-astronomical_object) ,(O) Haumea(B-astronomical_object) ,(O) Makemake(B-astronomical_object) and(O) Eris(B-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, country, event, chemical_element, protein, university, discipline, theory, organization, award, enzyme, astronomical_object, location, academic_journal, scientist, person\nGIVEN SENTENCE: This subcategory includes Pluto , Haumea , Makemake and Eris .\n","prediction_output":null,"prediction_outputs":null,"group":"121","words":["This","subcategory","includes","Pluto",",","Haumea",",","Makemake","and","Eris","."],"labels":["O","O","O","B-astronomical_object","O","B-astronomical_object","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","country","event","chemical_element","protein","university","discipline","theory","organization","award","enzyme","astronomical_object","location","academic_journal","scientist","person"]}
{"id":"122.S","dataset":"crossner_science","split":"dev","instance":{"id":"122.S","prompt_labels":"Since(O) then(O) ,(O) names(O) have(O) been(O) given(O) to(O) 134(O) additional(O) satellites(O) :(O) 57(O) satellites(O) of(O) Jupiter(B-astronomical_object) ,(O) 43(O) of(O) Saturn(B-astronomical_object) ,(O) 22(O) of(O) Uranus(B-astronomical_object) ,(O) 12(O) of(O) Neptune(B-astronomical_object) ,(O) 5(O) of(O) Pluto(B-astronomical_object) ,(O) 1(O) of(O) Eris(B-astronomical_object) ,(O) and(O) 2(O) of(O) Haumea(B-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: enzyme, protein, discipline, location, country, astronomical_object, chemical_element, scientist, chemical_compound, event, academic_journal, person, theory, award, organization, university\nGIVEN SENTENCE: Since then , names have been given to 134 additional satellites : 57 satellites of Jupiter , 43 of Saturn , 22 of Uranus , 12 of Neptune , 5 of Pluto , 1 of Eris , and 2 of Haumea .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Since","then",",","names","have","been","given","to","134","additional","satellites",":","57","satellites","of","Jupiter",",","43","of","Saturn",",","22","of","Uranus",",","12","of","Neptune",",","5","of","Pluto",",","1","of","Eris",",","and","2","of","Haumea","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","B-astronomical_object","O","O","O","B-astronomical_object","O","O","O","B-astronomical_object","O","O","O","B-astronomical_object","O","O","O","B-astronomical_object","O","O","O","O","B-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["enzyme","protein","discipline","location","country","astronomical_object","chemical_element","scientist","chemical_compound","event","academic_journal","person","theory","award","organization","university"]}
{"id":"123.S","dataset":"crossner_science","split":"dev","instance":{"id":"123.S","prompt_labels":"A(O) super-Earth(O) is(O) an(O) extrasolar(O) planet(O) with(O) a(O) mass(O) higher(O) than(O) Earth(B-astronomical_object) '(O) s(O) ,(O) but(O) substantially(O) below(O) those(O) of(O) the(O) Solar(O) System(O) 's(O) ice(O) giant(O) s(O) ,(O) Uranus(B-astronomical_object) and(O) Neptune(B-astronomical_object) ,(O) which(O) are(O) 14.5(O) and(O) 17(O) times(O) Earth(B-astronomical_object) 's(O) ,(O) respectively(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, person, chemical_element, country, location, theory, organization, chemical_compound, scientist, university, protein, discipline, enzyme, event, astronomical_object, academic_journal\nGIVEN SENTENCE: A super-Earth is an extrasolar planet with a mass higher than Earth ' s , but substantially below those of the Solar System 's ice giant s , Uranus and Neptune , which are 14.5 and 17 times Earth 's , respectively .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["A","super-Earth","is","an","extrasolar","planet","with","a","mass","higher","than","Earth","'","s",",","but","substantially","below","those","of","the","Solar","System","'s","ice","giant","s",",","Uranus","and","Neptune",",","which","are","14.5","and","17","times","Earth","'s",",","respectively","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","person","chemical_element","country","location","theory","organization","chemical_compound","scientist","university","protein","discipline","enzyme","event","astronomical_object","academic_journal"]}
{"id":"124.S","dataset":"crossner_science","split":"dev","instance":{"id":"124.S","prompt_labels":"Cooper(B-person) was(O) a(O) member(O) of(O) the(O) Society(B-organization) of(I-organization) Experimental(I-organization) Test(I-organization) Pilots(I-organization) ,(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization) ,(O) the(O) American(B-organization) Astronautical(I-organization) Society(I-organization) ,(O) Scottish(O) Rite(O) and(O) York(O) Rite(O) Masons(O) ,(O) Shriners(B-organization) ,(O) the(O) Royal(B-organization) Order(I-organization) of(I-organization) Jesters(I-organization) ,(O) the(O) Rotary(B-organization) Club(I-organization) ,(O) Order(B-organization) of(I-organization) Daedalians(I-organization) ,(O) Confederate(B-organization) Air(I-organization) Force(I-organization) ,(O) Adventurers(B-organization) '(I-organization) Club(I-organization) of(O) Los(B-location) Angeles(I-location) ,(O) and(O) Boy(B-organization) Scouts(I-organization) of(I-organization) America(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, discipline, academic_journal, event, theory, chemical_element, person, astronomical_object, country, location, award, organization, scientist, enzyme, university, chemical_compound\nGIVEN SENTENCE: Cooper was a member of the Society of Experimental Test Pilots , the American Institute of Aeronautics and Astronautics , the American Astronautical Society , Scottish Rite and York Rite Masons , Shriners , the Royal Order of Jesters , the Rotary Club , Order of Daedalians , Confederate Air Force , Adventurers ' Club of Los Angeles , and Boy Scouts of America .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["Cooper","was","a","member","of","the","Society","of","Experimental","Test","Pilots",",","the","American","Institute","of","Aeronautics","and","Astronautics",",","the","American","Astronautical","Society",",","Scottish","Rite","and","York","Rite","Masons",",","Shriners",",","the","Royal","Order","of","Jesters",",","the","Rotary","Club",",","Order","of","Daedalians",",","Confederate","Air","Force",",","Adventurers","'","Club","of","Los","Angeles",",","and","Boy","Scouts","of","America","."],"labels":["B-person","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","B-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","B-location","I-location","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["protein","discipline","academic_journal","event","theory","chemical_element","person","astronomical_object","country","location","award","organization","scientist","enzyme","university","chemical_compound"]}
{"id":"127.S","dataset":"crossner_science","split":"dev","instance":{"id":"127.S","prompt_labels":"Portions(O) of(O) Galveston(B-location) County(I-location) are(O) served(O) by(O) College(B-university) of(I-university) the(I-university) Mainland(I-university) and(O) Galveston(B-university) College(I-university) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: country, discipline, person, academic_journal, theory, chemical_element, astronomical_object, university, location, protein, event, organization, award, enzyme, chemical_compound, scientist\nGIVEN SENTENCE: Portions of Galveston County are served by College of the Mainland and Galveston College .\n","prediction_output":null,"prediction_outputs":null,"group":"127","words":["Portions","of","Galveston","County","are","served","by","College","of","the","Mainland","and","Galveston","College","."],"labels":["O","O","B-location","I-location","O","O","O","B-university","I-university","I-university","I-university","O","B-university","I-university","O"],"target_index":null,"target_label":null},"label_list":["country","discipline","person","academic_journal","theory","chemical_element","astronomical_object","university","location","protein","event","organization","award","enzyme","chemical_compound","scientist"]}
{"id":"128.S","dataset":"crossner_science","split":"dev","instance":{"id":"128.S","prompt_labels":"This(O) range(O) ,(O) as(O) well(O) as(O) the(O) relative(O) speeds(O) between(O) the(O) planets(O) ,(O) led(O) Kepler(B-scientist) to(O) conclude(O) that(O) the(O) Solar(O) System(O) was(O) composed(O) of(O) two(O) basses(O) ((O) Saturn(B-astronomical_object) and(O) Jupiter(B-astronomical_object) )(O) ,(O) a(O) tenor(O) ((O) Mars(B-astronomical_object) )(O) ,(O) two(O) altos(O) ((O) Venus(B-astronomical_object) and(O) Earth(B-astronomical_object) )(O) ,(O) and(O) a(O) soprano(O) ((O) Mercury(B-astronomical_object) )(O) ,(O) which(O) had(O) sung(O) in(O) perfect(O) concord(O) ,(O) at(O) the(O) beginning(O) of(O) time(O) ,(O) and(O) could(O) potentially(O) arrange(O) themselves(O) to(O) do(O) so(O) again(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, chemical_compound, award, event, country, scientist, organization, theory, chemical_element, astronomical_object, location, university, discipline, protein, enzyme, academic_journal\nGIVEN SENTENCE: This range , as well as the relative speeds between the planets , led Kepler to conclude that the Solar System was composed of two basses ( Saturn and Jupiter ) , a tenor ( Mars ) , two altos ( Venus and Earth ) , and a soprano ( Mercury ) , which had sung in perfect concord , at the beginning of time , and could potentially arrange themselves to do so again .\n","prediction_output":null,"prediction_outputs":null,"group":"128","words":["This","range",",","as","well","as","the","relative","speeds","between","the","planets",",","led","Kepler","to","conclude","that","the","Solar","System","was","composed","of","two","basses","(","Saturn","and","Jupiter",")",",","a","tenor","(","Mars",")",",","two","altos","(","Venus","and","Earth",")",",","and","a","soprano","(","Mercury",")",",","which","had","sung","in","perfect","concord",",","at","the","beginning","of","time",",","and","could","potentially","arrange","themselves","to","do","so","again","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","O","O","O","O","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","chemical_compound","award","event","country","scientist","organization","theory","chemical_element","astronomical_object","location","university","discipline","protein","enzyme","academic_journal"]}
{"id":"129.S","dataset":"crossner_science","split":"dev","instance":{"id":"129.S","prompt_labels":"Many(O) families(O) of(O) proteins(O) act(O) as(O) negative(O) regulators(O) categorized(O) into(O) either(O) antiapoptotic(O) factors(O) ,(O) such(O) as(O) IAP(B-protein) nowiki(O) /(O) s(O) and(O) Bcl-2(B-protein) family(I-protein) proteins(O) or(O) prosurvival(O) factors(O) like(O) cFLIP(B-protein) ,(O) BNIP3(B-protein) ,(O) FADD(B-protein) ,(O) Protein(B-protein) kinase(I-protein) B(I-protein) ,(O) and(O) NF-κB(B-protein) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: discipline, award, chemical_element, astronomical_object, organization, person, scientist, location, event, academic_journal, theory, chemical_compound, protein, university, country, enzyme\nGIVEN SENTENCE: Many families of proteins act as negative regulators categorized into either antiapoptotic factors , such as IAP nowiki / s and Bcl-2 family proteins or prosurvival factors like cFLIP , BNIP3 , FADD , Protein kinase B , and NF-κB .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["Many","families","of","proteins","act","as","negative","regulators","categorized","into","either","antiapoptotic","factors",",","such","as","IAP","nowiki","/","s","and","Bcl-2","family","proteins","or","prosurvival","factors","like","cFLIP",",","BNIP3",",","FADD",",","Protein","kinase","B",",","and","NF-κB","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","B-protein","I-protein","O","O","O","O","O","B-protein","O","B-protein","O","B-protein","O","B-protein","I-protein","I-protein","O","O","B-protein","O"],"target_index":null,"target_label":null},"label_list":["discipline","award","chemical_element","astronomical_object","organization","person","scientist","location","event","academic_journal","theory","chemical_compound","protein","university","country","enzyme"]}
{"id":"130.S","dataset":"crossner_science","split":"dev","instance":{"id":"130.S","prompt_labels":"Seven(O) other(O) objects(O) are(O) classified(O) as(O) both(O) periodic(O) comets(O) and(O) numbered(O) asteroids(O) :(O) 2060(B-astronomical_object) Chiron(I-astronomical_object) ((O) 95P(B-astronomical_object) /(I-astronomical_object) Chiron(I-astronomical_object) )(O) ,(O) 4015(B-astronomical_object) Wilson-Harrington(I-astronomical_object) ((O) 107P(B-astronomical_object) /(I-astronomical_object) Wilson-Harrington(I-astronomical_object) )(O) ,(O) 7968(B-astronomical_object) Elst-Pizarro(I-astronomical_object) ((O) 133P(B-astronomical_object) /(I-astronomical_object) Elst-Pizarro(I-astronomical_object) )(O) ,(O) 60558(B-astronomical_object) Echeclus(I-astronomical_object) ((O) 174P(B-astronomical_object) /(I-astronomical_object) Echeclus(I-astronomical_object) )(O) ,(O) ((O) 362P(B-astronomical_object) /(I-astronomical_object) 2008(I-astronomical_object) GOsub98(I-astronomical_object) /(I-astronomical_object) sub(I-astronomical_object) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_element, event, chemical_compound, award, university, location, organization, scientist, person, astronomical_object, academic_journal, enzyme, discipline, theory, country, protein\nGIVEN SENTENCE: Seven other objects are classified as both periodic comets and numbered asteroids : 2060 Chiron ( 95P / Chiron ) , 4015 Wilson-Harrington ( 107P / Wilson-Harrington ) , 7968 Elst-Pizarro ( 133P / Elst-Pizarro ) , 60558 Echeclus ( 174P / Echeclus ) , ( 362P / 2008 GOsub98 / sub ) .\n","prediction_output":null,"prediction_outputs":null,"group":"130","words":["Seven","other","objects","are","classified","as","both","periodic","comets","and","numbered","asteroids",":","2060","Chiron","(","95P","/","Chiron",")",",","4015","Wilson-Harrington","(","107P","/","Wilson-Harrington",")",",","7968","Elst-Pizarro","(","133P","/","Elst-Pizarro",")",",","60558","Echeclus","(","174P","/","Echeclus",")",",","(","362P","/","2008","GOsub98","/","sub",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","I-astronomical_object","O","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","I-astronomical_object","O","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","I-astronomical_object","O","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","I-astronomical_object","O","O","O","B-astronomical_object","I-astronomical_object","I-astronomical_object","I-astronomical_object","I-astronomical_object","I-astronomical_object","O","O"],"target_index":null,"target_label":null},"label_list":["chemical_element","event","chemical_compound","award","university","location","organization","scientist","person","astronomical_object","academic_journal","enzyme","discipline","theory","country","protein"]}
{"id":"134.S","dataset":"crossner_science","split":"dev","instance":{"id":"134.S","prompt_labels":"The(O) Montreal(B-organization) Neurological(I-organization) Institute(I-organization) ,(O) the(O) former(O) Royal(B-organization) Victoria(I-organization) Hospital(I-organization) ,(O) Allan(B-organization) Memorial(I-organization) Institute(I-organization) and(O) the(O) Montreal(B-organization) General(I-organization) Hospital(I-organization) of(I-organization) McGill(I-organization) University(I-organization) are(O) on(O) Pine(B-location) Avenue(I-location) ,(O) as(O) is(O) Cormier(B-location) House(I-location) ,(O) the(O) former(O) residence(O) of(O) Pierre(B-person) Elliott(I-person) Trudeau(I-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, award, theory, chemical_element, enzyme, country, location, astronomical_object, event, scientist, organization, university, discipline, academic_journal, person, chemical_compound\nGIVEN SENTENCE: The Montreal Neurological Institute , the former Royal Victoria Hospital , Allan Memorial Institute and the Montreal General Hospital of McGill University are on Pine Avenue , as is Cormier House , the former residence of Pierre Elliott Trudeau .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["The","Montreal","Neurological","Institute",",","the","former","Royal","Victoria","Hospital",",","Allan","Memorial","Institute","and","the","Montreal","General","Hospital","of","McGill","University","are","on","Pine","Avenue",",","as","is","Cormier","House",",","the","former","residence","of","Pierre","Elliott","Trudeau","."],"labels":["O","B-organization","I-organization","I-organization","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","I-location","O","O","O","B-location","I-location","O","O","O","O","O","B-person","I-person","I-person","O"],"target_index":null,"target_label":null},"label_list":["protein","award","theory","chemical_element","enzyme","country","location","astronomical_object","event","scientist","organization","university","discipline","academic_journal","person","chemical_compound"]}
{"id":"137.S","dataset":"crossner_science","split":"dev","instance":{"id":"137.S","prompt_labels":"García-Sastre(B-scientist) is(O) an(O) editor(O) for(O) the(O) Journal(B-academic_journal) of(I-academic_journal) Experimental(I-academic_journal) Medicine(I-academic_journal) and(O) PLOS(B-academic_journal) Pathogens(I-academic_journal) ,(O) and(O) he(O) sits(O) on(O) the(O) editorial(O) boards(O) of(O) the(O) Journal(B-academic_journal) of(I-academic_journal) Virology(I-academic_journal) ,(O) Virology(B-academic_journal) ,(O) Virus(B-academic_journal) Research(I-academic_journal) and(O) the(O) Journal(B-academic_journal) of(I-academic_journal) General(I-academic_journal) Virology(I-academic_journal) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, chemical_element, university, astronomical_object, theory, event, country, discipline, chemical_compound, award, scientist, organization, enzyme, location, protein, academic_journal\nGIVEN SENTENCE: García-Sastre is an editor for the Journal of Experimental Medicine and PLOS Pathogens , and he sits on the editorial boards of the Journal of Virology , Virology , Virus Research and the Journal of General Virology .\n","prediction_output":null,"prediction_outputs":null,"group":"137","words":["García-Sastre","is","an","editor","for","the","Journal","of","Experimental","Medicine","and","PLOS","Pathogens",",","and","he","sits","on","the","editorial","boards","of","the","Journal","of","Virology",",","Virology",",","Virus","Research","and","the","Journal","of","General","Virology","."],"labels":["B-scientist","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","O","B-academic_journal","I-academic_journal","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O"],"target_index":null,"target_label":null},"label_list":["person","chemical_element","university","astronomical_object","theory","event","country","discipline","chemical_compound","award","scientist","organization","enzyme","location","protein","academic_journal"]}
{"id":"139.S","dataset":"crossner_science","split":"dev","instance":{"id":"139.S","prompt_labels":"Some(O) of(O) these(O) mechanisms(O) include(O) ATP-dependent(O) chromatin(O) remodeling(O) ,(O) LINE1(B-protein) ,(O) and(O) prion(B-protein) protein-based(O) modifications(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, country, enzyme, scientist, theory, chemical_compound, discipline, chemical_element, university, organization, event, award, person, location, astronomical_object, academic_journal\nGIVEN SENTENCE: Some of these mechanisms include ATP-dependent chromatin remodeling , LINE1 , and prion protein-based modifications .\n","prediction_output":null,"prediction_outputs":null,"group":"139","words":["Some","of","these","mechanisms","include","ATP-dependent","chromatin","remodeling",",","LINE1",",","and","prion","protein-based","modifications","."],"labels":["O","O","O","O","O","O","O","O","O","B-protein","O","O","B-protein","O","O","O"],"target_index":null,"target_label":null},"label_list":["protein","country","enzyme","scientist","theory","chemical_compound","discipline","chemical_element","university","organization","event","award","person","location","astronomical_object","academic_journal"]}
{"id":"141.S","dataset":"crossner_science","split":"dev","instance":{"id":"141.S","prompt_labels":"A(O) stretch(O) of(O) road(O) in(O) the(O) natural(O) park(O) is(O) notable(O) for(O) being(O) the(O) scene(O) in(O) the(O) 1969(O) James(B-person) Bond(I-person) film(O) On(O) Her(O) Majesty(O) 's(O) Secret(O) Service(O) where(O) Tracy(B-person) Bond(I-person) ((O) played(O) by(O) Diana(B-person) Rigg(I-person) )(O) is(O) shot(O) dead(O) by(O) Irma(O) Bunt(O) ((O) Ilse(B-person) Steppat(I-person) )(O) in(O) a(O) drive-by(B-person) shooting(I-person) at(O) the(O) end(O) of(O) the(O) film.(O) at(O) the(O) Internet(O) Movie(O) Database(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, person, organization, university, enzyme, astronomical_object, discipline, chemical_element, protein, chemical_compound, country, award, academic_journal, event, location, scientist\nGIVEN SENTENCE: A stretch of road in the natural park is notable for being the scene in the 1969 James Bond film On Her Majesty 's Secret Service where Tracy Bond ( played by Diana Rigg ) is shot dead by Irma Bunt ( Ilse Steppat ) in a drive-by shooting at the end of the film. at the Internet Movie Database\n","prediction_output":null,"prediction_outputs":null,"group":"141","words":["A","stretch","of","road","in","the","natural","park","is","notable","for","being","the","scene","in","the","1969","James","Bond","film","On","Her","Majesty","'s","Secret","Service","where","Tracy","Bond","(","played","by","Diana","Rigg",")","is","shot","dead","by","Irma","Bunt","(","Ilse","Steppat",")","in","a","drive-by","shooting","at","the","end","of","the","film.","at","the","Internet","Movie","Database"],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["theory","person","organization","university","enzyme","astronomical_object","discipline","chemical_element","protein","chemical_compound","country","award","academic_journal","event","location","scientist"]}
{"id":"144.S","dataset":"crossner_science","split":"dev","instance":{"id":"144.S","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(B-enzyme) methyltransferase(I-enzyme) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, scientist, chemical_element, enzyme, university, protein, location, organization, chemical_compound, theory, discipline, award, person, country, astronomical_object, academic_journal\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":null},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"146.S","dataset":"crossner_science","split":"dev","instance":{"id":"146.S","prompt_labels":"Chiron(B-astronomical_object) 's(O) orbit(O) was(O) found(O) to(O) be(O) highly(O) eccentric(O) ((O) 0.37(O) )(O) ,(O) with(O) perihelion(O) just(O) inside(O) the(O) orbit(O) of(O) Saturn(B-astronomical_object) and(O) aphelion(O) just(O) outside(O) the(O) perihelion(O) of(O) Uranus(B-astronomical_object) ((O) it(O) does(O) not(O) reach(O) the(O) average(O) distance(O) of(O) Uranus(B-astronomical_object) ,(O) however(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: scientist, discipline, organization, chemical_element, theory, country, protein, astronomical_object, university, academic_journal, chemical_compound, award, enzyme, location, event, person\nGIVEN SENTENCE: Chiron 's orbit was found to be highly eccentric ( 0.37 ) , with perihelion just inside the orbit of Saturn and aphelion just outside the perihelion of Uranus ( it does not reach the average distance of Uranus , however ) .\n","prediction_output":null,"prediction_outputs":null,"group":"146","words":["Chiron","'s","orbit","was","found","to","be","highly","eccentric","(","0.37",")",",","with","perihelion","just","inside","the","orbit","of","Saturn","and","aphelion","just","outside","the","perihelion","of","Uranus","(","it","does","not","reach","the","average","distance","of","Uranus",",","however",")","."],"labels":["B-astronomical_object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","O","O","O","O","O","O","B-astronomical_object","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["scientist","discipline","organization","chemical_element","theory","country","protein","astronomical_object","university","academic_journal","chemical_compound","award","enzyme","location","event","person"]}
{"id":"147.S","dataset":"crossner_science","split":"dev","instance":{"id":"147.S","prompt_labels":"In(O) fact(O) ,(O) it(O) is(O) the(O) third(O) dimmest(O) of(O) the(O) first(O) twenty-three(O) asteroids(O) discovered(O) ,(O) with(O) only(O) 13(B-astronomical_object) Egeria(I-astronomical_object) and(O) 17(B-astronomical_object) Thetis(I-astronomical_object) having(O) lower(O) mean(O) opposition(O) magnitude(O) s(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: enzyme, organization, protein, chemical_element, location, country, astronomical_object, university, award, discipline, person, chemical_compound, academic_journal, theory, event, scientist\nGIVEN SENTENCE: In fact , it is the third dimmest of the first twenty-three asteroids discovered , with only 13 Egeria and 17 Thetis having lower mean opposition magnitude s .\n","prediction_output":null,"prediction_outputs":null,"group":"147","words":["In","fact",",","it","is","the","third","dimmest","of","the","first","twenty-three","asteroids","discovered",",","with","only","13","Egeria","and","17","Thetis","having","lower","mean","opposition","magnitude","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["enzyme","organization","protein","chemical_element","location","country","astronomical_object","university","award","discipline","person","chemical_compound","academic_journal","theory","event","scientist"]}
{"id":"148.S","dataset":"crossner_science","split":"dev","instance":{"id":"148.S","prompt_labels":"The(O) amino(O) acid(O) sequence(O) of(O) arginine(B-protein) vasopressin(I-protein) ((O) argipressin(B-protein) )(O) is(O) Cys(B-chemical_compound) -(O) Tyr(B-chemical_compound) -(O) Phenylalanine(B-chemical_compound) -(O) Gln(B-chemical_compound) -(O) Asn(B-chemical_compound) -(O) Cysteine(B-chemical_compound) -(O) Pro(B-chemical_compound) -(O) Arg(B-chemical_compound) -(O) Gly(B-chemical_compound) -NHsub2(B-chemical_compound) /(I-chemical_compound) sub(I-chemical_compound) ,(O) with(O) the(O) cysteine(O) residues(O) forming(O) a(O) disulfide(B-chemical_compound) bond(I-chemical_compound) and(O) the(O) C(O) -terminus(O) of(O) the(O) sequence(O) converted(O) to(O) a(O) primary(B-chemical_compound) amide(I-chemical_compound) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, discipline, enzyme, person, astronomical_object, academic_journal, university, award, scientist, organization, protein, location, country, theory, chemical_element, event\nGIVEN SENTENCE: The amino acid sequence of arginine vasopressin ( argipressin ) is Cys - Tyr - Phenylalanine - Gln - Asn - Cysteine - Pro - Arg - Gly -NHsub2 / sub , with the cysteine residues forming a disulfide bond and the C -terminus of the sequence converted to a primary amide .\n","prediction_output":null,"prediction_outputs":null,"group":"148","words":["The","amino","acid","sequence","of","arginine","vasopressin","(","argipressin",")","is","Cys","-","Tyr","-","Phenylalanine","-","Gln","-","Asn","-","Cysteine","-","Pro","-","Arg","-","Gly","-NHsub2","/","sub",",","with","the","cysteine","residues","forming","a","disulfide","bond","and","the","C","-terminus","of","the","sequence","converted","to","a","primary","amide","."],"labels":["O","O","O","O","O","B-protein","I-protein","O","B-protein","O","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","O","B-chemical_compound","B-chemical_compound","I-chemical_compound","I-chemical_compound","O","O","O","O","O","O","O","B-chemical_compound","I-chemical_compound","O","O","O","O","O","O","O","O","O","O","B-chemical_compound","I-chemical_compound","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","discipline","enzyme","person","astronomical_object","academic_journal","university","award","scientist","organization","protein","location","country","theory","chemical_element","event"]}
{"id":"150.S","dataset":"crossner_science","split":"dev","instance":{"id":"150.S","prompt_labels":"Eduard(B-scientist) Otto(I-scientist) Emil(I-scientist) Karl(I-scientist) Adam(I-scientist) Freiherr(I-scientist) von(I-scientist) Stackelberg(I-scientist) ((O) 6(O) November(O) 1867(O) in(O) Sillamäe(B-location) ,(O) Estonia(B-country) -(O) 7(O) April(O) 1943(O) in(O) Munich(B-location) ,(O) Nazi(B-country) Germany(I-country) )(O) was(O) an(O) Estonian(O) chemist(O) ,(O) landowner(O) and(O) politician(O) who(O) belonged(O) to(O) the(O) Stackelberg(O) family(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, theory, country, chemical_element, discipline, scientist, academic_journal, person, enzyme, astronomical_object, chemical_compound, award, university, location, protein, organization\nGIVEN SENTENCE: Eduard Otto Emil Karl Adam Freiherr von Stackelberg ( 6 November 1867 in Sillamäe , Estonia - 7 April 1943 in Munich , Nazi Germany ) was an Estonian chemist , landowner and politician who belonged to the Stackelberg family .\n","prediction_output":null,"prediction_outputs":null,"group":"150","words":["Eduard","Otto","Emil","Karl","Adam","Freiherr","von","Stackelberg","(","6","November","1867","in","Sillamäe",",","Estonia","-","7","April","1943","in","Munich",",","Nazi","Germany",")","was","an","Estonian","chemist",",","landowner","and","politician","who","belonged","to","the","Stackelberg","family","."],"labels":["B-scientist","I-scientist","I-scientist","I-scientist","I-scientist","I-scientist","I-scientist","I-scientist","O","O","O","O","O","B-location","O","B-country","O","O","O","O","O","B-location","O","B-country","I-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","theory","country","chemical_element","discipline","scientist","academic_journal","person","enzyme","astronomical_object","chemical_compound","award","university","location","protein","organization"]}
{"id":"151.S","dataset":"crossner_science","split":"dev","instance":{"id":"151.S","prompt_labels":"The(O) scientists(O) found(O) that(O) while(O) CRISPR(O) could(O) effectively(O) cleave(O) the(O) β-globin(O) gene(O) ((O) HBB(B-protein) )(O) ,(O) the(O) efficiency(O) of(O) homologous(O) recombination(O) directed(O) repair(O) of(O) HBB(B-protein) was(O) highly(O) inefficient(O) and(O) did(O) not(O) do(O) so(O) in(O) a(O) majority(O) of(O) the(O) trials(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, protein, event, university, theory, discipline, chemical_compound, location, country, chemical_element, scientist, organization, enzyme, academic_journal, person, astronomical_object\nGIVEN SENTENCE: The scientists found that while CRISPR could effectively cleave the β-globin gene ( HBB ) , the efficiency of homologous recombination directed repair of HBB was highly inefficient and did not do so in a majority of the trials .\n","prediction_output":null,"prediction_outputs":null,"group":"151","words":["The","scientists","found","that","while","CRISPR","could","effectively","cleave","the","β-globin","gene","(","HBB",")",",","the","efficiency","of","homologous","recombination","directed","repair","of","HBB","was","highly","inefficient","and","did","not","do","so","in","a","majority","of","the","trials","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","protein","event","university","theory","discipline","chemical_compound","location","country","chemical_element","scientist","organization","enzyme","academic_journal","person","astronomical_object"]}
{"id":"153.S","dataset":"crossner_science","split":"dev","instance":{"id":"153.S","prompt_labels":"In(O) this(O) respect(O) he(O) was(O) the(O) equivalent(O) of(O) Mars(B-astronomical_object) ,(O) Janus(B-astronomical_object) ,(O) Saturn(B-astronomical_object) and(O) even(O) Jupiter(B-astronomical_object) among(O) Latin(O) tribes(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, person, discipline, award, protein, country, enzyme, chemical_compound, chemical_element, astronomical_object, university, location, event, scientist, theory, academic_journal\nGIVEN SENTENCE: In this respect he was the equivalent of Mars , Janus , Saturn and even Jupiter among Latin tribes .\n","prediction_output":null,"prediction_outputs":null,"group":"153","words":["In","this","respect","he","was","the","equivalent","of","Mars",",","Janus",",","Saturn","and","even","Jupiter","among","Latin","tribes","."],"labels":["O","O","O","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O","B-astronomical_object","O","O","B-astronomical_object","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","person","discipline","award","protein","country","enzyme","chemical_compound","chemical_element","astronomical_object","university","location","event","scientist","theory","academic_journal"]}
{"id":"154.S","dataset":"crossner_science","split":"dev","instance":{"id":"154.S","prompt_labels":"His(O) work(O) has(O) been(O) published(O) in(O) international(O) refereed(O) journals(O) ,(O) including(O) American(B-academic_journal) Economic(I-academic_journal) Review(I-academic_journal) ,(O) Journal(O) of(O) European(B-academic_journal) Economic(I-academic_journal) Association(I-academic_journal) ,(O) Journal(B-academic_journal) of(I-academic_journal) Economic(I-academic_journal) Perspectives(I-academic_journal) ,(O) Economic(B-academic_journal) Journal(I-academic_journal) and(O) American(B-academic_journal) Political(I-academic_journal) Science(I-academic_journal) Review(I-academic_journal) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, chemical_compound, discipline, enzyme, scientist, country, theory, location, protein, astronomical_object, award, organization, event, academic_journal, chemical_element, university\nGIVEN SENTENCE: His work has been published in international refereed journals , including American Economic Review , Journal of European Economic Association , Journal of Economic Perspectives , Economic Journal and American Political Science Review .\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["His","work","has","been","published","in","international","refereed","journals",",","including","American","Economic","Review",",","Journal","of","European","Economic","Association",",","Journal","of","Economic","Perspectives",",","Economic","Journal","and","American","Political","Science","Review","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O"],"target_index":null,"target_label":null},"label_list":["person","chemical_compound","discipline","enzyme","scientist","country","theory","location","protein","astronomical_object","award","organization","event","academic_journal","chemical_element","university"]}
{"id":"155.S","dataset":"crossner_science","split":"dev","instance":{"id":"155.S","prompt_labels":"Known(O) for(O) his(O) research(O) on(O) Mitogen-activated(B-enzyme) protein(I-enzyme) kinase(I-enzyme) ((O) MAPK(B-enzyme) )(O) cascade(O) in(O) plants(O) ,(O) he(O) is(O) a(O) three-time(O) Alexander(B-award) von(I-award) Humboldt(I-award) Fellow(I-award) and(O) an(O) elected(O) fellow(B-award) of(I-award) the(I-award) National(I-award) Academy(I-award) of(I-award) Sciences(I-award) ,(O) India(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, scientist, enzyme, location, academic_journal, astronomical_object, protein, event, theory, chemical_compound, discipline, country, university, award, chemical_element, person\nGIVEN SENTENCE: Known for his research on Mitogen-activated protein kinase ( MAPK ) cascade in plants , he is a three-time Alexander von Humboldt Fellow and an elected fellow of the National Academy of Sciences , India .\n","prediction_output":null,"prediction_outputs":null,"group":"155","words":["Known","for","his","research","on","Mitogen-activated","protein","kinase","(","MAPK",")","cascade","in","plants",",","he","is","a","three-time","Alexander","von","Humboldt","Fellow","and","an","elected","fellow","of","the","National","Academy","of","Sciences",",","India","."],"labels":["O","O","O","O","O","B-enzyme","I-enzyme","I-enzyme","O","B-enzyme","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["organization","scientist","enzyme","location","academic_journal","astronomical_object","protein","event","theory","chemical_compound","discipline","country","university","award","chemical_element","person"]}
{"id":"156.S","dataset":"crossner_science","split":"dev","instance":{"id":"156.S","prompt_labels":"An(O) approved(O) residency(O) program(O) and(O) certification(O) ((O) in(O) the(O) U.S.(B-country) ,(O) the(O) American(B-organization) Board(I-organization) of(I-organization) Pathology(I-organization) or(O) the(O) American(B-organization) Osteopathic(I-organization) Board(I-organization) of(I-organization) Pathology(I-organization) )(O) is(O) usually(O) required(O) to(O) obtain(O) employment(O) or(O) hospital(O) privileges(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, organization, location, protein, person, university, scientist, country, event, chemical_element, discipline, astronomical_object, award, academic_journal, enzyme, theory\nGIVEN SENTENCE: An approved residency program and certification ( in the U.S. , the American Board of Pathology or the American Osteopathic Board of Pathology ) is usually required to obtain employment or hospital privileges .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["An","approved","residency","program","and","certification","(","in","the","U.S.",",","the","American","Board","of","Pathology","or","the","American","Osteopathic","Board","of","Pathology",")","is","usually","required","to","obtain","employment","or","hospital","privileges","."],"labels":["O","O","O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","organization","location","protein","person","university","scientist","country","event","chemical_element","discipline","astronomical_object","award","academic_journal","enzyme","theory"]}
{"id":"157.S","dataset":"crossner_science","split":"dev","instance":{"id":"157.S","prompt_labels":"Singer(B-scientist) is(O) a(O) member(O) of(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) and(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, theory, organization, chemical_element, location, scientist, academic_journal, award, discipline, enzyme, event, university, chemical_compound, astronomical_object, person, country\nGIVEN SENTENCE: Singer is a member of the National Academy of Sciences and the American Academy of Arts and Sciences .\n","prediction_output":null,"prediction_outputs":null,"group":"157","words":["Singer","is","a","member","of","the","National","Academy","of","Sciences","and","the","American","Academy","of","Arts","and","Sciences","."],"labels":["B-scientist","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":null},"label_list":["protein","theory","organization","chemical_element","location","scientist","academic_journal","award","discipline","enzyme","event","university","chemical_compound","astronomical_object","person","country"]}
{"id":"161.S","dataset":"crossner_science","split":"dev","instance":{"id":"161.S","prompt_labels":"The(O) Perturb-seq(O) protocol(O) uses(O) CRISPR(O) technology(O) to(O) inactivate(O) specific(O) genes(O) and(O) DNA(O) barcoding(O) of(O) each(O) guide(O) RNA(O) to(O) allow(O) for(O) all(O) perturbations(O) to(O) be(O) pooled(O) together(O) and(O) later(O) deconvoluted(O) ,(O) with(O) assignment(O) of(O) each(O) phenotype(O) to(O) a(O) specific(O) guide(O) RNA(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, astronomical_object, discipline, enzyme, chemical_element, protein, theory, scientist, location, university, award, person, organization, chemical_compound, country, academic_journal\nGIVEN SENTENCE: The Perturb-seq protocol uses CRISPR technology to inactivate specific genes and DNA barcoding of each guide RNA to allow for all perturbations to be pooled together and later deconvoluted , with assignment of each phenotype to a specific guide RNA .\n","prediction_output":null,"prediction_outputs":null,"group":"161","words":["The","Perturb-seq","protocol","uses","CRISPR","technology","to","inactivate","specific","genes","and","DNA","barcoding","of","each","guide","RNA","to","allow","for","all","perturbations","to","be","pooled","together","and","later","deconvoluted",",","with","assignment","of","each","phenotype","to","a","specific","guide","RNA","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","astronomical_object","discipline","enzyme","chemical_element","protein","theory","scientist","location","university","award","person","organization","chemical_compound","country","academic_journal"]}
{"id":"164.S","dataset":"crossner_science","split":"dev","instance":{"id":"164.S","prompt_labels":"Published(O) in(O) 1993(O) ,(O) it(O) won(O) the(O) 1994(O) Nebula(B-award) Award(I-award) for(I-award) Best(I-award) Novel(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, enzyme, scientist, discipline, award, university, country, location, astronomical_object, protein, chemical_compound, theory, academic_journal, chemical_element, event, person\nGIVEN SENTENCE: Published in 1993 , it won the 1994 Nebula Award for Best Novel .\n","prediction_output":null,"prediction_outputs":null,"group":"164","words":["Published","in","1993",",","it","won","the","1994","Nebula","Award","for","Best","Novel","."],"labels":["O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":null},"label_list":["organization","enzyme","scientist","discipline","award","university","country","location","astronomical_object","protein","chemical_compound","theory","academic_journal","chemical_element","event","person"]}
{"id":"166.S","dataset":"crossner_science","split":"dev","instance":{"id":"166.S","prompt_labels":"19126(B-astronomical_object) Ottohahn(I-astronomical_object) named(O) in(O) his(O) honor(O) ,(O) as(O) were(O) the(O) Otto(B-award) Hahn(I-award) Prize(I-award) of(I-award) both(I-award) the(I-award) German(I-award) Chemical(I-award) and(I-award) Physical(I-award) Societies(I-award) and(O) the(O) city(O) of(O) Frankfurt(B-location) /(O) Main(O) ,(O) the(O) Otto(B-award) Hahn(I-award) Medal(I-award) ,(O) and(O) the(O) Otto(B-award) Hahn(I-award) Award(I-award) of(I-award) the(I-award) Max(I-award) Planck(I-award) Society(I-award) and(O) ,(O) since(O) 1988(O) ,(O) the(O) Otto(B-award) Hahn(I-award) Peace(I-award) Medal(I-award) in(I-award) Gold(I-award) of(I-award) the(I-award) United(I-award) Nations(I-award) Association(I-award) of(I-award) Germany(I-award) ((O) DGVN(B-organization) )(O) in(O) Berlin(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: enzyme, chemical_compound, discipline, protein, chemical_element, person, theory, astronomical_object, location, award, country, scientist, university, academic_journal, organization, event\nGIVEN SENTENCE: 19126 Ottohahn named in his honor , as were the Otto Hahn Prize of both the German Chemical and Physical Societies and the city of Frankfurt / Main , the Otto Hahn Medal , and the Otto Hahn Award of the Max Planck Society and , since 1988 , the Otto Hahn Peace Medal in Gold of the United Nations Association of Germany ( DGVN ) in Berlin .\n","prediction_output":null,"prediction_outputs":null,"group":"166","words":["19126","Ottohahn","named","in","his","honor",",","as","were","the","Otto","Hahn","Prize","of","both","the","German","Chemical","and","Physical","Societies","and","the","city","of","Frankfurt","/","Main",",","the","Otto","Hahn","Medal",",","and","the","Otto","Hahn","Award","of","the","Max","Planck","Society","and",",","since","1988",",","the","Otto","Hahn","Peace","Medal","in","Gold","of","the","United","Nations","Association","of","Germany","(","DGVN",")","in","Berlin","."],"labels":["B-astronomical_object","I-astronomical_object","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","B-location","O","O","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","B-organization","O","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["enzyme","chemical_compound","discipline","protein","chemical_element","person","theory","astronomical_object","location","award","country","scientist","university","academic_journal","organization","event"]}
{"id":"168.S","dataset":"crossner_science","split":"dev","instance":{"id":"168.S","prompt_labels":"A(O) physician(O) and(O) professor(O) of(O) public(O) health(O) ,(O) he(O) worked(O) first(O) in(O) social(B-discipline) medicine(I-discipline) at(O) the(O) University(B-university) of(I-university) Sassari(I-university) ((O) 1969-1974(O) )(O) and(O) then(O) in(O) occupational(O) health(O) at(O) the(O) Sapienza(B-university) University(I-university) of(I-university) Rome(I-university) ((O) 1975-1999(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: academic_journal, event, protein, country, scientist, discipline, university, person, chemical_compound, location, enzyme, organization, astronomical_object, award, chemical_element, theory\nGIVEN SENTENCE: A physician and professor of public health , he worked first in social medicine at the University of Sassari ( 1969-1974 ) and then in occupational health at the Sapienza University of Rome ( 1975-1999 ) .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["A","physician","and","professor","of","public","health",",","he","worked","first","in","social","medicine","at","the","University","of","Sassari","(","1969-1974",")","and","then","in","occupational","health","at","the","Sapienza","University","of","Rome","(","1975-1999",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-discipline","I-discipline","O","O","B-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["academic_journal","event","protein","country","scientist","discipline","university","person","chemical_compound","location","enzyme","organization","astronomical_object","award","chemical_element","theory"]}
{"id":"169.S","dataset":"crossner_science","split":"dev","instance":{"id":"169.S","prompt_labels":"Segment(O) 7(O) encodes(O) the(O) M1(B-protein) protein(I-protein) and(O) the(O) smaller(O) M2(B-protein) proton(I-protein) channel(I-protein) protein(I-protein) ,(O) which(O) is(O) produced(O) by(O) RNA(O) splicing(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, astronomical_object, academic_journal, enzyme, discipline, organization, location, scientist, chemical_compound, university, event, country, theory, person, protein, chemical_element\nGIVEN SENTENCE: Segment 7 encodes the M1 protein and the smaller M2 proton channel protein , which is produced by RNA splicing .\n","prediction_output":null,"prediction_outputs":null,"group":"169","words":["Segment","7","encodes","the","M1","protein","and","the","smaller","M2","proton","channel","protein",",","which","is","produced","by","RNA","splicing","."],"labels":["O","O","O","O","B-protein","I-protein","O","O","O","B-protein","I-protein","I-protein","I-protein","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["award","astronomical_object","academic_journal","enzyme","discipline","organization","location","scientist","chemical_compound","university","event","country","theory","person","protein","chemical_element"]}
{"id":"173.S","dataset":"crossner_science","split":"dev","instance":{"id":"173.S","prompt_labels":"Among(O) the(O) researchers(O) who(O) laid(O) the(O) foundations(O) of(O) AI(O) were(O) Alan(B-scientist) Turing(I-scientist) ,(O) John(B-scientist) von(I-scientist) Neumann(I-scientist) ,(O) Norbert(B-scientist) Wiener(I-scientist) ,(O) Claude(B-scientist) Shannon(I-scientist) ,(O) Warren(B-scientist) McCullough(I-scientist) ,(O) Walter(B-scientist) Pitts(I-scientist) and(O) Donald(B-scientist) Hebb(I-scientist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, event, academic_journal, theory, chemical_compound, protein, scientist, award, university, organization, enzyme, astronomical_object, location, discipline, country, chemical_element\nGIVEN SENTENCE: Among the researchers who laid the foundations of AI were Alan Turing , John von Neumann , Norbert Wiener , Claude Shannon , Warren McCullough , Walter Pitts and Donald Hebb .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["Among","the","researchers","who","laid","the","foundations","of","AI","were","Alan","Turing",",","John","von","Neumann",",","Norbert","Wiener",",","Claude","Shannon",",","Warren","McCullough",",","Walter","Pitts","and","Donald","Hebb","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"target_index":null,"target_label":null},"label_list":["person","event","academic_journal","theory","chemical_compound","protein","scientist","award","university","organization","enzyme","astronomical_object","location","discipline","country","chemical_element"]}
{"id":"174.S","dataset":"crossner_science","split":"dev","instance":{"id":"174.S","prompt_labels":"The(O) two(O) factions(O) ,(O) Lawrence(B-person) Murphy(I-person) -(O) Dolan(B-person) and(O) John(B-person) Tunstall(I-person) -(O) McSween(B-person) ,(O) fought(O) a(O) series(O) of(O) escalating(O) battles(O) with(O) such(O) murderous(O) ferocity(O) that(O) the(O) repercussions(O) were(O) felt(O) as(O) far(O) away(O) as(O) the(O) state(O) capital(O) Santa(B-location) Fe(I-location) and(O) even(O) in(O) Washington(B-location) ,(I-location) D.C.(I-location)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: discipline, university, location, award, scientist, event, country, astronomical_object, organization, enzyme, theory, chemical_compound, protein, person, academic_journal, chemical_element\nGIVEN SENTENCE: The two factions , Lawrence Murphy - Dolan and John Tunstall - McSween , fought a series of escalating battles with such murderous ferocity that the repercussions were felt as far away as the state capital Santa Fe and even in Washington , D.C.\n","prediction_output":null,"prediction_outputs":null,"group":"174","words":["The","two","factions",",","Lawrence","Murphy","-","Dolan","and","John","Tunstall","-","McSween",",","fought","a","series","of","escalating","battles","with","such","murderous","ferocity","that","the","repercussions","were","felt","as","far","away","as","the","state","capital","Santa","Fe","and","even","in","Washington",",","D.C."],"labels":["O","O","O","O","B-person","I-person","O","B-person","O","B-person","I-person","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","B-location","I-location","I-location"],"target_index":null,"target_label":null},"label_list":["discipline","university","location","award","scientist","event","country","astronomical_object","organization","enzyme","theory","chemical_compound","protein","person","academic_journal","chemical_element"]}
{"id":"176.S","dataset":"crossner_science","split":"dev","instance":{"id":"176.S","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) Dutch(O) astronomer(O) couple(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Cornelis(B-scientist) van(I-scientist) Houten(I-scientist) in(O) collaboration(O) with(O) Dutch-American(O) astronomer(O) Tom(B-scientist) Gehrels(I-scientist) at(O) the(O) U.S.(B-location) Palomar(I-location) Observatory(I-location) in(O) California(B-location) ,(O) and(O) named(O) after(O) Dutch(O) astronomer(O) Gerard(B-scientist) Kuiper(I-scientist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, theory, enzyme, academic_journal, location, discipline, country, university, protein, organization, event, astronomical_object, award, chemical_compound, scientist, chemical_element\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by Dutch astronomer couple Ingrid van Houten-Groeneveld and Cornelis van Houten in collaboration with Dutch-American astronomer Tom Gehrels at the U.S. Palomar Observatory in California , and named after Dutch astronomer Gerard Kuiper .\n","prediction_output":null,"prediction_outputs":null,"group":"176","words":["It","was","discovered","on","24","September","1960",",","by","Dutch","astronomer","couple","Ingrid","van","Houten-Groeneveld","and","Cornelis","van","Houten","in","collaboration","with","Dutch-American","astronomer","Tom","Gehrels","at","the","U.S.","Palomar","Observatory","in","California",",","and","named","after","Dutch","astronomer","Gerard","Kuiper","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","O","O","O","O","B-scientist","I-scientist","O","O","B-location","I-location","I-location","O","B-location","O","O","O","O","O","O","B-scientist","I-scientist","O"],"target_index":null,"target_label":null},"label_list":["person","theory","enzyme","academic_journal","location","discipline","country","university","protein","organization","event","astronomical_object","award","chemical_compound","scientist","chemical_element"]}
{"id":"177.S","dataset":"crossner_science","split":"dev","instance":{"id":"177.S","prompt_labels":"He(O) was(O) internationally(O) recognized(O) with(O) membership(O) in(O) the(O) Japan(B-organization) Academy(I-organization) and(O) the(O) Brazilian(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) and(O) in(O) 1959(O) was(O) appointed(O) a(O) member(O) of(O) the(O) Board(O) of(O) Governors(O) of(O) the(O) Weizmann(B-university) Institute(I-university) of(I-university) Science(I-university) in(O) Israel(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: chemical_compound, discipline, enzyme, academic_journal, award, scientist, protein, theory, organization, astronomical_object, event, country, person, location, chemical_element, university\nGIVEN SENTENCE: He was internationally recognized with membership in the Japan Academy and the Brazilian Academy of Sciences , and in 1959 was appointed a member of the Board of Governors of the Weizmann Institute of Science in Israel .\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["He","was","internationally","recognized","with","membership","in","the","Japan","Academy","and","the","Brazilian","Academy","of","Sciences",",","and","in","1959","was","appointed","a","member","of","the","Board","of","Governors","of","the","Weizmann","Institute","of","Science","in","Israel","."],"labels":["O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","B-country","O"],"target_index":null,"target_label":null},"label_list":["chemical_compound","discipline","enzyme","academic_journal","award","scientist","protein","theory","organization","astronomical_object","event","country","person","location","chemical_element","university"]}
{"id":"178.S","dataset":"crossner_science","split":"dev","instance":{"id":"178.S","prompt_labels":"Among(O) Einstein(B-scientist) 's(O) well-known(O) friends(O) were(O) Michele(B-person) Besso(I-person) ,(O) Paul(B-scientist) Ehrenfest(I-scientist) ,(O) Marcel(B-scientist) Grossmann(I-scientist) ,(O) János(B-scientist) Plesch(I-scientist) ,(O) Daniel(B-scientist) Q.(I-scientist) Posin(I-scientist) ,(O) Maurice(B-scientist) Solovine(I-scientist) ,(O) and(O) Stephen(B-person) Samuel(I-person) Wise(I-person) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: award, theory, location, chemical_element, chemical_compound, person, scientist, academic_journal, protein, discipline, university, astronomical_object, event, country, enzyme, organization\nGIVEN SENTENCE: Among Einstein 's well-known friends were Michele Besso , Paul Ehrenfest , Marcel Grossmann , János Plesch , Daniel Q. Posin , Maurice Solovine , and Stephen Samuel Wise .\n","prediction_output":null,"prediction_outputs":null,"group":"178","words":["Among","Einstein","'s","well-known","friends","were","Michele","Besso",",","Paul","Ehrenfest",",","Marcel","Grossmann",",","János","Plesch",",","Daniel","Q.","Posin",",","Maurice","Solovine",",","and","Stephen","Samuel","Wise","."],"labels":["O","B-scientist","O","O","O","O","B-person","I-person","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","O","B-person","I-person","I-person","O"],"target_index":null,"target_label":null},"label_list":["award","theory","location","chemical_element","chemical_compound","person","scientist","academic_journal","protein","discipline","university","astronomical_object","event","country","enzyme","organization"]}
{"id":"180.S","dataset":"crossner_science","split":"dev","instance":{"id":"180.S","prompt_labels":"The(O) following(O) asteroids(O) were(O) also(O) named(O) in(O) memory(O) of(O) the(O) other(O) six(O) members(O) of(O) STS-107(B-event) :(O) 51823(B-astronomical_object) Rickhusband(I-astronomical_object) ,(O) 51824(B-astronomical_object) Mikeanderson(I-astronomical_object) ,(O) 51826(B-astronomical_object) Kalpanachawla(I-astronomical_object) ,(O) 51827(B-astronomical_object) Laurelclark(I-astronomical_object) ,(O) 51828(B-astronomical_object) Ilanramon(I-astronomical_object) and(O) 51829(B-astronomical_object) Williemccool(I-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, astronomical_object, academic_journal, event, enzyme, chemical_compound, university, discipline, location, chemical_element, organization, award, protein, theory, scientist\nGIVEN SENTENCE: The following asteroids were also named in memory of the other six members of STS-107 : 51823 Rickhusband , 51824 Mikeanderson , 51826 Kalpanachawla , 51827 Laurelclark , 51828 Ilanramon and 51829 Williemccool .\n","prediction_output":null,"prediction_outputs":null,"group":"180","words":["The","following","asteroids","were","also","named","in","memory","of","the","other","six","members","of","STS-107",":","51823","Rickhusband",",","51824","Mikeanderson",",","51826","Kalpanachawla",",","51827","Laurelclark",",","51828","Ilanramon","and","51829","Williemccool","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O"],"target_index":null,"target_label":null},"label_list":["person","country","astronomical_object","academic_journal","event","enzyme","chemical_compound","university","discipline","location","chemical_element","organization","award","protein","theory","scientist"]}
{"id":"182.S","dataset":"crossner_science","split":"dev","instance":{"id":"182.S","prompt_labels":"Lysostaphin(B-enzyme) can(O) lyse(O) Staphylococcus(O) ,(O) but(O) Micrococcus(O) bacteria(O) are(O) resistant(O) to(O) the(O) chemical(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: person, country, university, astronomical_object, event, chemical_compound, organization, chemical_element, discipline, award, academic_journal, scientist, enzyme, location, theory, protein\nGIVEN SENTENCE: Lysostaphin can lyse Staphylococcus , but Micrococcus bacteria are resistant to the chemical .\n","prediction_output":null,"prediction_outputs":null,"group":"182","words":["Lysostaphin","can","lyse","Staphylococcus",",","but","Micrococcus","bacteria","are","resistant","to","the","chemical","."],"labels":["B-enzyme","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["person","country","university","astronomical_object","event","chemical_compound","organization","chemical_element","discipline","award","academic_journal","scientist","enzyme","location","theory","protein"]}
{"id":"183.S","dataset":"crossner_science","split":"dev","instance":{"id":"183.S","prompt_labels":"Other(O) notable(O) German(O) scientists(O) ,(O) who(O) worked(O) on(O) the(O) Soviet(O) atomic(O) bomb(O) project(O) and(O) joined(O) Schintlmeister(B-scientist) at(O) the(O) Technische(B-university) Hochschule(I-university) Dresden(I-university) were(O) the(O) physicists(O) Heinz(B-scientist) Barwich(I-scientist) and(O) Werner(B-scientist) Hartmann(I-scientist) from(O) Institute(B-organization) G(I-organization) in(O) Agudzery(B-location) and(O) Heinz(B-scientist) Pose(I-scientist) and(O) Ernst(B-scientist) Rexer(I-scientist) from(O) Laboratory(B-organization) V(I-organization) in(O) Obninsk(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: astronomical_object, chemical_compound, academic_journal, theory, scientist, enzyme, event, university, location, chemical_element, country, organization, award, protein, discipline, person\nGIVEN SENTENCE: Other notable German scientists , who worked on the Soviet atomic bomb project and joined Schintlmeister at the Technische Hochschule Dresden were the physicists Heinz Barwich and Werner Hartmann from Institute G in Agudzery and Heinz Pose and Ernst Rexer from Laboratory V in Obninsk .\n","prediction_output":null,"prediction_outputs":null,"group":"183","words":["Other","notable","German","scientists",",","who","worked","on","the","Soviet","atomic","bomb","project","and","joined","Schintlmeister","at","the","Technische","Hochschule","Dresden","were","the","physicists","Heinz","Barwich","and","Werner","Hartmann","from","Institute","G","in","Agudzery","and","Heinz","Pose","and","Ernst","Rexer","from","Laboratory","V","in","Obninsk","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","B-university","I-university","I-university","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-organization","I-organization","O","B-location","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":null},"label_list":["astronomical_object","chemical_compound","academic_journal","theory","scientist","enzyme","event","university","location","chemical_element","country","organization","award","protein","discipline","person"]}
{"id":"184.S","dataset":"crossner_science","split":"dev","instance":{"id":"184.S","prompt_labels":"Starting(O) with(O) 1972(O) ,(O) the(O) Review(O) no(O) longer(O) appear(O) exclusively(O) in(O) Reviews(B-academic_journal) of(I-academic_journal) Modern(I-academic_journal) Physics(I-academic_journal) ,(O) but(O) also(O) in(O) Physics(B-academic_journal) Letters(I-academic_journal) B(I-academic_journal) ,(O) European(B-academic_journal) Physical(I-academic_journal) Journal(I-academic_journal) C(I-academic_journal) ,(O) Journal(B-academic_journal) of(I-academic_journal) Physics(I-academic_journal) G(I-academic_journal) ,(O) Physical(B-academic_journal) Review(I-academic_journal) D(I-academic_journal) ,(O) and(O) Chinese(B-academic_journal) Physics(I-academic_journal) C(I-academic_journal) ((O) depending(O) on(O) the(O) year(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: event, chemical_element, astronomical_object, discipline, university, enzyme, organization, protein, theory, scientist, country, location, award, academic_journal, person, chemical_compound\nGIVEN SENTENCE: Starting with 1972 , the Review no longer appear exclusively in Reviews of Modern Physics , but also in Physics Letters B , European Physical Journal C , Journal of Physics G , Physical Review D , and Chinese Physics C ( depending on the year ) .\n","prediction_output":null,"prediction_outputs":null,"group":"184","words":["Starting","with","1972",",","the","Review","no","longer","appear","exclusively","in","Reviews","of","Modern","Physics",",","but","also","in","Physics","Letters","B",",","European","Physical","Journal","C",",","Journal","of","Physics","G",",","Physical","Review","D",",","and","Chinese","Physics","C","(","depending","on","the","year",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","O","O","B-academic_journal","I-academic_journal","I-academic_journal","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["event","chemical_element","astronomical_object","discipline","university","enzyme","organization","protein","theory","scientist","country","location","award","academic_journal","person","chemical_compound"]}
{"id":"188.S","dataset":"crossner_science","split":"dev","instance":{"id":"188.S","prompt_labels":"Michel(B-scientist) Adanson(I-scientist) ((O) 1763(O) )(O) ,(O) Antoine(B-scientist) Laurent(I-scientist) de(I-scientist) Jussieu(I-scientist) ((O) 1789(O) )(O) ,(O) and(O) Augustin(B-scientist) Pyramus(I-scientist) de(I-scientist) Candolle(I-scientist) ((O) 1819(O) )(O) all(O) proposed(O) various(O) alternative(O) natural(O) systems(O) of(O) classification(O) that(O) grouped(O) plants(O) using(O) a(O) wider(O) range(O) of(O) shared(O) characters(O) and(O) were(O) widely(O) followed(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: theory, chemical_element, astronomical_object, protein, event, university, discipline, enzyme, country, person, academic_journal, location, chemical_compound, scientist, award, organization\nGIVEN SENTENCE: Michel Adanson ( 1763 ) , Antoine Laurent de Jussieu ( 1789 ) , and Augustin Pyramus de Candolle ( 1819 ) all proposed various alternative natural systems of classification that grouped plants using a wider range of shared characters and were widely followed .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["Michel","Adanson","(","1763",")",",","Antoine","Laurent","de","Jussieu","(","1789",")",",","and","Augustin","Pyramus","de","Candolle","(","1819",")","all","proposed","various","alternative","natural","systems","of","classification","that","grouped","plants","using","a","wider","range","of","shared","characters","and","were","widely","followed","."],"labels":["B-scientist","I-scientist","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["theory","chemical_element","astronomical_object","protein","event","university","discipline","enzyme","country","person","academic_journal","location","chemical_compound","scientist","award","organization"]}
{"id":"193.S","dataset":"crossner_science","split":"dev","instance":{"id":"193.S","prompt_labels":"He(O) was(O) educated(O) at(O) the(O) Technical(B-university) University(I-university) of(I-university) Munich(I-university) from(O) 1925(O) to(O) 1927(O) and(O) then(O) entered(O) the(O) Technical(B-university) University(I-university) of(I-university) Berlin(I-university) ,(O) where(O) he(O) posited(O) that(O) microscope(O) s(O) using(O) electrons(O) ,(O) with(O) wavelengths(O) 1000(O) times(O) shorter(O) than(O) those(O) of(O) light(O) ,(O) could(O) provide(O) a(O) more(O) detailed(O) picture(O) of(O) an(O) object(O) than(O) a(O) microscope(O) utilizing(O) light(O) ,(O) in(O) which(O) magnification(O) is(O) limited(O) by(O) the(O) size(O) of(O) the(O) wavelengths(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: scientist, enzyme, event, protein, organization, academic_journal, award, chemical_compound, chemical_element, theory, country, location, discipline, person, university, astronomical_object\nGIVEN SENTENCE: He was educated at the Technical University of Munich from 1925 to 1927 and then entered the Technical University of Berlin , where he posited that microscope s using electrons , with wavelengths 1000 times shorter than those of light , could provide a more detailed picture of an object than a microscope utilizing light , in which magnification is limited by the size of the wavelengths .\n","prediction_output":null,"prediction_outputs":null,"group":"193","words":["He","was","educated","at","the","Technical","University","of","Munich","from","1925","to","1927","and","then","entered","the","Technical","University","of","Berlin",",","where","he","posited","that","microscope","s","using","electrons",",","with","wavelengths","1000","times","shorter","than","those","of","light",",","could","provide","a","more","detailed","picture","of","an","object","than","a","microscope","utilizing","light",",","in","which","magnification","is","limited","by","the","size","of","the","wavelengths","."],"labels":["O","O","O","O","O","B-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","B-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["scientist","enzyme","event","protein","organization","academic_journal","award","chemical_compound","chemical_element","theory","country","location","discipline","person","university","astronomical_object"]}
{"id":"195.S","dataset":"crossner_science","split":"dev","instance":{"id":"195.S","prompt_labels":"The(O) minor(O) planets(O) 105(B-astronomical_object) Artemis(I-astronomical_object) ,(O) 399(B-astronomical_object) Persephone(I-astronomical_object) ,(O) 1388(B-astronomical_object) Aphrodite(I-astronomical_object) and(O) 5731(B-astronomical_object) Zeus(I-astronomical_object) were(O) named(O) for(O) these(O) Greek(O) gods(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: organization, university, chemical_element, protein, award, country, event, academic_journal, astronomical_object, scientist, theory, discipline, location, enzyme, person, chemical_compound\nGIVEN SENTENCE: The minor planets 105 Artemis , 399 Persephone , 1388 Aphrodite and 5731 Zeus were named for these Greek gods .\n","prediction_output":null,"prediction_outputs":null,"group":"195","words":["The","minor","planets","105","Artemis",",","399","Persephone",",","1388","Aphrodite","and","5731","Zeus","were","named","for","these","Greek","gods","."],"labels":["O","O","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","B-astronomical_object","I-astronomical_object","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["organization","university","chemical_element","protein","award","country","event","academic_journal","astronomical_object","scientist","theory","discipline","location","enzyme","person","chemical_compound"]}
{"id":"197.S","dataset":"crossner_science","split":"dev","instance":{"id":"197.S","prompt_labels":"In(O) 2010(O) ,(O) Goodall(B-scientist) through(O) JGI(B-organization) formed(O) a(O) coalition(O) with(O) a(O) number(O) of(O) organizations(O) such(O) as(O) the(O) Wildlife(B-organization) Conservation(I-organization) Society(I-organization) ((O) WCS(B-organization) )(O) and(O) the(O) Humane(B-organization) Society(I-organization) of(I-organization) the(I-organization) United(I-organization) States(I-organization) ((O) HSUS(B-organization) )(O) and(O) petitioned(O) to(O) list(O) all(O) chimpanzees(O) including(O) those(O) that(O) are(O) captive(O) as(O) endangered(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: protein, scientist, enzyme, chemical_compound, discipline, organization, person, academic_journal, event, astronomical_object, chemical_element, award, country, university, theory, location\nGIVEN SENTENCE: In 2010 , Goodall through JGI formed a coalition with a number of organizations such as the Wildlife Conservation Society ( WCS ) and the Humane Society of the United States ( HSUS ) and petitioned to list all chimpanzees including those that are captive as endangered .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["In","2010",",","Goodall","through","JGI","formed","a","coalition","with","a","number","of","organizations","such","as","the","Wildlife","Conservation","Society","(","WCS",")","and","the","Humane","Society","of","the","United","States","(","HSUS",")","and","petitioned","to","list","all","chimpanzees","including","those","that","are","captive","as","endangered","."],"labels":["O","O","O","B-scientist","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":null},"label_list":["protein","scientist","enzyme","chemical_compound","discipline","organization","person","academic_journal","event","astronomical_object","chemical_element","award","country","university","theory","location"]}
{"id":"199.S","dataset":"crossner_science","split":"dev","instance":{"id":"199.S","prompt_labels":"He(O) was(O) also(O) awarded(O) the(O) Davy(B-award) Medal(I-award) in(O) 1971(O) ,(O) the(O) Rumford(B-award) Medal(I-award) in(O) 1978(O) ,(O) the(O) Ellison-Cliffe(B-award) Medal(I-award) in(O) 1991(O) and(O) the(O) Copley(B-award) Medal(I-award) in(O) 1992(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below, and assign a BIO label to each token.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of any entity\n\nGIVEN ENTITY TYPES: astronomical_object, scientist, event, theory, organization, country, university, person, discipline, location, protein, award, chemical_element, academic_journal, enzyme, chemical_compound\nGIVEN SENTENCE: He was also awarded the Davy Medal in 1971 , the Rumford Medal in 1978 , the Ellison-Cliffe Medal in 1991 and the Copley Medal in 1992 .\n","prediction_output":null,"prediction_outputs":null,"group":"199","words":["He","was","also","awarded","the","Davy","Medal","in","1971",",","the","Rumford","Medal","in","1978",",","the","Ellison-Cliffe","Medal","in","1991","and","the","Copley","Medal","in","1992","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","O","O","B-award","I-award","O","O","O","O","B-award","I-award","O","O","O","O","B-award","I-award","O","O","O"],"target_index":null,"target_label":null},"label_list":["astronomical_object","scientist","event","theory","organization","country","university","person","discipline","location","protein","award","chemical_element","academic_journal","enzyme","chemical_compound"]}
{"id":"25.M1","dataset":"mit-movie","split":"dev","instance":{"id":"25.1","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"year"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M2","dataset":"mit-movie","split":"dev","instance":{"id":"25.2","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"average_ratings"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M3","dataset":"mit-movie","split":"dev","instance":{"id":"25.3","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"actor"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M4","dataset":"mit-movie","split":"dev","instance":{"id":"25.4","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"trailer"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M5","dataset":"mit-movie","split":"dev","instance":{"id":"25.5","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"song"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M6","dataset":"mit-movie","split":"dev","instance":{"id":"25.6","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"review"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M7","dataset":"mit-movie","split":"dev","instance":{"id":"25.7","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"character"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M8","dataset":"mit-movie","split":"dev","instance":{"id":"25.8","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"director"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M9","dataset":"mit-movie","split":"dev","instance":{"id":"25.9","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(B-plot)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"plot"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M10","dataset":"mit-movie","split":"dev","instance":{"id":"25.10","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"rating"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M11","dataset":"mit-movie","split":"dev","instance":{"id":"25.11","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"title"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"25.M12","dataset":"mit-movie","split":"dev","instance":{"id":"25.12","prompt_labels":"what(O) was(O) the(O) first(O) movie(O) in(O) color(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: what was the first movie in color\n","prediction_output":null,"prediction_outputs":null,"group":"25","words":["what","was","the","first","movie","in","color"],"labels":["O","O","O","O","O","O","B-plot"],"target_index":null,"target_label":"genre"},"label_list":["year","average_ratings","actor","trailer","song","review","character","director","plot","rating","title","genre"]}
{"id":"35.M1","dataset":"mit-movie","split":"dev","instance":{"id":"35.1","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"plot"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M2","dataset":"mit-movie","split":"dev","instance":{"id":"35.2","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"trailer"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M3","dataset":"mit-movie","split":"dev","instance":{"id":"35.3","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(B-genre) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"genre"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M4","dataset":"mit-movie","split":"dev","instance":{"id":"35.4","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"song"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M5","dataset":"mit-movie","split":"dev","instance":{"id":"35.5","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"rating"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M6","dataset":"mit-movie","split":"dev","instance":{"id":"35.6","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"year"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M7","dataset":"mit-movie","split":"dev","instance":{"id":"35.7","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"review"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M8","dataset":"mit-movie","split":"dev","instance":{"id":"35.8","prompt_labels":"did(O) george(B-director) clooney(I-director) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"director"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M9","dataset":"mit-movie","split":"dev","instance":{"id":"35.9","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"average_ratings"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M10","dataset":"mit-movie","split":"dev","instance":{"id":"35.10","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"character"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M11","dataset":"mit-movie","split":"dev","instance":{"id":"35.11","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"title"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"35.M12","dataset":"mit-movie","split":"dev","instance":{"id":"35.12","prompt_labels":"did(O) george(O) clooney(O) direct(O) any(O) comedy(O) films(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: did george clooney direct any comedy films\n","prediction_output":null,"prediction_outputs":null,"group":"35","words":["did","george","clooney","direct","any","comedy","films"],"labels":["O","B-director","I-director","O","O","B-genre","O"],"target_index":null,"target_label":"actor"},"label_list":["plot","trailer","genre","song","rating","year","review","director","average_ratings","character","title","actor"]}
{"id":"50.M1","dataset":"mit-movie","split":"dev","instance":{"id":"50.1","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"review"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M2","dataset":"mit-movie","split":"dev","instance":{"id":"50.2","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"song"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M3","dataset":"mit-movie","split":"dev","instance":{"id":"50.3","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"character"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M4","dataset":"mit-movie","split":"dev","instance":{"id":"50.4","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"average_ratings"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M5","dataset":"mit-movie","split":"dev","instance":{"id":"50.5","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"rating"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M6","dataset":"mit-movie","split":"dev","instance":{"id":"50.6","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"director"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M7","dataset":"mit-movie","split":"dev","instance":{"id":"50.7","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"genre"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M8","dataset":"mit-movie","split":"dev","instance":{"id":"50.8","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"year"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M9","dataset":"mit-movie","split":"dev","instance":{"id":"50.9","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(B-actor) hathaway(I-actor) and(O) julie(B-actor) andrews(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"actor"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M10","dataset":"mit-movie","split":"dev","instance":{"id":"50.10","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"title"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M11","dataset":"mit-movie","split":"dev","instance":{"id":"50.11","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"plot"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"50.M12","dataset":"mit-movie","split":"dev","instance":{"id":"50.12","prompt_labels":"find(O) me(O) the(O) movies(O) that(O) starred(O) anne(O) hathaway(O) and(O) julie(O) andrews(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: find me the movies that starred anne hathaway and julie andrews\n","prediction_output":null,"prediction_outputs":null,"group":"50","words":["find","me","the","movies","that","starred","anne","hathaway","and","julie","andrews"],"labels":["O","O","O","O","O","O","B-actor","I-actor","O","B-actor","I-actor"],"target_index":null,"target_label":"trailer"},"label_list":["review","song","character","average_ratings","rating","director","genre","year","actor","title","plot","trailer"]}
{"id":"71.M1","dataset":"mit-movie","split":"dev","instance":{"id":"71.1","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"song"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M2","dataset":"mit-movie","split":"dev","instance":{"id":"71.2","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"trailer"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M3","dataset":"mit-movie","split":"dev","instance":{"id":"71.3","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"rating"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M4","dataset":"mit-movie","split":"dev","instance":{"id":"71.4","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"year"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M5","dataset":"mit-movie","split":"dev","instance":{"id":"71.5","prompt_labels":"favorite(O) quote(O) from(O) action(B-genre) movies(I-genre)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"genre"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M6","dataset":"mit-movie","split":"dev","instance":{"id":"71.6","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"review"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M7","dataset":"mit-movie","split":"dev","instance":{"id":"71.7","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"title"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M8","dataset":"mit-movie","split":"dev","instance":{"id":"71.8","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"actor"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M9","dataset":"mit-movie","split":"dev","instance":{"id":"71.9","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"average_ratings"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M10","dataset":"mit-movie","split":"dev","instance":{"id":"71.10","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"director"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M11","dataset":"mit-movie","split":"dev","instance":{"id":"71.11","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"character"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"71.M12","dataset":"mit-movie","split":"dev","instance":{"id":"71.12","prompt_labels":"favorite(O) quote(O) from(O) action(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: favorite quote from action movies\n","prediction_output":null,"prediction_outputs":null,"group":"71","words":["favorite","quote","from","action","movies"],"labels":["O","O","O","B-genre","I-genre"],"target_index":null,"target_label":"plot"},"label_list":["song","trailer","rating","year","genre","review","title","actor","average_ratings","director","character","plot"]}
{"id":"105.M1","dataset":"mit-movie","split":"dev","instance":{"id":"105.1","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"plot"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M2","dataset":"mit-movie","split":"dev","instance":{"id":"105.2","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"song"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M3","dataset":"mit-movie","split":"dev","instance":{"id":"105.3","prompt_labels":"show(O) me(O) a(O) comedy(B-genre) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"genre"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M4","dataset":"mit-movie","split":"dev","instance":{"id":"105.4","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"character"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M5","dataset":"mit-movie","split":"dev","instance":{"id":"105.5","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"director"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M6","dataset":"mit-movie","split":"dev","instance":{"id":"105.6","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"average_ratings"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M7","dataset":"mit-movie","split":"dev","instance":{"id":"105.7","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(B-actor) murphy(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"actor"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M8","dataset":"mit-movie","split":"dev","instance":{"id":"105.8","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"title"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M9","dataset":"mit-movie","split":"dev","instance":{"id":"105.9","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"review"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M10","dataset":"mit-movie","split":"dev","instance":{"id":"105.10","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"rating"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M11","dataset":"mit-movie","split":"dev","instance":{"id":"105.11","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"trailer"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"105.M12","dataset":"mit-movie","split":"dev","instance":{"id":"105.12","prompt_labels":"show(O) me(O) a(O) comedy(O) movie(O) with(O) eddie(O) murphy(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: show me a comedy movie with eddie murphy\n","prediction_output":null,"prediction_outputs":null,"group":"105","words":["show","me","a","comedy","movie","with","eddie","murphy"],"labels":["O","O","O","B-genre","O","O","B-actor","I-actor"],"target_index":null,"target_label":"year"},"label_list":["plot","song","genre","character","director","average_ratings","actor","title","review","rating","trailer","year"]}
{"id":"109.M1","dataset":"mit-movie","split":"dev","instance":{"id":"109.1","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"review"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M2","dataset":"mit-movie","split":"dev","instance":{"id":"109.2","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"average_ratings"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M3","dataset":"mit-movie","split":"dev","instance":{"id":"109.3","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"plot"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M4","dataset":"mit-movie","split":"dev","instance":{"id":"109.4","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"character"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M5","dataset":"mit-movie","split":"dev","instance":{"id":"109.5","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"title"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M6","dataset":"mit-movie","split":"dev","instance":{"id":"109.6","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(B-year)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"year"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M7","dataset":"mit-movie","split":"dev","instance":{"id":"109.7","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"trailer"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M8","dataset":"mit-movie","split":"dev","instance":{"id":"109.8","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"rating"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M9","dataset":"mit-movie","split":"dev","instance":{"id":"109.9","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(B-actor) j(I-actor) fox(I-actor) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"actor"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M10","dataset":"mit-movie","split":"dev","instance":{"id":"109.10","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"genre"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M11","dataset":"mit-movie","split":"dev","instance":{"id":"109.11","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"director"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"109.M12","dataset":"mit-movie","split":"dev","instance":{"id":"109.12","prompt_labels":"show(O) me(O) movies(O) starring(O) michael(O) j(O) fox(O) from(O) 1993(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: show me movies starring michael j fox from 1993\n","prediction_output":null,"prediction_outputs":null,"group":"109","words":["show","me","movies","starring","michael","j","fox","from","1993"],"labels":["O","O","O","O","B-actor","I-actor","I-actor","O","B-year"],"target_index":null,"target_label":"song"},"label_list":["review","average_ratings","plot","character","title","year","trailer","rating","actor","genre","director","song"]}
{"id":"142.M1","dataset":"mit-movie","split":"dev","instance":{"id":"142.1","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"character"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M2","dataset":"mit-movie","split":"dev","instance":{"id":"142.2","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"actor"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M3","dataset":"mit-movie","split":"dev","instance":{"id":"142.3","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"director"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M4","dataset":"mit-movie","split":"dev","instance":{"id":"142.4","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"review"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M5","dataset":"mit-movie","split":"dev","instance":{"id":"142.5","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"song"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M6","dataset":"mit-movie","split":"dev","instance":{"id":"142.6","prompt_labels":"what(O) techno(B-genre) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"genre"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M7","dataset":"mit-movie","split":"dev","instance":{"id":"142.7","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"rating"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M8","dataset":"mit-movie","split":"dev","instance":{"id":"142.8","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"title"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M9","dataset":"mit-movie","split":"dev","instance":{"id":"142.9","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"plot"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M10","dataset":"mit-movie","split":"dev","instance":{"id":"142.10","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(B-average_ratings) rating(I-average_ratings)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"average_ratings"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M11","dataset":"mit-movie","split":"dev","instance":{"id":"142.11","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"trailer"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"142.M12","dataset":"mit-movie","split":"dev","instance":{"id":"142.12","prompt_labels":"what(O) techno(O) thriller(O) gets(O) a(O) low(O) rating(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: what techno thriller gets a low rating\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["what","techno","thriller","gets","a","low","rating"],"labels":["O","B-genre","O","O","O","B-average_ratings","I-average_ratings"],"target_index":null,"target_label":"year"},"label_list":["character","actor","director","review","song","genre","rating","title","plot","average_ratings","trailer","year"]}
{"id":"152.M1","dataset":"mit-movie","split":"dev","instance":{"id":"152.1","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"title"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M2","dataset":"mit-movie","split":"dev","instance":{"id":"152.2","prompt_labels":"show(O) me(O) terry(B-director) gilliam(I-director) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"director"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M3","dataset":"mit-movie","split":"dev","instance":{"id":"152.3","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"genre"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M4","dataset":"mit-movie","split":"dev","instance":{"id":"152.4","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"review"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M5","dataset":"mit-movie","split":"dev","instance":{"id":"152.5","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"rating"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M6","dataset":"mit-movie","split":"dev","instance":{"id":"152.6","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(B-actor) bridges(I-actor)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"actor"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M7","dataset":"mit-movie","split":"dev","instance":{"id":"152.7","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"character"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M8","dataset":"mit-movie","split":"dev","instance":{"id":"152.8","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"plot"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M9","dataset":"mit-movie","split":"dev","instance":{"id":"152.9","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"song"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M10","dataset":"mit-movie","split":"dev","instance":{"id":"152.10","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"average_ratings"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M11","dataset":"mit-movie","split":"dev","instance":{"id":"152.11","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"year"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"152.M12","dataset":"mit-movie","split":"dev","instance":{"id":"152.12","prompt_labels":"show(O) me(O) terry(O) gilliam(O) movies(O) starring(O) jeff(O) bridges(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: show me terry gilliam movies starring jeff bridges\n","prediction_output":null,"prediction_outputs":null,"group":"152","words":["show","me","terry","gilliam","movies","starring","jeff","bridges"],"labels":["O","O","B-director","I-director","O","O","B-actor","I-actor"],"target_index":null,"target_label":"trailer"},"label_list":["title","director","genre","review","rating","actor","character","plot","song","average_ratings","year","trailer"]}
{"id":"154.M1","dataset":"mit-movie","split":"dev","instance":{"id":"154.1","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"genre"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M2","dataset":"mit-movie","split":"dev","instance":{"id":"154.2","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"plot"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M3","dataset":"mit-movie","split":"dev","instance":{"id":"154.3","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"director"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M4","dataset":"mit-movie","split":"dev","instance":{"id":"154.4","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"character"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M5","dataset":"mit-movie","split":"dev","instance":{"id":"154.5","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"rating"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M6","dataset":"mit-movie","split":"dev","instance":{"id":"154.6","prompt_labels":"when(O) did(O) interview(B-title) with(I-title) a(I-title) vampire(I-title) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"title"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M7","dataset":"mit-movie","split":"dev","instance":{"id":"154.7","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"average_ratings"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M8","dataset":"mit-movie","split":"dev","instance":{"id":"154.8","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"year"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M9","dataset":"mit-movie","split":"dev","instance":{"id":"154.9","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"review"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M10","dataset":"mit-movie","split":"dev","instance":{"id":"154.10","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"trailer"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M11","dataset":"mit-movie","split":"dev","instance":{"id":"154.11","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"actor"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"154.M12","dataset":"mit-movie","split":"dev","instance":{"id":"154.12","prompt_labels":"when(O) did(O) interview(O) with(O) a(O) vampire(O) come(O) out(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: when did interview with a vampire come out\n","prediction_output":null,"prediction_outputs":null,"group":"154","words":["when","did","interview","with","a","vampire","come","out"],"labels":["O","O","B-title","I-title","I-title","I-title","O","O"],"target_index":null,"target_label":"song"},"label_list":["genre","plot","director","character","rating","title","average_ratings","year","review","trailer","actor","song"]}
{"id":"177.M1","dataset":"mit-movie","split":"dev","instance":{"id":"177.1","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: average_ratings\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"average_ratings"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M2","dataset":"mit-movie","split":"dev","instance":{"id":"177.2","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: title\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"title"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M3","dataset":"mit-movie","split":"dev","instance":{"id":"177.3","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: year\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"year"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M4","dataset":"mit-movie","split":"dev","instance":{"id":"177.4","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(B-plot) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: plot\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"plot"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M5","dataset":"mit-movie","split":"dev","instance":{"id":"177.5","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: rating\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"rating"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M6","dataset":"mit-movie","split":"dev","instance":{"id":"177.6","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"song"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M7","dataset":"mit-movie","split":"dev","instance":{"id":"177.7","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: genre\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"genre"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M8","dataset":"mit-movie","split":"dev","instance":{"id":"177.8","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: trailer\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"trailer"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M9","dataset":"mit-movie","split":"dev","instance":{"id":"177.9","prompt_labels":"what(O) are(O) the(O) best(B-review) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: review\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"review"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M10","dataset":"mit-movie","split":"dev","instance":{"id":"177.10","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: director\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"director"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M11","dataset":"mit-movie","split":"dev","instance":{"id":"177.11","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: actor\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"actor"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"177.M12","dataset":"mit-movie","split":"dev","instance":{"id":"177.12","prompt_labels":"what(O) are(O) the(O) best(O) werewolf(O) movies(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: character\nGIVEN SENTENCE: what are the best werewolf movies\n","prediction_output":null,"prediction_outputs":null,"group":"177","words":["what","are","the","best","werewolf","movies"],"labels":["O","O","O","B-review","B-plot","O"],"target_index":null,"target_label":"character"},"label_list":["average_ratings","title","year","plot","rating","song","genre","trailer","review","director","actor","character"]}
{"id":"1.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"1.1","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"task"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"1.2","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"researcher"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"1.3","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"metric"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"1.4","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"programming_language"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"1.5","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"person"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"1.6","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"conference"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"1.7","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"product"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"1.8","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(B-algorithm) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(B-algorithm) least-squares(I-algorithm) logistic(B-algorithm) regression(I-algorithm) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"algorithm"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"1.9","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"organization"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"1.10","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"field"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"1.11","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"location"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"1.12","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"country"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"1.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"1.13","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(O) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(O) least-squares(O) logistic(O) regression(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .\n","prediction_output":null,"prediction_outputs":null,"group":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"target_index":null,"target_label":"university"},"label_list":["task","researcher","metric","programming_language","person","conference","product","algorithm","organization","field","location","country","university"]}
{"id":"22.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"22.1","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"programming_language"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"22.2","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"conference"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"22.3","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"organization"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"22.4","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"university"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"22.5","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(B-field) and(O) database(B-field) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"field"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"22.6","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"researcher"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"22.7","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"person"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"22.8","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(B-task) natural(I-task) language(B-task) understanding(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"task"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"22.9","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"product"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"22.10","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"location"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"22.11","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"algorithm"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"22.12","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"metric"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"22.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"22.13","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(O) and(O) database(O) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(O) natural(O) language(O) understanding(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .\n","prediction_output":null,"prediction_outputs":null,"group":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"target_index":null,"target_label":"country"},"label_list":["programming_language","conference","organization","university","field","researcher","person","task","product","location","algorithm","metric","country"]}
{"id":"52.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"52.1","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"52.2","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"researcher"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"52.3","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"52.4","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"52.5","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"programming_language"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"52.6","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"product"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"52.7","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"metric"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"52.8","prompt_labels":"In(O) computer(B-field) vision(I-field) and(O) image(B-field) processing(I-field) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"field"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"52.9","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"task"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"52.10","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"52.11","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"conference"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"52.12","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"52.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"52.13","prompt_labels":"In(O) computer(O) vision(O) and(O) image(O) processing(O) ,(O) the(O) notion(O) of(O) scale(O) space(O) representation(O) and(O) Gaussian(O) derivative(O) operators(O) is(O) as(O) a(O) canonical(O) multi-scale(O) representation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: In computer vision and image processing , the notion of scale space representation and Gaussian derivative operators is as a canonical multi-scale representation .\n","prediction_output":null,"prediction_outputs":null,"group":"52","words":["In","computer","vision","and","image","processing",",","the","notion","of","scale","space","representation","and","Gaussian","derivative","operators","is","as","a","canonical","multi-scale","representation","."],"labels":["O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"algorithm"},"label_list":["person","researcher","organization","country","programming_language","product","metric","field","task","university","conference","location","algorithm"]}
{"id":"63.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"63.1","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"63.2","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"63.3","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"metric"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"63.4","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"63.5","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"researcher"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"63.6","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"product"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"63.7","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"63.8","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"field"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"63.9","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"63.10","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"conference"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"63.11","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"programming_language"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"63.12","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(O) function(O) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"task"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"63.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"63.13","prompt_labels":"In(O) many(O) applications(O) the(O) units(O) of(O) these(O) networks(O) apply(O) a(O) sigmoid(B-algorithm) function(I-algorithm) as(O) an(O) activation(O) function(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: In many applications the units of these networks apply a sigmoid function as an activation function .\n","prediction_output":null,"prediction_outputs":null,"group":"63","words":["In","many","applications","the","units","of","these","networks","apply","a","sigmoid","function","as","an","activation","function","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","O","O","O","O","O"],"target_index":null,"target_label":"algorithm"},"label_list":["location","person","metric","country","researcher","product","organization","field","university","conference","programming_language","task","algorithm"]}
{"id":"64.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"64.1","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"programming_language"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"64.2","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"product"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"64.3","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"task"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"64.4","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"conference"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"64.5","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"university"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"64.6","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"algorithm"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"64.7","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"location"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"64.8","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"country"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"64.9","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(B-organization) Academy(I-organization) of(I-organization) Arts(I-organization) and(I-organization) Sciences(I-organization) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(B-organization) Association(I-organization) for(I-organization) the(I-organization) Advancement(I-organization) of(I-organization) Science(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"organization"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"64.10","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"field"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"64.11","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"metric"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"64.12","prompt_labels":"In(O) 2001(O) ,(O) Mehler(B-researcher) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"researcher"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"64.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"64.13","prompt_labels":"In(O) 2001(O) ,(O) Mehler(O) was(O) elected(O) a(O) foreign(O) honorary(O) member(O) of(O) the(O) American(O) Academy(O) of(O) Arts(O) and(O) Sciences(O) ,(O) and(O) in(O) 2003(O) ,(O) he(O) was(O) elected(O) a(O) Fellow(O) of(O) the(O) American(O) Association(O) for(O) the(O) Advancement(O) of(O) Science(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In 2001 , Mehler was elected a foreign honorary member of the American Academy of Arts and Sciences , and in 2003 , he was elected a Fellow of the American Association for the Advancement of Science .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["In","2001",",","Mehler","was","elected","a","foreign","honorary","member","of","the","American","Academy","of","Arts","and","Sciences",",","and","in","2003",",","he","was","elected","a","Fellow","of","the","American","Association","for","the","Advancement","of","Science","."],"labels":["O","O","O","B-researcher","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"person"},"label_list":["programming_language","product","task","conference","university","algorithm","location","country","organization","field","metric","researcher","person"]}
{"id":"69.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"69.1","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"field"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"69.2","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(B-product) recognition(I-product) system(I-product) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"product"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"69.3","prompt_labels":"The(O) condensation(B-algorithm) algorithm(I-algorithm) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"algorithm"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"69.4","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"task"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"69.5","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"69.6","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"programming_language"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"69.7","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"69.8","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"69.9","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"69.10","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"metric"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"69.11","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"conference"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"69.12","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"researcher"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"69.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"69.13","prompt_labels":"The(O) condensation(O) algorithm(O) has(O) also(O) been(O) used(O) for(O) facial(O) recognition(O) system(O) in(O) a(O) video(O) sequence(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: The condensation algorithm has also been used for facial recognition system in a video sequence .\n","prediction_output":null,"prediction_outputs":null,"group":"69","words":["The","condensation","algorithm","has","also","been","used","for","facial","recognition","system","in","a","video","sequence","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["field","product","algorithm","task","university","programming_language","country","organization","location","metric","conference","researcher","person"]}
{"id":"79.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"79.1","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"programming_language"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"79.2","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"79.3","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"conference"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"79.4","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"researcher"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"79.5","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"79.6","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"metric"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"79.7","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"task"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"79.8","prompt_labels":"Several(O) metrics(O) use(O) WordNet(B-product) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"product"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"79.9","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"field"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"79.10","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"79.11","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"algorithm"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"79.12","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"79.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"79.13","prompt_labels":"Several(O) metrics(O) use(O) WordNet(O) ,(O) a(O) manually(O) constructed(O) lexical(O) database(O) of(O) English(O) words(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: Several metrics use WordNet , a manually constructed lexical database of English words .\n","prediction_output":null,"prediction_outputs":null,"group":"79","words":["Several","metrics","use","WordNet",",","a","manually","constructed","lexical","database","of","English","words","."],"labels":["O","O","O","B-product","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["programming_language","organization","conference","researcher","country","metric","task","product","field","location","algorithm","person","university"]}
{"id":"87.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"87.1","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"university"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"87.2","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"conference"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"87.3","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(B-task) detection(I-task) ,(O) feature(B-task) classification(I-task) ,(O) image(B-task) segmentation(I-task) ,(O) image(B-task) matching(I-task) ,(O) motion(B-task) estimation(I-task) ,(O) computation(B-task) of(I-task) shape(I-task) cues(I-task) and(O) object(B-task) recognition(I-task) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"task"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"87.4","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"country"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"87.5","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(B-field) vision(I-field) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"field"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"87.6","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"organization"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"87.7","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"person"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"87.8","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"researcher"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"87.9","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"product"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"87.10","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"algorithm"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"87.11","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"metric"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"87.12","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"programming_language"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"87.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"87.13","prompt_labels":"This(O) overall(O) framework(O) has(O) been(O) applied(O) to(O) a(O) large(O) variety(O) of(O) problems(O) in(O) computer(O) vision(O) ,(O) including(O) feature(O) detection(O) ,(O) feature(O) classification(O) ,(O) image(O) segmentation(O) ,(O) image(O) matching(O) ,(O) motion(O) estimation(O) ,(O) computation(O) of(O) shape(O) cues(O) and(O) object(O) recognition(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: This overall framework has been applied to a large variety of problems in computer vision , including feature detection , feature classification , image segmentation , image matching , motion estimation , computation of shape cues and object recognition .\n","prediction_output":null,"prediction_outputs":null,"group":"87","words":["This","overall","framework","has","been","applied","to","a","large","variety","of","problems","in","computer","vision",",","including","feature","detection",",","feature","classification",",","image","segmentation",",","image","matching",",","motion","estimation",",","computation","of","shape","cues","and","object","recognition","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","O","B-task","I-task","I-task","I-task","O","B-task","I-task","O"],"target_index":null,"target_label":"location"},"label_list":["university","conference","task","country","field","organization","person","researcher","product","algorithm","metric","programming_language","location"]}
{"id":"99.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"99.1","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(B-conference) Computational(I-conference) Intelligence(I-conference) Society(I-conference) in(O) 2004-05(O) and(O) the(O) ADCOM(B-conference) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"conference"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"99.2","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"programming_language"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"99.3","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"product"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"99.4","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"99.5","prompt_labels":"Zurada(B-researcher) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"researcher"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"99.6","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"algorithm"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"99.7","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"task"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"99.8","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"99.9","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"99.10","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"metric"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"99.11","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"field"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"99.12","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(B-organization) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"99.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"99.13","prompt_labels":"Zurada(O) has(O) served(O) the(O) engineering(O) profession(O) as(O) a(O) long-time(O) volunteer(O) of(O) IEEE(O) :(O) as(O) 2014(O) IEEE(O) Vice-President-Technical(O) Activities(O) ((O) TAB(O) Chair(O) )(O) ,(O) as(O) President(O) of(O) IEEE(O) Computational(O) Intelligence(O) Society(O) in(O) 2004-05(O) and(O) the(O) ADCOM(O) member(O) in(O) 2009-14(O) ,(O) 2016-18(O) and(O) earlier(O) years(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Zurada has served the engineering profession as a long-time volunteer of IEEE : as 2014 IEEE Vice-President-Technical Activities ( TAB Chair ) , as President of IEEE Computational Intelligence Society in 2004-05 and the ADCOM member in 2009-14 , 2016-18 and earlier years .\n","prediction_output":null,"prediction_outputs":null,"group":"99","words":["Zurada","has","served","the","engineering","profession","as","a","long-time","volunteer","of","IEEE",":","as","2014","IEEE","Vice-President-Technical","Activities","(","TAB","Chair",")",",","as","President","of","IEEE","Computational","Intelligence","Society","in","2004-05","and","the","ADCOM","member","in","2009-14",",","2016-18","and","earlier","years","."],"labels":["B-researcher","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","O","O","O","O","B-conference","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["conference","programming_language","product","country","researcher","algorithm","task","university","location","metric","field","organization","person"]}
{"id":"173.M1","dataset":"crossner_ai","split":"dev","instance":{"id":"173.1","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M2","dataset":"crossner_ai","split":"dev","instance":{"id":"173.2","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M3","dataset":"crossner_ai","split":"dev","instance":{"id":"173.3","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(B-conference) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: conference\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"conference"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M4","dataset":"crossner_ai","split":"dev","instance":{"id":"173.4","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M5","dataset":"crossner_ai","split":"dev","instance":{"id":"173.5","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: product\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"product"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M6","dataset":"crossner_ai","split":"dev","instance":{"id":"173.6","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: programming_language\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"programming_language"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M7","dataset":"crossner_ai","split":"dev","instance":{"id":"173.7","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: researcher\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"researcher"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M8","dataset":"crossner_ai","split":"dev","instance":{"id":"173.8","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M9","dataset":"crossner_ai","split":"dev","instance":{"id":"173.9","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(B-metric) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: metric\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"metric"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M10","dataset":"crossner_ai","split":"dev","instance":{"id":"173.10","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: task\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"task"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M11","dataset":"crossner_ai","split":"dev","instance":{"id":"173.11","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: field\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"field"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M12","dataset":"crossner_ai","split":"dev","instance":{"id":"173.12","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"173.M13","dataset":"crossner_ai","split":"dev","instance":{"id":"173.13","prompt_labels":"For(O) example(O) ,(O) the(O) best(O) system(O) entering(O) MUC-7(O) scored(O) 93.39(O) %(O) of(O) F-measure(O) while(O) human(O) annotators(O) scored(O) 97.6(O) %(O) and(O) 96.95(O) %(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: algorithm\nGIVEN SENTENCE: For example , the best system entering MUC-7 scored 93.39 % of F-measure while human annotators scored 97.6 % and 96.95 % .\n","prediction_output":null,"prediction_outputs":null,"group":"173","words":["For","example",",","the","best","system","entering","MUC-7","scored","93.39","%","of","F-measure","while","human","annotators","scored","97.6","%","and","96.95","%","."],"labels":["O","O","O","O","O","O","O","B-conference","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"algorithm"},"label_list":["person","university","conference","location","product","programming_language","researcher","country","metric","task","field","organization","algorithm"]}
{"id":"0.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"0.1","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(B-book) Color(I-book) Purple(I-book) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"book"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"0.2","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"location"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"0.3","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"writer"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"0.4","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"organization"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"0.5","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"country"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"0.6","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"person"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"0.7","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(B-literary_genre) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"0.8","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"poem"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"0.9","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"event"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"0.10","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(O) Book(O) Award(O) for(O) hardcover(O) fiction(O) ,(O) and(O) the(O) Pulitzer(O) Prize(O) for(O) Fiction(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"magazine"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"0.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"0.11","prompt_labels":"In(O) 1982(O) ,(O) she(O) wrote(O) the(O) novel(O) The(O) Color(O) Purple(O) ,(O) for(O) which(O) she(O) won(O) the(O) National(B-award) Book(I-award) Award(I-award) for(I-award) hardcover(I-award) fiction(I-award) ,(O) and(O) the(O) Pulitzer(B-award) Prize(I-award) for(I-award) Fiction(I-award) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: In 1982 , she wrote the novel The Color Purple , for which she won the National Book Award for hardcover fiction , and the Pulitzer Prize for Fiction .\n","prediction_output":null,"prediction_outputs":null,"group":"0","words":["In","1982",",","she","wrote","the","novel","The","Color","Purple",",","for","which","she","won","the","National","Book","Award","for","hardcover","fiction",",","and","the","Pulitzer","Prize","for","Fiction","."],"labels":["O","O","O","O","O","O","B-literary_genre","B-book","I-book","I-book","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"target_index":null,"target_label":"award"},"label_list":["book","location","writer","organization","country","person","literary_genre","poem","event","magazine","award"]}
{"id":"3.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"3.1","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"magazine"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"3.2","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"poem"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"3.3","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"book"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"3.4","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"award"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"3.5","prompt_labels":"Atwood(B-writer) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(B-writer) Gibson(I-writer) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"writer"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"3.6","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(B-organization) Bird(I-organization) Club(I-organization) within(O) BirdLife(B-organization) International(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"organization"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"3.7","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"country"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"3.8","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"person"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"3.9","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"event"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"3.10","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"location"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"3.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"3.11","prompt_labels":"Atwood(O) has(O) strong(O) views(O) on(O) environmental(O) issues(O) ,(O) and(O) she(O) and(O) Graeme(O) Gibson(O) were(O) the(O) joint(O) honorary(O) presidents(O) of(O) the(O) Rare(O) Bird(O) Club(O) within(O) BirdLife(O) International(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: Atwood has strong views on environmental issues , and she and Graeme Gibson were the joint honorary presidents of the Rare Bird Club within BirdLife International .\n","prediction_output":null,"prediction_outputs":null,"group":"3","words":["Atwood","has","strong","views","on","environmental","issues",",","and","she","and","Graeme","Gibson","were","the","joint","honorary","presidents","of","the","Rare","Bird","Club","within","BirdLife","International","."],"labels":["B-writer","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","I-organization","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["magazine","poem","book","award","writer","organization","country","person","event","location","literary_genre"]}
{"id":"44.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"44.1","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"44.2","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(B-location) Heights(I-location) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"44.3","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"44.4","prompt_labels":"Hesser(B-writer) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(B-writer) Friend(I-writer) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"writer"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"44.5","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(B-magazine) New(I-magazine) Yorker(I-magazine) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"magazine"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"44.6","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"44.7","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"44.8","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"poem"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"44.9","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"44.10","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"book"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"44.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"44.11","prompt_labels":"Hesser(O) lives(O) in(O) Brooklyn(O) Heights(O) with(O) her(O) husband(O) ,(O) Tad(O) Friend(O) ,(O) a(O) staff(O) writer(O) for(O) The(O) New(O) Yorker(O) ,(O) and(O) their(O) two(O) children(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Hesser lives in Brooklyn Heights with her husband , Tad Friend , a staff writer for The New Yorker , and their two children .\n","prediction_output":null,"prediction_outputs":null,"group":"44","words":["Hesser","lives","in","Brooklyn","Heights","with","her","husband",",","Tad","Friend",",","a","staff","writer","for","The","New","Yorker",",","and","their","two","children","."],"labels":["B-writer","O","O","B-location","I-location","O","O","O","O","B-writer","I-writer","O","O","O","O","O","B-magazine","I-magazine","I-magazine","O","O","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["country","location","award","writer","magazine","literary_genre","organization","poem","person","book","event"]}
{"id":"92.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"92.1","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"organization"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"92.2","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"event"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"92.3","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"poem"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"92.4","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"person"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"92.5","prompt_labels":"Before(O) writing(O) Dracula(B-book) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"book"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"92.6","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(B-country) of(I-country) Hungary(I-country) now(O) Svätý(O) Jur(O) ,(O) Slovakia(B-country) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"country"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"92.7","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"magazine"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"92.8","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"award"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"92.9","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(B-location) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(B-location) Jur(I-location) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"location"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"92.10","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(B-writer) met(O) Ármin(B-writer) Vámbéry(I-writer) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"writer"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"92.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"92.11","prompt_labels":"Before(O) writing(O) Dracula(O) ,(O) Stoker(O) met(O) Ármin(O) Vámbéry(O) ,(O) a(O) Hungarian-Jewish(O) writer(O) and(O) traveller(O) ((O) born(O) in(O) Szent-György(O) ,(O) Kingdom(O) of(O) Hungary(O) now(O) Svätý(O) Jur(O) ,(O) Slovakia(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: Before writing Dracula , Stoker met Ármin Vámbéry , a Hungarian-Jewish writer and traveller ( born in Szent-György , Kingdom of Hungary now Svätý Jur , Slovakia ) .\n","prediction_output":null,"prediction_outputs":null,"group":"92","words":["Before","writing","Dracula",",","Stoker","met","Ármin","Vámbéry",",","a","Hungarian-Jewish","writer","and","traveller","(","born","in","Szent-György",",","Kingdom","of","Hungary","now","Svätý","Jur",",","Slovakia",")","."],"labels":["O","O","B-book","O","B-writer","O","B-writer","I-writer","O","O","O","O","O","O","O","O","O","B-location","O","B-country","I-country","I-country","O","B-location","I-location","O","B-country","O","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["organization","event","poem","person","book","country","magazine","award","location","writer","literary_genre"]}
{"id":"106.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"106.1","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"poem"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"106.2","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(B-book) People(I-book) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(B-book) Mischief(I-book) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"book"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"106.3","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"106.4","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"106.5","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(B-writer) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"writer"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"106.6","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"magazine"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"106.7","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"106.8","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(B-location) East(I-location) Africa(I-location) colonies(I-location) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"106.9","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(B-country) Congo(I-country) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"106.10","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(B-literary_genre) novel(I-literary_genre) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"106.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"106.11","prompt_labels":"91(O) A(O) subsequent(O) journey(O) through(O) the(O) British(O) East(O) Africa(O) colonies(O) and(O) the(O) Belgian(O) Congo(O) formed(O) the(O) basis(O) of(O) two(O) books(O) ;(O) the(O) travelogue(O) Remote(O) People(O) ((O) 1931(O) )(O) and(O) the(O) comic(O) novel(O) Black(O) Mischief(O) ((O) 1932(O) )(O) .(O) Sykes(O) ,(O) p(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: 91 A subsequent journey through the British East Africa colonies and the Belgian Congo formed the basis of two books ; the travelogue Remote People ( 1931 ) and the comic novel Black Mischief ( 1932 ) . Sykes , p .\n","prediction_output":null,"prediction_outputs":null,"group":"106","words":["91","A","subsequent","journey","through","the","British","East","Africa","colonies","and","the","Belgian","Congo","formed","the","basis","of","two","books",";","the","travelogue","Remote","People","(","1931",")","and","the","comic","novel","Black","Mischief","(","1932",")",".","Sykes",",","p","."],"labels":["O","O","O","O","O","O","B-location","I-location","I-location","I-location","O","O","B-country","I-country","O","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","O","B-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-writer","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["poem","book","award","person","writer","magazine","organization","location","country","literary_genre","event"]}
{"id":"134.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"134.1","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"134.2","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"134.3","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"poem"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"134.4","prompt_labels":"Disraeli(O) 's(O) early(O) silver(B-literary_genre) fork(I-literary_genre) novels(I-literary_genre) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"134.5","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(B-book) Grey(I-book) ((O) 1826(O) )(O) and(O) The(B-book) Young(I-book) Duke(I-book) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"book"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"134.6","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"magazine"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"134.7","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"134.8","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"134.9","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"134.10","prompt_labels":"Disraeli(O) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"134.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"134.11","prompt_labels":"Disraeli(B-writer) 's(O) early(O) silver(O) fork(O) novels(O) Vivian(O) Grey(O) ((O) 1826(O) )(O) and(O) The(O) Young(O) Duke(O) ((O) 1831(O) )(O) featured(O) romanticised(O) depictions(O) of(O) aristocratic(O) life(O) ((O) despite(O) his(O) ignorance(O) of(O) it(O) )(O) with(O) character(O) sketches(O) of(O) well-known(O) public(O) figures(O) lightly(O) disguised(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: Disraeli 's early silver fork novels Vivian Grey ( 1826 ) and The Young Duke ( 1831 ) featured romanticised depictions of aristocratic life ( despite his ignorance of it ) with character sketches of well-known public figures lightly disguised .\n","prediction_output":null,"prediction_outputs":null,"group":"134","words":["Disraeli","'s","early","silver","fork","novels","Vivian","Grey","(","1826",")","and","The","Young","Duke","(","1831",")","featured","romanticised","depictions","of","aristocratic","life","(","despite","his","ignorance","of","it",")","with","character","sketches","of","well-known","public","figures","lightly","disguised","."],"labels":["B-writer","O","O","B-literary_genre","I-literary_genre","I-literary_genre","B-book","I-book","O","O","O","O","B-book","I-book","I-book","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"writer"},"label_list":["organization","award","poem","literary_genre","book","magazine","event","person","location","country","writer"]}
{"id":"167.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"167.1","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(B-book) of(I-book) Darkness(I-book) and(O) Lord(B-book) Jim(I-book) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"book"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"167.2","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"location"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"167.3","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"magazine"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"167.4","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(B-writer) Conrad(I-writer) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"writer"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"167.5","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"167.6","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"organization"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"167.7","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"country"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"167.8","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"award"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"167.9","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"person"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"167.10","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"poem"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"167.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"167.11","prompt_labels":"In(O) the(O) same(O) year(O) ,(O) he(O) produced(O) the(O) first(O) French(O) language(O) editions(O) of(O) Joseph(O) Conrad(O) '(O) s(O) Heart(O) of(O) Darkness(O) and(O) Lord(O) Jim(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: In the same year , he produced the first French language editions of Joseph Conrad ' s Heart of Darkness and Lord Jim .\n","prediction_output":null,"prediction_outputs":null,"group":"167","words":["In","the","same","year",",","he","produced","the","first","French","language","editions","of","Joseph","Conrad","'","s","Heart","of","Darkness","and","Lord","Jim","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-writer","I-writer","O","O","B-book","I-book","I-book","O","B-book","I-book","O"],"target_index":null,"target_label":"event"},"label_list":["book","location","magazine","writer","literary_genre","organization","country","award","person","poem","event"]}
{"id":"171.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"171.1","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(B-country) to(O) include(O) complete(O) India(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"country"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"171.2","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"book"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"171.3","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"event"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"171.4","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(B-writer) Tagore(I-writer) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"writer"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"171.5","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"poem"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"171.6","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"171.7","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"award"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"171.8","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"organization"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"171.9","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"location"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"171.10","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"person"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"171.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"171.11","prompt_labels":"But(O) opponents(O) of(O) this(O) proposition(O) claim(O) that(O) Rabindranath(O) Tagore(O) mentioned(O) only(O) the(O) border(O) states(O) of(O) India(O) to(O) include(O) complete(O) India(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: But opponents of this proposition claim that Rabindranath Tagore mentioned only the border states of India to include complete India .\n","prediction_output":null,"prediction_outputs":null,"group":"171","words":["But","opponents","of","this","proposition","claim","that","Rabindranath","Tagore","mentioned","only","the","border","states","of","India","to","include","complete","India","."],"labels":["O","O","O","O","O","O","O","B-writer","I-writer","O","O","O","O","O","O","B-country","O","O","O","B-country","O"],"target_index":null,"target_label":"magazine"},"label_list":["country","book","event","writer","poem","literary_genre","award","organization","location","person","magazine"]}
{"id":"190.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"190.1","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"award"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"190.2","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"magazine"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"190.3","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"country"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"190.4","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"190.5","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"book"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"190.6","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"person"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"190.7","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"writer"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"190.8","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(B-poem) Virgin(I-poem) Carrying(I-poem) a(I-poem) Lantern(I-poem) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"poem"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"190.9","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"organization"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"190.10","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"location"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"190.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"190.11","prompt_labels":"Another(O) poem(O) that(O) is(O) ambiguous(O) in(O) this(O) respect(O) is(O) The(O) Virgin(O) Carrying(O) a(O) Lantern(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Another poem that is ambiguous in this respect is The Virgin Carrying a Lantern .\n","prediction_output":null,"prediction_outputs":null,"group":"190","words":["Another","poem","that","is","ambiguous","in","this","respect","is","The","Virgin","Carrying","a","Lantern","."],"labels":["O","O","O","O","O","O","O","O","O","B-poem","I-poem","I-poem","I-poem","I-poem","O"],"target_index":null,"target_label":"event"},"label_list":["award","magazine","country","literary_genre","book","person","writer","poem","organization","location","event"]}
{"id":"198.M1","dataset":"crossner_literature","split":"dev","instance":{"id":"198.1","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(B-magazine) American(I-magazine) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: magazine\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"magazine"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M2","dataset":"crossner_literature","split":"dev","instance":{"id":"198.2","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"event"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M3","dataset":"crossner_literature","split":"dev","instance":{"id":"198.3","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: literary_genre\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"literary_genre"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M4","dataset":"crossner_literature","split":"dev","instance":{"id":"198.4","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"person"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M5","dataset":"crossner_literature","split":"dev","instance":{"id":"198.5","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"location"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M6","dataset":"crossner_literature","split":"dev","instance":{"id":"198.6","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"country"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M7","dataset":"crossner_literature","split":"dev","instance":{"id":"198.7","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: poem\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"poem"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M8","dataset":"crossner_literature","split":"dev","instance":{"id":"198.8","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"award"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M9","dataset":"crossner_literature","split":"dev","instance":{"id":"198.9","prompt_labels":"When(O) Martin(B-writer) Gardner(I-writer) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(B-writer) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: writer\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"writer"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M10","dataset":"crossner_literature","split":"dev","instance":{"id":"198.10","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(B-book) Games(I-book) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(B-book) Themas(I-book) ((O) an(O) anagram(O) of(O) Mathematical(B-book) Games(I-book) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: book\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"book"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"198.M11","dataset":"crossner_literature","split":"dev","instance":{"id":"198.11","prompt_labels":"When(O) Martin(O) Gardner(O) retired(O) from(O) writing(O) his(O) Mathematical(O) Games(O) column(O) for(O) Scientific(O) American(O) magazine(O) ,(O) Hofstadter(O) succeeded(O) him(O) in(O) 1981-1983(O) with(O) a(O) column(O) titled(O) Metamagical(O) Themas(O) ((O) an(O) anagram(O) of(O) Mathematical(O) Games(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: When Martin Gardner retired from writing his Mathematical Games column for Scientific American magazine , Hofstadter succeeded him in 1981-1983 with a column titled Metamagical Themas ( an anagram of Mathematical Games ) .\n","prediction_output":null,"prediction_outputs":null,"group":"198","words":["When","Martin","Gardner","retired","from","writing","his","Mathematical","Games","column","for","Scientific","American","magazine",",","Hofstadter","succeeded","him","in","1981-1983","with","a","column","titled","Metamagical","Themas","(","an","anagram","of","Mathematical","Games",")","."],"labels":["O","B-writer","I-writer","O","O","O","O","B-book","I-book","O","O","B-magazine","I-magazine","O","O","B-writer","O","O","O","O","O","O","O","O","B-book","I-book","O","O","O","O","B-book","I-book","O","O"],"target_index":null,"target_label":"organization"},"label_list":["magazine","event","literary_genre","person","location","country","poem","award","writer","book","organization"]}
{"id":"8.M1","dataset":"crossner_music","split":"dev","instance":{"id":"8.1","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"award"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M2","dataset":"crossner_music","split":"dev","instance":{"id":"8.2","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M3","dataset":"crossner_music","split":"dev","instance":{"id":"8.3","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"country"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M4","dataset":"crossner_music","split":"dev","instance":{"id":"8.4","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"person"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M5","dataset":"crossner_music","split":"dev","instance":{"id":"8.5","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"band"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M6","dataset":"crossner_music","split":"dev","instance":{"id":"8.6","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"event"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M7","dataset":"crossner_music","split":"dev","instance":{"id":"8.7","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"album"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M8","dataset":"crossner_music","split":"dev","instance":{"id":"8.8","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"song"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M9","dataset":"crossner_music","split":"dev","instance":{"id":"8.9","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"location"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M10","dataset":"crossner_music","split":"dev","instance":{"id":"8.10","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M11","dataset":"crossner_music","split":"dev","instance":{"id":"8.11","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"organization"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"8.M12","dataset":"crossner_music","split":"dev","instance":{"id":"8.12","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(O) by(O) the(O) Australian(O) Recording(O) Industry(O) Association(O) ((O) ARIA(O) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(O) by(O) the(O) British(O) Phonographic(O) Industry(O) ((O) BPI(O) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(O) by(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) ((O) RIAA(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .\n","prediction_output":null,"prediction_outputs":null,"group":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"target_index":null,"target_label":"music_genre"},"label_list":["award","musical_artist","country","person","band","event","album","song","location","musical_instrument","organization","music_genre"]}
{"id":"16.M1","dataset":"crossner_music","split":"dev","instance":{"id":"16.1","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2011(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2015(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2016(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2018(I-event) and(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2019(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"event"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M2","dataset":"crossner_music","split":"dev","instance":{"id":"16.2","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M3","dataset":"crossner_music","split":"dev","instance":{"id":"16.3","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"organization"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M4","dataset":"crossner_music","split":"dev","instance":{"id":"16.4","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"person"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M5","dataset":"crossner_music","split":"dev","instance":{"id":"16.5","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"band"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M6","dataset":"crossner_music","split":"dev","instance":{"id":"16.6","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"location"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M7","dataset":"crossner_music","split":"dev","instance":{"id":"16.7","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"album"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M8","dataset":"crossner_music","split":"dev","instance":{"id":"16.8","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"country"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M9","dataset":"crossner_music","split":"dev","instance":{"id":"16.9","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M10","dataset":"crossner_music","split":"dev","instance":{"id":"16.10","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"award"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M11","dataset":"crossner_music","split":"dev","instance":{"id":"16.11","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"music_genre"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"16.M12","dataset":"crossner_music","split":"dev","instance":{"id":"16.12","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(O) Song(O) Contest(O) 2011(O) ,(O) Eurovision(O) Song(O) Contest(O) 2015(O) ,(O) Eurovision(O) Song(O) Contest(O) 2016(O) ,(O) Eurovision(O) Song(O) Contest(O) 2018(O) and(O) Eurovision(O) Song(O) Contest(O) 2019(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .\n","prediction_output":null,"prediction_outputs":null,"group":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"target_index":null,"target_label":"song"},"label_list":["event","musical_artist","organization","person","band","location","album","country","musical_instrument","award","music_genre","song"]}
{"id":"102.M1","dataset":"crossner_music","split":"dev","instance":{"id":"102.1","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"event"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M2","dataset":"crossner_music","split":"dev","instance":{"id":"102.2","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M3","dataset":"crossner_music","split":"dev","instance":{"id":"102.3","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"album"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M4","dataset":"crossner_music","split":"dev","instance":{"id":"102.4","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"award"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M5","dataset":"crossner_music","split":"dev","instance":{"id":"102.5","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"music_genre"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M6","dataset":"crossner_music","split":"dev","instance":{"id":"102.6","prompt_labels":"Steve(B-musical_artist) Young(I-musical_artist) ,(O) David(B-musical_artist) Allan(I-musical_artist) Coe(I-musical_artist) ,(O) John(B-musical_artist) Prine(I-musical_artist) ,(O) Billy(B-musical_artist) Joe(I-musical_artist) Shaver(I-musical_artist) ,(O) Gary(B-musical_artist) Stewart(I-musical_artist) ,(O) Townes(B-musical_artist) Van(I-musical_artist) Zandt(I-musical_artist) ,(O) Kris(B-musical_artist) Kristofferson(I-musical_artist) ,(O) Michael(B-musical_artist) Martin(I-musical_artist) Murphey(I-musical_artist) ,(O) Tompall(B-musical_artist) Glaser(I-musical_artist) ,(O) Steve(B-musical_artist) Earle(I-musical_artist) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(B-musical_artist) Cash(I-musical_artist) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(B-musical_artist) Colter(I-musical_artist) ,(O) Sammi(B-musical_artist) Smith(I-musical_artist) ,(O) Tanya(B-musical_artist) Tucker(I-musical_artist) ,(O) and(O) Rosanne(B-musical_artist) Cash(I-musical_artist) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M7","dataset":"crossner_music","split":"dev","instance":{"id":"102.7","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"location"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M8","dataset":"crossner_music","split":"dev","instance":{"id":"102.8","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"organization"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M9","dataset":"crossner_music","split":"dev","instance":{"id":"102.9","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"country"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M10","dataset":"crossner_music","split":"dev","instance":{"id":"102.10","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"band"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M11","dataset":"crossner_music","split":"dev","instance":{"id":"102.11","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"song"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"102.M12","dataset":"crossner_music","split":"dev","instance":{"id":"102.12","prompt_labels":"Steve(O) Young(O) ,(O) David(O) Allan(O) Coe(O) ,(O) John(O) Prine(O) ,(O) Billy(O) Joe(O) Shaver(O) ,(O) Gary(O) Stewart(O) ,(O) Townes(O) Van(O) Zandt(O) ,(O) Kris(O) Kristofferson(O) ,(O) Michael(O) Martin(O) Murphey(O) ,(O) Tompall(O) Glaser(O) ,(O) Steve(O) Earle(O) ,(O) and(O) the(O) later(O) career(O) renaissance(O) of(O) Johnny(O) Cash(O) ,(O) along(O) with(O) a(O) few(O) female(O) vocalists(O) such(O) as(O) Jessi(O) Colter(O) ,(O) Sammi(O) Smith(O) ,(O) Tanya(O) Tucker(O) ,(O) and(O) Rosanne(O) Cash(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Steve Young , David Allan Coe , John Prine , Billy Joe Shaver , Gary Stewart , Townes Van Zandt , Kris Kristofferson , Michael Martin Murphey , Tompall Glaser , Steve Earle , and the later career renaissance of Johnny Cash , along with a few female vocalists such as Jessi Colter , Sammi Smith , Tanya Tucker , and Rosanne Cash .\n","prediction_output":null,"prediction_outputs":null,"group":"102","words":["Steve","Young",",","David","Allan","Coe",",","John","Prine",",","Billy","Joe","Shaver",",","Gary","Stewart",",","Townes","Van","Zandt",",","Kris","Kristofferson",",","Michael","Martin","Murphey",",","Tompall","Glaser",",","Steve","Earle",",","and","the","later","career","renaissance","of","Johnny","Cash",",","along","with","a","few","female","vocalists","such","as","Jessi","Colter",",","Sammi","Smith",",","Tanya","Tucker",",","and","Rosanne","Cash","."],"labels":["B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","O","B-musical_artist","I-musical_artist","O"],"target_index":null,"target_label":"person"},"label_list":["event","musical_instrument","album","award","music_genre","musical_artist","location","organization","country","band","song","person"]}
{"id":"117.M1","dataset":"crossner_music","split":"dev","instance":{"id":"117.1","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"song"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M2","dataset":"crossner_music","split":"dev","instance":{"id":"117.2","prompt_labels":"Jones(B-musical_artist) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M3","dataset":"crossner_music","split":"dev","instance":{"id":"117.3","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"location"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M4","dataset":"crossner_music","split":"dev","instance":{"id":"117.4","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"album"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M5","dataset":"crossner_music","split":"dev","instance":{"id":"117.5","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"music_genre"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M6","dataset":"crossner_music","split":"dev","instance":{"id":"117.6","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"band"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M7","dataset":"crossner_music","split":"dev","instance":{"id":"117.7","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M8","dataset":"crossner_music","split":"dev","instance":{"id":"117.8","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"person"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M9","dataset":"crossner_music","split":"dev","instance":{"id":"117.9","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"event"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M10","dataset":"crossner_music","split":"dev","instance":{"id":"117.10","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(B-organization) ,(O) GLAAD(B-organization) ,(O) Peace(B-organization) Games(I-organization) ,(O) AmfAR(B-organization) ,(O) and(O) the(O) Maybach(B-organization) Foundation(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"organization"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M11","dataset":"crossner_music","split":"dev","instance":{"id":"117.11","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"country"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"117.M12","dataset":"crossner_music","split":"dev","instance":{"id":"117.12","prompt_labels":"Jones(O) supports(O) a(O) number(O) of(O) other(O) charities(O) ,(O) including(O) the(O) NAACP(O) ,(O) GLAAD(O) ,(O) Peace(O) Games(O) ,(O) AmfAR(O) ,(O) and(O) the(O) Maybach(O) Foundation(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Jones supports a number of other charities , including the NAACP , GLAAD , Peace Games , AmfAR , and the Maybach Foundation .\n","prediction_output":null,"prediction_outputs":null,"group":"117","words":["Jones","supports","a","number","of","other","charities",",","including","the","NAACP",",","GLAAD",",","Peace","Games",",","AmfAR",",","and","the","Maybach","Foundation","."],"labels":["B-musical_artist","O","O","O","O","O","O","O","O","O","B-organization","O","B-organization","O","B-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O"],"target_index":null,"target_label":"award"},"label_list":["song","musical_artist","location","album","music_genre","band","musical_instrument","person","event","organization","country","award"]}
{"id":"124.M1","dataset":"crossner_music","split":"dev","instance":{"id":"124.1","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M2","dataset":"crossner_music","split":"dev","instance":{"id":"124.2","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"event"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M3","dataset":"crossner_music","split":"dev","instance":{"id":"124.3","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"location"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M4","dataset":"crossner_music","split":"dev","instance":{"id":"124.4","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"award"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M5","dataset":"crossner_music","split":"dev","instance":{"id":"124.5","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"album"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M6","dataset":"crossner_music","split":"dev","instance":{"id":"124.6","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"song"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M7","dataset":"crossner_music","split":"dev","instance":{"id":"124.7","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(B-music_genre) metal(I-music_genre) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"music_genre"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M8","dataset":"crossner_music","split":"dev","instance":{"id":"124.8","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"organization"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M9","dataset":"crossner_music","split":"dev","instance":{"id":"124.9","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M10","dataset":"crossner_music","split":"dev","instance":{"id":"124.10","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(B-band) ,(O) Aborted(B-band) ,(O) Exhumed(B-band) ,(O) Dying(B-band) Fetus(I-band) ,(O) Cannibal(B-band) Corpse(I-band) ,(O) and(O) Deicide(B-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"band"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M11","dataset":"crossner_music","split":"dev","instance":{"id":"124.11","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"country"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"124.M12","dataset":"crossner_music","split":"dev","instance":{"id":"124.12","prompt_labels":"High-pitched(O) screaming(O) is(O) occasionally(O) utilized(O) in(O) death(O) metal(O) ,(O) being(O) heard(O) in(O) songs(O) by(O) Death(O) ,(O) Aborted(O) ,(O) Exhumed(O) ,(O) Dying(O) Fetus(O) ,(O) Cannibal(O) Corpse(O) ,(O) and(O) Deicide(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: High-pitched screaming is occasionally utilized in death metal , being heard in songs by Death , Aborted , Exhumed , Dying Fetus , Cannibal Corpse , and Deicide .\n","prediction_output":null,"prediction_outputs":null,"group":"124","words":["High-pitched","screaming","is","occasionally","utilized","in","death","metal",",","being","heard","in","songs","by","Death",",","Aborted",",","Exhumed",",","Dying","Fetus",",","Cannibal","Corpse",",","and","Deicide","."],"labels":["O","O","O","O","O","O","B-music_genre","I-music_genre","O","O","O","O","O","O","B-band","O","B-band","O","B-band","O","B-band","I-band","O","B-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"person"},"label_list":["musical_artist","event","location","award","album","song","music_genre","organization","musical_instrument","band","country","person"]}
{"id":"143.M1","dataset":"crossner_music","split":"dev","instance":{"id":"143.1","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(B-band) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(B-band) ,(O) Rage(B-band) Against(I-band) the(I-band) Machine(I-band) ,(O) The(B-band) Smashing(I-band) Pumpkins(I-band) ,(O) and(O) U2(B-band) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"band"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M2","dataset":"crossner_music","split":"dev","instance":{"id":"143.2","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M3","dataset":"crossner_music","split":"dev","instance":{"id":"143.3","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"event"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M4","dataset":"crossner_music","split":"dev","instance":{"id":"143.4","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"album"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M5","dataset":"crossner_music","split":"dev","instance":{"id":"143.5","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"organization"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M6","dataset":"crossner_music","split":"dev","instance":{"id":"143.6","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"song"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M7","dataset":"crossner_music","split":"dev","instance":{"id":"143.7","prompt_labels":"In(O) 1994(O) ,(O) Yauch(B-musical_artist) and(O) activist(O) Erin(B-musical_artist) Potts(I-musical_artist) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(B-musical_artist) Mills(I-musical_artist) and(O) Michael(B-musical_artist) Stipe(I-musical_artist) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M8","dataset":"crossner_music","split":"dev","instance":{"id":"143.8","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"location"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M9","dataset":"crossner_music","split":"dev","instance":{"id":"143.9","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"country"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M10","dataset":"crossner_music","split":"dev","instance":{"id":"143.10","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"award"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M11","dataset":"crossner_music","split":"dev","instance":{"id":"143.11","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"person"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"143.M12","dataset":"crossner_music","split":"dev","instance":{"id":"143.12","prompt_labels":"In(O) 1994(O) ,(O) Yauch(O) and(O) activist(O) Erin(O) Potts(O) The(O) events(O) became(O) annual(O) ,(O) and(O) shortly(O) after(O) went(O) international(O) with(O) acts(O) such(O) as(O) Live(O) ,(O) Mike(O) Mills(O) and(O) Michael(O) Stipe(O) of(O) R.E.M.(O) ,(O) Rage(O) Against(O) the(O) Machine(O) ,(O) The(O) Smashing(O) Pumpkins(O) ,(O) and(O) U2(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: In 1994 , Yauch and activist Erin Potts The events became annual , and shortly after went international with acts such as Live , Mike Mills and Michael Stipe of R.E.M. , Rage Against the Machine , The Smashing Pumpkins , and U2 .\n","prediction_output":null,"prediction_outputs":null,"group":"143","words":["In","1994",",","Yauch","and","activist","Erin","Potts","The","events","became","annual",",","and","shortly","after","went","international","with","acts","such","as","Live",",","Mike","Mills","and","Michael","Stipe","of","R.E.M.",",","Rage","Against","the","Machine",",","The","Smashing","Pumpkins",",","and","U2","."],"labels":["O","O","O","B-musical_artist","O","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","O","B-band","O","B-band","I-band","I-band","I-band","O","B-band","I-band","I-band","O","O","B-band","O"],"target_index":null,"target_label":"music_genre"},"label_list":["band","musical_instrument","event","album","organization","song","musical_artist","location","country","award","person","music_genre"]}
{"id":"156.M1","dataset":"crossner_music","split":"dev","instance":{"id":"156.1","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"award"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M2","dataset":"crossner_music","split":"dev","instance":{"id":"156.2","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"location"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M3","dataset":"crossner_music","split":"dev","instance":{"id":"156.3","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M4","dataset":"crossner_music","split":"dev","instance":{"id":"156.4","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"band"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M5","dataset":"crossner_music","split":"dev","instance":{"id":"156.5","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"organization"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M6","dataset":"crossner_music","split":"dev","instance":{"id":"156.6","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"country"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M7","dataset":"crossner_music","split":"dev","instance":{"id":"156.7","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M8","dataset":"crossner_music","split":"dev","instance":{"id":"156.8","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(B-song) Ain(I-song) 't(I-song) Marching(I-song) Anymore(I-song) ,(O) Changes(B-song) ,(O) Crucifixion(B-song) ,(O) Draft(B-song) Dodger(I-song) Rag(I-song) ,(O) Love(B-song) Me(I-song) ,(I-song) I(I-song) 'm(I-song) a(I-song) Liberal(I-song) ,(O) Outside(B-song) of(I-song) a(I-song) Small(I-song) Circle(I-song) of(I-song) Friends(I-song) ,(O) Power(B-song) and(I-song) the(I-song) Glory(I-song) ,(O) There(B-song) but(I-song) for(I-song) Fortune(I-song) ,(O) and(O) The(B-song) War(I-song) Is(I-song) Over(I-song) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"song"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M9","dataset":"crossner_music","split":"dev","instance":{"id":"156.9","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"music_genre"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M10","dataset":"crossner_music","split":"dev","instance":{"id":"156.10","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"person"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M11","dataset":"crossner_music","split":"dev","instance":{"id":"156.11","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"event"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"156.M12","dataset":"crossner_music","split":"dev","instance":{"id":"156.12","prompt_labels":"His(O) best-known(O) songs(O) include(O) I(O) Ain(O) 't(O) Marching(O) Anymore(O) ,(O) Changes(O) ,(O) Crucifixion(O) ,(O) Draft(O) Dodger(O) Rag(O) ,(O) Love(O) Me(O) ,(O) I(O) 'm(O) a(O) Liberal(O) ,(O) Outside(O) of(O) a(O) Small(O) Circle(O) of(O) Friends(O) ,(O) Power(O) and(O) the(O) Glory(O) ,(O) There(O) but(O) for(O) Fortune(O) ,(O) and(O) The(O) War(O) Is(O) Over(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: His best-known songs include I Ain 't Marching Anymore , Changes , Crucifixion , Draft Dodger Rag , Love Me , I 'm a Liberal , Outside of a Small Circle of Friends , Power and the Glory , There but for Fortune , and The War Is Over .\n","prediction_output":null,"prediction_outputs":null,"group":"156","words":["His","best-known","songs","include","I","Ain","'t","Marching","Anymore",",","Changes",",","Crucifixion",",","Draft","Dodger","Rag",",","Love","Me",",","I","'m","a","Liberal",",","Outside","of","a","Small","Circle","of","Friends",",","Power","and","the","Glory",",","There","but","for","Fortune",",","and","The","War","Is","Over","."],"labels":["O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-song","O","B-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"album"},"label_list":["award","location","musical_artist","band","organization","country","musical_instrument","song","music_genre","person","event","album"]}
{"id":"168.M1","dataset":"crossner_music","split":"dev","instance":{"id":"168.1","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M2","dataset":"crossner_music","split":"dev","instance":{"id":"168.2","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M3","dataset":"crossner_music","split":"dev","instance":{"id":"168.3","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"song"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M4","dataset":"crossner_music","split":"dev","instance":{"id":"168.4","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M5","dataset":"crossner_music","split":"dev","instance":{"id":"168.5","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"album"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M6","dataset":"crossner_music","split":"dev","instance":{"id":"168.6","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) and(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M7","dataset":"crossner_music","split":"dev","instance":{"id":"168.7","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"music_genre"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M8","dataset":"crossner_music","split":"dev","instance":{"id":"168.8","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M9","dataset":"crossner_music","split":"dev","instance":{"id":"168.9","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"band"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M10","dataset":"crossner_music","split":"dev","instance":{"id":"168.10","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M11","dataset":"crossner_music","split":"dev","instance":{"id":"168.11","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"168.M12","dataset":"crossner_music","split":"dev","instance":{"id":"168.12","prompt_labels":"The(O) album(O) was(O) certified(O) gold(O) by(O) both(O) British(O) Phonographic(O) Industry(O) and(O) the(O) Recording(O) Industry(O) Association(O) of(O) America(O) in(O) December(O) 2007(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: The album was certified gold by both British Phonographic Industry and the Recording Industry Association of America in December 2007 .\n","prediction_output":null,"prediction_outputs":null,"group":"168","words":["The","album","was","certified","gold","by","both","British","Phonographic","Industry","and","the","Recording","Industry","Association","of","America","in","December","2007","."],"labels":["O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["musical_artist","award","song","location","album","organization","music_genre","event","band","musical_instrument","person","country"]}
{"id":"188.M1","dataset":"crossner_music","split":"dev","instance":{"id":"188.1","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(B-band) Class(I-band) Heroes(I-band) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"band"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M2","dataset":"crossner_music","split":"dev","instance":{"id":"188.2","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M3","dataset":"crossner_music","split":"dev","instance":{"id":"188.3","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M4","dataset":"crossner_music","split":"dev","instance":{"id":"188.4","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"album"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M5","dataset":"crossner_music","split":"dev","instance":{"id":"188.5","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"song"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M6","dataset":"crossner_music","split":"dev","instance":{"id":"188.6","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(B-musical_artist) D(I-musical_artist) and(O) LL(B-musical_artist) Cool(I-musical_artist) J(I-musical_artist) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(B-musical_artist) Thought(I-musical_artist) ,(O) Travie(B-musical_artist) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(B-musical_artist) Rock(I-musical_artist) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M7","dataset":"crossner_music","split":"dev","instance":{"id":"188.7","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M8","dataset":"crossner_music","split":"dev","instance":{"id":"188.8","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"music_genre"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M9","dataset":"crossner_music","split":"dev","instance":{"id":"188.9","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M10","dataset":"crossner_music","split":"dev","instance":{"id":"188.10","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M11","dataset":"crossner_music","split":"dev","instance":{"id":"188.11","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"188.M12","dataset":"crossner_music","split":"dev","instance":{"id":"188.12","prompt_labels":"They(O) were(O) inducted(O) by(O) Chuck(O) D(O) and(O) LL(O) Cool(O) J(O) on(O) April(O) 14(O) ,(O) 2012(O) therefore(O) the(O) group(O) didn(O) 't(O) perform(O) ;(O) instead(O) Black(O) Thought(O) ,(O) Travie(O) from(O) Gym(O) Class(O) Heroes(O) and(O) Kid(O) Rock(O) performed(O) a(O) medley(O) of(O) their(O) songs(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: They were inducted by Chuck D and LL Cool J on April 14 , 2012 therefore the group didn 't perform ; instead Black Thought , Travie from Gym Class Heroes and Kid Rock performed a medley of their songs .\n","prediction_output":null,"prediction_outputs":null,"group":"188","words":["They","were","inducted","by","Chuck","D","and","LL","Cool","J","on","April","14",",","2012","therefore","the","group","didn","'t","perform",";","instead","Black","Thought",",","Travie","from","Gym","Class","Heroes","and","Kid","Rock","performed","a","medley","of","their","songs","."],"labels":["O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","I-musical_artist","I-musical_artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical_artist","I-musical_artist","O","B-musical_artist","O","B-band","I-band","I-band","O","B-musical_artist","I-musical_artist","O","O","O","O","O","O","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["band","person","organization","album","song","musical_artist","event","music_genre","location","award","country","musical_instrument"]}
{"id":"197.M1","dataset":"crossner_music","split":"dev","instance":{"id":"197.1","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"country"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M2","dataset":"crossner_music","split":"dev","instance":{"id":"197.2","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(B-song) Queen(I-song) ,(O) Bohemian(B-song) Rhapsody(I-song) ,(O) Somebody(B-song) to(I-song) Love(I-song) ,(O) We(B-song) Are(I-song) the(I-song) Champions(I-song) ,(O) Don(B-song) 't(I-song) Stop(I-song) Me(I-song) Now(I-song) ,(O) and(O) Crazy(B-song) Little(I-song) Thing(I-song) Called(I-song) Love(I-song) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: song\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"song"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M3","dataset":"crossner_music","split":"dev","instance":{"id":"197.3","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: album\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"album"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M4","dataset":"crossner_music","split":"dev","instance":{"id":"197.4","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(B-band) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: band\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"band"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M5","dataset":"crossner_music","split":"dev","instance":{"id":"197.5","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"organization"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M6","dataset":"crossner_music","split":"dev","instance":{"id":"197.6","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"award"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M7","dataset":"crossner_music","split":"dev","instance":{"id":"197.7","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"location"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M8","dataset":"crossner_music","split":"dev","instance":{"id":"197.8","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"event"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M9","dataset":"crossner_music","split":"dev","instance":{"id":"197.9","prompt_labels":"Mercury(B-musical_artist) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_artist\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"musical_artist"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M10","dataset":"crossner_music","split":"dev","instance":{"id":"197.10","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"person"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M11","dataset":"crossner_music","split":"dev","instance":{"id":"197.11","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: musical_instrument\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"musical_instrument"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"197.M12","dataset":"crossner_music","split":"dev","instance":{"id":"197.12","prompt_labels":"Mercury(O) wrote(O) numerous(O) hits(O) for(O) Queen(O) ,(O) including(O) Killer(O) Queen(O) ,(O) Bohemian(O) Rhapsody(O) ,(O) Somebody(O) to(O) Love(O) ,(O) We(O) Are(O) the(O) Champions(O) ,(O) Don(O) 't(O) Stop(O) Me(O) Now(O) ,(O) and(O) Crazy(O) Little(O) Thing(O) Called(O) Love(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: music_genre\nGIVEN SENTENCE: Mercury wrote numerous hits for Queen , including Killer Queen , Bohemian Rhapsody , Somebody to Love , We Are the Champions , Don 't Stop Me Now , and Crazy Little Thing Called Love .\n","prediction_output":null,"prediction_outputs":null,"group":"197","words":["Mercury","wrote","numerous","hits","for","Queen",",","including","Killer","Queen",",","Bohemian","Rhapsody",",","Somebody","to","Love",",","We","Are","the","Champions",",","Don","'t","Stop","Me","Now",",","and","Crazy","Little","Thing","Called","Love","."],"labels":["B-musical_artist","O","O","O","O","B-band","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","I-song","O"],"target_index":null,"target_label":"music_genre"},"label_list":["country","song","album","band","organization","award","location","event","musical_artist","person","musical_instrument","music_genre"]}
{"id":"30.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"30.1","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(O) Ross(O) of(O) the(O) Ulster(O) Unionist(O) Party(O) who(O) had(O) represented(O) East(O) Londonderry(O) since(O) 1983(O) United(O) Kingdom(O) general(O) election(O) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(O) between(O) February(O) 1974(O) United(O) Kingdom(O) general(O) election(O) and(O) 1983(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"country"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"30.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"30.2","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(O) Ross(O) of(O) the(O) Ulster(O) Unionist(O) Party(O) who(O) had(O) represented(O) East(O) Londonderry(O) since(O) 1983(O) United(O) Kingdom(O) general(O) election(O) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(O) between(O) February(O) 1974(O) United(O) Kingdom(O) general(O) election(O) and(O) 1983(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"organization"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"30.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"30.3","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(O) Ross(O) of(O) the(O) Ulster(B-political_party) Unionist(I-political_party) Party(I-political_party) who(O) had(O) represented(O) East(O) Londonderry(O) since(O) 1983(O) United(O) Kingdom(O) general(O) election(O) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(O) between(O) February(O) 1974(O) United(O) Kingdom(O) general(O) election(O) and(O) 1983(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"political_party"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"30.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"30.4","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(O) Ross(O) of(O) the(O) Ulster(O) Unionist(O) Party(O) who(O) had(O) represented(O) East(O) Londonderry(O) since(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(O) between(O) February(B-election) 1974(I-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1983(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"election"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"30.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"30.5","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(B-politician) Ross(I-politician) of(O) the(O) Ulster(O) Unionist(O) Party(O) who(O) had(O) represented(O) East(O) Londonderry(O) since(O) 1983(O) United(O) Kingdom(O) general(O) election(O) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(O) between(O) February(O) 1974(O) United(O) Kingdom(O) general(O) election(O) and(O) 1983(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"politician"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"30.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"30.6","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(O) Ross(O) of(O) the(O) Ulster(O) Unionist(O) Party(O) who(O) had(O) represented(O) East(B-location) Londonderry(I-location) since(O) 1983(O) United(O) Kingdom(O) general(O) election(O) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(B-location) between(O) February(O) 1974(O) United(O) Kingdom(O) general(O) election(O) and(O) 1983(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"location"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"30.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"30.7","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(O) Ross(O) of(O) the(O) Ulster(O) Unionist(O) Party(O) who(O) had(O) represented(O) East(O) Londonderry(O) since(O) 1983(O) United(O) Kingdom(O) general(O) election(O) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(O) between(O) February(O) 1974(O) United(O) Kingdom(O) general(O) election(O) and(O) 1983(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"person"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"30.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"30.8","prompt_labels":"In(O) that(O) election(O) he(O) defeated(O) William(O) Ross(O) of(O) the(O) Ulster(O) Unionist(O) Party(O) who(O) had(O) represented(O) East(O) Londonderry(O) since(O) 1983(O) United(O) Kingdom(O) general(O) election(O) and(O) its(O) predecessor(O) seat(O) of(O) Londonderry(O) between(O) February(O) 1974(O) United(O) Kingdom(O) general(O) election(O) and(O) 1983(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: In that election he defeated William Ross of the Ulster Unionist Party who had represented East Londonderry since 1983 United Kingdom general election and its predecessor seat of Londonderry between February 1974 United Kingdom general election and 1983 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["In","that","election","he","defeated","William","Ross","of","the","Ulster","Unionist","Party","who","had","represented","East","Londonderry","since","1983","United","Kingdom","general","election","and","its","predecessor","seat","of","Londonderry","between","February","1974","United","Kingdom","general","election","and","1983","United","Kingdom","general","election","."],"labels":["O","O","O","O","O","B-politician","I-politician","O","O","B-political_party","I-political_party","I-political_party","O","O","O","B-location","I-location","O","B-election","I-election","I-election","I-election","I-election","O","O","O","O","O","B-location","O","B-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"event"},"label_list":["country","organization","political_party","election","politician","location","person","event"]}
{"id":"49.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"49.1","prompt_labels":"AP(O) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(O) Nord(O) in(O) Italy(O) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(O) Marino(O) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(O) Christian(O) Democratic(O) Party(O) ((O) PDCS(O) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(O) of(O) Socialists(O) and(O) Democrats(O) ((O) PSD(O) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"49.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"49.2","prompt_labels":"AP(O) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(O) Nord(O) in(O) Italy(O) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(O) Marino(O) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(O) Christian(O) Democratic(O) Party(O) ((O) PDCS(O) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(O) of(O) Socialists(O) and(O) Democrats(O) ((O) PSD(O) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"election"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"49.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"49.3","prompt_labels":"AP(O) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(O) Nord(O) in(O) Italy(O) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(B-location) Marino(I-location) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(O) Christian(O) Democratic(O) Party(O) ((O) PDCS(O) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(O) of(O) Socialists(O) and(O) Democrats(O) ((O) PSD(O) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"49.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"49.4","prompt_labels":"AP(O) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(O) Nord(O) in(O) Italy(O) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(O) Marino(O) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(O) Christian(O) Democratic(O) Party(O) ((O) PDCS(O) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(O) of(O) Socialists(O) and(O) Democrats(O) ((O) PSD(O) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"49.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"49.5","prompt_labels":"AP(O) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(O) Nord(O) in(O) Italy(O) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(O) Marino(O) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(O) Christian(O) Democratic(O) Party(O) ((O) PDCS(O) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(O) of(O) Socialists(O) and(O) Democrats(O) ((O) PSD(O) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"49.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"49.6","prompt_labels":"AP(O) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(O) Nord(O) in(O) Italy(O) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(O) Marino(O) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(O) Christian(O) Democratic(O) Party(O) ((O) PDCS(O) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(O) of(O) Socialists(O) and(O) Democrats(O) ((O) PSD(O) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"politician"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"49.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"49.7","prompt_labels":"AP(B-political_party) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(B-political_party) Nord(I-political_party) in(O) Italy(O) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(O) Marino(O) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(B-political_party) Christian(I-political_party) Democratic(I-political_party) Party(I-political_party) ((O) PDCS(B-political_party) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(B-political_party) of(I-political_party) Socialists(I-political_party) and(I-political_party) Democrats(I-political_party) ((O) PSD(B-political_party) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"political_party"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"49.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"49.8","prompt_labels":"AP(O) was(O) born(O) as(O) an(O) anti-establishment(O) party(O) in(O) 1993(O) ,(O) in(O) parallel(O) with(O) the(O) rise(O) of(O) Lega(O) Nord(O) in(O) Italy(B-country) ,(O) of(O) which(O) it(O) has(O) been(O) long(O) considered(O) the(O) Sanmarinese(O) counterpart(O) ,(O) but(O) has(O) since(O) then(O) become(O) a(O) stable(O) political(O) force(O) in(O) San(O) Marino(O) ,(O) participating(O) in(O) government(O) coalitions(O) with(O) the(O) centrist(O) Sammarinese(O) Christian(O) Democratic(O) Party(O) ((O) PDCS(O) )(O) as(O) well(O) as(O) with(O) the(O) centre-left(O) Party(O) of(O) Socialists(O) and(O) Democrats(O) ((O) PSD(O) )(O) since(O) 2002(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: AP was born as an anti-establishment party in 1993 , in parallel with the rise of Lega Nord in Italy , of which it has been long considered the Sanmarinese counterpart , but has since then become a stable political force in San Marino , participating in government coalitions with the centrist Sammarinese Christian Democratic Party ( PDCS ) as well as with the centre-left Party of Socialists and Democrats ( PSD ) since 2002 .\n","prediction_output":null,"prediction_outputs":null,"group":"49","words":["AP","was","born","as","an","anti-establishment","party","in","1993",",","in","parallel","with","the","rise","of","Lega","Nord","in","Italy",",","of","which","it","has","been","long","considered","the","Sanmarinese","counterpart",",","but","has","since","then","become","a","stable","political","force","in","San","Marino",",","participating","in","government","coalitions","with","the","centrist","Sammarinese","Christian","Democratic","Party","(","PDCS",")","as","well","as","with","the","centre-left","Party","of","Socialists","and","Democrats","(","PSD",")","since","2002","."],"labels":["B-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["event","election","location","organization","person","politician","political_party","country"]}
{"id":"64.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"64.1","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(O) Unionist(O) Party(O) and(O) the(O) Democratic(O) Unionist(O) Party(O) to(O) be(O) the(O) leading(O) unionist(O) party(O) ,(O) between(O) the(O) Social(O) Democratic(O) and(O) Labour(O) Party(O) and(O) Sinn(O) Féin(O) to(O) be(O) the(O) leading(O) nationalist(O) party(O) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(O) Down(O) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"64.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"64.2","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(O) Unionist(O) Party(O) and(O) the(O) Democratic(O) Unionist(O) Party(O) to(O) be(O) the(O) leading(O) unionist(O) party(O) ,(O) between(O) the(O) Social(O) Democratic(O) and(O) Labour(O) Party(O) and(O) Sinn(O) Féin(O) to(O) be(O) the(O) leading(O) nationalist(O) party(O) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(O) Down(O) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"64.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"64.3","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(B-political_party) Unionist(I-political_party) Party(I-political_party) and(O) the(O) Democratic(B-political_party) Unionist(I-political_party) Party(I-political_party) to(O) be(O) the(O) leading(O) unionist(B-political_party) party(I-political_party) ,(O) between(O) the(O) Social(B-political_party) Democratic(I-political_party) and(I-political_party) Labour(I-political_party) Party(I-political_party) and(O) Sinn(B-political_party) Féin(I-political_party) to(O) be(O) the(O) leading(O) nationalist(B-political_party) party(I-political_party) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(O) Down(O) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"political_party"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"64.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"64.4","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(O) Unionist(O) Party(O) and(O) the(O) Democratic(O) Unionist(O) Party(O) to(O) be(O) the(O) leading(O) unionist(O) party(O) ,(O) between(O) the(O) Social(O) Democratic(O) and(O) Labour(O) Party(O) and(O) Sinn(O) Féin(O) to(O) be(O) the(O) leading(O) nationalist(O) party(O) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(O) Down(O) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"politician"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"64.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"64.5","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(O) Unionist(O) Party(O) and(O) the(O) Democratic(O) Unionist(O) Party(O) to(O) be(O) the(O) leading(O) unionist(O) party(O) ,(O) between(O) the(O) Social(O) Democratic(O) and(O) Labour(O) Party(O) and(O) Sinn(O) Féin(O) to(O) be(O) the(O) leading(O) nationalist(O) party(O) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(O) Down(O) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"64.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"64.6","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(O) Unionist(O) Party(O) and(O) the(O) Democratic(O) Unionist(O) Party(O) to(O) be(O) the(O) leading(O) unionist(O) party(O) ,(O) between(O) the(O) Social(O) Democratic(O) and(O) Labour(O) Party(O) and(O) Sinn(O) Féin(O) to(O) be(O) the(O) leading(O) nationalist(O) party(O) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(O) Down(O) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"election"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"64.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"64.7","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(O) Unionist(O) Party(O) and(O) the(O) Democratic(O) Unionist(O) Party(O) to(O) be(O) the(O) leading(O) unionist(O) party(O) ,(O) between(O) the(O) Social(O) Democratic(O) and(O) Labour(O) Party(O) and(O) Sinn(O) Féin(O) to(O) be(O) the(O) leading(O) nationalist(O) party(O) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(B-location) Down(I-location) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"64.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"64.8","prompt_labels":"Whereas(O) elsewhere(O) there(O) are(O) effectively(O) three(O) fundamental(O) battles(O) fought(O) in(O) elections(O) -(O) between(O) the(O) Ulster(O) Unionist(O) Party(O) and(O) the(O) Democratic(O) Unionist(O) Party(O) to(O) be(O) the(O) leading(O) unionist(O) party(O) ,(O) between(O) the(O) Social(O) Democratic(O) and(O) Labour(O) Party(O) and(O) Sinn(O) Féin(O) to(O) be(O) the(O) leading(O) nationalist(O) party(O) ,(O) and(O) between(O) unionism(O) and(O) nationalism(O) as(O) a(O) whole(O) ,(O) North(O) Down(O) is(O) different(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Whereas elsewhere there are effectively three fundamental battles fought in elections - between the Ulster Unionist Party and the Democratic Unionist Party to be the leading unionist party , between the Social Democratic and Labour Party and Sinn Féin to be the leading nationalist party , and between unionism and nationalism as a whole , North Down is different .\n","prediction_output":null,"prediction_outputs":null,"group":"64","words":["Whereas","elsewhere","there","are","effectively","three","fundamental","battles","fought","in","elections","-","between","the","Ulster","Unionist","Party","and","the","Democratic","Unionist","Party","to","be","the","leading","unionist","party",",","between","the","Social","Democratic","and","Labour","Party","and","Sinn","Féin","to","be","the","leading","nationalist","party",",","and","between","unionism","and","nationalism","as","a","whole",",","North","Down","is","different","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","O","O","O","O","B-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["event","person","political_party","politician","organization","election","location","country"]}
{"id":"67.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"67.1","prompt_labels":"Ayaan(O) Hirsi(O) Ali(O) is(O) a(O) Fellow(O) with(O) the(O) Hoover(O) Institution(O) at(O) Stanford(O) University(O) ,(O) a(O) Fellow(O) with(O) the(O) Future(O) of(O) Diplomacy(O) Project(O) at(O) the(O) Belfer(O) Center(O) for(O) Science(O) and(O) International(O) Affairs(O) at(O) The(O) Harvard(O) Kennedy(O) School(O) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(O) Enterprise(O) Institute(O) in(O) Washington(O) ,(O) D.C.(O) ,(O) and(O) a(O) member(O) of(O) the(O) Council(O) on(O) Foreign(O) Relations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"event"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"67.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"67.2","prompt_labels":"Ayaan(O) Hirsi(O) Ali(O) is(O) a(O) Fellow(O) with(O) the(O) Hoover(O) Institution(O) at(O) Stanford(O) University(O) ,(O) a(O) Fellow(O) with(O) the(O) Future(O) of(O) Diplomacy(O) Project(O) at(O) the(O) Belfer(O) Center(O) for(O) Science(O) and(O) International(O) Affairs(O) at(O) The(O) Harvard(O) Kennedy(O) School(O) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(O) Enterprise(O) Institute(O) in(O) Washington(O) ,(O) D.C.(O) ,(O) and(O) a(O) member(O) of(O) the(O) Council(O) on(O) Foreign(O) Relations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"person"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"67.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"67.3","prompt_labels":"Ayaan(O) Hirsi(O) Ali(O) is(O) a(O) Fellow(O) with(O) the(O) Hoover(O) Institution(O) at(O) Stanford(O) University(O) ,(O) a(O) Fellow(O) with(O) the(O) Future(O) of(O) Diplomacy(O) Project(O) at(O) the(O) Belfer(O) Center(O) for(O) Science(O) and(O) International(O) Affairs(O) at(O) The(O) Harvard(O) Kennedy(O) School(O) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(O) Enterprise(O) Institute(O) in(O) Washington(B-location) ,(I-location) D.C.(I-location) ,(O) and(O) a(O) member(O) of(O) the(O) Council(O) on(O) Foreign(O) Relations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"location"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"67.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"67.4","prompt_labels":"Ayaan(B-politician) Hirsi(I-politician) Ali(I-politician) is(O) a(O) Fellow(O) with(O) the(O) Hoover(O) Institution(O) at(O) Stanford(O) University(O) ,(O) a(O) Fellow(O) with(O) the(O) Future(O) of(O) Diplomacy(O) Project(O) at(O) the(O) Belfer(O) Center(O) for(O) Science(O) and(O) International(O) Affairs(O) at(O) The(O) Harvard(O) Kennedy(O) School(O) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(O) Enterprise(O) Institute(O) in(O) Washington(O) ,(O) D.C.(O) ,(O) and(O) a(O) member(O) of(O) the(O) Council(O) on(O) Foreign(O) Relations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"politician"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"67.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"67.5","prompt_labels":"Ayaan(O) Hirsi(O) Ali(O) is(O) a(O) Fellow(O) with(O) the(O) Hoover(O) Institution(O) at(O) Stanford(O) University(O) ,(O) a(O) Fellow(O) with(O) the(O) Future(O) of(O) Diplomacy(O) Project(O) at(O) the(O) Belfer(O) Center(O) for(O) Science(O) and(O) International(O) Affairs(O) at(O) The(O) Harvard(O) Kennedy(O) School(O) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(O) Enterprise(O) Institute(O) in(O) Washington(O) ,(O) D.C.(O) ,(O) and(O) a(O) member(O) of(O) the(O) Council(O) on(O) Foreign(O) Relations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"election"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"67.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"67.6","prompt_labels":"Ayaan(O) Hirsi(O) Ali(O) is(O) a(O) Fellow(O) with(O) the(O) Hoover(B-organization) Institution(I-organization) at(O) Stanford(B-organization) University(I-organization) ,(O) a(O) Fellow(O) with(O) the(O) Future(B-organization) of(I-organization) Diplomacy(I-organization) Project(I-organization) at(O) the(O) Belfer(B-organization) Center(I-organization) for(I-organization) Science(I-organization) and(I-organization) International(I-organization) Affairs(I-organization) at(O) The(O) Harvard(B-organization) Kennedy(I-organization) School(I-organization) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(B-organization) Enterprise(I-organization) Institute(I-organization) in(O) Washington(O) ,(O) D.C.(O) ,(O) and(O) a(O) member(O) of(O) the(O) Council(B-organization) on(I-organization) Foreign(I-organization) Relations(I-organization) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"organization"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"67.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"67.7","prompt_labels":"Ayaan(O) Hirsi(O) Ali(O) is(O) a(O) Fellow(O) with(O) the(O) Hoover(O) Institution(O) at(O) Stanford(O) University(O) ,(O) a(O) Fellow(O) with(O) the(O) Future(O) of(O) Diplomacy(O) Project(O) at(O) the(O) Belfer(O) Center(O) for(O) Science(O) and(O) International(O) Affairs(O) at(O) The(O) Harvard(O) Kennedy(O) School(O) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(O) Enterprise(O) Institute(O) in(O) Washington(O) ,(O) D.C.(O) ,(O) and(O) a(O) member(O) of(O) the(O) Council(O) on(O) Foreign(O) Relations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"political_party"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"67.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"67.8","prompt_labels":"Ayaan(O) Hirsi(O) Ali(O) is(O) a(O) Fellow(O) with(O) the(O) Hoover(O) Institution(O) at(O) Stanford(O) University(O) ,(O) a(O) Fellow(O) with(O) the(O) Future(O) of(O) Diplomacy(O) Project(O) at(O) the(O) Belfer(O) Center(O) for(O) Science(O) and(O) International(O) Affairs(O) at(O) The(O) Harvard(O) Kennedy(O) School(O) ,(O) a(O) visiting(O) scholar(O) at(O) the(O) American(O) Enterprise(O) Institute(O) in(O) Washington(O) ,(O) D.C.(O) ,(O) and(O) a(O) member(O) of(O) the(O) Council(O) on(O) Foreign(O) Relations(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Ayaan Hirsi Ali is a Fellow with the Hoover Institution at Stanford University , a Fellow with the Future of Diplomacy Project at the Belfer Center for Science and International Affairs at The Harvard Kennedy School , a visiting scholar at the American Enterprise Institute in Washington , D.C. , and a member of the Council on Foreign Relations .\n","prediction_output":null,"prediction_outputs":null,"group":"67","words":["Ayaan","Hirsi","Ali","is","a","Fellow","with","the","Hoover","Institution","at","Stanford","University",",","a","Fellow","with","the","Future","of","Diplomacy","Project","at","the","Belfer","Center","for","Science","and","International","Affairs","at","The","Harvard","Kennedy","School",",","a","visiting","scholar","at","the","American","Enterprise","Institute","in","Washington",",","D.C.",",","and","a","member","of","the","Council","on","Foreign","Relations","."],"labels":["B-politician","I-politician","I-politician","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-location","I-location","I-location","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O"],"target_index":null,"target_label":"country"},"label_list":["event","person","location","politician","election","organization","political_party","country"]}
{"id":"68.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"68.1","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(O) Party(O) of(O) Canada(O) ,(O) the(O) Conservative(O) Party(O) of(O) Canada(O) ,(O) the(O) New(O) Democratic(O) Party(O) and(O) the(O) Green(O) Party(O) of(O) Canada(O) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(B-location) remaining(O) part(O) of(O) Canada(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"location"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"68.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"68.2","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(O) Party(O) of(O) Canada(O) ,(O) the(O) Conservative(O) Party(O) of(O) Canada(O) ,(O) the(O) New(O) Democratic(O) Party(O) and(O) the(O) Green(O) Party(O) of(O) Canada(O) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(O) remaining(O) part(O) of(O) Canada(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"politician"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"68.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"68.3","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(O) Party(O) of(O) Canada(O) ,(O) the(O) Conservative(O) Party(O) of(O) Canada(O) ,(O) the(O) New(O) Democratic(O) Party(O) and(O) the(O) Green(O) Party(O) of(O) Canada(O) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(O) remaining(O) part(O) of(O) Canada(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"event"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"68.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"68.4","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ,(O) the(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) ,(O) the(O) New(B-political_party) Democratic(I-political_party) Party(I-political_party) and(O) the(O) Green(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(O) remaining(O) part(O) of(O) Canada(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"political_party"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"68.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"68.5","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(O) Party(O) of(O) Canada(O) ,(O) the(O) Conservative(O) Party(O) of(O) Canada(O) ,(O) the(O) New(O) Democratic(O) Party(O) and(O) the(O) Green(O) Party(O) of(O) Canada(O) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(O) remaining(O) part(O) of(O) Canada(B-country) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"country"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"68.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"68.6","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(O) Party(O) of(O) Canada(O) ,(O) the(O) Conservative(O) Party(O) of(O) Canada(O) ,(O) the(O) New(O) Democratic(O) Party(O) and(O) the(O) Green(O) Party(O) of(O) Canada(O) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(O) remaining(O) part(O) of(O) Canada(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"person"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"68.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"68.7","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(O) Party(O) of(O) Canada(O) ,(O) the(O) Conservative(O) Party(O) of(O) Canada(O) ,(O) the(O) New(O) Democratic(O) Party(O) and(O) the(O) Green(O) Party(O) of(O) Canada(O) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(O) remaining(O) part(O) of(O) Canada(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"election"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"68.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"68.8","prompt_labels":"Most(O) major(O) federal(O) political(O) parties(O) ,(O) including(O) the(O) Liberal(O) Party(O) of(O) Canada(O) ,(O) the(O) Conservative(O) Party(O) of(O) Canada(O) ,(O) the(O) New(O) Democratic(O) Party(O) and(O) the(O) Green(O) Party(O) of(O) Canada(O) support(O) maintaining(O) the(O) status(O) quo(O) with(O) Quebec(O) remaining(O) part(O) of(O) Canada(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Most major federal political parties , including the Liberal Party of Canada , the Conservative Party of Canada , the New Democratic Party and the Green Party of Canada support maintaining the status quo with Quebec remaining part of Canada .\n","prediction_output":null,"prediction_outputs":null,"group":"68","words":["Most","major","federal","political","parties",",","including","the","Liberal","Party","of","Canada",",","the","Conservative","Party","of","Canada",",","the","New","Democratic","Party","and","the","Green","Party","of","Canada","support","maintaining","the","status","quo","with","Quebec","remaining","part","of","Canada","."],"labels":["O","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","O","O","O","O","B-location","O","O","O","B-country","O"],"target_index":null,"target_label":"organization"},"label_list":["location","politician","event","political_party","country","person","election","organization"]}
{"id":"104.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"104.1","prompt_labels":"Those(O) were(O) the(O) Croatian(B-political_party) Democratic(I-political_party) Union(I-political_party) ,(O) the(O) Croatian(B-political_party) Peasant(I-political_party) Party(I-political_party) ,(O) the(O) Croatian(B-political_party) People(I-political_party) 's(I-political_party) Party(I-political_party) -(I-political_party) Liberal(I-political_party) Democrats(I-political_party) ,(O) the(O) Croatian(B-political_party) Social(I-political_party) Liberal(I-political_party) Party(I-political_party) ,(O) Social(B-political_party) Democratic(I-political_party) Party(I-political_party) of(I-political_party) Croatia(I-political_party) and(O) the(O) Bridge(B-political_party) of(I-political_party) Independent(I-political_party) Lists(I-political_party) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"political_party"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"104.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"104.2","prompt_labels":"Those(O) were(O) the(O) Croatian(O) Democratic(O) Union(O) ,(O) the(O) Croatian(O) Peasant(O) Party(O) ,(O) the(O) Croatian(O) People(O) 's(O) Party(O) -(O) Liberal(O) Democrats(O) ,(O) the(O) Croatian(O) Social(O) Liberal(O) Party(O) ,(O) Social(O) Democratic(O) Party(O) of(O) Croatia(O) and(O) the(O) Bridge(O) of(O) Independent(O) Lists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"event"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"104.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"104.3","prompt_labels":"Those(O) were(O) the(O) Croatian(O) Democratic(O) Union(O) ,(O) the(O) Croatian(O) Peasant(O) Party(O) ,(O) the(O) Croatian(O) People(O) 's(O) Party(O) -(O) Liberal(O) Democrats(O) ,(O) the(O) Croatian(O) Social(O) Liberal(O) Party(O) ,(O) Social(O) Democratic(O) Party(O) of(O) Croatia(O) and(O) the(O) Bridge(O) of(O) Independent(O) Lists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"location"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"104.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"104.4","prompt_labels":"Those(O) were(O) the(O) Croatian(O) Democratic(O) Union(O) ,(O) the(O) Croatian(O) Peasant(O) Party(O) ,(O) the(O) Croatian(O) People(O) 's(O) Party(O) -(O) Liberal(O) Democrats(O) ,(O) the(O) Croatian(O) Social(O) Liberal(O) Party(O) ,(O) Social(O) Democratic(O) Party(O) of(O) Croatia(O) and(O) the(O) Bridge(O) of(O) Independent(O) Lists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"election"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"104.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"104.5","prompt_labels":"Those(O) were(O) the(O) Croatian(O) Democratic(O) Union(O) ,(O) the(O) Croatian(O) Peasant(O) Party(O) ,(O) the(O) Croatian(O) People(O) 's(O) Party(O) -(O) Liberal(O) Democrats(O) ,(O) the(O) Croatian(O) Social(O) Liberal(O) Party(O) ,(O) Social(O) Democratic(O) Party(O) of(O) Croatia(O) and(O) the(O) Bridge(O) of(O) Independent(O) Lists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"country"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"104.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"104.6","prompt_labels":"Those(O) were(O) the(O) Croatian(O) Democratic(O) Union(O) ,(O) the(O) Croatian(O) Peasant(O) Party(O) ,(O) the(O) Croatian(O) People(O) 's(O) Party(O) -(O) Liberal(O) Democrats(O) ,(O) the(O) Croatian(O) Social(O) Liberal(O) Party(O) ,(O) Social(O) Democratic(O) Party(O) of(O) Croatia(O) and(O) the(O) Bridge(O) of(O) Independent(O) Lists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"politician"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"104.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"104.7","prompt_labels":"Those(O) were(O) the(O) Croatian(O) Democratic(O) Union(O) ,(O) the(O) Croatian(O) Peasant(O) Party(O) ,(O) the(O) Croatian(O) People(O) 's(O) Party(O) -(O) Liberal(O) Democrats(O) ,(O) the(O) Croatian(O) Social(O) Liberal(O) Party(O) ,(O) Social(O) Democratic(O) Party(O) of(O) Croatia(O) and(O) the(O) Bridge(O) of(O) Independent(O) Lists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"person"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"104.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"104.8","prompt_labels":"Those(O) were(O) the(O) Croatian(O) Democratic(O) Union(O) ,(O) the(O) Croatian(O) Peasant(O) Party(O) ,(O) the(O) Croatian(O) People(O) 's(O) Party(O) -(O) Liberal(O) Democrats(O) ,(O) the(O) Croatian(O) Social(O) Liberal(O) Party(O) ,(O) Social(O) Democratic(O) Party(O) of(O) Croatia(O) and(O) the(O) Bridge(O) of(O) Independent(O) Lists(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Those were the Croatian Democratic Union , the Croatian Peasant Party , the Croatian People 's Party - Liberal Democrats , the Croatian Social Liberal Party , Social Democratic Party of Croatia and the Bridge of Independent Lists .\n","prediction_output":null,"prediction_outputs":null,"group":"104","words":["Those","were","the","Croatian","Democratic","Union",",","the","Croatian","Peasant","Party",",","the","Croatian","People","'s","Party","-","Liberal","Democrats",",","the","Croatian","Social","Liberal","Party",",","Social","Democratic","Party","of","Croatia","and","the","Bridge","of","Independent","Lists","."],"labels":["O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","B-political_party","I-political_party","I-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O"],"target_index":null,"target_label":"organization"},"label_list":["political_party","event","location","election","country","politician","person","organization"]}
{"id":"122.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"122.1","prompt_labels":"Stanley(O) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(O) Lyulph(O) Stanley(O) )(O) contested(O) Oldham(B-location) ,(O) in(O) the(O) Liberal(O) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(O) United(O) Kingdom(O) general(O) election(O) ,(O) 1880(O) United(O) Kingdom(O) general(O) election(O) and(O) 1885(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"location"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"122.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"122.2","prompt_labels":"Stanley(O) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(O) Lyulph(O) Stanley(O) )(O) contested(O) Oldham(O) ,(O) in(O) the(O) Liberal(O) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(O) United(O) Kingdom(O) general(O) election(O) ,(O) 1880(O) United(O) Kingdom(O) general(O) election(O) and(O) 1885(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"country"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"122.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"122.3","prompt_labels":"Stanley(O) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(O) Lyulph(O) Stanley(O) )(O) contested(O) Oldham(O) ,(O) in(O) the(O) Liberal(O) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(O) United(O) Kingdom(O) general(O) election(O) ,(O) 1880(O) United(O) Kingdom(O) general(O) election(O) and(O) 1885(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"person"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"122.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"122.4","prompt_labels":"Stanley(O) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(O) Lyulph(O) Stanley(O) )(O) contested(O) Oldham(O) ,(O) in(O) the(O) Liberal(O) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(O) United(O) Kingdom(O) general(O) election(O) ,(O) 1880(O) United(O) Kingdom(O) general(O) election(O) and(O) 1885(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"organization"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"122.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"122.5","prompt_labels":"Stanley(O) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(O) Lyulph(O) Stanley(O) )(O) contested(O) Oldham(O) ,(O) in(O) the(O) Liberal(O) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(O) United(O) Kingdom(O) general(O) election(O) ,(O) 1880(O) United(O) Kingdom(O) general(O) election(O) and(O) 1885(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"event"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"122.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"122.6","prompt_labels":"Stanley(O) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(O) Lyulph(O) Stanley(O) )(O) contested(O) Oldham(O) ,(O) in(O) the(O) Liberal(B-political_party) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(O) United(O) Kingdom(O) general(O) election(O) ,(O) 1880(O) United(O) Kingdom(O) general(O) election(O) and(O) 1885(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"political_party"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"122.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"122.7","prompt_labels":"Stanley(B-politician) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(B-politician) Lyulph(I-politician) Stanley(I-politician) )(O) contested(O) Oldham(O) ,(O) in(O) the(O) Liberal(O) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(O) United(O) Kingdom(O) general(O) election(O) ,(O) 1880(O) United(O) Kingdom(O) general(O) election(O) and(O) 1885(O) United(O) Kingdom(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"politician"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"122.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"122.8","prompt_labels":"Stanley(O) ((O) then(O) known(O) as(O) the(O) Honourable(O) Edward(O) Lyulph(O) Stanley(O) )(O) contested(O) Oldham(O) ,(O) in(O) the(O) Liberal(O) interest(O) ,(O) at(O) elections(O) in(O) 1872(O) ,(O) 1874(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) ,(O) 1880(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) and(O) 1885(B-election) United(I-election) Kingdom(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: Stanley ( then known as the Honourable Edward Lyulph Stanley ) contested Oldham , in the Liberal interest , at elections in 1872 , 1874 United Kingdom general election , 1880 United Kingdom general election and 1885 United Kingdom general election .\n","prediction_output":null,"prediction_outputs":null,"group":"122","words":["Stanley","(","then","known","as","the","Honourable","Edward","Lyulph","Stanley",")","contested","Oldham",",","in","the","Liberal","interest",",","at","elections","in","1872",",","1874","United","Kingdom","general","election",",","1880","United","Kingdom","general","election","and","1885","United","Kingdom","general","election","."],"labels":["B-politician","O","O","O","O","O","O","B-politician","I-politician","I-politician","O","O","B-location","O","O","O","B-political_party","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"election"},"label_list":["location","country","person","organization","event","political_party","politician","election"]}
{"id":"123.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"123.1","prompt_labels":"Malagodi(O) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(O) Social(O) Movement(O) ,(O) the(O) Monarchist(O) National(O) Party(O) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(O) Italian(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"organization"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"123.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"123.2","prompt_labels":"Malagodi(O) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(O) Social(O) Movement(O) ,(O) the(O) Monarchist(O) National(O) Party(O) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(O) Italian(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"country"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"123.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"123.3","prompt_labels":"Malagodi(B-politician) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(O) Social(O) Movement(O) ,(O) the(O) Monarchist(O) National(O) Party(O) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(O) Italian(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"politician"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"123.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"123.4","prompt_labels":"Malagodi(O) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(O) Social(O) Movement(O) ,(O) the(O) Monarchist(O) National(O) Party(O) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(B-election) Italian(I-election) general(I-election) election(I-election) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"election"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"123.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"123.5","prompt_labels":"Malagodi(O) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(B-political_party) Social(I-political_party) Movement(I-political_party) ,(O) the(O) Monarchist(B-political_party) National(I-political_party) Party(I-political_party) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(O) Italian(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"political_party"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"123.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"123.6","prompt_labels":"Malagodi(O) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(O) Social(O) Movement(O) ,(O) the(O) Monarchist(O) National(O) Party(O) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(O) Italian(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"event"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"123.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"123.7","prompt_labels":"Malagodi(O) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(O) Social(O) Movement(O) ,(O) the(O) Monarchist(O) National(O) Party(O) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(O) Italian(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"person"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"123.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"123.8","prompt_labels":"Malagodi(O) managed(O) to(O) draw(O) some(O) votes(O) from(O) the(O) Italian(O) Social(O) Movement(O) ,(O) the(O) Monarchist(O) National(O) Party(O) and(O) especially(O) Christian(O) Democracy(O) ,(O) whose(O) electoral(O) base(O) was(O) composed(O) also(O) by(O) conservatives(O) suspicious(O) of(O) the(O) Socialists(O) ,(O) increasing(O) the(O) party(O) 's(O) share(O) to(O) a(O) historical(O) record(O) of(O) 7.0(O) %(O) in(O) the(O) 1963(O) Italian(O) general(O) election(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Malagodi managed to draw some votes from the Italian Social Movement , the Monarchist National Party and especially Christian Democracy , whose electoral base was composed also by conservatives suspicious of the Socialists , increasing the party 's share to a historical record of 7.0 % in the 1963 Italian general election .\n","prediction_output":null,"prediction_outputs":null,"group":"123","words":["Malagodi","managed","to","draw","some","votes","from","the","Italian","Social","Movement",",","the","Monarchist","National","Party","and","especially","Christian","Democracy",",","whose","electoral","base","was","composed","also","by","conservatives","suspicious","of","the","Socialists",",","increasing","the","party","'s","share","to","a","historical","record","of","7.0","%","in","the","1963","Italian","general","election","."],"labels":["B-politician","O","O","O","O","O","O","O","B-political_party","I-political_party","I-political_party","O","O","B-political_party","I-political_party","I-political_party","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","O"],"target_index":null,"target_label":"location"},"label_list":["organization","country","politician","election","political_party","event","person","location"]}
{"id":"129.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"129.1","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(O) Party(O) of(O) Canada(O) in(O) the(O) 1911(O) Canadian(O) federal(O) election(O) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(O) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(O) Party(O) of(O) Canada(O) Frank(O) Oliver(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"person"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"129.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"129.2","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(O) Party(O) of(O) Canada(O) in(O) the(O) 1911(B-election) Canadian(I-election) federal(I-election) election(I-election) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(O) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(O) Party(O) of(O) Canada(O) Frank(O) Oliver(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"election"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"129.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"129.3","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(O) Party(O) of(O) Canada(O) in(O) the(O) 1911(O) Canadian(O) federal(O) election(O) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(O) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(O) Party(O) of(O) Canada(O) Frank(O) Oliver(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"event"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"129.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"129.4","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(O) Party(O) of(O) Canada(O) in(O) the(O) 1911(O) Canadian(O) federal(O) election(O) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(O) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(O) Party(O) of(O) Canada(O) Frank(O) Oliver(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"organization"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"129.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"129.5","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(O) Party(O) of(O) Canada(O) in(O) the(O) 1911(O) Canadian(O) federal(O) election(O) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(O) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(O) Party(O) of(O) Canada(O) Frank(B-politician) Oliver(I-politician) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"politician"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"129.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"129.6","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(O) Party(O) of(O) Canada(O) in(O) the(O) 1911(O) Canadian(O) federal(O) election(O) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(B-location) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(O) Party(O) of(O) Canada(O) Frank(O) Oliver(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"location"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"129.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"129.7","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(O) Party(O) of(O) Canada(O) in(O) the(O) 1911(O) Canadian(O) federal(O) election(O) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(O) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(O) Party(O) of(O) Canada(O) Frank(O) Oliver(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"country"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"129.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"129.8","prompt_labels":"He(O) ran(O) as(O) a(O) Conservative(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) in(O) the(O) 1911(O) Canadian(O) federal(O) election(O) ,(O) finishing(O) second(O) of(O) three(O) candidates(O) in(O) the(O) riding(O) of(O) Edmonton(O) ((O) the(O) victorious(O) candidate(O) was(O) Liberal(B-political_party) Party(I-political_party) of(I-political_party) Canada(I-political_party) Frank(O) Oliver(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: He ran as a Conservative Party of Canada in the 1911 Canadian federal election , finishing second of three candidates in the riding of Edmonton ( the victorious candidate was Liberal Party of Canada Frank Oliver ) .\n","prediction_output":null,"prediction_outputs":null,"group":"129","words":["He","ran","as","a","Conservative","Party","of","Canada","in","the","1911","Canadian","federal","election",",","finishing","second","of","three","candidates","in","the","riding","of","Edmonton","(","the","victorious","candidate","was","Liberal","Party","of","Canada","Frank","Oliver",")","."],"labels":["O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","O","O","B-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","B-location","O","O","O","O","O","B-political_party","I-political_party","I-political_party","I-political_party","B-politician","I-politician","O","O"],"target_index":null,"target_label":"political_party"},"label_list":["person","election","event","organization","politician","location","country","political_party"]}
{"id":"133.M1","dataset":"crossner_politics","split":"dev","instance":{"id":"133.1","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 1994(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2006(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2010(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) and(O) 2018(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"133.M2","dataset":"crossner_politics","split":"dev","instance":{"id":"133.2","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 1994(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2006(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2010(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) and(O) 2018(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"133.M3","dataset":"crossner_politics","split":"dev","instance":{"id":"133.3","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 1994(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2006(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2010(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) and(O) 2018(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: politician\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"politician"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"133.M4","dataset":"crossner_politics","split":"dev","instance":{"id":"133.4","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 1994(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2006(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2010(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) and(O) 2018(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"133.M5","dataset":"crossner_politics","split":"dev","instance":{"id":"133.5","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 1994(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2006(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2010(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) and(O) 2018(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"133.M6","dataset":"crossner_politics","split":"dev","instance":{"id":"133.6","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 1994(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2006(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2010(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) and(O) 2018(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: political_party\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"political_party"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"133.M7","dataset":"crossner_politics","split":"dev","instance":{"id":"133.7","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) ,(O) 1994(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) ,(O) 2006(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) ,(O) 2010(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) and(O) 2018(B-election) United(I-election) States(I-election) House(I-election) of(I-election) Representatives(I-election) elections(I-election) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: election\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"election"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"133.M8","dataset":"crossner_politics","split":"dev","instance":{"id":"133.8","prompt_labels":"Since(O) 1952(O) ,(O) control(O) of(O) the(O) House(O) has(O) changed(O) hands(O) five(O) times(O) ,(O) all(O) of(O) which(O) were(O) in(O) midterm(O) elections(O) ((O) 1954(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 1994(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2006(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) ,(O) 2010(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) and(O) 2018(O) United(O) States(O) House(O) of(O) Representatives(O) elections(O) )(O) and(O) all(O) of(O) which(O) were(O) at(O) the(O) expense(O) of(O) the(O) incumbent(O) President(O) 's(O) party(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Since 1952 , control of the House has changed hands five times , all of which were in midterm elections ( 1954 United States House of Representatives elections , 1994 United States House of Representatives elections , 2006 United States House of Representatives elections , 2010 United States House of Representatives elections and 2018 United States House of Representatives elections ) and all of which were at the expense of the incumbent President 's party .\n","prediction_output":null,"prediction_outputs":null,"group":"133","words":["Since","1952",",","control","of","the","House","has","changed","hands","five","times",",","all","of","which","were","in","midterm","elections","(","1954","United","States","House","of","Representatives","elections",",","1994","United","States","House","of","Representatives","elections",",","2006","United","States","House","of","Representatives","elections",",","2010","United","States","House","of","Representatives","elections","and","2018","United","States","House","of","Representatives","elections",")","and","all","of","which","were","at","the","expense","of","the","incumbent","President","'s","party","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","B-election","I-election","I-election","I-election","I-election","I-election","I-election","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["person","country","politician","event","organization","political_party","election","location"]}
{"id":"13.M1","dataset":"crossner_science","split":"dev","instance":{"id":"13.1","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"country"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M2","dataset":"crossner_science","split":"dev","instance":{"id":"13.2","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"enzyme"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M3","dataset":"crossner_science","split":"dev","instance":{"id":"13.3","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"scientist"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M4","dataset":"crossner_science","split":"dev","instance":{"id":"13.4","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"university"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M5","dataset":"crossner_science","split":"dev","instance":{"id":"13.5","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M6","dataset":"crossner_science","split":"dev","instance":{"id":"13.6","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"award"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M7","dataset":"crossner_science","split":"dev","instance":{"id":"13.7","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M8","dataset":"crossner_science","split":"dev","instance":{"id":"13.8","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M9","dataset":"crossner_science","split":"dev","instance":{"id":"13.9","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"theory"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M10","dataset":"crossner_science","split":"dev","instance":{"id":"13.10","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"location"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M11","dataset":"crossner_science","split":"dev","instance":{"id":"13.11","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"protein"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M12","dataset":"crossner_science","split":"dev","instance":{"id":"13.12","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"discipline"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M13","dataset":"crossner_science","split":"dev","instance":{"id":"13.13","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"event"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M14","dataset":"crossner_science","split":"dev","instance":{"id":"13.14","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic_journal) Journal(I-academic_journal) of(I-academic_journal) Physics(I-academic_journal) ,(O) European(B-academic_journal) Journal(I-academic_journal) of(I-academic_journal) Physics(I-academic_journal) ,(O) Journal(B-academic_journal) of(I-academic_journal) Chemical(I-academic_journal) Education(I-academic_journal) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M15","dataset":"crossner_science","split":"dev","instance":{"id":"13.15","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"person"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"13.M16","dataset":"crossner_science","split":"dev","instance":{"id":"13.16","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(O) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(O) Journal(O) of(O) Physics(O) ,(O) European(O) Journal(O) of(O) Physics(O) ,(O) Journal(O) of(O) Chemical(O) Education(O) )(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .\n","prediction_output":null,"prediction_outputs":null,"group":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","B-academic_journal","I-academic_journal","I-academic_journal","I-academic_journal","O","O"],"target_index":null,"target_label":"organization"},"label_list":["country","enzyme","scientist","university","chemical_compound","award","chemical_element","astronomical_object","theory","location","protein","discipline","event","academic_journal","person","organization"]}
{"id":"30.M1","dataset":"crossner_science","split":"dev","instance":{"id":"30.1","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M2","dataset":"crossner_science","split":"dev","instance":{"id":"30.2","prompt_labels":"His(O) Nobel(B-award) Prize(I-award) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"award"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M3","dataset":"crossner_science","split":"dev","instance":{"id":"30.3","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"university"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M4","dataset":"crossner_science","split":"dev","instance":{"id":"30.4","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"theory"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M5","dataset":"crossner_science","split":"dev","instance":{"id":"30.5","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"enzyme"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M6","dataset":"crossner_science","split":"dev","instance":{"id":"30.6","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"protein"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M7","dataset":"crossner_science","split":"dev","instance":{"id":"30.7","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"country"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M8","dataset":"crossner_science","split":"dev","instance":{"id":"30.8","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"person"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M9","dataset":"crossner_science","split":"dev","instance":{"id":"30.9","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(B-organization) Red(I-organization) Cross(I-organization) and(I-organization) Red(I-organization) Crescent(I-organization) Movement(I-organization) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"organization"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M10","dataset":"crossner_science","split":"dev","instance":{"id":"30.10","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(B-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"location"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M11","dataset":"crossner_science","split":"dev","instance":{"id":"30.11","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M12","dataset":"crossner_science","split":"dev","instance":{"id":"30.12","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M13","dataset":"crossner_science","split":"dev","instance":{"id":"30.13","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"scientist"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M14","dataset":"crossner_science","split":"dev","instance":{"id":"30.14","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"event"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M15","dataset":"crossner_science","split":"dev","instance":{"id":"30.15","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"30.M16","dataset":"crossner_science","split":"dev","instance":{"id":"30.16","prompt_labels":"His(O) Nobel(O) Prize(O) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(O) Red(O) Cross(O) and(O) Red(O) Crescent(O) Movement(O) in(O) Geneva(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .\n","prediction_output":null,"prediction_outputs":null,"group":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"target_index":null,"target_label":"discipline"},"label_list":["academic_journal","award","university","theory","enzyme","protein","country","person","organization","location","chemical_element","chemical_compound","scientist","event","astronomical_object","discipline"]}
{"id":"43.M1","dataset":"crossner_science","split":"dev","instance":{"id":"43.1","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M2","dataset":"crossner_science","split":"dev","instance":{"id":"43.2","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"person"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M3","dataset":"crossner_science","split":"dev","instance":{"id":"43.3","prompt_labels":"Heartstone(B-event) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(B-event) Asian(I-event) Indoor(I-event) and(I-event) Martial(I-event) Arts(I-event) Games(I-event) and(O) 2018(B-event) Asian(I-event) Games(I-event) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"event"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M4","dataset":"crossner_science","split":"dev","instance":{"id":"43.4","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"discipline"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M5","dataset":"crossner_science","split":"dev","instance":{"id":"43.5","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"organization"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M6","dataset":"crossner_science","split":"dev","instance":{"id":"43.6","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M7","dataset":"crossner_science","split":"dev","instance":{"id":"43.7","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"scientist"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M8","dataset":"crossner_science","split":"dev","instance":{"id":"43.8","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M9","dataset":"crossner_science","split":"dev","instance":{"id":"43.9","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"award"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M10","dataset":"crossner_science","split":"dev","instance":{"id":"43.10","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"theory"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M11","dataset":"crossner_science","split":"dev","instance":{"id":"43.11","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M12","dataset":"crossner_science","split":"dev","instance":{"id":"43.12","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"enzyme"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M13","dataset":"crossner_science","split":"dev","instance":{"id":"43.13","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"country"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M14","dataset":"crossner_science","split":"dev","instance":{"id":"43.14","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"university"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M15","dataset":"crossner_science","split":"dev","instance":{"id":"43.15","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"protein"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"43.M16","dataset":"crossner_science","split":"dev","instance":{"id":"43.16","prompt_labels":"Heartstone(O) has(O) also(O) been(O) a(O) part(O) of(O) a(O) number(O) of(O) esport(O) demonstration(O) event(O) s(O) at(O) international(O) competitions(O) ,(O) such(O) as(O) the(O) 2017(O) Asian(O) Indoor(O) and(O) Martial(O) Arts(O) Games(O) and(O) 2018(O) Asian(O) Games(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Heartstone has also been a part of a number of esport demonstration event s at international competitions , such as the 2017 Asian Indoor and Martial Arts Games and 2018 Asian Games .\n","prediction_output":null,"prediction_outputs":null,"group":"43","words":["Heartstone","has","also","been","a","part","of","a","number","of","esport","demonstration","event","s","at","international","competitions",",","such","as","the","2017","Asian","Indoor","and","Martial","Arts","Games","and","2018","Asian","Games","."],"labels":["B-event","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","I-event","I-event","I-event","O","B-event","I-event","I-event","O"],"target_index":null,"target_label":"location"},"label_list":["chemical_element","person","event","discipline","organization","chemical_compound","scientist","academic_journal","award","theory","astronomical_object","enzyme","country","university","protein","location"]}
{"id":"48.M1","dataset":"crossner_science","split":"dev","instance":{"id":"48.1","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"enzyme"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M2","dataset":"crossner_science","split":"dev","instance":{"id":"48.2","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M3","dataset":"crossner_science","split":"dev","instance":{"id":"48.3","prompt_labels":"John(B-scientist) Hopkinson(I-scientist) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"scientist"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M4","dataset":"crossner_science","split":"dev","instance":{"id":"48.4","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M5","dataset":"crossner_science","split":"dev","instance":{"id":"48.5","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"theory"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M6","dataset":"crossner_science","split":"dev","instance":{"id":"48.6","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(B-organization) of(I-organization) Electrical(I-organization) Engineers(I-organization) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M7","dataset":"crossner_science","split":"dev","instance":{"id":"48.7","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M8","dataset":"crossner_science","split":"dev","instance":{"id":"48.8","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M9","dataset":"crossner_science","split":"dev","instance":{"id":"48.9","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M10","dataset":"crossner_science","split":"dev","instance":{"id":"48.10","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(B-award) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(B-award) of(I-award) the(I-award) Royal(I-award) Society(I-award) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M11","dataset":"crossner_science","split":"dev","instance":{"id":"48.11","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M12","dataset":"crossner_science","split":"dev","instance":{"id":"48.12","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(B-country) Kingdom(I-country) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M13","dataset":"crossner_science","split":"dev","instance":{"id":"48.13","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M14","dataset":"crossner_science","split":"dev","instance":{"id":"48.14","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M15","dataset":"crossner_science","split":"dev","instance":{"id":"48.15","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"protein"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"48.M16","dataset":"crossner_science","split":"dev","instance":{"id":"48.16","prompt_labels":"John(O) Hopkinson(O) ,(O) FRS(O) ,(O) ((O) 27(O) July(O) 1849(O) -(O) 27(O) August(O) 1898(O) )(O) was(O) a(O) United(O) Kingdom(O) physicist(O) ,(O) electrical(O) engineer(O) ,(O) Fellow(O) of(O) the(O) Royal(O) Society(O) and(O) President(O) of(O) the(O) Institution(O) of(O) Electrical(O) Engineers(O) twice(O) in(O) 1890(O) and(O) 1896(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: John Hopkinson , FRS , ( 27 July 1849 - 27 August 1898 ) was a United Kingdom physicist , electrical engineer , Fellow of the Royal Society and President of the Institution of Electrical Engineers twice in 1890 and 1896 .\n","prediction_output":null,"prediction_outputs":null,"group":"48","words":["John","Hopkinson",",","FRS",",","(","27","July","1849","-","27","August","1898",")","was","a","United","Kingdom","physicist",",","electrical","engineer",",","Fellow","of","the","Royal","Society","and","President","of","the","Institution","of","Electrical","Engineers","twice","in","1890","and","1896","."],"labels":["B-scientist","I-scientist","O","B-award","O","O","O","O","O","O","O","O","O","O","O","O","B-country","I-country","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O"],"target_index":null,"target_label":"discipline"},"label_list":["enzyme","academic_journal","scientist","person","theory","organization","location","university","chemical_compound","award","event","country","astronomical_object","chemical_element","protein","discipline"]}
{"id":"54.M1","dataset":"crossner_science","split":"dev","instance":{"id":"54.1","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"discipline"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M2","dataset":"crossner_science","split":"dev","instance":{"id":"54.2","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M3","dataset":"crossner_science","split":"dev","instance":{"id":"54.3","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"enzyme"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M4","dataset":"crossner_science","split":"dev","instance":{"id":"54.4","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M5","dataset":"crossner_science","split":"dev","instance":{"id":"54.5","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M6","dataset":"crossner_science","split":"dev","instance":{"id":"54.6","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(B-academic_journal) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M7","dataset":"crossner_science","split":"dev","instance":{"id":"54.7","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M8","dataset":"crossner_science","split":"dev","instance":{"id":"54.8","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"protein"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M9","dataset":"crossner_science","split":"dev","instance":{"id":"54.9","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"theory"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M10","dataset":"crossner_science","split":"dev","instance":{"id":"54.10","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(B-location) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M11","dataset":"crossner_science","split":"dev","instance":{"id":"54.11","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M12","dataset":"crossner_science","split":"dev","instance":{"id":"54.12","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M13","dataset":"crossner_science","split":"dev","instance":{"id":"54.13","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"scientist"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M14","dataset":"crossner_science","split":"dev","instance":{"id":"54.14","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M15","dataset":"crossner_science","split":"dev","instance":{"id":"54.15","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"54.M16","dataset":"crossner_science","split":"dev","instance":{"id":"54.16","prompt_labels":"In(O) August(O) 2017(O) a(O) group(O) of(O) scientists(O) from(O) Oregon(O) published(O) an(O) article(O) in(O) Nature(O) journal(O) detailing(O) the(O) successful(O) use(O) of(O) CRISPR(O) to(O) edit(O) out(O) a(O) mutation(O) responsible(O) for(O) congenital(O) heart(O) disease(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: In August 2017 a group of scientists from Oregon published an article in Nature journal detailing the successful use of CRISPR to edit out a mutation responsible for congenital heart disease .\n","prediction_output":null,"prediction_outputs":null,"group":"54","words":["In","August","2017","a","group","of","scientists","from","Oregon","published","an","article","in","Nature","journal","detailing","the","successful","use","of","CRISPR","to","edit","out","a","mutation","responsible","for","congenital","heart","disease","."],"labels":["O","O","O","O","O","O","O","O","B-location","O","O","O","O","B-academic_journal","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["discipline","country","enzyme","award","university","academic_journal","person","protein","theory","location","organization","astronomical_object","scientist","chemical_element","chemical_compound","event"]}
{"id":"56.M1","dataset":"crossner_science","split":"dev","instance":{"id":"56.1","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"country"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M2","dataset":"crossner_science","split":"dev","instance":{"id":"56.2","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"award"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M3","dataset":"crossner_science","split":"dev","instance":{"id":"56.3","prompt_labels":"UCSI(B-university) University(I-university) ,(I-university) Sarawak(I-university) Campus(I-university) ,(O) University(B-university) College(I-university) of(I-university) Technology(I-university) Sarawak(I-university) ((O) UCTS(B-university) )(O) Tunku(B-university) Abdul(I-university) Rahman(I-university) University(I-university) College(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) International(B-university) University(I-university) College(I-university) Of(I-university) Technology(I-university) Twintech(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) ,(O) and(O) Open(B-university) University(I-university) Malaysia(I-university) ((I-university) Sabah(I-university) campus(I-university) )(I-university) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"university"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M4","dataset":"crossner_science","split":"dev","instance":{"id":"56.4","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"enzyme"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M5","dataset":"crossner_science","split":"dev","instance":{"id":"56.5","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M6","dataset":"crossner_science","split":"dev","instance":{"id":"56.6","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M7","dataset":"crossner_science","split":"dev","instance":{"id":"56.7","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"organization"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M8","dataset":"crossner_science","split":"dev","instance":{"id":"56.8","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"event"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M9","dataset":"crossner_science","split":"dev","instance":{"id":"56.9","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"theory"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M10","dataset":"crossner_science","split":"dev","instance":{"id":"56.10","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M11","dataset":"crossner_science","split":"dev","instance":{"id":"56.11","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(B-location) Malaysia(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"location"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M12","dataset":"crossner_science","split":"dev","instance":{"id":"56.12","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"discipline"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M13","dataset":"crossner_science","split":"dev","instance":{"id":"56.13","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"protein"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M14","dataset":"crossner_science","split":"dev","instance":{"id":"56.14","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M15","dataset":"crossner_science","split":"dev","instance":{"id":"56.15","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"person"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"56.M16","dataset":"crossner_science","split":"dev","instance":{"id":"56.16","prompt_labels":"UCSI(O) University(O) ,(O) Sarawak(O) Campus(O) ,(O) University(O) College(O) of(O) Technology(O) Sarawak(O) ((O) UCTS(O) )(O) Tunku(O) Abdul(O) Rahman(O) University(O) College(O) ((O) Sabah(O) campus(O) )(O) ,(O) International(O) University(O) College(O) Of(O) Technology(O) Twintech(O) ((O) Sabah(O) campus(O) )(O) ,(O) and(O) Open(O) University(O) Malaysia(O) ((O) Sabah(O) campus(O) )(O) have(O) local(O) private(O) university(O) branch(O) campuses(O) in(O) East(O) Malaysia(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: UCSI University , Sarawak Campus , University College of Technology Sarawak ( UCTS ) Tunku Abdul Rahman University College ( Sabah campus ) , International University College Of Technology Twintech ( Sabah campus ) , and Open University Malaysia ( Sabah campus ) have local private university branch campuses in East Malaysia .\n","prediction_output":null,"prediction_outputs":null,"group":"56","words":["UCSI","University",",","Sarawak","Campus",",","University","College","of","Technology","Sarawak","(","UCTS",")","Tunku","Abdul","Rahman","University","College","(","Sabah","campus",")",",","International","University","College","Of","Technology","Twintech","(","Sabah","campus",")",",","and","Open","University","Malaysia","(","Sabah","campus",")","have","local","private","university","branch","campuses","in","East","Malaysia","."],"labels":["B-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","O","B-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","B-university","I-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","B-location","I-location","O"],"target_index":null,"target_label":"scientist"},"label_list":["country","award","university","enzyme","chemical_element","academic_journal","organization","event","theory","chemical_compound","location","discipline","protein","astronomical_object","person","scientist"]}
{"id":"61.M1","dataset":"crossner_science","split":"dev","instance":{"id":"61.1","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"organization"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M2","dataset":"crossner_science","split":"dev","instance":{"id":"61.2","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(B-person) Kurzweil(I-person) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"person"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M3","dataset":"crossner_science","split":"dev","instance":{"id":"61.3","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"university"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M4","dataset":"crossner_science","split":"dev","instance":{"id":"61.4","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"award"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M5","dataset":"crossner_science","split":"dev","instance":{"id":"61.5","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M6","dataset":"crossner_science","split":"dev","instance":{"id":"61.6","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"event"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M7","dataset":"crossner_science","split":"dev","instance":{"id":"61.7","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"location"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M8","dataset":"crossner_science","split":"dev","instance":{"id":"61.8","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"enzyme"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M9","dataset":"crossner_science","split":"dev","instance":{"id":"61.9","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M10","dataset":"crossner_science","split":"dev","instance":{"id":"61.10","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M11","dataset":"crossner_science","split":"dev","instance":{"id":"61.11","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M12","dataset":"crossner_science","split":"dev","instance":{"id":"61.12","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"discipline"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M13","dataset":"crossner_science","split":"dev","instance":{"id":"61.13","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"theory"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M14","dataset":"crossner_science","split":"dev","instance":{"id":"61.14","prompt_labels":"Robot(O) designer(O) Hans(B-scientist) Moravec(I-scientist) ,(O) cyberneticist(O) Kevin(B-scientist) Warwick(I-scientist) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"scientist"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M15","dataset":"crossner_science","split":"dev","instance":{"id":"61.15","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"protein"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"61.M16","dataset":"crossner_science","split":"dev","instance":{"id":"61.16","prompt_labels":"Robot(O) designer(O) Hans(O) Moravec(O) ,(O) cyberneticist(O) Kevin(O) Warwick(O) and(O) inventor(O) Ray(O) Kurzweil(O) have(O) predicted(O) that(O) humans(O) and(O) machines(O) will(O) merge(O) in(O) the(O) future(O) into(O) cyborg(O) s(O) that(O) are(O) more(O) capable(O) and(O) powerful(O) than(O) either(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: Robot designer Hans Moravec , cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborg s that are more capable and powerful than either .\n","prediction_output":null,"prediction_outputs":null,"group":"61","words":["Robot","designer","Hans","Moravec",",","cyberneticist","Kevin","Warwick","and","inventor","Ray","Kurzweil","have","predicted","that","humans","and","machines","will","merge","in","the","future","into","cyborg","s","that","are","more","capable","and","powerful","than","either","."],"labels":["O","O","B-scientist","I-scientist","O","O","B-scientist","I-scientist","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"target_index":null,"target_label":"country"},"label_list":["organization","person","university","award","astronomical_object","event","location","enzyme","academic_journal","chemical_element","chemical_compound","discipline","theory","scientist","protein","country"]}
{"id":"112.M1","dataset":"crossner_science","split":"dev","instance":{"id":"112.1","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M2","dataset":"crossner_science","split":"dev","instance":{"id":"112.2","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"country"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M3","dataset":"crossner_science","split":"dev","instance":{"id":"112.3","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"person"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M4","dataset":"crossner_science","split":"dev","instance":{"id":"112.4","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"theory"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M5","dataset":"crossner_science","split":"dev","instance":{"id":"112.5","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(B-location) Observatory(I-location) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"location"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M6","dataset":"crossner_science","split":"dev","instance":{"id":"112.6","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"award"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M7","dataset":"crossner_science","split":"dev","instance":{"id":"112.7","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"organization"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M8","dataset":"crossner_science","split":"dev","instance":{"id":"112.8","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(B-scientist) Johannes(I-scientist) van(I-scientist) Houten(I-scientist) ,(O) Ingrid(B-scientist) van(I-scientist) Houten-Groeneveld(I-scientist) and(O) Tom(B-scientist) Gehrels(I-scientist) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"scientist"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M9","dataset":"crossner_science","split":"dev","instance":{"id":"112.9","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M10","dataset":"crossner_science","split":"dev","instance":{"id":"112.10","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"event"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M11","dataset":"crossner_science","split":"dev","instance":{"id":"112.11","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M12","dataset":"crossner_science","split":"dev","instance":{"id":"112.12","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"discipline"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M13","dataset":"crossner_science","split":"dev","instance":{"id":"112.13","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"enzyme"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M14","dataset":"crossner_science","split":"dev","instance":{"id":"112.14","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"protein"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M15","dataset":"crossner_science","split":"dev","instance":{"id":"112.15","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"112.M16","dataset":"crossner_science","split":"dev","instance":{"id":"112.16","prompt_labels":"It(O) was(O) discovered(O) on(O) 24(O) September(O) 1960(O) ,(O) by(O) astronomers(O) Cornelis(O) Johannes(O) van(O) Houten(O) ,(O) Ingrid(O) van(O) Houten-Groeneveld(O) and(O) Tom(O) Gehrels(O) at(O) Palomar(O) Observatory(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: It was discovered on 24 September 1960 , by astronomers Cornelis Johannes van Houten , Ingrid van Houten-Groeneveld and Tom Gehrels at Palomar Observatory .\n","prediction_output":null,"prediction_outputs":null,"group":"112","words":["It","was","discovered","on","24","September","1960",",","by","astronomers","Cornelis","Johannes","van","Houten",",","Ingrid","van","Houten-Groeneveld","and","Tom","Gehrels","at","Palomar","Observatory","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","B-location","I-location","O"],"target_index":null,"target_label":"university"},"label_list":["chemical_element","country","person","theory","location","award","organization","scientist","academic_journal","event","chemical_compound","discipline","enzyme","protein","astronomical_object","university"]}
{"id":"142.M1","dataset":"crossner_science","split":"dev","instance":{"id":"142.1","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"university"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M2","dataset":"crossner_science","split":"dev","instance":{"id":"142.2","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M3","dataset":"crossner_science","split":"dev","instance":{"id":"142.3","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"enzyme"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M4","dataset":"crossner_science","split":"dev","instance":{"id":"142.4","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(B-astronomical_object) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(B-astronomical_object) and(O) Kepler-62c(B-astronomical_object) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M5","dataset":"crossner_science","split":"dev","instance":{"id":"142.5","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"location"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M6","dataset":"crossner_science","split":"dev","instance":{"id":"142.6","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"country"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M7","dataset":"crossner_science","split":"dev","instance":{"id":"142.7","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"event"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M8","dataset":"crossner_science","split":"dev","instance":{"id":"142.8","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M9","dataset":"crossner_science","split":"dev","instance":{"id":"142.9","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"organization"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M10","dataset":"crossner_science","split":"dev","instance":{"id":"142.10","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M11","dataset":"crossner_science","split":"dev","instance":{"id":"142.11","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"award"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M12","dataset":"crossner_science","split":"dev","instance":{"id":"142.12","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"scientist"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M13","dataset":"crossner_science","split":"dev","instance":{"id":"142.13","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"protein"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M14","dataset":"crossner_science","split":"dev","instance":{"id":"142.14","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"theory"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M15","dataset":"crossner_science","split":"dev","instance":{"id":"142.15","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"person"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"142.M16","dataset":"crossner_science","split":"dev","instance":{"id":"142.16","prompt_labels":"In(O) 2013(O) ,(O) the(O) exoplanet(O) Kepler-62f(O) was(O) discovered(O) ,(O) along(O) with(O) Kepler-62e(O) and(O) Kepler-62c(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: In 2013 , the exoplanet Kepler-62f was discovered , along with Kepler-62e and Kepler-62c .\n","prediction_output":null,"prediction_outputs":null,"group":"142","words":["In","2013",",","the","exoplanet","Kepler-62f","was","discovered",",","along","with","Kepler-62e","and","Kepler-62c","."],"labels":["O","O","O","O","O","B-astronomical_object","O","O","O","O","O","B-astronomical_object","O","B-astronomical_object","O"],"target_index":null,"target_label":"discipline"},"label_list":["university","academic_journal","enzyme","astronomical_object","location","country","event","chemical_element","organization","chemical_compound","award","scientist","protein","theory","person","discipline"]}
{"id":"144.M1","dataset":"crossner_science","split":"dev","instance":{"id":"144.1","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: event\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"event"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M2","dataset":"crossner_science","split":"dev","instance":{"id":"144.2","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: scientist\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"scientist"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M3","dataset":"crossner_science","split":"dev","instance":{"id":"144.3","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_element\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"chemical_element"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M4","dataset":"crossner_science","split":"dev","instance":{"id":"144.4","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(B-enzyme) methyltransferase(I-enzyme) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: enzyme\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"enzyme"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M5","dataset":"crossner_science","split":"dev","instance":{"id":"144.5","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: university\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"university"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M6","dataset":"crossner_science","split":"dev","instance":{"id":"144.6","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: protein\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"protein"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M7","dataset":"crossner_science","split":"dev","instance":{"id":"144.7","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: location\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"location"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M8","dataset":"crossner_science","split":"dev","instance":{"id":"144.8","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: organization\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"organization"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M9","dataset":"crossner_science","split":"dev","instance":{"id":"144.9","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: chemical_compound\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"chemical_compound"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M10","dataset":"crossner_science","split":"dev","instance":{"id":"144.10","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: theory\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"theory"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M11","dataset":"crossner_science","split":"dev","instance":{"id":"144.11","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: discipline\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"discipline"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M12","dataset":"crossner_science","split":"dev","instance":{"id":"144.12","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: award\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"award"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M13","dataset":"crossner_science","split":"dev","instance":{"id":"144.13","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: person\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"person"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M14","dataset":"crossner_science","split":"dev","instance":{"id":"144.14","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: country\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"country"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M15","dataset":"crossner_science","split":"dev","instance":{"id":"144.15","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: astronomical_object\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"astronomical_object"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
{"id":"144.M16","dataset":"crossner_science","split":"dev","instance":{"id":"144.16","prompt_labels":"DNA(O) cytosine(O) methylation(O) is(O) catalyzed(O) by(O) DNA(O) methyltransferase(O) .(O)","instruction_inputs":"You are an advanced Named Entity Recognition (NER) assistant.\nYour goal is to label each token in the user-provided sentence\naccording to the BIO format, for the entity types given by the user.\n\nTask:\nPlease analyze the sentence below across multiple rounds.\nIn each round, FOCUS ON EXACTLY ONE ENTITY TYPE.\nUse BIO format and label every token for that specific entity or 'O' otherwise.\n\nWe use the BIO-format:\n- B (Begin): first token of an entity\n- I (Inside): subsequent token of the same entity\n- O (Outside): token not part of that entity type\n\nFOCUSED ONE ENTITY TYPE: academic_journal\nGIVEN SENTENCE: DNA cytosine methylation is catalyzed by DNA methyltransferase .\n","prediction_output":null,"prediction_outputs":null,"group":"144","words":["DNA","cytosine","methylation","is","catalyzed","by","DNA","methyltransferase","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"target_index":null,"target_label":"academic_journal"},"label_list":["event","scientist","chemical_element","enzyme","university","protein","location","organization","chemical_compound","theory","discipline","award","person","country","astronomical_object","academic_journal"]}
