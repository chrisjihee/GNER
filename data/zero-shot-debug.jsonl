{"id":"0","dataset":"crossner_ai","split":"dev","label_list":["metric","field","person","researcher","programming language","product","country","algorithm","organization","task","location","university","conference"],"instance":{"id":"0","words":["Here",",","accuracy","is","measured","by","error","rate",",","which","is","defined","as",":"],"labels":["O","O","B-metric","O","O","O","B-metric","I-metric","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, field, person, researcher, programming language, product, country, algorithm, organization, task, location, university, conference and O.\nSentence: Here , accuracy is measured by error rate , which is defined as :","prompt_labels":"Here(O) ,(O) accuracy(B-metric) is(O) measured(O) by(O) error(B-metric) rate(I-metric) ,(O) which(O) is(O) defined(O) as(O) :(O)"}}
{"id":"1","dataset":"crossner_ai","split":"dev","label_list":["conference","country","task","location","person","organization","product","algorithm","university","researcher","programming language","metric","field"],"instance":{"id":"1","words":["From","this","perspective",",","SVM","is","closely","related","to","other","fundamental","classification","algorithms","such","as","regularized","least-squares","logistic","regression","."],"labels":["O","O","O","O","B-algorithm","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","B-algorithm","I-algorithm","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, country, task, location, person, organization, product, algorithm, university, researcher, programming language, metric, field and O.\nSentence: From this perspective , SVM is closely related to other fundamental classification algorithms such as regularized least-squares logistic regression .","prompt_labels":"From(O) this(O) perspective(O) ,(O) SVM(B-algorithm) is(O) closely(O) related(O) to(O) other(O) fundamental(O) classification(O) algorithms(O) such(O) as(O) regularized(B-algorithm) least-squares(I-algorithm) logistic(B-algorithm) regression(I-algorithm) .(O)"}}
{"id":"2","dataset":"crossner_ai","split":"dev","label_list":["organization","location","researcher","task","country","programming language","conference","university","product","metric","algorithm","person","field"],"instance":{"id":"2","words":["Brion","James","portrays","Leon","Kowalski",",","a","combat","and","laborer","replicant",",","and","Joanna","Cassidy","portrays","Zhora",",","an","assassin","replicant","."],"labels":["B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","O","O","B-person","I-person","O","B-person","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, location, researcher, task, country, programming language, conference, university, product, metric, algorithm, person, field and O.\nSentence: Brion James portrays Leon Kowalski , a combat and laborer replicant , and Joanna Cassidy portrays Zhora , an assassin replicant .","prompt_labels":"Brion(B-person) James(I-person) portrays(O) Leon(B-person) Kowalski(I-person) ,(O) a(O) combat(O) and(O) laborer(O) replicant(O) ,(O) and(O) Joanna(B-person) Cassidy(I-person) portrays(O) Zhora(B-person) ,(O) an(O) assassin(O) replicant(O) .(O)"}}
{"id":"3","dataset":"crossner_ai","split":"dev","label_list":["field","organization","programming language","country","researcher","algorithm","task","person","conference","location","product","metric","university"],"instance":{"id":"3","words":["The","first","picture","to","be","scanned",",","stored",",","and","recreated","in","digital","pixels","was","displayed","on","the","Standards","Eastern","Automatic","Computer","(","SEAC",")","at","NIST","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","I-product","I-product","I-product","O","B-product","O","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, organization, programming language, country, researcher, algorithm, task, person, conference, location, product, metric, university and O.\nSentence: The first picture to be scanned , stored , and recreated in digital pixels was displayed on the Standards Eastern Automatic Computer ( SEAC ) at NIST .","prompt_labels":"The(O) first(O) picture(O) to(O) be(O) scanned(O) ,(O) stored(O) ,(O) and(O) recreated(O) in(O) digital(O) pixels(O) was(O) displayed(O) on(O) the(O) Standards(B-product) Eastern(I-product) Automatic(I-product) Computer(I-product) ((O) SEAC(B-product) )(O) at(O) NIST(B-organization) .(O)"}}
{"id":"4","dataset":"crossner_ai","split":"dev","label_list":["researcher","field","metric","organization","product","country","programming language","conference","location","university","person","task","algorithm"],"instance":{"id":"4","words":["Segmenting","the","text","into","topics","or","discourse","turns","might","be","useful","in","some","natural","processing","tasks",":","it","can","improve","information","retrieval","or","speech","recognition","significantly","(","by","indexing","/","recognizing","documents","more","precisely","or","by","giving","the","specific","part","of","a","document","corresponding","to","the","query","as","a","result",")","."],"labels":["B-task","I-task","I-task","I-task","I-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, field, metric, organization, product, country, programming language, conference, location, university, person, task, algorithm and O.\nSentence: Segmenting the text into topics or discourse turns might be useful in some natural processing tasks : it can improve information retrieval or speech recognition significantly ( by indexing / recognizing documents more precisely or by giving the specific part of a document corresponding to the query as a result ) .","prompt_labels":"Segmenting(B-task) the(I-task) text(I-task) into(I-task) topics(I-task) or(O) discourse(O) turns(O) might(O) be(O) useful(O) in(O) some(O) natural(O) processing(O) tasks(O) :(O) it(O) can(O) improve(O) information(B-task) retrieval(I-task) or(O) speech(B-task) recognition(I-task) significantly(O) ((O) by(O) indexing(O) /(O) recognizing(O) documents(O) more(O) precisely(O) or(O) by(O) giving(O) the(O) specific(O) part(O) of(O) a(O) document(O) corresponding(O) to(O) the(O) query(O) as(O) a(O) result(O) )(O) .(O)"}}
{"id":"5","dataset":"crossner_ai","split":"dev","label_list":["organization","field","metric","product","programming language","person","conference","algorithm","task","country","researcher","university","location"],"instance":{"id":"5","words":["At","Indiana","University","in","1999","he","organized","such","a","symposium",",","and","in","April","2000",",","he","organized","a","larger","symposium","entitled","Spiritual","Robots","at","Stanford","University",",","in","which","he","moderated","a","panel","consisting","of","Ray","Kurzweil",",","Hans","Moravec",",","Kevin","Kelly",",","Ralph","Merkle",",","Bill","Joy",",","Frank","Drake",",","John","Henry","Holland","and","John","Koza","."],"labels":["O","B-university","I-university","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","O","B-university","I-university","O","O","O","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","B-researcher","I-researcher","I-researcher","O","B-researcher","I-researcher","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, field, metric, product, programming language, person, conference, algorithm, task, country, researcher, university, location and O.\nSentence: At Indiana University in 1999 he organized such a symposium , and in April 2000 , he organized a larger symposium entitled Spiritual Robots at Stanford University , in which he moderated a panel consisting of Ray Kurzweil , Hans Moravec , Kevin Kelly , Ralph Merkle , Bill Joy , Frank Drake , John Henry Holland and John Koza .","prompt_labels":"At(O) Indiana(B-university) University(I-university) in(O) 1999(O) he(O) organized(O) such(O) a(O) symposium(O) ,(O) and(O) in(O) April(O) 2000(O) ,(O) he(O) organized(O) a(O) larger(O) symposium(O) entitled(O) Spiritual(B-conference) Robots(I-conference) at(O) Stanford(B-university) University(I-university) ,(O) in(O) which(O) he(O) moderated(O) a(O) panel(O) consisting(O) of(O) Ray(B-researcher) Kurzweil(I-researcher) ,(O) Hans(B-researcher) Moravec(I-researcher) ,(O) Kevin(B-researcher) Kelly(I-researcher) ,(O) Ralph(B-researcher) Merkle(I-researcher) ,(O) Bill(B-researcher) Joy(I-researcher) ,(O) Frank(B-researcher) Drake(I-researcher) ,(O) John(B-researcher) Henry(I-researcher) Holland(I-researcher) and(O) John(B-researcher) Koza(I-researcher) .(O)"}}
{"id":"6","dataset":"crossner_ai","split":"dev","label_list":["conference","university","product","organization","person","field","researcher","country","programming language","task","algorithm","location","metric"],"instance":{"id":"6","words":["It","considers","both","the","precision","p","and","the","recall","r","of","the","test","to","compute","the","score",":","p","is","the","number","of","correct","positive","results","divided","by","the","number","of","all","positive","results","returned","by","the","classifier",",","and","r","is","the","number","of","correct","positive","results","divided","by","the","number","of","all","relevant","samples","(","all","samples","that","should","have","been","identified","as","positive",")","."],"labels":["O","O","O","O","B-metric","B-metric","O","O","B-metric","B-metric","O","O","O","O","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, university, product, organization, person, field, researcher, country, programming language, task, algorithm, location, metric and O.\nSentence: It considers both the precision p and the recall r of the test to compute the score : p is the number of correct positive results divided by the number of all positive results returned by the classifier , and r is the number of correct positive results divided by the number of all relevant samples ( all samples that should have been identified as positive ) .","prompt_labels":"It(O) considers(O) both(O) the(O) precision(B-metric) p(B-metric) and(O) the(O) recall(B-metric) r(B-metric) of(O) the(O) test(O) to(O) compute(O) the(O) score(O) :(O) p(B-metric) is(O) the(O) number(O) of(O) correct(O) positive(O) results(O) divided(O) by(O) the(O) number(O) of(O) all(O) positive(O) results(O) returned(O) by(O) the(O) classifier(O) ,(O) and(O) r(B-metric) is(O) the(O) number(O) of(O) correct(O) positive(O) results(O) divided(O) by(O) the(O) number(O) of(O) all(O) relevant(O) samples(O) ((O) all(O) samples(O) that(O) should(O) have(O) been(O) identified(O) as(O) positive(O) )(O) .(O)"}}
{"id":"7","dataset":"crossner_ai","split":"dev","label_list":["person","metric","task","location","programming language","field","conference","researcher","product","organization","university","country","algorithm"],"instance":{"id":"7","words":["Since","the","Google","acquisition",",","the","company","has","notched","up","a","number","of","significant","achievements",",","perhaps","the","most","notable","being","the","creation","of","AlphaGo",",","a","program","that","defeated","world","champion","Lee","Sedol","at","the","complex","game","of","Go","."],"labels":["O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, metric, task, location, programming language, field, conference, researcher, product, organization, university, country, algorithm and O.\nSentence: Since the Google acquisition , the company has notched up a number of significant achievements , perhaps the most notable being the creation of AlphaGo , a program that defeated world champion Lee Sedol at the complex game of Go .","prompt_labels":"Since(O) the(O) Google(B-organization) acquisition(O) ,(O) the(O) company(O) has(O) notched(O) up(O) a(O) number(O) of(O) significant(O) achievements(O) ,(O) perhaps(O) the(O) most(O) notable(O) being(O) the(O) creation(O) of(O) AlphaGo(B-product) ,(O) a(O) program(O) that(O) defeated(O) world(O) champion(O) Lee(B-person) Sedol(I-person) at(O) the(O) complex(O) game(O) of(O) Go(O) .(O)"}}
{"id":"8","dataset":"crossner_ai","split":"dev","label_list":["programming language","algorithm","location","product","organization","task","researcher","conference","university","country","metric","person","field"],"instance":{"id":"8","words":["Representing","words","considering","their","context","through","fixed","size","dense","vectors","(","word","embedding","s",")","has","become","one","the","most","fundamental","blocks","in","several","NLP","systems.","an","unsupervised","disambiguation","system","uses","the","similarity","between","word","senses","in","a","fixed","context","window","to","select","the","most","suitable","word","sense","using","a","pre-trained","word","embedding","model","and","WordNet","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","O","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: programming language, algorithm, location, product, organization, task, researcher, conference, university, country, metric, person, field and O.\nSentence: Representing words considering their context through fixed size dense vectors ( word embedding s ) has become one the most fundamental blocks in several NLP systems. an unsupervised disambiguation system uses the similarity between word senses in a fixed context window to select the most suitable word sense using a pre-trained word embedding model and WordNet .","prompt_labels":"Representing(O) words(O) considering(O) their(O) context(O) through(O) fixed(O) size(O) dense(O) vectors(O) ((O) word(O) embedding(O) s(O) )(O) has(O) become(O) one(O) the(O) most(O) fundamental(O) blocks(O) in(O) several(O) NLP(B-field) systems.(O) an(O) unsupervised(B-product) disambiguation(I-product) system(I-product) uses(O) the(O) similarity(O) between(O) word(O) senses(O) in(O) a(O) fixed(O) context(O) window(O) to(O) select(O) the(O) most(O) suitable(O) word(O) sense(O) using(O) a(O) pre-trained(O) word(O) embedding(O) model(O) and(O) WordNet(B-product) .(O)"}}
{"id":"9","dataset":"crossner_ai","split":"dev","label_list":["task","metric","researcher","programming language","field","country","product","algorithm","location","person","conference","university","organization"],"instance":{"id":"9","words":["Machine","learning","techniques",",","either","Supervised","learning","or","Unsupervised","learning",",","have","been","used","to","induce","such","rules","automatically","."],"labels":["B-field","I-field","O","O","O","B-field","I-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, metric, researcher, programming language, field, country, product, algorithm, location, person, conference, university, organization and O.\nSentence: Machine learning techniques , either Supervised learning or Unsupervised learning , have been used to induce such rules automatically .","prompt_labels":"Machine(B-field) learning(I-field) techniques(O) ,(O) either(O) Supervised(B-field) learning(I-field) or(O) Unsupervised(B-field) learning(I-field) ,(O) have(O) been(O) used(O) to(O) induce(O) such(O) rules(O) automatically(O) .(O)"}}
{"id":"10","dataset":"crossner_ai","split":"dev","label_list":["task","product","conference","location","researcher","country","field","programming language","university","organization","person","algorithm","metric"],"instance":{"id":"10","words":["In","1969",",","Scheinman","invented","the","Stanford","arm",","],"labels":["O","O","O","B-researcher","O","O","B-product","I-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, product, conference, location, researcher, country, field, programming language, university, organization, person, algorithm, metric and O.\nSentence: In 1969 , Scheinman invented the Stanford arm ,","prompt_labels":"In(O) 1969(O) ,(O) Scheinman(B-researcher) invented(O) the(O) Stanford(B-product) arm(I-product) ,(O)"}}
{"id":"11","dataset":"crossner_ai","split":"dev","label_list":["conference","field","programming language","organization","metric","researcher","product","location","university","task","country","person","algorithm"],"instance":{"id":"11","words":["Since","the","Log","loss","is","differentiable",",","a","gradient-based","method","can","be","used","to","optimize","the","model","."],"labels":["O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, field, programming language, organization, metric, researcher, product, location, university, task, country, person, algorithm and O.\nSentence: Since the Log loss is differentiable , a gradient-based method can be used to optimize the model .","prompt_labels":"Since(O) the(O) Log(B-metric) loss(I-metric) is(O) differentiable(O) ,(O) a(O) gradient-based(O) method(O) can(O) be(O) used(O) to(O) optimize(O) the(O) model(O) .(O)"}}
{"id":"12","dataset":"crossner_ai","split":"dev","label_list":["conference","organization","algorithm","person","researcher","metric","country","field","university","product","programming language","location","task"],"instance":{"id":"12","words":["In","machine","learning",",","support-vector","machines","(","SVMs",",","also","support-vector","networks",")","are","supervised","learning","models","with","learning","algorithm","s","that","analyze","data","used","for","classification","and","regression","analysis","."],"labels":["O","B-field","I-field","O","B-algorithm","I-algorithm","O","B-algorithm","O","O","B-algorithm","I-algorithm","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","B-task","O","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, organization, algorithm, person, researcher, metric, country, field, university, product, programming language, location, task and O.\nSentence: In machine learning , support-vector machines ( SVMs , also support-vector networks ) are supervised learning models with learning algorithm s that analyze data used for classification and regression analysis .","prompt_labels":"In(O) machine(B-field) learning(I-field) ,(O) support-vector(B-algorithm) machines(I-algorithm) ((O) SVMs(B-algorithm) ,(O) also(O) support-vector(B-algorithm) networks(I-algorithm) )(O) are(O) supervised(B-field) learning(I-field) models(O) with(O) learning(O) algorithm(O) s(O) that(O) analyze(O) data(O) used(O) for(O) classification(B-task) and(O) regression(B-task) analysis(I-task) .(O)"}}
{"id":"13","dataset":"crossner_ai","split":"dev","label_list":["field","metric","researcher","location","organization","country","person","product","programming language","university","conference","task","algorithm"],"instance":{"id":"13","words":[",","(","2002",")","as","the","automatic","metric","for","Machine","translation","(","MT",")","evaluation",",","many","other","methods","have","been","proposed","to","revise","or","improve","it",",","such","as","TER",",","METEOR",",","Banerjee","and","Lavie",",","(","2005",")","etc","."],"labels":["O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","O","B-metric","O","B-researcher","O","B-researcher","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, metric, researcher, location, organization, country, person, product, programming language, university, conference, task, algorithm and O.\nSentence: , ( 2002 ) as the automatic metric for Machine translation ( MT ) evaluation , many other methods have been proposed to revise or improve it , such as TER , METEOR , Banerjee and Lavie , ( 2005 ) etc .","prompt_labels":",(O) ((O) 2002(O) )(O) as(O) the(O) automatic(O) metric(O) for(O) Machine(B-task) translation(I-task) ((O) MT(B-task) )(O) evaluation(O) ,(O) many(O) other(O) methods(O) have(O) been(O) proposed(O) to(O) revise(O) or(O) improve(O) it(O) ,(O) such(O) as(O) TER(B-metric) ,(O) METEOR(B-metric) ,(O) Banerjee(B-researcher) and(O) Lavie(B-researcher) ,(O) ((O) 2005(O) )(O) etc(O) .(O)"}}
{"id":"14","dataset":"crossner_ai","split":"dev","label_list":["product","programming language","person","organization","researcher","algorithm","field","conference","task","country","metric","location","university"],"instance":{"id":"14","words":["It","includes","an","upper","ontology",",","created","by","the","IEEE","working","group","P1600.1","(","originally","by","Ian","Niles","and","Adam","Pease",")","."],"labels":["O","O","O","O","O","O","O","O","O","B-organization","O","O","O","O","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: product, programming language, person, organization, researcher, algorithm, field, conference, task, country, metric, location, university and O.\nSentence: It includes an upper ontology , created by the IEEE working group P1600.1 ( originally by Ian Niles and Adam Pease ) .","prompt_labels":"It(O) includes(O) an(O) upper(O) ontology(O) ,(O) created(O) by(O) the(O) IEEE(B-organization) working(O) group(O) P1600.1(O) ((O) originally(O) by(O) Ian(B-researcher) Niles(I-researcher) and(O) Adam(B-researcher) Pease(I-researcher) )(O) .(O)"}}
{"id":"15","dataset":"crossner_ai","split":"dev","label_list":["algorithm","country","product","university","location","programming language","researcher","task","conference","metric","field","person","organization"],"instance":{"id":"15","words":["In","Cryo","Electron","Tomography",",","where","the","limited","number","of","projections","are","acquired","due","to","the","hardware","limitations","and","to","avoid","the","biological","specimen","damage",",","it","can","be","used","along","with","compressive","sensing","techniques","or","regularization","functions","(","e.g.","Huber","loss",")","to","improve","the","reconstruction","for","better","interpretation","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","I-algorithm","I-algorithm","O","B-algorithm","I-algorithm","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, country, product, university, location, programming language, researcher, task, conference, metric, field, person, organization and O.\nSentence: In Cryo Electron Tomography , where the limited number of projections are acquired due to the hardware limitations and to avoid the biological specimen damage , it can be used along with compressive sensing techniques or regularization functions ( e.g. Huber loss ) to improve the reconstruction for better interpretation .","prompt_labels":"In(O) Cryo(O) Electron(O) Tomography(O) ,(O) where(O) the(O) limited(O) number(O) of(O) projections(O) are(O) acquired(O) due(O) to(O) the(O) hardware(O) limitations(O) and(O) to(O) avoid(O) the(O) biological(O) specimen(O) damage(O) ,(O) it(O) can(O) be(O) used(O) along(O) with(O) compressive(B-algorithm) sensing(I-algorithm) techniques(I-algorithm) or(O) regularization(B-algorithm) functions(I-algorithm) ((O) e.g.(O) Huber(B-metric) loss(I-metric) )(O) to(O) improve(O) the(O) reconstruction(O) for(O) better(O) interpretation(O) .(O)"}}
{"id":"16","dataset":"crossner_ai","split":"dev","label_list":["university","researcher","programming language","product","conference","field","metric","task","location","algorithm","organization","person","country"],"instance":{"id":"16","words":["An","implementation","of","several","whitening","procedures","in","R",",","including","ZCA-whitening","and","PCA","whitening","but","also","CCA","whitening",",","is","available","in","the","whitening","R","package","published","on","CRAN","."],"labels":["O","O","O","O","O","O","O","B-programming language","O","O","B-algorithm","O","B-algorithm","I-algorithm","O","O","B-algorithm","I-algorithm","O","O","O","O","O","B-product","I-product","I-product","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, researcher, programming language, product, conference, field, metric, task, location, algorithm, organization, person, country and O.\nSentence: An implementation of several whitening procedures in R , including ZCA-whitening and PCA whitening but also CCA whitening , is available in the whitening R package published on CRAN .","prompt_labels":"An(O) implementation(O) of(O) several(O) whitening(O) procedures(O) in(O) R(B-programming language) ,(O) including(O) ZCA-whitening(B-algorithm) and(O) PCA(B-algorithm) whitening(I-algorithm) but(O) also(O) CCA(B-algorithm) whitening(I-algorithm) ,(O) is(O) available(O) in(O) the(O) whitening(B-product) R(I-product) package(I-product) published(O) on(O) CRAN(B-product) .(O)"}}
{"id":"17","dataset":"crossner_ai","split":"dev","label_list":["university","country","task","researcher","organization","product","person","programming language","field","metric","conference","algorithm","location"],"instance":{"id":"17","words":["Today",",","the","field","has","become","even","more","daunting","and","complex","with","the","addition","of","circuit",",","systems","and","signal","analysis","and","design","languages","and","software",",","from","MATLAB","and","Simulink","to","NumPy",",","VHDL",",","PSpice",",","Verilog","and","even","Assembly","language","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","B-product","O","B-product","O","B-product","O","B-product","O","O","B-programming language","I-programming language","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, country, task, researcher, organization, product, person, programming language, field, metric, conference, algorithm, location and O.\nSentence: Today , the field has become even more daunting and complex with the addition of circuit , systems and signal analysis and design languages and software , from MATLAB and Simulink to NumPy , VHDL , PSpice , Verilog and even Assembly language .","prompt_labels":"Today(O) ,(O) the(O) field(O) has(O) become(O) even(O) more(O) daunting(O) and(O) complex(O) with(O) the(O) addition(O) of(O) circuit(O) ,(O) systems(O) and(O) signal(O) analysis(O) and(O) design(O) languages(O) and(O) software(O) ,(O) from(O) MATLAB(B-product) and(O) Simulink(B-product) to(O) NumPy(B-product) ,(O) VHDL(B-product) ,(O) PSpice(B-product) ,(O) Verilog(B-product) and(O) even(O) Assembly(B-programming language) language(I-programming language) .(O)"}}
{"id":"18","dataset":"crossner_ai","split":"dev","label_list":["metric","country","university","field","person","location","product","algorithm","researcher","task","programming language","organization","conference"],"instance":{"id":"18","words":["The","company","was","founded","by","Kiichiro","Toyoda","in","1937",",","as","a","spinoff","from","Sakichi","Toyoda","company","Toyota","Industries","to","create","automobiles","."],"labels":["O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","B-person","I-person","O","B-organization","I-organization","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, country, university, field, person, location, product, algorithm, researcher, task, programming language, organization, conference and O.\nSentence: The company was founded by Kiichiro Toyoda in 1937 , as a spinoff from Sakichi Toyoda company Toyota Industries to create automobiles .","prompt_labels":"The(O) company(O) was(O) founded(O) by(O) Kiichiro(B-person) Toyoda(I-person) in(O) 1937(O) ,(O) as(O) a(O) spinoff(O) from(O) Sakichi(B-person) Toyoda(I-person) company(O) Toyota(B-organization) Industries(I-organization) to(O) create(O) automobiles(B-product) .(O)"}}
{"id":"19","dataset":"crossner_ai","split":"dev","label_list":["researcher","person","programming language","task","organization","product","university","field","metric","location","conference","country","algorithm"],"instance":{"id":"19","words":["Unsupervised","learning",",","on","the","other","hand",",","assumes","training","data","that","has","not","been","hand-labeled",",","and","attempts","to","find","inherent","patterns","in","the","data","that","can","then","be","used","to","determine","the","correct","output","value","for","new","data","instances","..","A","combination","of","the","two","that","has","recently","been","explored","is","semi-supervised","learning",",","which","uses","a","combination","of","labeled","and","unlabeled","data","(","typically","a","small","set","of","labeled","data","combined","with","a","large","amount","of","unlabeled","data",")","."],"labels":["B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, person, programming language, task, organization, product, university, field, metric, location, conference, country, algorithm and O.\nSentence: Unsupervised learning , on the other hand , assumes training data that has not been hand-labeled , and attempts to find inherent patterns in the data that can then be used to determine the correct output value for new data instances .. A combination of the two that has recently been explored is semi-supervised learning , which uses a combination of labeled and unlabeled data ( typically a small set of labeled data combined with a large amount of unlabeled data ) .","prompt_labels":"Unsupervised(B-field) learning(I-field) ,(O) on(O) the(O) other(O) hand(O) ,(O) assumes(O) training(O) data(O) that(O) has(O) not(O) been(O) hand-labeled(O) ,(O) and(O) attempts(O) to(O) find(O) inherent(O) patterns(O) in(O) the(O) data(O) that(O) can(O) then(O) be(O) used(O) to(O) determine(O) the(O) correct(O) output(O) value(O) for(O) new(O) data(O) instances(O) ..(O) A(O) combination(O) of(O) the(O) two(O) that(O) has(O) recently(O) been(O) explored(O) is(O) semi-supervised(B-field) learning(I-field) ,(O) which(O) uses(O) a(O) combination(O) of(O) labeled(O) and(O) unlabeled(O) data(O) ((O) typically(O) a(O) small(O) set(O) of(O) labeled(O) data(O) combined(O) with(O) a(O) large(O) amount(O) of(O) unlabeled(O) data(O) )(O) .(O)"}}
{"id":"20","dataset":"crossner_ai","split":"dev","label_list":["researcher","country","conference","person","task","algorithm","organization","product","university","programming language","metric","location","field"],"instance":{"id":"20","words":["Despite","those","humanoid","robots","for","utilitarian","uses",",","there","are","some","humanoid","robots","which","aims","at","entertainment","uses",",","such","as","Sony","'","s","QRIO","and","Wow","Wee","'","s","RoboSapien","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","O","O","B-product","O","B-organization","I-organization","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, country, conference, person, task, algorithm, organization, product, university, programming language, metric, location, field and O.\nSentence: Despite those humanoid robots for utilitarian uses , there are some humanoid robots which aims at entertainment uses , such as Sony ' s QRIO and Wow Wee ' s RoboSapien .","prompt_labels":"Despite(O) those(O) humanoid(O) robots(O) for(O) utilitarian(O) uses(O) ,(O) there(O) are(O) some(O) humanoid(O) robots(O) which(O) aims(O) at(O) entertainment(O) uses(O) ,(O) such(O) as(O) Sony(B-organization) '(O) s(O) QRIO(B-product) and(O) Wow(B-organization) Wee(I-organization) '(O) s(O) RoboSapien(B-product) .(O)"}}
{"id":"21","dataset":"crossner_ai","split":"dev","label_list":["location","task","product","country","organization","researcher","programming language","conference","field","university","person","algorithm","metric"],"instance":{"id":"21","words":["Webber","became","a","Fellow","of","the","Association","for","the","Advancement","of","Artificial","Intelligence","in","1991",","],"labels":["B-researcher","O","O","O","O","O","B-conference","I-conference","I-conference","I-conference","I-conference","I-conference","I-conference","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, task, product, country, organization, researcher, programming language, conference, field, university, person, algorithm, metric and O.\nSentence: Webber became a Fellow of the Association for the Advancement of Artificial Intelligence in 1991 ,","prompt_labels":"Webber(B-researcher) became(O) a(O) Fellow(O) of(O) the(O) Association(B-conference) for(I-conference) the(I-conference) Advancement(I-conference) of(I-conference) Artificial(I-conference) Intelligence(I-conference) in(O) 1991(O) ,(O)"}}
{"id":"22","dataset":"crossner_ai","split":"dev","label_list":["person","metric","location","country","researcher","conference","field","organization","programming language","university","product","task","algorithm"],"instance":{"id":"22","words":["With","this","company","he","was","developing","data-mining","and","database","technology",",","more","specific","high-level","ontologies","for","intelligence","and","automated","natural","language","understanding","."],"labels":["O","O","O","O","O","O","B-field","O","B-field","O","O","O","O","O","O","O","O","O","B-task","I-task","B-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, metric, location, country, researcher, conference, field, organization, programming language, university, product, task, algorithm and O.\nSentence: With this company he was developing data-mining and database technology , more specific high-level ontologies for intelligence and automated natural language understanding .","prompt_labels":"With(O) this(O) company(O) he(O) was(O) developing(O) data-mining(B-field) and(O) database(B-field) technology(O) ,(O) more(O) specific(O) high-level(O) ontologies(O) for(O) intelligence(O) and(O) automated(B-task) natural(I-task) language(B-task) understanding(I-task) .(O)"}}
{"id":"23","dataset":"crossner_ai","split":"dev","label_list":["researcher","conference","algorithm","task","country","metric","field","location","programming language","person","university","product","organization"],"instance":{"id":"23","words":["However",",","in","the","last","years",",","one","can","observe","appearing","of","different","e-services","and","related","initiatives","in","developing","countries","such","as","Project","Nemmadi",",","MCA21","Mission","Mode","Project","or","Digital","India","even","more",",","in","India",";","Electronic","Government","Directorate","in","Pakistan",";","etc","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-country","O","B-organization","I-organization","I-organization","O","B-country","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, conference, algorithm, task, country, metric, field, location, programming language, person, university, product, organization and O.\nSentence: However , in the last years , one can observe appearing of different e-services and related initiatives in developing countries such as Project Nemmadi , MCA21 Mission Mode Project or Digital India even more , in India ; Electronic Government Directorate in Pakistan ; etc .","prompt_labels":"However(O) ,(O) in(O) the(O) last(O) years(O) ,(O) one(O) can(O) observe(O) appearing(O) of(O) different(O) e-services(O) and(O) related(O) initiatives(O) in(O) developing(O) countries(O) such(O) as(O) Project(O) Nemmadi(O) ,(O) MCA21(O) Mission(O) Mode(O) Project(O) or(O) Digital(O) India(O) even(O) more(O) ,(O) in(O) India(B-country) ;(O) Electronic(B-organization) Government(I-organization) Directorate(I-organization) in(O) Pakistan(B-country) ;(O) etc(O) .(O)"}}
{"id":"24","dataset":"crossner_ai","split":"dev","label_list":["task","metric","programming language","conference","researcher","country","algorithm","location","field","product","person","university","organization"],"instance":{"id":"24","words":["He","received","a","PhD","in","Radio","Physics","and","Electronics","from","the","Rajabazar","Science","College","campus","of","University","of","Calcutta","in","1979","as","a","student","of","Indian","Statistical","Institute",",","and","another","PhD","in","Electrical","Engineering","along","with","Diploma","of","the","Imperial","College","from","Imperial","College",",","University","of","London",",","in","1982","."],"labels":["O","O","O","O","O","B-field","I-field","O","B-field","O","O","B-university","I-university","I-university","O","O","B-university","I-university","I-university","O","O","O","O","O","O","B-university","I-university","I-university","O","O","O","O","O","B-field","I-field","O","O","O","O","O","O","O","O","B-university","I-university","O","B-university","I-university","I-university","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: task, metric, programming language, conference, researcher, country, algorithm, location, field, product, person, university, organization and O.\nSentence: He received a PhD in Radio Physics and Electronics from the Rajabazar Science College campus of University of Calcutta in 1979 as a student of Indian Statistical Institute , and another PhD in Electrical Engineering along with Diploma of the Imperial College from Imperial College , University of London , in 1982 .","prompt_labels":"He(O) received(O) a(O) PhD(O) in(O) Radio(B-field) Physics(I-field) and(O) Electronics(B-field) from(O) the(O) Rajabazar(B-university) Science(I-university) College(I-university) campus(O) of(O) University(B-university) of(I-university) Calcutta(I-university) in(O) 1979(O) as(O) a(O) student(O) of(O) Indian(B-university) Statistical(I-university) Institute(I-university) ,(O) and(O) another(O) PhD(O) in(O) Electrical(B-field) Engineering(I-field) along(O) with(O) Diploma(O) of(O) the(O) Imperial(O) College(O) from(O) Imperial(B-university) College(I-university) ,(O) University(B-university) of(I-university) London(I-university) ,(O) in(O) 1982(O) .(O)"}}
{"id":"25","dataset":"crossner_ai","split":"dev","label_list":["algorithm","person","metric","conference","location","field","university","programming language","task","country","organization","researcher","product"],"instance":{"id":"25","words":["Expo","II","was","announced","as","being","the","locale","for","the","world","premiere","of","several","films","never","before","seen","in","3D",",","including","The","Diamond","Wizard","and","the","Universal","short",",","Hawaiian","Nights","with","Mamie","Van","Doren","and","Pinky","Lee","."],"labels":["B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","I-person","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, person, metric, conference, location, field, university, programming language, task, country, organization, researcher, product and O.\nSentence: Expo II was announced as being the locale for the world premiere of several films never before seen in 3D , including The Diamond Wizard and the Universal short , Hawaiian Nights with Mamie Van Doren and Pinky Lee .","prompt_labels":"Expo(B-location) II(I-location) was(O) announced(O) as(O) being(O) the(O) locale(O) for(O) the(O) world(O) premiere(O) of(O) several(O) films(O) never(O) before(O) seen(O) in(O) 3D(O) ,(O) including(O) The(O) Diamond(O) Wizard(O) and(O) the(O) Universal(O) short(O) ,(O) Hawaiian(O) Nights(O) with(O) Mamie(B-person) Van(I-person) Doren(I-person) and(O) Pinky(B-person) Lee(I-person) .(O)"}}
{"id":"26","dataset":"crossner_ai","split":"dev","label_list":["metric","task","field","programming language","researcher","product","algorithm","country","person","location","organization","conference","university"],"instance":{"id":"26","words":["The","maximum","subarray","problem","was","proposed","by","Ulf","Grenander","in","1977","as","a","simplified","model","for","maximum","likelihood","estimation","of","patterns","in","digitized","images","."],"labels":["O","O","O","O","O","O","O","B-researcher","I-researcher","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: metric, task, field, programming language, researcher, product, algorithm, country, person, location, organization, conference, university and O.\nSentence: The maximum subarray problem was proposed by Ulf Grenander in 1977 as a simplified model for maximum likelihood estimation of patterns in digitized images .","prompt_labels":"The(O) maximum(O) subarray(O) problem(O) was(O) proposed(O) by(O) Ulf(B-researcher) Grenander(I-researcher) in(O) 1977(O) as(O) a(O) simplified(O) model(O) for(O) maximum(B-metric) likelihood(I-metric) estimation(I-metric) of(O) patterns(O) in(O) digitized(O) images(O) .(O)"}}
{"id":"27","dataset":"crossner_ai","split":"dev","label_list":["algorithm","programming language","field","country","researcher","location","person","task","organization","university","metric","conference","product"],"instance":{"id":"27","words":["The","iPhone","4S",",","iPad","3",",","iPad","Mini","1G",",","iPad","Air",",","iPad","Pro","1G",",","iPod","Touch","5G","and","later",",","all","come","with","a","more","advanced","voice","assistant","called","Siri","."],"labels":["O","B-product","I-product","O","B-product","I-product","O","B-product","I-product","I-product","O","B-product","I-product","O","B-product","I-product","I-product","O","B-product","I-product","I-product","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: algorithm, programming language, field, country, researcher, location, person, task, organization, university, metric, conference, product and O.\nSentence: The iPhone 4S , iPad 3 , iPad Mini 1G , iPad Air , iPad Pro 1G , iPod Touch 5G and later , all come with a more advanced voice assistant called Siri .","prompt_labels":"The(O) iPhone(B-product) 4S(I-product) ,(O) iPad(B-product) 3(I-product) ,(O) iPad(B-product) Mini(I-product) 1G(I-product) ,(O) iPad(B-product) Air(I-product) ,(O) iPad(B-product) Pro(I-product) 1G(I-product) ,(O) iPod(B-product) Touch(I-product) 5G(I-product) and(O) later(O) ,(O) all(O) come(O) with(O) a(O) more(O) advanced(O) voice(O) assistant(O) called(O) Siri(B-product) .(O)"}}
{"id":"28","dataset":"crossner_ai","split":"dev","label_list":["organization","university","person","task","conference","researcher","country","location","algorithm","metric","product","programming language","field"],"instance":{"id":"28","words":["It","'s","easy","to","check","that","the","logistic","loss","and","binary","cross","entropy","loss","(","Log","loss",")","are","in","fact","the","same","(","up","to","a","multiplicative","constant","math","\\","frac","{","1","}","{","\\","log","(","2",")","}","/","math",")",".The","cross","entropy","loss","is","closely","related","to","the","Kullback-Leibler","divergence","between","the","empirical","distribution","and","the","predicted","distribution","."],"labels":["O","O","O","O","O","O","O","B-metric","I-metric","O","B-metric","I-metric","I-metric","I-metric","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-metric","I-metric","I-metric","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, university, person, task, conference, researcher, country, location, algorithm, metric, product, programming language, field and O.\nSentence: It 's easy to check that the logistic loss and binary cross entropy loss ( Log loss ) are in fact the same ( up to a multiplicative constant math \\ frac { 1 } { \\ log ( 2 ) } / math ) .The cross entropy loss is closely related to the Kullback-Leibler divergence between the empirical distribution and the predicted distribution .","prompt_labels":"It(O) 's(O) easy(O) to(O) check(O) that(O) the(O) logistic(B-metric) loss(I-metric) and(O) binary(B-metric) cross(I-metric) entropy(I-metric) loss(I-metric) ((O) Log(B-metric) loss(I-metric) )(O) are(O) in(O) fact(O) the(O) same(O) ((O) up(O) to(O) a(O) multiplicative(O) constant(O) math(O) \\(O) frac(O) {(O) 1(O) }(O) {(O) \\(O) log(O) ((O) 2(O) )(O) }(O) /(O) math(O) )(O) .The(O) cross(B-metric) entropy(I-metric) loss(I-metric) is(O) closely(O) related(O) to(O) the(O) Kullback-Leibler(B-metric) divergence(I-metric) between(O) the(O) empirical(O) distribution(O) and(O) the(O) predicted(O) distribution(O) .(O)"}}
{"id":"29","dataset":"crossner_ai","split":"dev","label_list":["person","field","algorithm","metric","task","product","country","university","location","conference","researcher","organization","programming language"],"instance":{"id":"29","words":["The","EM","algorithm","is","used","to","find","(","local",")","maximum","likelihood","parameters","of","a","statistical","model","in","cases","where","the","equations","cannot","be","solved","directly","."],"labels":["O","B-algorithm","I-algorithm","O","O","O","O","O","O","O","B-metric","I-metric","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, field, algorithm, metric, task, product, country, university, location, conference, researcher, organization, programming language and O.\nSentence: The EM algorithm is used to find ( local ) maximum likelihood parameters of a statistical model in cases where the equations cannot be solved directly .","prompt_labels":"The(O) EM(B-algorithm) algorithm(I-algorithm) is(O) used(O) to(O) find(O) ((O) local(O) )(O) maximum(B-metric) likelihood(I-metric) parameters(O) of(O) a(O) statistical(O) model(O) in(O) cases(O) where(O) the(O) equations(O) cannot(O) be(O) solved(O) directly(O) .(O)"}}
{"id":"30","dataset":"crossner_ai","split":"dev","label_list":["researcher","conference","algorithm","person","field","location","product","task","university","programming language","country","metric","organization"],"instance":{"id":"30","words":["This","research","was","fundamental","to","the","development","of","modern","techniques","of","speech","synthesis",",","reading","machines","for","the","blind",",","the","study","of","speech","perception","and","speech","recognition",",","and","the","development","of","the","motor","theory","of","speech","perception","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-task","I-task","O","B-task","I-task","I-task","I-task","I-task","O","O","O","O","B-task","I-task","O","B-task","I-task","O","O","O","O","O","O","B-task","I-task","I-task","I-task","I-task","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, conference, algorithm, person, field, location, product, task, university, programming language, country, metric, organization and O.\nSentence: This research was fundamental to the development of modern techniques of speech synthesis , reading machines for the blind , the study of speech perception and speech recognition , and the development of the motor theory of speech perception .","prompt_labels":"This(O) research(O) was(O) fundamental(O) to(O) the(O) development(O) of(O) modern(O) techniques(O) of(O) speech(B-task) synthesis(I-task) ,(O) reading(B-task) machines(I-task) for(I-task) the(I-task) blind(I-task) ,(O) the(O) study(O) of(O) speech(B-task) perception(I-task) and(O) speech(B-task) recognition(I-task) ,(O) and(O) the(O) development(O) of(O) the(O) motor(B-task) theory(I-task) of(I-task) speech(I-task) perception(I-task) .(O)"}}
{"id":"31","dataset":"crossner_ai","split":"dev","label_list":["conference","person","university","metric","country","organization","location","researcher","algorithm","field","task","product","programming language"],"instance":{"id":"31","words":["The","Arduino","integrated","development","environment","(","IDE",")","is","a","cross-platform","application","(","for","Windows",",","macOS",",","and","Linux",")","that","is","written","in","the","programming","language","Java","."],"labels":["O","B-product","O","O","O","O","O","O","O","O","O","O","O","O","B-product","O","B-product","O","O","B-product","O","O","O","O","O","O","O","O","B-programming language","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, person, university, metric, country, organization, location, researcher, algorithm, field, task, product, programming language and O.\nSentence: The Arduino integrated development environment ( IDE ) is a cross-platform application ( for Windows , macOS , and Linux ) that is written in the programming language Java .","prompt_labels":"The(O) Arduino(B-product) integrated(O) development(O) environment(O) ((O) IDE(O) )(O) is(O) a(O) cross-platform(O) application(O) ((O) for(O) Windows(B-product) ,(O) macOS(B-product) ,(O) and(O) Linux(B-product) )(O) that(O) is(O) written(O) in(O) the(O) programming(O) language(O) Java(B-programming language) .(O)"}}
{"id":"32","dataset":"crossner_ai","split":"dev","label_list":["conference","task","country","metric","researcher","person","product","programming language","organization","field","algorithm","university","location"],"instance":{"id":"32","words":["Neural","network","research","stagnated","after","the","publication","of","machine","learning","research","by","Marvin","Minsky","and","Seymour","Papert","(","1969",")","."],"labels":["B-algorithm","I-algorithm","O","O","O","O","O","O","B-field","I-field","O","O","B-researcher","I-researcher","O","B-researcher","I-researcher","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, task, country, metric, researcher, person, product, programming language, organization, field, algorithm, university, location and O.\nSentence: Neural network research stagnated after the publication of machine learning research by Marvin Minsky and Seymour Papert ( 1969 ) .","prompt_labels":"Neural(B-algorithm) network(I-algorithm) research(O) stagnated(O) after(O) the(O) publication(O) of(O) machine(B-field) learning(I-field) research(O) by(O) Marvin(B-researcher) Minsky(I-researcher) and(O) Seymour(B-researcher) Papert(I-researcher) ((O) 1969(O) )(O) .(O)"}}
{"id":"33","dataset":"crossner_ai","split":"dev","label_list":["conference","metric","location","country","algorithm","person","organization","university","product","task","field","programming language","researcher"],"instance":{"id":"33","words":["Only","a","few","non-Japanese","companies","ultimately","managed","to","survive","in","this","market",",","the","major","ones","being",":","Adept","Technology",",","Stäubli",",","the","Sweden","-","Switzerland","company","ABB","Asea","Brown","Boveri",",","the","Germany","company","KUKA","Robotics","and","the","Italy","company","Comau","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","O","O","B-country","O","B-country","O","B-organization","I-organization","I-organization","I-organization","O","O","B-country","O","B-organization","I-organization","O","O","B-country","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, metric, location, country, algorithm, person, organization, university, product, task, field, programming language, researcher and O.\nSentence: Only a few non-Japanese companies ultimately managed to survive in this market , the major ones being : Adept Technology , Stäubli , the Sweden - Switzerland company ABB Asea Brown Boveri , the Germany company KUKA Robotics and the Italy company Comau .","prompt_labels":"Only(O) a(O) few(O) non-Japanese(O) companies(O) ultimately(O) managed(O) to(O) survive(O) in(O) this(O) market(O) ,(O) the(O) major(O) ones(O) being(O) :(O) Adept(B-organization) Technology(I-organization) ,(O) Stäubli(B-organization) ,(O) the(O) Sweden(B-country) -(O) Switzerland(B-country) company(O) ABB(B-organization) Asea(I-organization) Brown(I-organization) Boveri(I-organization) ,(O) the(O) Germany(B-country) company(O) KUKA(B-organization) Robotics(I-organization) and(O) the(O) Italy(B-country) company(O) Comau(B-organization) .(O)"}}
{"id":"34","dataset":"crossner_ai","split":"dev","label_list":["location","programming language","field","metric","university","organization","conference","task","algorithm","person","product","researcher","country"],"instance":{"id":"34","words":["The","research","activities","include","an","annual","research","conference",",","the","RuleML","Symposium",",","also","known","as","RuleML","for","short","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-conference","I-conference","O","O","O","O","B-conference","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, programming language, field, metric, university, organization, conference, task, algorithm, person, product, researcher, country and O.\nSentence: The research activities include an annual research conference , the RuleML Symposium , also known as RuleML for short .","prompt_labels":"The(O) research(O) activities(O) include(O) an(O) annual(O) research(O) conference(O) ,(O) the(O) RuleML(B-conference) Symposium(I-conference) ,(O) also(O) known(O) as(O) RuleML(B-conference) for(O) short(O) .(O)"}}
{"id":"35","dataset":"crossner_ai","split":"dev","label_list":["field","location","metric","person","task","product","university","country","researcher","organization","algorithm","programming language","conference"],"instance":{"id":"35","words":["Concepts","are","used","as","formal","tools","or","models","in","mathematics",",","computer","science",",","databases","and","artificial","intelligence","where","they","are","sometimes","called","classes",",","schema","or","categories","."],"labels":["O","O","O","O","O","O","O","O","O","B-field","O","B-field","I-field","O","B-field","O","B-field","I-field","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, location, metric, person, task, product, university, country, researcher, organization, algorithm, programming language, conference and O.\nSentence: Concepts are used as formal tools or models in mathematics , computer science , databases and artificial intelligence where they are sometimes called classes , schema or categories .","prompt_labels":"Concepts(O) are(O) used(O) as(O) formal(O) tools(O) or(O) models(O) in(O) mathematics(B-field) ,(O) computer(B-field) science(I-field) ,(O) databases(B-field) and(O) artificial(B-field) intelligence(I-field) where(O) they(O) are(O) sometimes(O) called(O) classes(O) ,(O) schema(O) or(O) categories(O) .(O)"}}
{"id":"36","dataset":"crossner_ai","split":"dev","label_list":["field","university","researcher","programming language","conference","metric","country","algorithm","person","organization","location","product","task"],"instance":{"id":"36","words":["He","has","won","awards","from","the","American","Psychological","Association",",","the","National","Academy","of","Sciences",",","the","Royal",",","the","Cognitive","Neuroscience","Society","and","the","American","Humanist","Association","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","B-organization","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, university, researcher, programming language, conference, metric, country, algorithm, person, organization, location, product, task and O.\nSentence: He has won awards from the American Psychological Association , the National Academy of Sciences , the Royal , the Cognitive Neuroscience Society and the American Humanist Association .","prompt_labels":"He(O) has(O) won(O) awards(O) from(O) the(O) American(B-organization) Psychological(I-organization) Association(I-organization) ,(O) the(O) National(B-organization) Academy(I-organization) of(I-organization) Sciences(I-organization) ,(O) the(O) Royal(B-organization) ,(O) the(O) Cognitive(B-organization) Neuroscience(I-organization) Society(I-organization) and(O) the(O) American(B-organization) Humanist(I-organization) Association(I-organization) .(O)"}}
{"id":"37","dataset":"crossner_ai","split":"dev","label_list":["field","algorithm","task","location","organization","researcher","university","person","conference","product","metric","country","programming language"],"instance":{"id":"37","words":["Starring","Harrison","Ford",",","Rutger","Hauer","and","Sean","Young",",","it","is","loosely","based","on","Philip","K.","Dick","'","s","novel","Do","Androids","Dream","of","Electric","Sheep","?","(","1968",")","."],"labels":["O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","O","O","O","O","B-person","I-person","I-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: field, algorithm, task, location, organization, researcher, university, person, conference, product, metric, country, programming language and O.\nSentence: Starring Harrison Ford , Rutger Hauer and Sean Young , it is loosely based on Philip K. Dick ' s novel Do Androids Dream of Electric Sheep ? ( 1968 ) .","prompt_labels":"Starring(O) Harrison(B-person) Ford(I-person) ,(O) Rutger(B-person) Hauer(I-person) and(O) Sean(B-person) Young(I-person) ,(O) it(O) is(O) loosely(O) based(O) on(O) Philip(B-person) K.(I-person) Dick(I-person) '(O) s(O) novel(O) Do(O) Androids(O) Dream(O) of(O) Electric(O) Sheep(O) ?(O) ((O) 1968(O) )(O) .(O)"}}
{"id":"38","dataset":"crossner_ai","split":"dev","label_list":["conference","algorithm","location","field","product","programming language","task","organization","metric","person","country","researcher","university"],"instance":{"id":"38","words":["Image","segmentation","using","k-means","clustering","algorithms","has","long","been","used","for","pattern","recognition",",","object","detection",",","and","medical","imaging","."],"labels":["B-task","I-task","O","B-algorithm","I-algorithm","I-algorithm","O","O","O","O","O","B-field","I-field","O","B-task","I-task","O","O","B-field","I-field","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: conference, algorithm, location, field, product, programming language, task, organization, metric, person, country, researcher, university and O.\nSentence: Image segmentation using k-means clustering algorithms has long been used for pattern recognition , object detection , and medical imaging .","prompt_labels":"Image(B-task) segmentation(I-task) using(O) k-means(B-algorithm) clustering(I-algorithm) algorithms(I-algorithm) has(O) long(O) been(O) used(O) for(O) pattern(B-field) recognition(I-field) ,(O) object(B-task) detection(I-task) ,(O) and(O) medical(B-field) imaging(I-field) .(O)"}}
{"id":"39","dataset":"crossner_ai","split":"dev","label_list":["researcher","organization","algorithm","university","metric","conference","field","product","person","location","programming language","task","country"],"instance":{"id":"39","words":["General","sampling","from","the","truncated","normal","can","be","achieved","using","approximations","to","the","normal","CDF","and","the","probit","function",",","and","R","has","a","function","codertnorm","(",")","/","code","for","generating","truncated-normal","samples","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-algorithm","O","O","B-algorithm","I-algorithm","O","O","B-programming language","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: researcher, organization, algorithm, university, metric, conference, field, product, person, location, programming language, task, country and O.\nSentence: General sampling from the truncated normal can be achieved using approximations to the normal CDF and the probit function , and R has a function codertnorm ( ) / code for generating truncated-normal samples .","prompt_labels":"General(O) sampling(O) from(O) the(O) truncated(O) normal(O) can(O) be(O) achieved(O) using(O) approximations(O) to(O) the(O) normal(O) CDF(B-algorithm) and(O) the(O) probit(B-algorithm) function(I-algorithm) ,(O) and(O) R(B-programming language) has(O) a(O) function(O) codertnorm(O) ((O) )(O) /(O) code(O) for(O) generating(O) truncated-normal(O) samples(O) .(O)"}}
{"id":"0","dataset":"crossner_music","split":"dev","label_list":["musical instrument","band","song","location","album","musical artist","country","award","music genre","person","organization","event"],"instance":{"id":"0","words":["As","part","of","the","2010","leg","of","the","My","Christmas","Tour",",","Bocelli","gave","two","concerts","in","The","O2","Arena",",","in","London",",","and","the","Manchester","Arena",",","in","Manchester",",","and","a","concert","at","3Arena",",","in","Dublin",",","in","late","November","2010","."],"labels":["O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","B-musical artist","O","O","O","O","B-location","I-location","I-location","O","O","B-location","O","O","O","B-location","I-location","O","O","B-location","O","O","O","O","O","B-location","O","O","B-location","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, band, song, location, album, musical artist, country, award, music genre, person, organization, event and O.\nSentence: As part of the 2010 leg of the My Christmas Tour , Bocelli gave two concerts in The O2 Arena , in London , and the Manchester Arena , in Manchester , and a concert at 3Arena , in Dublin , in late November 2010 .","prompt_labels":"As(O) part(O) of(O) the(O) 2010(O) leg(O) of(O) the(O) My(B-event) Christmas(I-event) Tour(I-event) ,(O) Bocelli(B-musical artist) gave(O) two(O) concerts(O) in(O) The(B-location) O2(I-location) Arena(I-location) ,(O) in(O) London(B-location) ,(O) and(O) the(O) Manchester(B-location) Arena(I-location) ,(O) in(O) Manchester(B-location) ,(O) and(O) a(O) concert(O) at(O) 3Arena(B-location) ,(O) in(O) Dublin(B-location) ,(O) in(O) late(O) November(O) 2010(O) .(O)"}}
{"id":"1","dataset":"crossner_music","split":"dev","label_list":["location","music genre","award","musical instrument","event","musical artist","organization","song","band","person","album","country"],"instance":{"id":"1","words":["Squarepusher","continues","to","push","new","boundaries","to","this","day",",","where","he","still","calls","Warp","Records","his","home",",","having","released","numerous","albums","to","critical","acclaim","in","the","years","to","follow",",","such","as","Go","Plastic",",","Do","You","Know","Squarepusher",",","Ultravisitor",",","Hello","Everything",",","Just","a","Souvenir",",","Solo","Electric","Bass","1",",","Ufabulum","and","Damogen","Furies","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","O","B-album","I-album","O","B-album","I-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, award, musical instrument, event, musical artist, organization, song, band, person, album, country and O.\nSentence: Squarepusher continues to push new boundaries to this day , where he still calls Warp Records his home , having released numerous albums to critical acclaim in the years to follow , such as Go Plastic , Do You Know Squarepusher , Ultravisitor , Hello Everything , Just a Souvenir , Solo Electric Bass 1 , Ufabulum and Damogen Furies .","prompt_labels":"Squarepusher(B-musical artist) continues(O) to(O) push(O) new(O) boundaries(O) to(O) this(O) day(O) ,(O) where(O) he(O) still(O) calls(O) Warp(B-organization) Records(I-organization) his(O) home(O) ,(O) having(O) released(O) numerous(O) albums(O) to(O) critical(O) acclaim(O) in(O) the(O) years(O) to(O) follow(O) ,(O) such(O) as(O) Go(B-album) Plastic(I-album) ,(O) Do(B-album) You(I-album) Know(I-album) Squarepusher(I-album) ,(O) Ultravisitor(B-album) ,(O) Hello(B-album) Everything(I-album) ,(O) Just(B-album) a(I-album) Souvenir(I-album) ,(O) Solo(B-album) Electric(I-album) Bass(I-album) 1(I-album) ,(O) Ufabulum(B-album) and(O) Damogen(B-album) Furies(I-album) .(O)"}}
{"id":"2","dataset":"crossner_music","split":"dev","label_list":["event","musical instrument","person","organization","musical artist","album","country","location","song","award","music genre","band"],"instance":{"id":"2","words":["During","the","1990s",",","many","releases","included","recordings","of","classical","compositions",":","Pictures","at","an","Exhibition","(","on","Turn","of","the","Tides",")",",","Largo","(","from","Xerxes",")","(","on","Tyranny","of","Beauty",")",",","Symphony","in","A","Minor","(","by","J.","S.","Bach",")",",","and","Concerto","in","A","Major","/","Adagio","(","by","Wolfgang","Amadeus","Mozart",")","(","both","on","Ambient","Monkeys",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-song","I-song","I-song","I-song","O","O","B-album","I-album","I-album","I-album","O","O","B-song","O","O","O","O","O","O","B-album","I-album","I-album","O","O","B-song","I-song","I-song","I-song","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","B-song","I-song","I-song","I-song","I-song","I-song","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","B-album","I-album","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical instrument, person, organization, musical artist, album, country, location, song, award, music genre, band and O.\nSentence: During the 1990s , many releases included recordings of classical compositions : Pictures at an Exhibition ( on Turn of the Tides ) , Largo ( from Xerxes ) ( on Tyranny of Beauty ) , Symphony in A Minor ( by J. S. Bach ) , and Concerto in A Major / Adagio ( by Wolfgang Amadeus Mozart ) ( both on Ambient Monkeys ) .","prompt_labels":"During(O) the(O) 1990s(O) ,(O) many(O) releases(O) included(O) recordings(O) of(O) classical(O) compositions(O) :(O) Pictures(B-song) at(I-song) an(I-song) Exhibition(I-song) ((O) on(O) Turn(B-album) of(I-album) the(I-album) Tides(I-album) )(O) ,(O) Largo(B-song) ((O) from(O) Xerxes(O) )(O) ((O) on(O) Tyranny(B-album) of(I-album) Beauty(I-album) )(O) ,(O) Symphony(B-song) in(I-song) A(I-song) Minor(I-song) ((O) by(O) J.(B-musical artist) S.(I-musical artist) Bach(I-musical artist) )(O) ,(O) and(O) Concerto(B-song) in(I-song) A(I-song) Major(I-song) /(I-song) Adagio(I-song) ((O) by(O) Wolfgang(B-musical artist) Amadeus(I-musical artist) Mozart(I-musical artist) )(O) ((O) both(O) on(O) Ambient(B-album) Monkeys(I-album) )(O) .(O)"}}
{"id":"3","dataset":"crossner_music","split":"dev","label_list":["award","musical instrument","event","location","country","musical artist","music genre","organization","song","album","band","person"],"instance":{"id":"3","words":["He","has","also","won","three","Grammy","Awards",",","14","Academy","of","Country","Music","awards",",","11","Country","Music","Association","(","CMA",")","awards",",","10","American","Music","Awards",",","and","three","People","'s","Choice","Awards","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, musical instrument, event, location, country, musical artist, music genre, organization, song, album, band, person and O.\nSentence: He has also won three Grammy Awards , 14 Academy of Country Music awards , 11 Country Music Association ( CMA ) awards , 10 American Music Awards , and three People 's Choice Awards .","prompt_labels":"He(O) has(O) also(O) won(O) three(O) Grammy(B-award) Awards(I-award) ,(O) 14(O) Academy(B-award) of(I-award) Country(I-award) Music(I-award) awards(I-award) ,(O) 11(O) Country(B-award) Music(I-award) Association(I-award) ((I-award) CMA(I-award) )(I-award) awards(I-award) ,(O) 10(O) American(B-award) Music(I-award) Awards(I-award) ,(O) and(O) three(O) People(B-award) 's(I-award) Choice(I-award) Awards(I-award) .(O)"}}
{"id":"4","dataset":"crossner_music","split":"dev","label_list":["band","album","location","country","musical artist","person","event","music genre","award","organization","musical instrument","song"],"instance":{"id":"4","words":["ABBA","were","soon","recognised","and","embraced","by","other","acts",":","Evan","Dando","of","the","Lemonheads","recorded","a","cover","version","of","Knowing","Me",",","Knowing","You",";","Sinéad","O","'Connor","and","Boyzone","'s","Stephen","Gately","have","recorded","Chiquitita",";","Tanita","Tikaram",",","Blancmange","and","Steven","Wilson","paid","tribute","to","The","Day","Before","You","Came","."],"labels":["B-band","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-band","I-band","O","O","O","O","O","B-song","I-song","I-song","I-song","I-song","O","B-musical artist","I-musical artist","I-musical artist","O","B-band","O","B-musical artist","I-musical artist","O","O","B-song","O","B-musical artist","I-musical artist","O","B-band","O","B-musical artist","I-musical artist","O","O","O","B-song","I-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, album, location, country, musical artist, person, event, music genre, award, organization, musical instrument, song and O.\nSentence: ABBA were soon recognised and embraced by other acts : Evan Dando of the Lemonheads recorded a cover version of Knowing Me , Knowing You ; Sinéad O 'Connor and Boyzone 's Stephen Gately have recorded Chiquitita ; Tanita Tikaram , Blancmange and Steven Wilson paid tribute to The Day Before You Came .","prompt_labels":"ABBA(B-band) were(O) soon(O) recognised(O) and(O) embraced(O) by(O) other(O) acts(O) :(O) Evan(B-musical artist) Dando(I-musical artist) of(O) the(B-band) Lemonheads(I-band) recorded(O) a(O) cover(O) version(O) of(O) Knowing(B-song) Me(I-song) ,(I-song) Knowing(I-song) You(I-song) ;(O) Sinéad(B-musical artist) O(I-musical artist) 'Connor(I-musical artist) and(O) Boyzone(B-band) 's(O) Stephen(B-musical artist) Gately(I-musical artist) have(O) recorded(O) Chiquitita(B-song) ;(O) Tanita(B-musical artist) Tikaram(I-musical artist) ,(O) Blancmange(B-band) and(O) Steven(B-musical artist) Wilson(I-musical artist) paid(O) tribute(O) to(O) The(B-song) Day(I-song) Before(I-song) You(I-song) Came(I-song) .(O)"}}
{"id":"5","dataset":"crossner_music","split":"dev","label_list":["album","band","person","event","music genre","country","location","musical artist","musical instrument","organization","song","award"],"instance":{"id":"5","words":["His","style","incorporates","elements","of","Rock","music",",","blues",",","Soul","music",",","R","&","B",",","funk",",","jazz",",","reggae",",","hard","rock",",","Psychedelic","rock",",","Pop","music",",","Folk","music",",","and","ballads","."],"labels":["O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","O","B-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","O","B-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, band, person, event, music genre, country, location, musical artist, musical instrument, organization, song, award and O.\nSentence: His style incorporates elements of Rock music , blues , Soul music , R & B , funk , jazz , reggae , hard rock , Psychedelic rock , Pop music , Folk music , and ballads .","prompt_labels":"His(O) style(O) incorporates(O) elements(O) of(O) Rock(B-music genre) music(I-music genre) ,(O) blues(B-music genre) ,(O) Soul(B-music genre) music(I-music genre) ,(O) R(B-music genre) &(I-music genre) B(I-music genre) ,(O) funk(B-music genre) ,(O) jazz(B-music genre) ,(O) reggae(B-music genre) ,(O) hard(B-music genre) rock(I-music genre) ,(O) Psychedelic(B-music genre) rock(I-music genre) ,(O) Pop(B-music genre) music(I-music genre) ,(O) Folk(B-music genre) music(I-music genre) ,(O) and(O) ballads(B-music genre) .(O)"}}
{"id":"6","dataset":"crossner_music","split":"dev","label_list":["organization","album","musical artist","award","country","location","band","song","event","music genre","musical instrument","person"],"instance":{"id":"6","words":["Hildy","tempts","him","into","taking","a","tour","of","the","city",",","but","all","the","places","he","wants","to","go","(","New","York","Hippodrome",",","the","Forrest","Theatre","to","see","Tobacco","Road",",","the","New","York","City","Aquarium",",","and","the","Woolworth","Building",")","are","either","no","longer","in","existence","or","no","longer","notable","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-location","I-location","I-location","O","O","B-location","I-location","O","O","B-location","I-location","O","O","B-location","I-location","I-location","I-location","O","O","O","B-location","I-location","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, album, musical artist, award, country, location, band, song, event, music genre, musical instrument, person and O.\nSentence: Hildy tempts him into taking a tour of the city , but all the places he wants to go ( New York Hippodrome , the Forrest Theatre to see Tobacco Road , the New York City Aquarium , and the Woolworth Building ) are either no longer in existence or no longer notable .","prompt_labels":"Hildy(B-person) tempts(O) him(O) into(O) taking(O) a(O) tour(O) of(O) the(O) city(O) ,(O) but(O) all(O) the(O) places(O) he(O) wants(O) to(O) go(O) ((O) New(B-location) York(I-location) Hippodrome(I-location) ,(O) the(O) Forrest(B-location) Theatre(I-location) to(O) see(O) Tobacco(B-location) Road(I-location) ,(O) the(O) New(B-location) York(I-location) City(I-location) Aquarium(I-location) ,(O) and(O) the(O) Woolworth(B-location) Building(I-location) )(O) are(O) either(O) no(O) longer(O) in(O) existence(O) or(O) no(O) longer(O) notable(O) .(O)"}}
{"id":"7","dataset":"crossner_music","split":"dev","label_list":["musical instrument","band","music genre","organization","award","country","event","person","song","location","album","musical artist"],"instance":{"id":"7","words":["It","was","Recording","Industry","Association","of","America","triple","platinum","in","America",",","Two","more","singles","from","the","album","-","Policy","of","Truth","and","World","in","My","Eyes","-","were","hits","in","the","UK",",","with","the","former","also","charting","in","the","US","."],"labels":["O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","B-country","O","O","O","O","O","O","O","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","O","O","O","O","B-country","O","O","O","O","O","O","O","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, band, music genre, organization, award, country, event, person, song, location, album, musical artist and O.\nSentence: It was Recording Industry Association of America triple platinum in America , Two more singles from the album - Policy of Truth and World in My Eyes - were hits in the UK , with the former also charting in the US .","prompt_labels":"It(O) was(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) triple(O) platinum(O) in(O) America(B-country) ,(O) Two(O) more(O) singles(O) from(O) the(O) album(O) -(O) Policy(B-song) of(I-song) Truth(I-song) and(O) World(B-song) in(I-song) My(I-song) Eyes(I-song) -(O) were(O) hits(O) in(O) the(O) UK(B-country) ,(O) with(O) the(O) former(O) also(O) charting(O) in(O) the(O) US(B-country) .(O)"}}
{"id":"8","dataset":"crossner_music","split":"dev","label_list":["band","organization","location","country","album","music genre","musical instrument","song","musical artist","award","person","event"],"instance":{"id":"8","words":["The","album","was","certified","seven-times","platinum","in","Australia","by","the","Australian","Recording","Industry","Association","(","ARIA",")",",","five-times","platinum","in","the","UK","by","the","British","Phonographic","Industry","(","BPI",")",",","and","platinum","in","the","US","by","the","Recording","Industry","Association","of","America","(","RIAA",")","."],"labels":["O","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","O","B-organization","O","O","O","O","O","O","B-country","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, organization, location, country, album, music genre, musical instrument, song, musical artist, award, person, event and O.\nSentence: The album was certified seven-times platinum in Australia by the Australian Recording Industry Association ( ARIA ) , five-times platinum in the UK by the British Phonographic Industry ( BPI ) , and platinum in the US by the Recording Industry Association of America ( RIAA ) .","prompt_labels":"The(O) album(O) was(O) certified(O) seven-times(O) platinum(O) in(O) Australia(B-country) by(O) the(O) Australian(B-organization) Recording(I-organization) Industry(I-organization) Association(I-organization) ((O) ARIA(B-organization) )(O) ,(O) five-times(O) platinum(O) in(O) the(O) UK(B-country) by(O) the(O) British(B-organization) Phonographic(I-organization) Industry(I-organization) ((O) BPI(B-organization) )(O) ,(O) and(O) platinum(O) in(O) the(O) US(B-country) by(O) the(O) Recording(B-organization) Industry(I-organization) Association(I-organization) of(I-organization) America(I-organization) ((O) RIAA(B-organization) )(O) .(O)"}}
{"id":"9","dataset":"crossner_music","split":"dev","label_list":["band","location","organization","country","album","song","person","music genre","musical artist","event","award","musical instrument"],"instance":{"id":"9","words":["Ernest","Jennings","Ford","(","February","13",",","1919","-","October","17",",","1991",")",",","known","professionally","as","Tennessee","Ernie","Ford",",","was","an","American","singer","and","television","host","who","enjoyed","success","in","the","Country","music",",","Pop","music",",","and","Gospel","music","musical","genres","."],"labels":["B-musical artist","I-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","O","B-music genre","I-music genre","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, location, organization, country, album, song, person, music genre, musical artist, event, award, musical instrument and O.\nSentence: Ernest Jennings Ford ( February 13 , 1919 - October 17 , 1991 ) , known professionally as Tennessee Ernie Ford , was an American singer and television host who enjoyed success in the Country music , Pop music , and Gospel music musical genres .","prompt_labels":"Ernest(B-musical artist) Jennings(I-musical artist) Ford(I-musical artist) ((O) February(O) 13(O) ,(O) 1919(O) -(O) October(O) 17(O) ,(O) 1991(O) )(O) ,(O) known(O) professionally(O) as(O) Tennessee(B-musical artist) Ernie(I-musical artist) Ford(I-musical artist) ,(O) was(O) an(O) American(O) singer(O) and(O) television(O) host(O) who(O) enjoyed(O) success(O) in(O) the(O) Country(B-music genre) music(I-music genre) ,(O) Pop(B-music genre) music(I-music genre) ,(O) and(O) Gospel(B-music genre) music(I-music genre) musical(O) genres(O) .(O)"}}
{"id":"10","dataset":"crossner_music","split":"dev","label_list":["music genre","album","song","organization","award","event","musical instrument","person","country","band","location","musical artist"],"instance":{"id":"10","words":["South","Africa","'s","Cape","Town","Opera","has","frequently","performed","Porgy","and","Bess","abroad",",","most","notably","with","the","Welsh","National","Opera",",","NorrlandsOperan",",","Deutsche","Oper","Berlin","and","at","the","Wales","Millennium","Centre",",","Royal","Festival","Hall","and","Edinburgh","Festival","Theatre","."],"labels":["B-country","I-country","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","B-organization","O","B-organization","I-organization","I-organization","O","O","O","B-location","I-location","I-location","O","B-location","I-location","I-location","O","B-location","I-location","I-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, album, song, organization, award, event, musical instrument, person, country, band, location, musical artist and O.\nSentence: South Africa 's Cape Town Opera has frequently performed Porgy and Bess abroad , most notably with the Welsh National Opera , NorrlandsOperan , Deutsche Oper Berlin and at the Wales Millennium Centre , Royal Festival Hall and Edinburgh Festival Theatre .","prompt_labels":"South(B-country) Africa(I-country) 's(O) Cape(B-organization) Town(I-organization) Opera(I-organization) has(O) frequently(O) performed(O) Porgy(O) and(O) Bess(O) abroad(O) ,(O) most(O) notably(O) with(O) the(O) Welsh(B-organization) National(I-organization) Opera(I-organization) ,(O) NorrlandsOperan(B-organization) ,(O) Deutsche(B-organization) Oper(I-organization) Berlin(I-organization) and(O) at(O) the(O) Wales(B-location) Millennium(I-location) Centre(I-location) ,(O) Royal(B-location) Festival(I-location) Hall(I-location) and(O) Edinburgh(B-location) Festival(I-location) Theatre(I-location) .(O)"}}
{"id":"11","dataset":"crossner_music","split":"dev","label_list":["musical instrument","album","music genre","organization","person","song","musical artist","location","event","country","band","award"],"instance":{"id":"11","words":["Some","of","his","most","celebrated","designs","adorned","the","sleeves","of","albums","such","as","Midnight","Blue",",","Out","to","Lunch","!",",","Unity",",","Somethin","'","Else",",","Let","Freedom","Ring",",","Hub-Tones",",","No","Room","for","Squares",",","Cool","Struttin","'",",","and","The","Sidewinder","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-album","I-album","O","B-album","I-album","I-album","I-album","O","B-album","O","B-album","I-album","I-album","O","B-album","I-album","I-album","O","B-album","O","B-album","I-album","I-album","I-album","O","B-album","I-album","I-album","O","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, album, music genre, organization, person, song, musical artist, location, event, country, band, award and O.\nSentence: Some of his most celebrated designs adorned the sleeves of albums such as Midnight Blue , Out to Lunch ! , Unity , Somethin ' Else , Let Freedom Ring , Hub-Tones , No Room for Squares , Cool Struttin ' , and The Sidewinder .","prompt_labels":"Some(O) of(O) his(O) most(O) celebrated(O) designs(O) adorned(O) the(O) sleeves(O) of(O) albums(O) such(O) as(O) Midnight(B-album) Blue(I-album) ,(O) Out(B-album) to(I-album) Lunch(I-album) !(I-album) ,(O) Unity(B-album) ,(O) Somethin(B-album) '(I-album) Else(I-album) ,(O) Let(B-album) Freedom(I-album) Ring(I-album) ,(O) Hub-Tones(B-album) ,(O) No(B-album) Room(I-album) for(I-album) Squares(I-album) ,(O) Cool(B-album) Struttin(I-album) '(I-album) ,(O) and(O) The(B-album) Sidewinder(I-album) .(O)"}}
{"id":"12","dataset":"crossner_music","split":"dev","label_list":["music genre","album","organization","country","person","event","musical artist","band","musical instrument","award","location","song"],"instance":{"id":"12","words":["Pop","'s","music","has","encompassed","a","number","of","styles","over","the","course","of","his","career",",","including","garage","rock",",","punk","rock",",","hard","rock",",","Heavy","metal","music",",","art","rock",",","New","wave","music",",","jazz",",","blues",",","and","Electronic","music","."],"labels":["B-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","I-music genre","O","B-music genre","I-music genre","I-music genre","O","B-music genre","O","B-music genre","O","O","B-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: music genre, album, organization, country, person, event, musical artist, band, musical instrument, award, location, song and O.\nSentence: Pop 's music has encompassed a number of styles over the course of his career , including garage rock , punk rock , hard rock , Heavy metal music , art rock , New wave music , jazz , blues , and Electronic music .","prompt_labels":"Pop(B-music genre) 's(O) music(O) has(O) encompassed(O) a(O) number(O) of(O) styles(O) over(O) the(O) course(O) of(O) his(O) career(O) ,(O) including(O) garage(B-music genre) rock(I-music genre) ,(O) punk(B-music genre) rock(I-music genre) ,(O) hard(B-music genre) rock(I-music genre) ,(O) Heavy(B-music genre) metal(I-music genre) music(I-music genre) ,(O) art(B-music genre) rock(I-music genre) ,(O) New(B-music genre) wave(I-music genre) music(I-music genre) ,(O) jazz(B-music genre) ,(O) blues(B-music genre) ,(O) and(O) Electronic(B-music genre) music(I-music genre) .(O)"}}
{"id":"13","dataset":"crossner_music","split":"dev","label_list":["organization","song","location","musical artist","award","country","album","music genre","musical instrument","band","person","event"],"instance":{"id":"13","words":["Although","his","bandmate","Martin","Gore","continues","to","be","the","main","songwriter","for","Depeche","Mode",",","Gahan","has","contributed","a","number","of","songs","to","the","albums","Playing","the","Angel","(","2005",")",",","Sounds","of","the","Universe","(","2009",")",",","Delta","Machine","(","2013",")","and","Spirit","(","2017",")","."],"labels":["O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","B-band","I-band","O","B-musical artist","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","O","B-album","I-album","I-album","I-album","O","O","O","O","B-album","I-album","O","O","O","O","B-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, song, location, musical artist, award, country, album, music genre, musical instrument, band, person, event and O.\nSentence: Although his bandmate Martin Gore continues to be the main songwriter for Depeche Mode , Gahan has contributed a number of songs to the albums Playing the Angel ( 2005 ) , Sounds of the Universe ( 2009 ) , Delta Machine ( 2013 ) and Spirit ( 2017 ) .","prompt_labels":"Although(O) his(O) bandmate(O) Martin(B-musical artist) Gore(I-musical artist) continues(O) to(O) be(O) the(O) main(O) songwriter(O) for(O) Depeche(B-band) Mode(I-band) ,(O) Gahan(B-musical artist) has(O) contributed(O) a(O) number(O) of(O) songs(O) to(O) the(O) albums(O) Playing(B-album) the(I-album) Angel(I-album) ((O) 2005(O) )(O) ,(O) Sounds(B-album) of(I-album) the(I-album) Universe(I-album) ((O) 2009(O) )(O) ,(O) Delta(B-album) Machine(I-album) ((O) 2013(O) )(O) and(O) Spirit(B-album) ((O) 2017(O) )(O) .(O)"}}
{"id":"14","dataset":"crossner_music","split":"dev","label_list":["musical instrument","song","person","country","band","music genre","musical artist","organization","album","award","location","event"],"instance":{"id":"14","words":["Phoenix","has","long","been","a","social","activist",",","lending","his","support","to","a","number","of","charities","and","humanitarian","organizations",",","such","as","Amnesty","International",",","The","Art","of","Elysium",",","HEART",",","and","the","Peace","Alliance","(","which","campaigns","for","a","United","States","Department","of","Peace",")","."],"labels":["B-band","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-organization","I-organization","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","O","B-organization","I-organization","O","O","O","O","O","B-country","I-country","B-organization","I-organization","I-organization","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, song, person, country, band, music genre, musical artist, organization, album, award, location, event and O.\nSentence: Phoenix has long been a social activist , lending his support to a number of charities and humanitarian organizations , such as Amnesty International , The Art of Elysium , HEART , and the Peace Alliance ( which campaigns for a United States Department of Peace ) .","prompt_labels":"Phoenix(B-band) has(O) long(O) been(O) a(O) social(O) activist(O) ,(O) lending(O) his(O) support(O) to(O) a(O) number(O) of(O) charities(O) and(O) humanitarian(O) organizations(O) ,(O) such(O) as(O) Amnesty(B-organization) International(I-organization) ,(O) The(B-organization) Art(I-organization) of(I-organization) Elysium(I-organization) ,(O) HEART(B-organization) ,(O) and(O) the(O) Peace(B-organization) Alliance(I-organization) ((O) which(O) campaigns(O) for(O) a(O) United(B-country) States(I-country) Department(B-organization) of(I-organization) Peace(I-organization) )(O) .(O)"}}
{"id":"15","dataset":"crossner_music","split":"dev","label_list":["event","musical instrument","award","person","album","organization","song","location","music genre","country","band","musical artist"],"instance":{"id":"15","words":["The","best-selling","album","in","the","band","'s","catalog",",","I","Against","I","is","an","album","that","mixes","American","hardcore","punk","with","funk",",","Soul","music",",","reggae","and","Heavy","metal","music","."],"labels":["O","O","O","O","O","O","O","O","O","O","B-album","O","O","O","O","O","O","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","O","B-music genre","O","B-music genre","I-music genre","I-music genre","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, musical instrument, award, person, album, organization, song, location, music genre, country, band, musical artist and O.\nSentence: The best-selling album in the band 's catalog , I Against I is an album that mixes American hardcore punk with funk , Soul music , reggae and Heavy metal music .","prompt_labels":"The(O) best-selling(O) album(O) in(O) the(O) band(O) 's(O) catalog(O) ,(O) I(O) Against(B-album) I(O) is(O) an(O) album(O) that(O) mixes(O) American(O) hardcore(B-music genre) punk(I-music genre) with(O) funk(B-music genre) ,(O) Soul(B-music genre) music(I-music genre) ,(O) reggae(B-music genre) and(O) Heavy(B-music genre) metal(I-music genre) music(I-music genre) .(O)"}}
{"id":"16","dataset":"crossner_music","split":"dev","label_list":["location","musical instrument","country","album","song","organization","musical artist","band","person","music genre","award","event"],"instance":{"id":"16","words":["Since","the","introduction","of","the","50","/","50","voting","system","in","2009",",","the","juries","and","the","voters","have","disagreed","on","the","winner","on","five","occasions",",","in","Eurovision","Song","Contest","2011",",","Eurovision","Song","Contest","2015",",","Eurovision","Song","Contest","2016",",","Eurovision","Song","Contest","2018","and","Eurovision","Song","Contest","2019","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O","B-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, musical instrument, country, album, song, organization, musical artist, band, person, music genre, award, event and O.\nSentence: Since the introduction of the 50 / 50 voting system in 2009 , the juries and the voters have disagreed on the winner on five occasions , in Eurovision Song Contest 2011 , Eurovision Song Contest 2015 , Eurovision Song Contest 2016 , Eurovision Song Contest 2018 and Eurovision Song Contest 2019 .","prompt_labels":"Since(O) the(O) introduction(O) of(O) the(O) 50(O) /(O) 50(O) voting(O) system(O) in(O) 2009(O) ,(O) the(O) juries(O) and(O) the(O) voters(O) have(O) disagreed(O) on(O) the(O) winner(O) on(O) five(O) occasions(O) ,(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2011(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2015(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2016(I-event) ,(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2018(I-event) and(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2019(I-event) .(O)"}}
{"id":"17","dataset":"crossner_music","split":"dev","label_list":["musical instrument","country","event","location","award","band","musical artist","person","song","album","organization","music genre"],"instance":{"id":"17","words":["Artists","from","outside","California","who","were","associated","with","early","alternative","country","included","singer-songwriters","such","as","Lucinda","Williams",",","Lyle","Lovett","and","Steve","Earle",",","the","Nashville","country","rock","band","Jason","and","the","Scorchers","and","the","British","post-punk","band","The","Mekons","."],"labels":["O","O","O","B-location","O","O","O","O","O","B-music genre","I-music genre","O","O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","O","O","O","O","B-band","I-band","I-band","I-band","O","O","O","B-music genre","O","B-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, country, event, location, award, band, musical artist, person, song, album, organization, music genre and O.\nSentence: Artists from outside California who were associated with early alternative country included singer-songwriters such as Lucinda Williams , Lyle Lovett and Steve Earle , the Nashville country rock band Jason and the Scorchers and the British post-punk band The Mekons .","prompt_labels":"Artists(O) from(O) outside(O) California(B-location) who(O) were(O) associated(O) with(O) early(O) alternative(B-music genre) country(I-music genre) included(O) singer-songwriters(O) such(O) as(O) Lucinda(B-musical artist) Williams(I-musical artist) ,(O) Lyle(B-musical artist) Lovett(I-musical artist) and(O) Steve(B-musical artist) Earle(I-musical artist) ,(O) the(O) Nashville(O) country(O) rock(O) band(O) Jason(B-band) and(I-band) the(I-band) Scorchers(I-band) and(O) the(O) British(O) post-punk(B-music genre) band(O) The(B-band) Mekons(I-band) .(O)"}}
{"id":"18","dataset":"crossner_music","split":"dev","label_list":["country","person","location","band","song","event","album","organization","music genre","award","musical artist","musical instrument"],"instance":{"id":"18","words":["Andrews","has","won","an","Academy","Award",",","a","BAFTA",",","five","Golden","Globes",",","three","Grammy","Award",",","two","Emmy","Award",",","the","AFI","Life","Achievement","Award",",","the","Screen","Actors","Guild","Life","Achievement","Award",",","the","Kennedy","Center","Honors","Award",",","and","the","Disney","Legends","Award","."],"labels":["B-person","O","O","O","B-award","I-award","O","O","B-award","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, location, band, song, event, album, organization, music genre, award, musical artist, musical instrument and O.\nSentence: Andrews has won an Academy Award , a BAFTA , five Golden Globes , three Grammy Award , two Emmy Award , the AFI Life Achievement Award , the Screen Actors Guild Life Achievement Award , the Kennedy Center Honors Award , and the Disney Legends Award .","prompt_labels":"Andrews(B-person) has(O) won(O) an(O) Academy(B-award) Award(I-award) ,(O) a(O) BAFTA(B-award) ,(O) five(O) Golden(B-award) Globes(I-award) ,(O) three(O) Grammy(B-award) Award(I-award) ,(O) two(O) Emmy(B-award) Award(I-award) ,(O) the(O) AFI(B-award) Life(I-award) Achievement(I-award) Award(I-award) ,(O) the(O) Screen(B-award) Actors(I-award) Guild(I-award) Life(I-award) Achievement(I-award) Award(I-award) ,(O) the(O) Kennedy(B-award) Center(I-award) Honors(I-award) Award(I-award) ,(O) and(O) the(O) Disney(B-award) Legends(I-award) Award(I-award) .(O)"}}
{"id":"19","dataset":"crossner_music","split":"dev","label_list":["organization","musical instrument","music genre","location","musical artist","band","song","person","country","event","album","award"],"instance":{"id":"19","words":["The","film","was","nominated","for","the","Academy","Awards","for","Academy","Award","for","Best","Picture",",","as","well","as","Academy","Award","for","Best","Production","Design","(","Carroll","Clark","and","Van","Nest","Polglase",")",",","Academy","Award","for","Best","Original","Song","(","Irving","Berlin","for","Cheek","to","Cheek",")",",","and","Dance","Direction","(","Hermes","Pan","for","Piccolino","and","Top","Hat",")","."],"labels":["O","O","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-person","I-person","O","B-person","I-person","I-person","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-musical artist","I-musical artist","O","B-song","I-song","I-song","O","O","O","B-award","I-award","O","B-person","I-person","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, musical instrument, music genre, location, musical artist, band, song, person, country, event, album, award and O.\nSentence: The film was nominated for the Academy Awards for Academy Award for Best Picture , as well as Academy Award for Best Production Design ( Carroll Clark and Van Nest Polglase ) , Academy Award for Best Original Song ( Irving Berlin for Cheek to Cheek ) , and Dance Direction ( Hermes Pan for Piccolino and Top Hat ) .","prompt_labels":"The(O) film(O) was(O) nominated(O) for(O) the(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) ,(O) as(O) well(O) as(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) ((O) Carroll(B-person) Clark(I-person) and(O) Van(B-person) Nest(I-person) Polglase(I-person) )(O) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) ((O) Irving(B-musical artist) Berlin(I-musical artist) for(O) Cheek(B-song) to(I-song) Cheek(I-song) )(O) ,(O) and(O) Dance(B-award) Direction(I-award) ((O) Hermes(B-person) Pan(I-person) for(O) Piccolino(O) and(O) Top(O) Hat(O) )(O) .(O)"}}
{"id":"20","dataset":"crossner_music","split":"dev","label_list":["organization","song","band","location","album","person","musical instrument","country","music genre","event","musical artist","award"],"instance":{"id":"20","words":["It","received","14","nominations","at","the","89th","Academy","Awards",",","tying","the","record","for","most","nominations","with","All","About","Eve","(","1950",")","and","Titanic","(","1997",")",",","and","won","the","awards","for","Academy","Award","for","Best","Director",",","Academy","Award","for","Best","Actress",",","Academy","Award","for","Best","Cinematography",",","Academy","Award","for","Best","Original","Score",",","Academy","Award","for","Best","Original","Song",",","and","Academy","Award","for","Best","Production","Design","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, song, band, location, album, person, musical instrument, country, music genre, event, musical artist, award and O.\nSentence: It received 14 nominations at the 89th Academy Awards , tying the record for most nominations with All About Eve ( 1950 ) and Titanic ( 1997 ) , and won the awards for Academy Award for Best Director , Academy Award for Best Actress , Academy Award for Best Cinematography , Academy Award for Best Original Score , Academy Award for Best Original Song , and Academy Award for Best Production Design .","prompt_labels":"It(O) received(O) 14(O) nominations(O) at(O) the(O) 89th(B-award) Academy(I-award) Awards(I-award) ,(O) tying(O) the(O) record(O) for(O) most(O) nominations(O) with(O) All(O) About(O) Eve(O) ((O) 1950(O) )(O) and(O) Titanic(O) ((O) 1997(O) )(O) ,(O) and(O) won(O) the(O) awards(O) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Cinematography(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) ,(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) .(O)"}}
{"id":"21","dataset":"crossner_music","split":"dev","label_list":["band","album","music genre","location","musical artist","song","person","country","event","organization","musical instrument","award"],"instance":{"id":"21","words":["Western","music","artists","such","as","Michael","Martin","Murphey",",","and","artists","within","the","aforementioned","styles","and","genres",",","have","seen","continued","success","throughout","their","respective","fields",",","including","the","likes","of","The","Great","Divide",",","Lorenzo","Antonio",",","Sparx",",","Pat","Green",",","and","Jack","Ingram","."],"labels":["B-music genre","I-music genre","O","O","O","B-musical artist","I-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","O","B-musical artist","I-musical artist","O","B-band","O","B-musical artist","I-musical artist","O","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, album, music genre, location, musical artist, song, person, country, event, organization, musical instrument, award and O.\nSentence: Western music artists such as Michael Martin Murphey , and artists within the aforementioned styles and genres , have seen continued success throughout their respective fields , including the likes of The Great Divide , Lorenzo Antonio , Sparx , Pat Green , and Jack Ingram .","prompt_labels":"Western(B-music genre) music(I-music genre) artists(O) such(O) as(O) Michael(B-musical artist) Martin(I-musical artist) Murphey(I-musical artist) ,(O) and(O) artists(O) within(O) the(O) aforementioned(O) styles(O) and(O) genres(O) ,(O) have(O) seen(O) continued(O) success(O) throughout(O) their(O) respective(O) fields(O) ,(O) including(O) the(O) likes(O) of(O) The(B-band) Great(I-band) Divide(I-band) ,(O) Lorenzo(B-musical artist) Antonio(I-musical artist) ,(O) Sparx(B-band) ,(O) Pat(B-musical artist) Green(I-musical artist) ,(O) and(O) Jack(B-musical artist) Ingram(I-musical artist) .(O)"}}
{"id":"22","dataset":"crossner_music","split":"dev","label_list":["award","music genre","musical instrument","organization","event","country","album","person","band","location","song","musical artist"],"instance":{"id":"22","words":["The","band","have","received","seven","Grammy","Award","s",",","four","Brit","Awards",",","an","Academy","Award","(","for","Best","Original","Song","Score","for","the","1970","film","Let","It","Be",")","and","fifteen","Ivor","Novello","Awards","."],"labels":["O","O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","O","O","B-award","I-award","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, music genre, musical instrument, organization, event, country, album, person, band, location, song, musical artist and O.\nSentence: The band have received seven Grammy Award s , four Brit Awards , an Academy Award ( for Best Original Song Score for the 1970 film Let It Be ) and fifteen Ivor Novello Awards .","prompt_labels":"The(O) band(O) have(O) received(O) seven(O) Grammy(B-award) Award(I-award) s(O) ,(O) four(O) Brit(B-award) Awards(I-award) ,(O) an(O) Academy(B-award) Award(I-award) ((O) for(O) Best(B-award) Original(I-award) Song(I-award) Score(I-award) for(O) the(O) 1970(O) film(O) Let(O) It(O) Be(O) )(O) and(O) fifteen(O) Ivor(B-award) Novello(I-award) Awards(I-award) .(O)"}}
{"id":"23","dataset":"crossner_music","split":"dev","label_list":["person","location","album","song","band","country","award","organization","musical artist","event","musical instrument","music genre"],"instance":{"id":"23","words":["She","rose","to","stardom","in","the","romantic","comedy","Roman","Holiday","(","1953",")",",","alongside","Gregory","Peck",",","for","which","she","was","the","first","actress","to","win","an","Academy","Awards",",","a","Golden","Globe","Awards",",","and","a","British","Academy","Film","Awards","for","a","single","performance","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","B-award","I-award","I-award","O","O","O","B-award","I-award","I-award","I-award","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, album, song, band, country, award, organization, musical artist, event, musical instrument, music genre and O.\nSentence: She rose to stardom in the romantic comedy Roman Holiday ( 1953 ) , alongside Gregory Peck , for which she was the first actress to win an Academy Awards , a Golden Globe Awards , and a British Academy Film Awards for a single performance .","prompt_labels":"She(O) rose(O) to(O) stardom(O) in(O) the(O) romantic(O) comedy(O) Roman(O) Holiday(O) ((O) 1953(O) )(O) ,(O) alongside(O) Gregory(B-person) Peck(I-person) ,(O) for(O) which(O) she(O) was(O) the(O) first(O) actress(O) to(O) win(O) an(O) Academy(B-award) Awards(I-award) ,(O) a(O) Golden(B-award) Globe(I-award) Awards(I-award) ,(O) and(O) a(O) British(B-award) Academy(I-award) Film(I-award) Awards(I-award) for(O) a(O) single(O) performance(O) .(O)"}}
{"id":"24","dataset":"crossner_music","split":"dev","label_list":["band","country","musical instrument","musical artist","location","album","award","person","organization","music genre","song","event"],"instance":{"id":"24","words":["Within","the","mainline","United","States","drum","and","bugle","corps","can","trace","their","origins","to","the","many","Veterans","of","Foreign","Wars","(","VFW",")","and","American","Legion","(","AL",")","meeting","halls",",","where","First","World","War","and","Spanish-American","War","veterans","met","and","formed","musical","ensemble","s","to","entertain","their","communities","."],"labels":["O","O","O","B-country","I-country","B-event","I-event","I-event","I-event","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-organization","O","O","B-organization","I-organization","O","B-organization","O","O","O","O","O","B-event","I-event","I-event","O","B-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, country, musical instrument, musical artist, location, album, award, person, organization, music genre, song, event and O.\nSentence: Within the mainline United States drum and bugle corps can trace their origins to the many Veterans of Foreign Wars ( VFW ) and American Legion ( AL ) meeting halls , where First World War and Spanish-American War veterans met and formed musical ensemble s to entertain their communities .","prompt_labels":"Within(O) the(O) mainline(O) United(B-country) States(I-country) drum(B-event) and(I-event) bugle(I-event) corps(I-event) can(O) trace(O) their(O) origins(O) to(O) the(O) many(O) Veterans(B-organization) of(I-organization) Foreign(I-organization) Wars(I-organization) ((O) VFW(B-organization) )(O) and(O) American(B-organization) Legion(I-organization) ((O) AL(B-organization) )(O) meeting(O) halls(O) ,(O) where(O) First(B-event) World(I-event) War(I-event) and(O) Spanish-American(B-event) War(I-event) veterans(O) met(O) and(O) formed(O) musical(O) ensemble(O) s(O) to(O) entertain(O) their(O) communities(O) .(O)"}}
{"id":"25","dataset":"crossner_music","split":"dev","label_list":["person","location","musical artist","organization","song","award","band","musical instrument","country","music genre","album","event"],"instance":{"id":"25","words":["Western","music","'s","influence","would","continue","to","grow","within","the","country","music","sphere",",","Western","musicians","like","Michael","Martin","Murphey",",","New","Mexico","music","artists","Al","Hurricane","and","Antonia","Apodaca",",","Tejano","music","performer","Little","Joe",",","and","even","folk","revivalist","John","Denver",",","all","first","rose","to","prominence","during","this","time","."],"labels":["B-music genre","I-music genre","O","O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","B-music genre","O","O","B-musical artist","I-musical artist","I-musical artist","O","B-music genre","I-music genre","I-music genre","O","B-musical artist","I-musical artist","O","B-person","I-person","O","B-music genre","I-music genre","O","B-musical artist","I-musical artist","O","O","O","O","O","B-musical artist","I-musical artist","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, location, musical artist, organization, song, award, band, musical instrument, country, music genre, album, event and O.\nSentence: Western music 's influence would continue to grow within the country music sphere , Western musicians like Michael Martin Murphey , New Mexico music artists Al Hurricane and Antonia Apodaca , Tejano music performer Little Joe , and even folk revivalist John Denver , all first rose to prominence during this time .","prompt_labels":"Western(B-music genre) music(I-music genre) 's(O) influence(O) would(O) continue(O) to(O) grow(O) within(O) the(O) country(B-music genre) music(I-music genre) sphere(O) ,(O) Western(B-music genre) musicians(O) like(O) Michael(B-musical artist) Martin(I-musical artist) Murphey(I-musical artist) ,(O) New(B-music genre) Mexico(I-music genre) music(I-music genre) artists(O) Al(B-musical artist) Hurricane(I-musical artist) and(O) Antonia(B-person) Apodaca(I-person) ,(O) Tejano(B-music genre) music(I-music genre) performer(O) Little(B-musical artist) Joe(I-musical artist) ,(O) and(O) even(O) folk(O) revivalist(O) John(B-musical artist) Denver(I-musical artist) ,(O) all(O) first(O) rose(O) to(O) prominence(O) during(O) this(O) time(O) .(O)"}}
{"id":"26","dataset":"crossner_music","split":"dev","label_list":["musical artist","event","musical instrument","organization","song","music genre","award","country","band","person","location","album"],"instance":{"id":"26","words":["Special","guests","were","Pete","Seeger",",","Bonnie","Raitt",",","David","Bromberg","and","Jerry","Jeff","Walker","."],"labels":["O","O","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, event, musical instrument, organization, song, music genre, award, country, band, person, location, album and O.\nSentence: Special guests were Pete Seeger , Bonnie Raitt , David Bromberg and Jerry Jeff Walker .","prompt_labels":"Special(O) guests(O) were(O) Pete(B-musical artist) Seeger(I-musical artist) ,(O) Bonnie(B-musical artist) Raitt(I-musical artist) ,(O) David(B-musical artist) Bromberg(I-musical artist) and(O) Jerry(B-musical artist) Jeff(I-musical artist) Walker(I-musical artist) .(O)"}}
{"id":"27","dataset":"crossner_music","split":"dev","label_list":["location","music genre","song","country","organization","award","event","musical artist","person","album","musical instrument","band"],"instance":{"id":"27","words":["Under","the","current","voting","system",",","in","place","since","2016",",","the","highest-scoring","winner","is","Salvador","Sobral","of","Portugal","who","won","the","Eurovision","Song","Contest","2017","in","Kiev",",","Ukraine",",","with","758","points",";","under","the","previous","system",",","the","highest-scoring","winner","was","Alexander","Rybak","of","Norway","with","387","points","in","Eurovision","Song","Contest","2009","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-country","O","O","O","B-event","I-event","I-event","I-event","O","B-location","O","B-country","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-musical artist","I-musical artist","O","B-country","O","O","O","O","B-event","I-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, song, country, organization, award, event, musical artist, person, album, musical instrument, band and O.\nSentence: Under the current voting system , in place since 2016 , the highest-scoring winner is Salvador Sobral of Portugal who won the Eurovision Song Contest 2017 in Kiev , Ukraine , with 758 points ; under the previous system , the highest-scoring winner was Alexander Rybak of Norway with 387 points in Eurovision Song Contest 2009 .","prompt_labels":"Under(O) the(O) current(O) voting(O) system(O) ,(O) in(O) place(O) since(O) 2016(O) ,(O) the(O) highest-scoring(O) winner(O) is(O) Salvador(B-musical artist) Sobral(I-musical artist) of(O) Portugal(B-country) who(O) won(O) the(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2017(I-event) in(O) Kiev(B-location) ,(O) Ukraine(B-country) ,(O) with(O) 758(O) points(O) ;(O) under(O) the(O) previous(O) system(O) ,(O) the(O) highest-scoring(O) winner(O) was(O) Alexander(B-musical artist) Rybak(I-musical artist) of(O) Norway(B-country) with(O) 387(O) points(O) in(O) Eurovision(B-event) Song(I-event) Contest(I-event) 2009(I-event) .(O)"}}
{"id":"28","dataset":"crossner_music","split":"dev","label_list":["album","band","music genre","country","musical artist","event","song","organization","person","award","location","musical instrument"],"instance":{"id":"28","words":["The","band","'s","biggest","hit","singles","are","Sentimental","ballad","such","as","Easy",",","Three","Times","a","Lady",",","and","Nightshift",";","and","funk","y","dance","hits","which","include","Brick","House",",","Fancy","Dancer",",","Lady","(","You","Bring","Me","Up",")",",","and","Too","Hot","ta","Trot","."],"labels":["O","O","O","O","O","O","O","B-music genre","I-music genre","O","O","B-song","O","B-song","I-song","I-song","I-song","O","O","B-song","O","O","O","O","O","O","O","O","B-song","I-song","O","B-song","I-song","O","B-song","I-song","I-song","I-song","I-song","I-song","I-song","O","O","B-song","I-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, band, music genre, country, musical artist, event, song, organization, person, award, location, musical instrument and O.\nSentence: The band 's biggest hit singles are Sentimental ballad such as Easy , Three Times a Lady , and Nightshift ; and funk y dance hits which include Brick House , Fancy Dancer , Lady ( You Bring Me Up ) , and Too Hot ta Trot .","prompt_labels":"The(O) band(O) 's(O) biggest(O) hit(O) singles(O) are(O) Sentimental(B-music genre) ballad(I-music genre) such(O) as(O) Easy(B-song) ,(O) Three(B-song) Times(I-song) a(I-song) Lady(I-song) ,(O) and(O) Nightshift(B-song) ;(O) and(O) funk(O) y(O) dance(O) hits(O) which(O) include(O) Brick(B-song) House(I-song) ,(O) Fancy(B-song) Dancer(I-song) ,(O) Lady(B-song) ((I-song) You(I-song) Bring(I-song) Me(I-song) Up(I-song) )(I-song) ,(O) and(O) Too(B-song) Hot(I-song) ta(I-song) Trot(I-song) .(O)"}}
{"id":"29","dataset":"crossner_music","split":"dev","label_list":["musical artist","musical instrument","award","person","location","country","album","music genre","event","organization","band","song"],"instance":{"id":"29","words":["In","central","Europe",",","Italo","disco","(","a.k.a.","1980s","Euro","disco",")","and","Euro","house","were","the","predominant","attempts","by","young","musicians","to","have","a","hit","record","in","and","beyond","the","borders","of","their","own","country","."],"labels":["O","B-location","I-location","O","B-music genre","I-music genre","O","O","O","B-music genre","I-music genre","O","O","B-music genre","I-music genre","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical artist, musical instrument, award, person, location, country, album, music genre, event, organization, band, song and O.\nSentence: In central Europe , Italo disco ( a.k.a. 1980s Euro disco ) and Euro house were the predominant attempts by young musicians to have a hit record in and beyond the borders of their own country .","prompt_labels":"In(O) central(B-location) Europe(I-location) ,(O) Italo(B-music genre) disco(I-music genre) ((O) a.k.a.(O) 1980s(O) Euro(B-music genre) disco(I-music genre) )(O) and(O) Euro(B-music genre) house(I-music genre) were(O) the(O) predominant(O) attempts(O) by(O) young(O) musicians(O) to(O) have(O) a(O) hit(O) record(O) in(O) and(O) beyond(O) the(O) borders(O) of(O) their(O) own(O) country(O) .(O)"}}
{"id":"30","dataset":"crossner_music","split":"dev","label_list":["location","music genre","album","band","organization","country","event","person","musical instrument","song","musical artist","award"],"instance":{"id":"30","words":["Some","modern","artists","that","primarily","or","entirely","produce","country","pop","music","include","Kacey","Musgraves",",","Maren","Morris",",","Kelsea","Ballerini",",","Sam","Hunt",",","Kane","Brown",",","Chris","Lane",",","and","Dan","+","Shay","."],"labels":["O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","B-musical artist","I-musical artist","O","O","B-band","I-band","I-band","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, music genre, album, band, organization, country, event, person, musical instrument, song, musical artist, award and O.\nSentence: Some modern artists that primarily or entirely produce country pop music include Kacey Musgraves , Maren Morris , Kelsea Ballerini , Sam Hunt , Kane Brown , Chris Lane , and Dan + Shay .","prompt_labels":"Some(O) modern(O) artists(O) that(O) primarily(O) or(O) entirely(O) produce(O) country(B-music genre) pop(I-music genre) music(I-music genre) include(O) Kacey(B-musical artist) Musgraves(I-musical artist) ,(O) Maren(B-musical artist) Morris(I-musical artist) ,(O) Kelsea(B-musical artist) Ballerini(I-musical artist) ,(O) Sam(B-musical artist) Hunt(I-musical artist) ,(O) Kane(B-musical artist) Brown(I-musical artist) ,(O) Chris(B-musical artist) Lane(I-musical artist) ,(O) and(O) Dan(B-band) +(I-band) Shay(I-band) .(O)"}}
{"id":"31","dataset":"crossner_music","split":"dev","label_list":["band","award","location","album","person","musical artist","country","event","song","organization","music genre","musical instrument"],"instance":{"id":"31","words":["In","the","summer","of","2004",",","Diab",",","having","left","Alam","El","Phan",",","released","his","first","album","with","Rotana","Records",",","Leily","Nahary",",","which","he","followed","up","with","the","hugely","successful","Kammel","Kalamak","(","2005",")",",","and","El","Lilady","(","2007",")","."],"labels":["O","O","O","O","O","O","B-musical artist","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","O","B-organization","I-organization","O","B-album","I-album","O","O","O","O","O","O","O","O","O","B-album","I-album","O","O","O","O","O","B-album","I-album","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, award, location, album, person, musical artist, country, event, song, organization, music genre, musical instrument and O.\nSentence: In the summer of 2004 , Diab , having left Alam El Phan , released his first album with Rotana Records , Leily Nahary , which he followed up with the hugely successful Kammel Kalamak ( 2005 ) , and El Lilady ( 2007 ) .","prompt_labels":"In(O) the(O) summer(O) of(O) 2004(O) ,(O) Diab(B-musical artist) ,(O) having(O) left(O) Alam(B-organization) El(I-organization) Phan(I-organization) ,(O) released(O) his(O) first(O) album(O) with(O) Rotana(B-organization) Records(I-organization) ,(O) Leily(B-album) Nahary(I-album) ,(O) which(O) he(O) followed(O) up(O) with(O) the(O) hugely(O) successful(O) Kammel(B-album) Kalamak(I-album) ((O) 2005(O) )(O) ,(O) and(O) El(B-album) Lilady(I-album) ((O) 2007(O) )(O) .(O)"}}
{"id":"32","dataset":"crossner_music","split":"dev","label_list":["band","country","award","song","organization","location","musical instrument","event","person","album","musical artist","music genre"],"instance":{"id":"32","words":["Four","singles","-","Until","It","Sleeps",",","Hero","of","the","Day",",","Mama","Said",",","and","King","Nothing","-","were","released","as","part","of","the","marketing","campaign","for","the","album","."],"labels":["O","O","O","B-song","I-song","I-song","O","B-song","I-song","I-song","I-song","O","B-song","I-song","O","O","B-song","I-song","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: band, country, award, song, organization, location, musical instrument, event, person, album, musical artist, music genre and O.\nSentence: Four singles - Until It Sleeps , Hero of the Day , Mama Said , and King Nothing - were released as part of the marketing campaign for the album .","prompt_labels":"Four(O) singles(O) -(O) Until(B-song) It(I-song) Sleeps(I-song) ,(O) Hero(B-song) of(I-song) the(I-song) Day(I-song) ,(O) Mama(B-song) Said(I-song) ,(O) and(O) King(B-song) Nothing(I-song) -(O) were(O) released(O) as(O) part(O) of(O) the(O) marketing(O) campaign(O) for(O) the(O) album(O) .(O)"}}
{"id":"33","dataset":"crossner_music","split":"dev","label_list":["country","musical artist","music genre","person","organization","award","song","musical instrument","event","album","location","band"],"instance":{"id":"33","words":["In","2007",",","Standing","on","the","Outside",":","The","Songs","of","Cold","Chisel","was","released",",","featuring","a","collection","of","the","band","'s","songs","as","performed","by","artists","including","The","Living","End",",","Evermore",",","Something","for","Kate",",","Pete","Murray",",","Katie","Noonan",",","You","Am","I",",","Paul","Kelly",",","Alex","Lloyd",",","Thirsty","Merc","and","Ben","Lee",","],"labels":["O","O","O","B-album","I-album","I-album","I-album","I-album","I-album","I-album","I-album","I-album","I-album","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-band","I-band","I-band","O","B-band","O","B-band","I-band","I-band","O","B-band","I-band","O","B-musical artist","I-musical artist","O","B-band","I-band","I-band","O","B-musical artist","I-musical artist","O","B-band","I-band","O","B-band","I-band","O","B-musical artist","I-musical artist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, musical artist, music genre, person, organization, award, song, musical instrument, event, album, location, band and O.\nSentence: In 2007 , Standing on the Outside : The Songs of Cold Chisel was released , featuring a collection of the band 's songs as performed by artists including The Living End , Evermore , Something for Kate , Pete Murray , Katie Noonan , You Am I , Paul Kelly , Alex Lloyd , Thirsty Merc and Ben Lee ,","prompt_labels":"In(O) 2007(O) ,(O) Standing(B-album) on(I-album) the(I-album) Outside(I-album) :(I-album) The(I-album) Songs(I-album) of(I-album) Cold(I-album) Chisel(I-album) was(O) released(O) ,(O) featuring(O) a(O) collection(O) of(O) the(O) band(O) 's(O) songs(O) as(O) performed(O) by(O) artists(O) including(O) The(B-band) Living(I-band) End(I-band) ,(O) Evermore(B-band) ,(O) Something(B-band) for(I-band) Kate(I-band) ,(O) Pete(B-band) Murray(I-band) ,(O) Katie(B-musical artist) Noonan(I-musical artist) ,(O) You(B-band) Am(I-band) I(I-band) ,(O) Paul(B-musical artist) Kelly(I-musical artist) ,(O) Alex(B-band) Lloyd(I-band) ,(O) Thirsty(B-band) Merc(I-band) and(O) Ben(B-musical artist) Lee(I-musical artist) ,(O)"}}
{"id":"34","dataset":"crossner_music","split":"dev","label_list":["person","musical instrument","location","event","musical artist","song","award","organization","music genre","band","country","album"],"instance":{"id":"34","words":["Heard","released","five","albums","for","the","label",";","1981","'s","Stop","the","Dominoes",",","1982","'s","Victims","of","the","Age",";","1983","'s","Eye","of","the","Storm",";","1984","'s","Ashes","and","Light",";","and","1985","'s","Mosaics","."],"labels":["B-musical artist","O","O","O","O","O","O","O","O","O","B-album","I-album","I-album","O","O","O","B-album","I-album","I-album","I-album","O","O","O","B-album","I-album","I-album","I-album","O","O","O","B-album","I-album","I-album","O","O","O","O","B-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, musical instrument, location, event, musical artist, song, award, organization, music genre, band, country, album and O.\nSentence: Heard released five albums for the label ; 1981 's Stop the Dominoes , 1982 's Victims of the Age ; 1983 's Eye of the Storm ; 1984 's Ashes and Light ; and 1985 's Mosaics .","prompt_labels":"Heard(B-musical artist) released(O) five(O) albums(O) for(O) the(O) label(O) ;(O) 1981(O) 's(O) Stop(B-album) the(I-album) Dominoes(I-album) ,(O) 1982(O) 's(O) Victims(B-album) of(I-album) the(I-album) Age(I-album) ;(O) 1983(O) 's(O) Eye(B-album) of(I-album) the(I-album) Storm(I-album) ;(O) 1984(O) 's(O) Ashes(B-album) and(I-album) Light(I-album) ;(O) and(O) 1985(O) 's(O) Mosaics(B-album) .(O)"}}
{"id":"35","dataset":"crossner_music","split":"dev","label_list":["album","song","award","musical instrument","band","music genre","country","musical artist","event","organization","location","person"],"instance":{"id":"35","words":["Construction","commenced","in","1975","and","the","venue","opened","ahead","of","the","1978","Commonwealth","Games","(","hence","its","name",")",",","replacing","the","adjacent","Clarke","Stadium","as","the","Eskimos","home","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","B-location","I-location","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: album, song, award, musical instrument, band, music genre, country, musical artist, event, organization, location, person and O.\nSentence: Construction commenced in 1975 and the venue opened ahead of the 1978 Commonwealth Games ( hence its name ) , replacing the adjacent Clarke Stadium as the Eskimos home .","prompt_labels":"Construction(O) commenced(O) in(O) 1975(O) and(O) the(O) venue(O) opened(O) ahead(O) of(O) the(O) 1978(B-event) Commonwealth(I-event) Games(I-event) ((O) hence(O) its(O) name(O) )(O) ,(O) replacing(O) the(O) adjacent(O) Clarke(B-location) Stadium(I-location) as(O) the(O) Eskimos(O) home(O) .(O)"}}
{"id":"36","dataset":"crossner_music","split":"dev","label_list":["musical instrument","organization","band","music genre","person","musical artist","album","country","award","event","song","location"],"instance":{"id":"36","words":["Rocks","and","Honey","was","released","in","2013","and","features","the","single","Believe","in","Me","which","she","performed","representing","the","United","Kingdom","at","the","Eurovision","Song","Contest","2013","in","Malmö",",","Sweden","."],"labels":["B-album","I-album","I-album","O","O","O","O","O","O","O","O","B-song","I-song","I-song","O","O","O","O","O","B-country","I-country","O","O","B-album","I-album","I-album","I-album","O","B-location","O","B-country","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, organization, band, music genre, person, musical artist, album, country, award, event, song, location and O.\nSentence: Rocks and Honey was released in 2013 and features the single Believe in Me which she performed representing the United Kingdom at the Eurovision Song Contest 2013 in Malmö , Sweden .","prompt_labels":"Rocks(B-album) and(I-album) Honey(I-album) was(O) released(O) in(O) 2013(O) and(O) features(O) the(O) single(O) Believe(B-song) in(I-song) Me(I-song) which(O) she(O) performed(O) representing(O) the(O) United(B-country) Kingdom(I-country) at(O) the(O) Eurovision(B-album) Song(I-album) Contest(I-album) 2013(I-album) in(O) Malmö(B-location) ,(O) Sweden(B-country) .(O)"}}
{"id":"37","dataset":"crossner_music","split":"dev","label_list":["organization","event","person","music genre","album","award","song","country","location","musical artist","musical instrument","band"],"instance":{"id":"37","words":["Several","albums","that","continued","this","style",",","which","had","come","to","be","known","as","technical","thrash","metal",",","were","released","in","1991",",","such","as","Overkill","'s","Horrorscope",",","Heathen","'","s","Victims","of","Deception",",","Dark","Angel","'","s","Time","Does","Not","Heal",",","Sepultura","'s","Arise",",","and","Coroner","'s","Mental","Vortex","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-music genre","I-music genre","I-music genre","O","O","O","O","O","O","O","O","B-band","O","B-album","O","B-band","O","O","B-album","I-album","I-album","O","B-band","I-band","O","O","B-album","I-album","I-album","I-album","O","B-band","O","B-album","O","O","B-band","O","B-album","I-album","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, event, person, music genre, album, award, song, country, location, musical artist, musical instrument, band and O.\nSentence: Several albums that continued this style , which had come to be known as technical thrash metal , were released in 1991 , such as Overkill 's Horrorscope , Heathen ' s Victims of Deception , Dark Angel ' s Time Does Not Heal , Sepultura 's Arise , and Coroner 's Mental Vortex .","prompt_labels":"Several(O) albums(O) that(O) continued(O) this(O) style(O) ,(O) which(O) had(O) come(O) to(O) be(O) known(O) as(O) technical(B-music genre) thrash(I-music genre) metal(I-music genre) ,(O) were(O) released(O) in(O) 1991(O) ,(O) such(O) as(O) Overkill(B-band) 's(O) Horrorscope(B-album) ,(O) Heathen(B-band) '(O) s(O) Victims(B-album) of(I-album) Deception(I-album) ,(O) Dark(B-band) Angel(I-band) '(O) s(O) Time(B-album) Does(I-album) Not(I-album) Heal(I-album) ,(O) Sepultura(B-band) 's(O) Arise(B-album) ,(O) and(O) Coroner(B-band) 's(O) Mental(B-album) Vortex(I-album) .(O)"}}
{"id":"38","dataset":"crossner_music","split":"dev","label_list":["person","award","band","organization","country","event","musical artist","song","music genre","location","album","musical instrument"],"instance":{"id":"38","words":["Burton","'s","work","on","Sweeney","Todd","won","the","National","Board","of","Review","Award","for","Best","Director",",","and","won","an","Academy","Awards","for","Academy","Award","for","Best","Production","Design","."],"labels":["B-person","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","B-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, award, band, organization, country, event, musical artist, song, music genre, location, album, musical instrument and O.\nSentence: Burton 's work on Sweeney Todd won the National Board of Review Award for Best Director , and won an Academy Awards for Academy Award for Best Production Design .","prompt_labels":"Burton(B-person) 's(O) work(O) on(O) Sweeney(O) Todd(O) won(O) the(O) National(B-award) Board(I-award) of(I-award) Review(I-award) Award(I-award) for(I-award) Best(I-award) Director(I-award) ,(O) and(O) won(O) an(O) Academy(B-award) Awards(I-award) for(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Production(I-award) Design(I-award) .(O)"}}
{"id":"39","dataset":"crossner_music","split":"dev","label_list":["musical instrument","album","band","person","event","song","music genre","organization","award","musical artist","location","country"],"instance":{"id":"39","words":["It","received","a","total","of","13","Academy","Awards","nominations",",","including","Academy","Award","for","Best","Picture","-","a","record","for","any","film","released","by","Walt","Disney","Studios","-","and","won","five",":","Academy","Award","for","Best","Actress","for","Andrews",",","Academy","Award","for","Best","Film","Editing",",","Academy","Award","for","Best","Original","Score",",","Academy","Award","for","Best","Visual","Effects",",","and","Academy","Award","for","Best","Original","Song","for","Chim","Chim","Cher-ee","."],"labels":["O","O","O","O","O","O","B-award","I-award","O","O","O","B-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","O","B-person","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","B-song","I-song","I-song","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: musical instrument, album, band, person, event, song, music genre, organization, award, musical artist, location, country and O.\nSentence: It received a total of 13 Academy Awards nominations , including Academy Award for Best Picture - a record for any film released by Walt Disney Studios - and won five : Academy Award for Best Actress for Andrews , Academy Award for Best Film Editing , Academy Award for Best Original Score , Academy Award for Best Visual Effects , and Academy Award for Best Original Song for Chim Chim Cher-ee .","prompt_labels":"It(O) received(O) a(O) total(O) of(O) 13(O) Academy(B-award) Awards(I-award) nominations(O) ,(O) including(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Picture(I-award) -(O) a(O) record(O) for(O) any(O) film(O) released(O) by(O) Walt(B-organization) Disney(I-organization) Studios(I-organization) -(O) and(O) won(O) five(O) :(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Actress(I-award) for(O) Andrews(B-person) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Film(I-award) Editing(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Score(I-award) ,(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Visual(I-award) Effects(I-award) ,(O) and(O) Academy(B-award) Award(I-award) for(I-award) Best(I-award) Original(I-award) Song(I-award) for(O) Chim(B-song) Chim(I-song) Cher-ee(I-song) .(O)"}}
{"id":"0","dataset":"crossner_science","split":"dev","label_list":["academic journal","location","astronomical object","award","chemical element","person","event","scientist","chemical compound","country","protein","theory","organization","university","enzyme","discipline"],"instance":{"id":"0","words":["Between","2006","and","2019",",","ICRANet","has","released","over","1800","scientific","publications","in","refereed","journals","such","as","Physical","Review",",","the","The","Astrophysical","Journal",",","Astronomy","and","Astrophysics","etc","."],"labels":["O","O","O","O","O","B-organization","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","O","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, location, astronomical object, award, chemical element, person, event, scientist, chemical compound, country, protein, theory, organization, university, enzyme, discipline and O.\nSentence: Between 2006 and 2019 , ICRANet has released over 1800 scientific publications in refereed journals such as Physical Review , the The Astrophysical Journal , Astronomy and Astrophysics etc .","prompt_labels":"Between(O) 2006(O) and(O) 2019(O) ,(O) ICRANet(B-organization) has(O) released(O) over(O) 1800(O) scientific(O) publications(O) in(O) refereed(O) journals(O) such(O) as(O) Physical(B-academic journal) Review(I-academic journal) ,(O) the(O) The(B-academic journal) Astrophysical(I-academic journal) Journal(I-academic journal) ,(O) Astronomy(B-academic journal) and(I-academic journal) Astrophysics(I-academic journal) etc(O) .(O)"}}
{"id":"1","dataset":"crossner_science","split":"dev","label_list":["academic journal","location","country","astronomical object","organization","enzyme","university","discipline","award","protein","event","chemical compound","person","theory","chemical element","scientist"],"instance":{"id":"1","words":["Scheele","discovered","organic","acids","Tartaric","acid",",","Oxalic","acid",",","Uric","acid",",","Lactic","acid",",","and","Citric","acid",",","as","well","as","Hydrofluoric","acid",",","hydrocyanic",",","and","Arsenic","acid","acids",".","Richard","Myers",",","(","2003",")","He","preferred","speaking","German","to","Swedish","his","whole","life",",","as","German","was","commonly","spoken","among","Swedish","pharmacists","."],"labels":["B-scientist","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","O","B-chemical compound","I-chemical compound","O","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","O","O","B-chemical compound","I-chemical compound","O","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, location, country, astronomical object, organization, enzyme, university, discipline, award, protein, event, chemical compound, person, theory, chemical element, scientist and O.\nSentence: Scheele discovered organic acids Tartaric acid , Oxalic acid , Uric acid , Lactic acid , and Citric acid , as well as Hydrofluoric acid , hydrocyanic , and Arsenic acid acids . Richard Myers , ( 2003 ) He preferred speaking German to Swedish his whole life , as German was commonly spoken among Swedish pharmacists .","prompt_labels":"Scheele(B-scientist) discovered(O) organic(O) acids(O) Tartaric(B-chemical compound) acid(I-chemical compound) ,(O) Oxalic(B-chemical compound) acid(I-chemical compound) ,(O) Uric(B-chemical compound) acid(I-chemical compound) ,(O) Lactic(B-chemical compound) acid(I-chemical compound) ,(O) and(O) Citric(B-chemical compound) acid(I-chemical compound) ,(O) as(O) well(O) as(O) Hydrofluoric(B-chemical compound) acid(I-chemical compound) ,(O) hydrocyanic(B-chemical compound) ,(O) and(O) Arsenic(B-chemical compound) acid(I-chemical compound) acids(O) .(O) Richard(B-scientist) Myers(I-scientist) ,(O) ((O) 2003(O) )(O) He(O) preferred(O) speaking(O) German(O) to(O) Swedish(O) his(O) whole(O) life(O) ,(O) as(O) German(O) was(O) commonly(O) spoken(O) among(O) Swedish(O) pharmacists(O) .(O)"}}
{"id":"2","dataset":"crossner_science","split":"dev","label_list":["country","theory","scientist","protein","enzyme","discipline","event","person","chemical compound","chemical element","award","astronomical object","academic journal","organization","location","university"],"instance":{"id":"2","words":["Labeled","genomic","DNA","is","extracted","from","nuclei","and","fragmented","by","HaeIII","digestion","and","sonication","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, theory, scientist, protein, enzyme, discipline, event, person, chemical compound, chemical element, award, astronomical object, academic journal, organization, location, university and O.\nSentence: Labeled genomic DNA is extracted from nuclei and fragmented by HaeIII digestion and sonication .","prompt_labels":"Labeled(O) genomic(O) DNA(O) is(O) extracted(O) from(O) nuclei(O) and(O) fragmented(O) by(O) HaeIII(O) digestion(O) and(O) sonication(O) .(O)"}}
{"id":"3","dataset":"crossner_science","split":"dev","label_list":["protein","organization","chemical compound","astronomical object","country","location","award","discipline","person","academic journal","university","scientist","event","chemical element","theory","enzyme"],"instance":{"id":"3","words":["He","attended","the","U.S.","Air","Force","Institute","of","Technology","for","a","year",",","earning","a","bachelor","'s","degree","in","aeromechanics",",","and","received","his","test","pilot","training","at","Edwards","Air","Force","Base","in","California","before","his","assignment","as","a","test","pilot","at","Wright-Patterson","Air","Force","Base","in","Ohio","."],"labels":["O","O","O","B-university","I-university","I-university","I-university","I-university","I-university","O","O","O","O","O","O","O","O","O","O","B-discipline","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-location","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: protein, organization, chemical compound, astronomical object, country, location, award, discipline, person, academic journal, university, scientist, event, chemical element, theory, enzyme and O.\nSentence: He attended the U.S. Air Force Institute of Technology for a year , earning a bachelor 's degree in aeromechanics , and received his test pilot training at Edwards Air Force Base in California before his assignment as a test pilot at Wright-Patterson Air Force Base in Ohio .","prompt_labels":"He(O) attended(O) the(O) U.S.(B-university) Air(I-university) Force(I-university) Institute(I-university) of(I-university) Technology(I-university) for(O) a(O) year(O) ,(O) earning(O) a(O) bachelor(O) 's(O) degree(O) in(O) aeromechanics(B-discipline) ,(O) and(O) received(O) his(O) test(O) pilot(O) training(O) at(O) Edwards(B-organization) Air(I-organization) Force(I-organization) Base(I-organization) in(O) California(B-location) before(O) his(O) assignment(O) as(O) a(O) test(O) pilot(O) at(O) Wright-Patterson(B-organization) Air(I-organization) Force(I-organization) Base(I-organization) in(O) Ohio(B-location) .(O)"}}
{"id":"4","dataset":"crossner_science","split":"dev","label_list":["event","discipline","chemical element","award","protein","scientist","astronomical object","enzyme","academic journal","location","university","organization","theory","chemical compound","person","country"],"instance":{"id":"4","words":["This","binding","results","in","the","activation","of","a","signalling","pathway","which","allows","for","the","transcription","factor","NF-κB","to","enter","the","nucleus","of","the","macrophage","and","initiate","the","transcription","and","eventual","secretion","of","various","cytokines","such","as","Il-8",",","Interleukin-1","family",",","and","TNFα","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-protein","O","B-protein","I-protein","O","O","B-protein","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, discipline, chemical element, award, protein, scientist, astronomical object, enzyme, academic journal, location, university, organization, theory, chemical compound, person, country and O.\nSentence: This binding results in the activation of a signalling pathway which allows for the transcription factor NF-κB to enter the nucleus of the macrophage and initiate the transcription and eventual secretion of various cytokines such as Il-8 , Interleukin-1 family , and TNFα .","prompt_labels":"This(O) binding(O) results(O) in(O) the(O) activation(O) of(O) a(O) signalling(O) pathway(O) which(O) allows(O) for(O) the(O) transcription(O) factor(O) NF-κB(B-protein) to(O) enter(O) the(O) nucleus(O) of(O) the(O) macrophage(O) and(O) initiate(O) the(O) transcription(O) and(O) eventual(O) secretion(O) of(O) various(O) cytokines(O) such(O) as(O) Il-8(B-protein) ,(O) Interleukin-1(B-protein) family(I-protein) ,(O) and(O) TNFα(B-protein) .(O)"}}
{"id":"5","dataset":"crossner_science","split":"dev","label_list":["chemical element","astronomical object","event","person","discipline","country","scientist","theory","chemical compound","academic journal","award","organization","university","location","enzyme","protein"],"instance":{"id":"5","words":["In","addition",",","there","would","probably","have","been","simple","hydride","s","such","as","those","now","found","in","gas","giants","like","Jupiter","and","Saturn",",","notably","water","vapor",",","methane",",","and","ammonia","."],"labels":["O","O","O","O","O","O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","O","O","B-chemical compound","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, astronomical object, event, person, discipline, country, scientist, theory, chemical compound, academic journal, award, organization, university, location, enzyme, protein and O.\nSentence: In addition , there would probably have been simple hydride s such as those now found in gas giants like Jupiter and Saturn , notably water vapor , methane , and ammonia .","prompt_labels":"In(O) addition(O) ,(O) there(O) would(O) probably(O) have(O) been(O) simple(O) hydride(B-chemical compound) s(O) such(O) as(O) those(O) now(O) found(O) in(O) gas(O) giants(O) like(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) ,(O) notably(O) water(B-chemical compound) vapor(I-chemical compound) ,(O) methane(B-chemical compound) ,(O) and(O) ammonia(B-chemical compound) .(O)"}}
{"id":"6","dataset":"crossner_science","split":"dev","label_list":["organization","person","university","theory","scientist","award","event","enzyme","country","chemical element","chemical compound","discipline","astronomical object","protein","location","academic journal"],"instance":{"id":"6","words":["Like","aluminium",",","According","to","the","International","Resource","Panel","'","s","Metal","Stocks","in","Society","report",",","the","global","per","capita","stock","of","copper","in","use","in","society","is","35-55","kg","."],"labels":["O","B-chemical element","O","O","O","O","B-organization","I-organization","I-organization","O","O","B-organization","I-organization","I-organization","I-organization","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, person, university, theory, scientist, award, event, enzyme, country, chemical element, chemical compound, discipline, astronomical object, protein, location, academic journal and O.\nSentence: Like aluminium , According to the International Resource Panel ' s Metal Stocks in Society report , the global per capita stock of copper in use in society is 35-55 kg .","prompt_labels":"Like(O) aluminium(B-chemical element) ,(O) According(O) to(O) the(O) International(B-organization) Resource(I-organization) Panel(I-organization) '(O) s(O) Metal(B-organization) Stocks(I-organization) in(I-organization) Society(I-organization) report(O) ,(O) the(O) global(O) per(O) capita(O) stock(O) of(O) copper(O) in(O) use(O) in(O) society(O) is(O) 35-55(O) kg(O) .(O)"}}
{"id":"7","dataset":"crossner_science","split":"dev","label_list":["chemical element","protein","university","scientist","location","theory","discipline","enzyme","academic journal","country","astronomical object","award","person","organization","event","chemical compound"],"instance":{"id":"7","words":["The","Olympic","golf","course","is","a","new","venue","built","for","the","Golf","at","the","2016","Summer","Olympics","."],"labels":["O","B-location","I-location","I-location","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, protein, university, scientist, location, theory, discipline, enzyme, academic journal, country, astronomical object, award, person, organization, event, chemical compound and O.\nSentence: The Olympic golf course is a new venue built for the Golf at the 2016 Summer Olympics .","prompt_labels":"The(O) Olympic(B-location) golf(I-location) course(I-location) is(O) a(O) new(O) venue(O) built(O) for(O) the(O) Golf(O) at(O) the(O) 2016(B-event) Summer(I-event) Olympics(I-event) .(O)"}}
{"id":"8","dataset":"crossner_science","split":"dev","label_list":["location","discipline","astronomical object","academic journal","university","theory","award","scientist","chemical compound","chemical element","protein","person","event","enzyme","country","organization"],"instance":{"id":"8","words":["Removing","a","TAD","boundary","(","for","example",",","using","CRISPR","to","delete","the","relevant","region","of","the","genome",")","can","allow","new","promoter-enhancer","contacts","to","form","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: location, discipline, astronomical object, academic journal, university, theory, award, scientist, chemical compound, chemical element, protein, person, event, enzyme, country, organization and O.\nSentence: Removing a TAD boundary ( for example , using CRISPR to delete the relevant region of the genome ) can allow new promoter-enhancer contacts to form .","prompt_labels":"Removing(O) a(O) TAD(O) boundary(O) ((O) for(O) example(O) ,(O) using(O) CRISPR(O) to(O) delete(O) the(O) relevant(O) region(O) of(O) the(O) genome(O) )(O) can(O) allow(O) new(O) promoter-enhancer(O) contacts(O) to(O) form(O) .(O)"}}
{"id":"9","dataset":"crossner_science","split":"dev","label_list":["astronomical object","chemical compound","location","discipline","award","protein","enzyme","person","country","theory","academic journal","event","chemical element","scientist","university","organization"],"instance":{"id":"9","words":["The","1982","Commonwealth","Games","in","Brisbane","left","Tasmania","off","the","map","of","Australia","during","the","opening","ceremony",",","as","did","the","designs","of","the","Australian","Swim","Team","uniform","for","the","2014","Commonwealth","Games","."],"labels":["O","B-event","I-event","I-event","O","B-location","O","B-location","O","O","O","O","B-location","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-event","I-event","I-event","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, chemical compound, location, discipline, award, protein, enzyme, person, country, theory, academic journal, event, chemical element, scientist, university, organization and O.\nSentence: The 1982 Commonwealth Games in Brisbane left Tasmania off the map of Australia during the opening ceremony , as did the designs of the Australian Swim Team uniform for the 2014 Commonwealth Games .","prompt_labels":"The(O) 1982(B-event) Commonwealth(I-event) Games(I-event) in(O) Brisbane(B-location) left(O) Tasmania(B-location) off(O) the(O) map(O) of(O) Australia(B-location) during(O) the(O) opening(O) ceremony(O) ,(O) as(O) did(O) the(O) designs(O) of(O) the(O) Australian(O) Swim(O) Team(O) uniform(O) for(O) the(O) 2014(B-event) Commonwealth(I-event) Games(I-event) .(O)"}}
{"id":"10","dataset":"crossner_science","split":"dev","label_list":["chemical compound","location","protein","event","organization","theory","country","scientist","award","enzyme","discipline","chemical element","person","university","academic journal","astronomical object"],"instance":{"id":"10","words":["He","is","currently","Director","of","the","Yale","Center","for","the","Study","of","Globalization","at","Yale","University",",","is","the","Latin","American","co-chair","of","the","Inter-American","Dialogue",",","and","is","on","the","board","of","directors","of","Citigroup","."],"labels":["O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-university","I-university","O","O","O","O","O","O","O","O","B-organization","I-organization","O","O","O","O","O","O","O","O","O","B-organization","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, location, protein, event, organization, theory, country, scientist, award, enzyme, discipline, chemical element, person, university, academic journal, astronomical object and O.\nSentence: He is currently Director of the Yale Center for the Study of Globalization at Yale University , is the Latin American co-chair of the Inter-American Dialogue , and is on the board of directors of Citigroup .","prompt_labels":"He(O) is(O) currently(O) Director(O) of(O) the(O) Yale(B-organization) Center(I-organization) for(I-organization) the(I-organization) Study(I-organization) of(I-organization) Globalization(I-organization) at(O) Yale(B-university) University(I-university) ,(O) is(O) the(O) Latin(O) American(O) co-chair(O) of(O) the(O) Inter-American(B-organization) Dialogue(I-organization) ,(O) and(O) is(O) on(O) the(O) board(O) of(O) directors(O) of(O) Citigroup(B-organization) .(O)"}}
{"id":"11","dataset":"crossner_science","split":"dev","label_list":["person","astronomical object","award","organization","scientist","discipline","enzyme","country","academic journal","protein","event","chemical element","university","chemical compound","location","theory"],"instance":{"id":"11","words":["Saturn","is","usually","depicted","with","a","scythe","or","sickle",",","and","the","planetary","symbol","has","apparently","evolved","from","a","picture","of","this","attribute",",","in","Kamateros","(","12th","century",")","shown","in","a","shape","similar","to","the","letter","eta","η",",","with","the","horizontal","stroke","added","along","with","the","Christianization","of","the","other","symbols","in","the","early","16th","century",",","Saturn","(","U","+","2644",")","."],"labels":["B-astronomical object","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, astronomical object, award, organization, scientist, discipline, enzyme, country, academic journal, protein, event, chemical element, university, chemical compound, location, theory and O.\nSentence: Saturn is usually depicted with a scythe or sickle , and the planetary symbol has apparently evolved from a picture of this attribute , in Kamateros ( 12th century ) shown in a shape similar to the letter eta η , with the horizontal stroke added along with the Christianization of the other symbols in the early 16th century , Saturn ( U + 2644 ) .","prompt_labels":"Saturn(B-astronomical object) is(O) usually(O) depicted(O) with(O) a(O) scythe(O) or(O) sickle(O) ,(O) and(O) the(O) planetary(O) symbol(O) has(O) apparently(O) evolved(O) from(O) a(O) picture(O) of(O) this(O) attribute(O) ,(O) in(O) Kamateros(O) ((O) 12th(O) century(O) )(O) shown(O) in(O) a(O) shape(O) similar(O) to(O) the(O) letter(O) eta(O) η(O) ,(O) with(O) the(O) horizontal(O) stroke(O) added(O) along(O) with(O) the(O) Christianization(O) of(O) the(O) other(O) symbols(O) in(O) the(O) early(O) 16th(O) century(O) ,(O) Saturn(B-astronomical object) ((O) U(O) +(O) 2644(O) )(O) .(O)"}}
{"id":"12","dataset":"crossner_science","split":"dev","label_list":["enzyme","theory","astronomical object","academic journal","organization","person","event","chemical compound","country","scientist","university","location","chemical element","protein","award","discipline"],"instance":{"id":"12","words":["The","traditional","precursor","is","N-Nitroso-N-methylurea",",","but","this","compound","is","itself","somewhat","unstable",",","and","nowadays","compounds","such","as","Methylnitronitrosoguanidine","(","MNNG",")","and","Diazald","(","Diazald",")","are","preferred","."],"labels":["O","O","O","O","B-chemical compound","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","O","B-chemical compound","O","O","B-chemical compound","O","B-chemical compound","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, theory, astronomical object, academic journal, organization, person, event, chemical compound, country, scientist, university, location, chemical element, protein, award, discipline and O.\nSentence: The traditional precursor is N-Nitroso-N-methylurea , but this compound is itself somewhat unstable , and nowadays compounds such as Methylnitronitrosoguanidine ( MNNG ) and Diazald ( Diazald ) are preferred .","prompt_labels":"The(O) traditional(O) precursor(O) is(O) N-Nitroso-N-methylurea(B-chemical compound) ,(O) but(O) this(O) compound(O) is(O) itself(O) somewhat(O) unstable(O) ,(O) and(O) nowadays(O) compounds(O) such(O) as(O) Methylnitronitrosoguanidine(B-chemical compound) ((O) MNNG(B-chemical compound) )(O) and(O) Diazald(B-chemical compound) ((O) Diazald(B-chemical compound) )(O) are(O) preferred(O) .(O)"}}
{"id":"13","dataset":"crossner_science","split":"dev","label_list":["university","chemical element","event","academic journal","country","scientist","location","protein","person","astronomical object","award","organization","discipline","chemical compound","enzyme","theory"],"instance":{"id":"13","words":["In","addition","to","his","steady","research","output",",","Naqvi","has","manifested","his","commitment","to","teaching","by","contributing","to","journals","devoted","to","didactical","aspects","of","science","(","American","Journal","of","Physics",",","European","Journal","of","Physics",",","Journal","of","Chemical","Education",")","."],"labels":["O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: university, chemical element, event, academic journal, country, scientist, location, protein, person, astronomical object, award, organization, discipline, chemical compound, enzyme, theory and O.\nSentence: In addition to his steady research output , Naqvi has manifested his commitment to teaching by contributing to journals devoted to didactical aspects of science ( American Journal of Physics , European Journal of Physics , Journal of Chemical Education ) .","prompt_labels":"In(O) addition(O) to(O) his(O) steady(O) research(O) output(O) ,(O) Naqvi(B-scientist) has(O) manifested(O) his(O) commitment(O) to(O) teaching(O) by(O) contributing(O) to(O) journals(O) devoted(O) to(O) didactical(O) aspects(O) of(O) science(O) ((O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) European(B-academic journal) Journal(I-academic journal) of(I-academic journal) Physics(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Chemical(I-academic journal) Education(I-academic journal) )(O) .(O)"}}
{"id":"14","dataset":"crossner_science","split":"dev","label_list":["country","chemical compound","location","protein","event","academic journal","theory","astronomical object","enzyme","university","discipline","award","organization","person","scientist","chemical element"],"instance":{"id":"14","words":["Most","of","the","outer","irregular","moon","s","of","Jupiter","and","Saturn","also","have","retrograde","orbits",",","as","do","some","of","Uranus","'","s","outer","moons","."],"labels":["O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","O","O","O","O","O","O","O","O","B-astronomical object","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, chemical compound, location, protein, event, academic journal, theory, astronomical object, enzyme, university, discipline, award, organization, person, scientist, chemical element and O.\nSentence: Most of the outer irregular moon s of Jupiter and Saturn also have retrograde orbits , as do some of Uranus ' s outer moons .","prompt_labels":"Most(O) of(O) the(O) outer(O) irregular(O) moon(O) s(O) of(O) Jupiter(B-astronomical object) and(O) Saturn(B-astronomical object) also(O) have(O) retrograde(O) orbits(O) ,(O) as(O) do(O) some(O) of(O) Uranus(B-astronomical object) '(O) s(O) outer(O) moons(O) .(O)"}}
{"id":"15","dataset":"crossner_science","split":"dev","label_list":["award","chemical compound","event","person","organization","chemical element","location","scientist","university","protein","academic journal","astronomical object","country","discipline","enzyme","theory"],"instance":{"id":"15","words":["For","example",",","that","ancestor","had","at","least","7","Pax","genes","for","transcription","factor","s","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, chemical compound, event, person, organization, chemical element, location, scientist, university, protein, academic journal, astronomical object, country, discipline, enzyme, theory and O.\nSentence: For example , that ancestor had at least 7 Pax genes for transcription factor s .","prompt_labels":"For(O) example(O) ,(O) that(O) ancestor(O) had(O) at(O) least(O) 7(O) Pax(O) genes(O) for(O) transcription(O) factor(O) s(O) .(O)"}}
{"id":"16","dataset":"crossner_science","split":"dev","label_list":["chemical compound","theory","country","location","chemical element","award","enzyme","astronomical object","person","organization","scientist","university","discipline","academic journal","event","protein"],"instance":{"id":"16","words":["In","most","cases",",","planets","named","with","Bayer",",","Flamsteed",",","and","or","Variable","star","designation","have","a","space",",","but","usage","with","other","designations","varies","e.g.","WASP-12b","but","HD","209458","b","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","I-astronomical object","I-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, theory, country, location, chemical element, award, enzyme, astronomical object, person, organization, scientist, university, discipline, academic journal, event, protein and O.\nSentence: In most cases , planets named with Bayer , Flamsteed , and or Variable star designation have a space , but usage with other designations varies e.g. WASP-12b but HD 209458 b .","prompt_labels":"In(O) most(O) cases(O) ,(O) planets(O) named(O) with(O) Bayer(O) ,(O) Flamsteed(O) ,(O) and(O) or(O) Variable(O) star(O) designation(O) have(O) a(O) space(O) ,(O) but(O) usage(O) with(O) other(O) designations(O) varies(O) e.g.(O) WASP-12b(B-astronomical object) but(O) HD(B-astronomical object) 209458(I-astronomical object) b(I-astronomical object) .(O)"}}
{"id":"17","dataset":"crossner_science","split":"dev","label_list":["country","person","event","academic journal","enzyme","discipline","university","chemical element","award","location","chemical compound","protein","organization","scientist","theory","astronomical object"],"instance":{"id":"17","words":["Schirra","was","a","33rd","Degree","Mason","and","part","of","the","American","Institute","of","Aeronautics","and","Astronautics",",","as","well","as","a","fellow","of","the","American","Astronautical","Society","."],"labels":["B-person","O","O","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, person, event, academic journal, enzyme, discipline, university, chemical element, award, location, chemical compound, protein, organization, scientist, theory, astronomical object and O.\nSentence: Schirra was a 33rd Degree Mason and part of the American Institute of Aeronautics and Astronautics , as well as a fellow of the American Astronautical Society .","prompt_labels":"Schirra(B-person) was(O) a(O) 33rd(O) Degree(O) Mason(O) and(O) part(O) of(O) the(O) American(B-organization) Institute(I-organization) of(I-organization) Aeronautics(I-organization) and(I-organization) Astronautics(I-organization) ,(O) as(O) well(O) as(O) a(O) fellow(B-award) of(I-award) the(I-award) American(I-award) Astronautical(I-award) Society(I-award) .(O)"}}
{"id":"18","dataset":"crossner_science","split":"dev","label_list":["scientist","academic journal","event","organization","location","chemical compound","protein","theory","country","astronomical object","university","person","award","discipline","chemical element","enzyme"],"instance":{"id":"18","words":["Gerty","Theresa","Cori","(","née","Radnitz",";","August","15",",","1896","-","October","26",",","1957",")","was","a","Austria-Hungary","-","American","biochemist","who","in","1947","was","the","third","woman","-","and","first","American","woman","-","to","win","a","Nobel","Prize","in","science",",","and","the","first","woman","to","be","awarded","the","Nobel","Prize","in","Physiology","or","Medicine",",","for","her","role","in","the","discovery","of","glycogen","metabolism","."],"labels":["B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","O","O","O","O","O","O","O","O","O","O","O","B-award","I-award","I-award","I-award","I-award","I-award","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, academic journal, event, organization, location, chemical compound, protein, theory, country, astronomical object, university, person, award, discipline, chemical element, enzyme and O.\nSentence: Gerty Theresa Cori ( née Radnitz ; August 15 , 1896 - October 26 , 1957 ) was a Austria-Hungary - American biochemist who in 1947 was the third woman - and first American woman - to win a Nobel Prize in science , and the first woman to be awarded the Nobel Prize in Physiology or Medicine , for her role in the discovery of glycogen metabolism .","prompt_labels":"Gerty(B-scientist) Theresa(I-scientist) Cori(I-scientist) ((O) née(B-scientist) Radnitz(I-scientist) ;(O) August(O) 15(O) ,(O) 1896(O) -(O) October(O) 26(O) ,(O) 1957(O) )(O) was(O) a(O) Austria-Hungary(O) -(O) American(O) biochemist(O) who(O) in(O) 1947(O) was(O) the(O) third(O) woman(O) -(O) and(O) first(O) American(O) woman(O) -(O) to(O) win(O) a(O) Nobel(B-award) Prize(I-award) in(O) science(O) ,(O) and(O) the(O) first(O) woman(O) to(O) be(O) awarded(O) the(O) Nobel(B-award) Prize(I-award) in(I-award) Physiology(I-award) or(I-award) Medicine(I-award) ,(O) for(O) her(O) role(O) in(O) the(O) discovery(O) of(O) glycogen(O) metabolism(O) .(O)"}}
{"id":"19","dataset":"crossner_science","split":"dev","label_list":["enzyme","academic journal","organization","scientist","location","discipline","person","university","award","chemical element","country","astronomical object","protein","theory","chemical compound","event"],"instance":{"id":"19","words":["PCH1","reduces","hypocotyl","growth","during","long","nights","by","preferentially","binding","and","stabilizing","the","active","form","of","Phytochrome","(","phyB",")",",","prolonging","its","activity","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, academic journal, organization, scientist, location, discipline, person, university, award, chemical element, country, astronomical object, protein, theory, chemical compound, event and O.\nSentence: PCH1 reduces hypocotyl growth during long nights by preferentially binding and stabilizing the active form of Phytochrome ( phyB ) , prolonging its activity .","prompt_labels":"PCH1(O) reduces(O) hypocotyl(O) growth(O) during(O) long(O) nights(O) by(O) preferentially(O) binding(O) and(O) stabilizing(O) the(O) active(O) form(O) of(O) Phytochrome(O) ((O) phyB(O) )(O) ,(O) prolonging(O) its(O) activity(O) .(O)"}}
{"id":"20","dataset":"crossner_science","split":"dev","label_list":["enzyme","award","organization","country","scientist","theory","university","astronomical object","event","chemical compound","person","protein","chemical element","discipline","location","academic journal"],"instance":{"id":"20","words":["Generally",",","Potassium","cyanide","or","its","less","toxic","surrogate","Zinc","cyanide","are","used","as","nucleophilic","cyanide","sources","."],"labels":["O","O","B-chemical compound","I-chemical compound","O","O","O","O","O","B-chemical compound","I-chemical compound","O","O","O","B-chemical compound","I-chemical compound","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: enzyme, award, organization, country, scientist, theory, university, astronomical object, event, chemical compound, person, protein, chemical element, discipline, location, academic journal and O.\nSentence: Generally , Potassium cyanide or its less toxic surrogate Zinc cyanide are used as nucleophilic cyanide sources .","prompt_labels":"Generally(O) ,(O) Potassium(B-chemical compound) cyanide(I-chemical compound) or(O) its(O) less(O) toxic(O) surrogate(O) Zinc(B-chemical compound) cyanide(I-chemical compound) are(O) used(O) as(O) nucleophilic(B-chemical compound) cyanide(I-chemical compound) sources(O) .(O)"}}
{"id":"21","dataset":"crossner_science","split":"dev","label_list":["academic journal","country","protein","event","discipline","theory","scientist","location","organization","astronomical object","enzyme","chemical element","award","chemical compound","person","university"],"instance":{"id":"21","words":["Somatic","enrichment","for","transversion","mutations","(","G",":","CT",":","A",")","has","been","associated","with","base","excision","repair","(","BER",")","deficiency","and","linked","to","defective","MUTYH",",","a","DNA","glycosylase",",","in","colorectal","cancer","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, country, protein, event, discipline, theory, scientist, location, organization, astronomical object, enzyme, chemical element, award, chemical compound, person, university and O.\nSentence: Somatic enrichment for transversion mutations ( G : CT : A ) has been associated with base excision repair ( BER ) deficiency and linked to defective MUTYH , a DNA glycosylase , in colorectal cancer .","prompt_labels":"Somatic(O) enrichment(O) for(O) transversion(O) mutations(O) ((O) G(O) :(O) CT(O) :(O) A(O) )(O) has(O) been(O) associated(O) with(O) base(O) excision(O) repair(O) ((O) BER(O) )(O) deficiency(O) and(O) linked(O) to(O) defective(O) MUTYH(O) ,(O) a(O) DNA(B-enzyme) glycosylase(I-enzyme) ,(O) in(O) colorectal(O) cancer(O) .(O)"}}
{"id":"22","dataset":"crossner_science","split":"dev","label_list":["award","chemical compound","protein","event","enzyme","theory","location","person","scientist","chemical element","country","university","organization","academic journal","astronomical object","discipline"],"instance":{"id":"22","words":["The","process","is","highly","endergonic","until","it","is","coupled","to","the","hydrolysis","of","Adenosine","triphosphate","or","Guanosine","triphosphate",",","effectively","making","the","process","exergonic","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","B-chemical compound","I-chemical compound","O","B-chemical compound","I-chemical compound","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: award, chemical compound, protein, event, enzyme, theory, location, person, scientist, chemical element, country, university, organization, academic journal, astronomical object, discipline and O.\nSentence: The process is highly endergonic until it is coupled to the hydrolysis of Adenosine triphosphate or Guanosine triphosphate , effectively making the process exergonic .","prompt_labels":"The(O) process(O) is(O) highly(O) endergonic(O) until(O) it(O) is(O) coupled(O) to(O) the(O) hydrolysis(O) of(O) Adenosine(B-chemical compound) triphosphate(I-chemical compound) or(O) Guanosine(B-chemical compound) triphosphate(I-chemical compound) ,(O) effectively(O) making(O) the(O) process(O) exergonic(O) .(O)"}}
{"id":"23","dataset":"crossner_science","split":"dev","label_list":["astronomical object","country","university","discipline","academic journal","protein","person","enzyme","organization","scientist","chemical compound","location","event","theory","award","chemical element"],"instance":{"id":"23","words":["Other","notable","German","scientists",",","who","worked","on","the","Soviet","atomic","bomb","project","and","joined","Rexer","at","the","Technische","Hochschule","Dresden","were","Heinz","Pose","and","two","other","physicists",",","Werner","Hartmann","and","Heinz","Barwich",",","who","had","been","at","Gustav","Hertz","'s","Institute","G",",","in","Agudseri","(","Agudzery",")","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","B-university","I-university","I-university","O","B-scientist","I-scientist","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","O","B-location","O","B-location","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, country, university, discipline, academic journal, protein, person, enzyme, organization, scientist, chemical compound, location, event, theory, award, chemical element and O.\nSentence: Other notable German scientists , who worked on the Soviet atomic bomb project and joined Rexer at the Technische Hochschule Dresden were Heinz Pose and two other physicists , Werner Hartmann and Heinz Barwich , who had been at Gustav Hertz 's Institute G , in Agudseri ( Agudzery ) .","prompt_labels":"Other(O) notable(O) German(O) scientists(O) ,(O) who(O) worked(O) on(O) the(O) Soviet(O) atomic(O) bomb(O) project(O) and(O) joined(O) Rexer(B-scientist) at(O) the(O) Technische(B-university) Hochschule(I-university) Dresden(I-university) were(O) Heinz(B-scientist) Pose(I-scientist) and(O) two(O) other(O) physicists(O) ,(O) Werner(B-scientist) Hartmann(I-scientist) and(O) Heinz(B-scientist) Barwich(I-scientist) ,(O) who(O) had(O) been(O) at(O) Gustav(B-organization) Hertz(I-organization) 's(I-organization) Institute(I-organization) G(I-organization) ,(O) in(O) Agudseri(B-location) ((O) Agudzery(B-location) )(O) .(O)"}}
{"id":"24","dataset":"crossner_science","split":"dev","label_list":["country","event","astronomical object","theory","scientist","person","chemical compound","discipline","location","award","academic journal","protein","university","chemical element","enzyme","organization"],"instance":{"id":"24","words":["He","received","the","Society","of","Experimental","Test","Pilots","(","SETP",")","James","H.","Doolittle","Award","in","1972","and","the","SETP","Iven","C.","Kincheloe","Award","."],"labels":["O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","O","B-organization","O","B-award","I-award","I-award","I-award","O","O","O","O","B-organization","B-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: country, event, astronomical object, theory, scientist, person, chemical compound, discipline, location, award, academic journal, protein, university, chemical element, enzyme, organization and O.\nSentence: He received the Society of Experimental Test Pilots ( SETP ) James H. Doolittle Award in 1972 and the SETP Iven C. Kincheloe Award .","prompt_labels":"He(O) received(O) the(O) Society(B-organization) of(I-organization) Experimental(I-organization) Test(I-organization) Pilots(I-organization) ((O) SETP(B-organization) )(O) James(B-award) H.(I-award) Doolittle(I-award) Award(I-award) in(O) 1972(O) and(O) the(O) SETP(B-organization) Iven(B-award) C.(I-award) Kincheloe(I-award) Award(I-award) .(O)"}}
{"id":"25","dataset":"crossner_science","split":"dev","label_list":["discipline","university","protein","scientist","chemical element","theory","astronomical object","academic journal","award","enzyme","person","chemical compound","country","organization","event","location"],"instance":{"id":"25","words":["Such","mass","wasting","occurs","on","both","terrestrial","and","submarine","slopes",",","and","has","been","observed","on","Earth",",","Mars",",","Venus",",","Titan","and","Iapetus","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O","B-astronomical object","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, university, protein, scientist, chemical element, theory, astronomical object, academic journal, award, enzyme, person, chemical compound, country, organization, event, location and O.\nSentence: Such mass wasting occurs on both terrestrial and submarine slopes , and has been observed on Earth , Mars , Venus , Titan and Iapetus .","prompt_labels":"Such(O) mass(O) wasting(O) occurs(O) on(O) both(O) terrestrial(O) and(O) submarine(O) slopes(O) ,(O) and(O) has(O) been(O) observed(O) on(O) Earth(B-astronomical object) ,(O) Mars(B-astronomical object) ,(O) Venus(B-astronomical object) ,(O) Titan(B-astronomical object) and(O) Iapetus(B-astronomical object) .(O)"}}
{"id":"26","dataset":"crossner_science","split":"dev","label_list":["chemical element","scientist","astronomical object","location","organization","award","event","country","academic journal","enzyme","theory","university","protein","person","chemical compound","discipline"],"instance":{"id":"26","words":["Jingūji","has","been","voiced","by","Yukimasa","Kishino",",","Akio","Ōtsuka",",","Jūrōta","Kosugi",",","and","Kaoru","Katō",";","Yōko","by","Tsumugi","Ōsawa",",","Yōko","Saitō",",","Fumiko","Orikasa",",","Kazue","Nakamoto",",","Seiko","Yoshida",",","and","Mamiko","Noto",";","and","Sanzō","by","Fumihiko","Tachiki",",","Kōji","Ishii",",","Masaaki","Tsukada",",","and","Naomi","Otome","."],"labels":["B-location","O","O","O","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O","B-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O","O","B-person","O","B-person","I-person","O","B-person","I-person","O","B-person","I-person","O","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical element, scientist, astronomical object, location, organization, award, event, country, academic journal, enzyme, theory, university, protein, person, chemical compound, discipline and O.\nSentence: Jingūji has been voiced by Yukimasa Kishino , Akio Ōtsuka , Jūrōta Kosugi , and Kaoru Katō ; Yōko by Tsumugi Ōsawa , Yōko Saitō , Fumiko Orikasa , Kazue Nakamoto , Seiko Yoshida , and Mamiko Noto ; and Sanzō by Fumihiko Tachiki , Kōji Ishii , Masaaki Tsukada , and Naomi Otome .","prompt_labels":"Jingūji(B-location) has(O) been(O) voiced(O) by(O) Yukimasa(B-person) Kishino(I-person) ,(O) Akio(B-person) Ōtsuka(I-person) ,(O) Jūrōta(B-person) Kosugi(I-person) ,(O) and(O) Kaoru(B-person) Katō(I-person) ;(O) Yōko(B-person) by(O) Tsumugi(B-person) Ōsawa(I-person) ,(O) Yōko(B-person) Saitō(I-person) ,(O) Fumiko(B-person) Orikasa(I-person) ,(O) Kazue(B-person) Nakamoto(I-person) ,(O) Seiko(B-person) Yoshida(I-person) ,(O) and(O) Mamiko(B-person) Noto(I-person) ;(O) and(O) Sanzō(B-person) by(O) Fumihiko(B-person) Tachiki(I-person) ,(O) Kōji(B-person) Ishii(I-person) ,(O) Masaaki(B-person) Tsukada(I-person) ,(O) and(O) Naomi(B-person) Otome(I-person) .(O)"}}
{"id":"27","dataset":"crossner_science","split":"dev","label_list":["organization","country","university","astronomical object","protein","scientist","enzyme","discipline","theory","location","person","chemical element","award","chemical compound","academic journal","event"],"instance":{"id":"27","words":["He","is","known","for","his","studies","on","DNA","and","RNA","polymerase","s","."],"labels":["O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: organization, country, university, astronomical object, protein, scientist, enzyme, discipline, theory, location, person, chemical element, award, chemical compound, academic journal, event and O.\nSentence: He is known for his studies on DNA and RNA polymerase s .","prompt_labels":"He(O) is(O) known(O) for(O) his(O) studies(O) on(O) DNA(O) and(O) RNA(B-enzyme) polymerase(I-enzyme) s(O) .(O)"}}
{"id":"28","dataset":"crossner_science","split":"dev","label_list":["astronomical object","award","theory","scientist","chemical compound","discipline","enzyme","protein","organization","event","chemical element","person","academic journal","university","country","location"],"instance":{"id":"28","words":["He","has","served","on","scientific","journal","editorial","boards","including","American","Scientist",",","Physics","of","Fluids",",","Journal","of","Fluid","Mechanics",",","Physical","Review","E",",","Physical","Review","Letters",",","Journal","of","Theoretical","and","Computational","Fluid","Dynamics",","],"labels":["O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: astronomical object, award, theory, scientist, chemical compound, discipline, enzyme, protein, organization, event, chemical element, person, academic journal, university, country, location and O.\nSentence: He has served on scientific journal editorial boards including American Scientist , Physics of Fluids , Journal of Fluid Mechanics , Physical Review E , Physical Review Letters , Journal of Theoretical and Computational Fluid Dynamics ,","prompt_labels":"He(O) has(O) served(O) on(O) scientific(O) journal(O) editorial(O) boards(O) including(O) American(B-academic journal) Scientist(I-academic journal) ,(O) Physics(B-academic journal) of(I-academic journal) Fluids(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Fluid(I-academic journal) Mechanics(I-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) E(I-academic journal) ,(O) Physical(B-academic journal) Review(I-academic journal) Letters(I-academic journal) ,(O) Journal(B-academic journal) of(I-academic journal) Theoretical(I-academic journal) and(I-academic journal) Computational(I-academic journal) Fluid(I-academic journal) Dynamics(I-academic journal) ,(O)"}}
{"id":"29","dataset":"crossner_science","split":"dev","label_list":["person","protein","enzyme","academic journal","theory","country","university","chemical compound","discipline","award","scientist","astronomical object","location","chemical element","event","organization"],"instance":{"id":"29","words":["This","led","to","a","vigorous","debate","between","the","biometricians",",","who","supported","Galton","'s","ideas",",","as","Walter","Weldon",",","Arthur","Dukinfield","Darbishire","and","Karl","Pearson",",","and","Mendelians",",","who","supported","Bateson","'s","(","and","Mendel","'s",")","ideas",",","such","as","Charles","Davenport","and","Wilhelm","Johannsen","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O","O","O","O","O","O","B-scientist","O","O","O","B-scientist","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: person, protein, enzyme, academic journal, theory, country, university, chemical compound, discipline, award, scientist, astronomical object, location, chemical element, event, organization and O.\nSentence: This led to a vigorous debate between the biometricians , who supported Galton 's ideas , as Walter Weldon , Arthur Dukinfield Darbishire and Karl Pearson , and Mendelians , who supported Bateson 's ( and Mendel 's ) ideas , such as Charles Davenport and Wilhelm Johannsen .","prompt_labels":"This(O) led(O) to(O) a(O) vigorous(O) debate(O) between(O) the(O) biometricians(O) ,(O) who(O) supported(O) Galton(B-scientist) 's(O) ideas(O) ,(O) as(O) Walter(B-scientist) Weldon(I-scientist) ,(O) Arthur(B-scientist) Dukinfield(I-scientist) Darbishire(I-scientist) and(O) Karl(B-scientist) Pearson(I-scientist) ,(O) and(O) Mendelians(O) ,(O) who(O) supported(O) Bateson(B-scientist) 's(O) ((O) and(O) Mendel(B-scientist) 's(O) )(O) ideas(O) ,(O) such(O) as(O) Charles(B-scientist) Davenport(I-scientist) and(O) Wilhelm(B-scientist) Johannsen(I-scientist) .(O)"}}
{"id":"30","dataset":"crossner_science","split":"dev","label_list":["scientist","discipline","university","location","protein","chemical compound","award","enzyme","astronomical object","person","event","chemical element","theory","academic journal","country","organization"],"instance":{"id":"30","words":["His","Nobel","Prize","is","now","kept","on","display","at","the","International","Red","Cross","and","Red","Crescent","Movement","in","Geneva","."],"labels":["O","B-award","I-award","O","O","O","O","O","O","O","B-organization","I-organization","I-organization","I-organization","I-organization","I-organization","I-organization","O","B-location","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, discipline, university, location, protein, chemical compound, award, enzyme, astronomical object, person, event, chemical element, theory, academic journal, country, organization and O.\nSentence: His Nobel Prize is now kept on display at the International Red Cross and Red Crescent Movement in Geneva .","prompt_labels":"His(O) Nobel(B-award) Prize(I-award) is(O) now(O) kept(O) on(O) display(O) at(O) the(O) International(B-organization) Red(I-organization) Cross(I-organization) and(I-organization) Red(I-organization) Crescent(I-organization) Movement(I-organization) in(O) Geneva(B-location) .(O)"}}
{"id":"31","dataset":"crossner_science","split":"dev","label_list":["discipline","person","university","event","enzyme","astronomical object","scientist","academic journal","chemical element","organization","award","location","country","theory","protein","chemical compound"],"instance":{"id":"31","words":["Usually",",","in","the","presence","of","NADPH","dehydrogenase","or","NADH","dehydrogenase","as","the","enzyme",",","NADPH","or","NADH","is","the","reductant","that","converts","resazurin","to","resorufin","."],"labels":["O","O","O","O","O","O","B-enzyme","I-enzyme","O","B-enzyme","I-enzyme","O","O","O","O","B-chemical compound","O","B-chemical compound","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: discipline, person, university, event, enzyme, astronomical object, scientist, academic journal, chemical element, organization, award, location, country, theory, protein, chemical compound and O.\nSentence: Usually , in the presence of NADPH dehydrogenase or NADH dehydrogenase as the enzyme , NADPH or NADH is the reductant that converts resazurin to resorufin .","prompt_labels":"Usually(O) ,(O) in(O) the(O) presence(O) of(O) NADPH(B-enzyme) dehydrogenase(I-enzyme) or(O) NADH(B-enzyme) dehydrogenase(I-enzyme) as(O) the(O) enzyme(O) ,(O) NADPH(B-chemical compound) or(O) NADH(B-chemical compound) is(O) the(O) reductant(O) that(O) converts(O) resazurin(O) to(O) resorufin(O) .(O)"}}
{"id":"32","dataset":"crossner_science","split":"dev","label_list":["academic journal","protein","organization","university","astronomical object","country","chemical element","award","discipline","location","scientist","person","chemical compound","event","theory","enzyme"],"instance":{"id":"32","words":["The","minor","planet","is","named","after","the","Leakey","'s",",","a","family","of","Kenyan","paleoanthropologist","s",":","Mary","Leakey","(","1913-1996",")",",","her","husband","Louis","Leakey","(","1903-1972",")",",","and","their","son","Richard","Leakey","(","born","1944",")","."],"labels":["O","O","O","O","O","O","O","B-scientist","O","O","O","O","O","B-country","O","O","O","B-scientist","I-scientist","O","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","O","O","O","B-scientist","I-scientist","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, protein, organization, university, astronomical object, country, chemical element, award, discipline, location, scientist, person, chemical compound, event, theory, enzyme and O.\nSentence: The minor planet is named after the Leakey 's , a family of Kenyan paleoanthropologist s : Mary Leakey ( 1913-1996 ) , her husband Louis Leakey ( 1903-1972 ) , and their son Richard Leakey ( born 1944 ) .","prompt_labels":"The(O) minor(O) planet(O) is(O) named(O) after(O) the(O) Leakey(B-scientist) 's(O) ,(O) a(O) family(O) of(O) Kenyan(B-country) paleoanthropologist(O) s(O) :(O) Mary(B-scientist) Leakey(I-scientist) ((O) 1913-1996(O) )(O) ,(O) her(O) husband(O) Louis(B-scientist) Leakey(I-scientist) ((O) 1903-1972(O) )(O) ,(O) and(O) their(O) son(O) Richard(B-scientist) Leakey(I-scientist) ((O) born(O) 1944(O) )(O) .(O)"}}
{"id":"33","dataset":"crossner_science","split":"dev","label_list":["theory","discipline","academic journal","university","person","location","country","protein","award","organization","chemical compound","enzyme","chemical element","astronomical object","event","scientist"],"instance":{"id":"33","words":["In","1880",",","Hall","'s","experimentation","was","published","as","a","doctoral","thesis","in","the","American","Journal","of","Science","and","in","the","Philosophical","Magazine","."],"labels":["O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","B-academic journal","I-academic journal","I-academic journal","I-academic journal","O","O","O","B-academic journal","I-academic journal","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: theory, discipline, academic journal, university, person, location, country, protein, award, organization, chemical compound, enzyme, chemical element, astronomical object, event, scientist and O.\nSentence: In 1880 , Hall 's experimentation was published as a doctoral thesis in the American Journal of Science and in the Philosophical Magazine .","prompt_labels":"In(O) 1880(O) ,(O) Hall(B-person) 's(O) experimentation(O) was(O) published(O) as(O) a(O) doctoral(O) thesis(O) in(O) the(O) American(B-academic journal) Journal(I-academic journal) of(I-academic journal) Science(I-academic journal) and(O) in(O) the(O) Philosophical(B-academic journal) Magazine(I-academic journal) .(O)"}}
{"id":"34","dataset":"crossner_science","split":"dev","label_list":["chemical compound","country","event","person","scientist","organization","location","academic journal","discipline","university","theory","protein","astronomical object","chemical element","enzyme","award"],"instance":{"id":"34","words":["Helicase","s","unwind","the","strands","to","facilitate","the","advance","of","sequence-reading","enzymes","such","as","DNA","polymerase","."],"labels":["B-enzyme","O","O","O","O","O","O","O","O","O","O","O","O","O","B-enzyme","I-enzyme","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, country, event, person, scientist, organization, location, academic journal, discipline, university, theory, protein, astronomical object, chemical element, enzyme, award and O.\nSentence: Helicase s unwind the strands to facilitate the advance of sequence-reading enzymes such as DNA polymerase .","prompt_labels":"Helicase(B-enzyme) s(O) unwind(O) the(O) strands(O) to(O) facilitate(O) the(O) advance(O) of(O) sequence-reading(O) enzymes(O) such(O) as(O) DNA(B-enzyme) polymerase(I-enzyme) .(O)"}}
{"id":"35","dataset":"crossner_science","split":"dev","label_list":["scientist","university","academic journal","protein","organization","chemical element","enzyme","award","location","astronomical object","event","chemical compound","country","discipline","person","theory"],"instance":{"id":"35","words":["The","album","was","nominated","at","the","41st","Annual","Grammy","Awards","for","Grammy","Award","for","Best","Rap","Album","."],"labels":["O","O","O","O","O","O","B-award","I-award","I-award","I-award","O","B-award","I-award","I-award","I-award","I-award","I-award","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, university, academic journal, protein, organization, chemical element, enzyme, award, location, astronomical object, event, chemical compound, country, discipline, person, theory and O.\nSentence: The album was nominated at the 41st Annual Grammy Awards for Grammy Award for Best Rap Album .","prompt_labels":"The(O) album(O) was(O) nominated(O) at(O) the(O) 41st(B-award) Annual(I-award) Grammy(I-award) Awards(I-award) for(O) Grammy(B-award) Award(I-award) for(I-award) Best(I-award) Rap(I-award) Album(I-award) .(O)"}}
{"id":"36","dataset":"crossner_science","split":"dev","label_list":["event","astronomical object","person","academic journal","enzyme","scientist","discipline","chemical compound","location","university","chemical element","award","organization","protein","theory","country"],"instance":{"id":"36","words":["Lincoln","looks","much","as","it","did","during","the","Lincoln","County","War","(","1878-1881",")","when","its","single","street","was","peopled","with","characters","like","Billy","the","Kid",",","John","Chisum","and","Lawrence","Murphy","."],"labels":["B-person","O","O","O","O","O","O","O","B-event","I-event","I-event","O","O","O","O","O","O","O","O","O","O","O","O","B-person","I-person","I-person","O","B-person","I-person","O","B-person","I-person","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: event, astronomical object, person, academic journal, enzyme, scientist, discipline, chemical compound, location, university, chemical element, award, organization, protein, theory, country and O.\nSentence: Lincoln looks much as it did during the Lincoln County War ( 1878-1881 ) when its single street was peopled with characters like Billy the Kid , John Chisum and Lawrence Murphy .","prompt_labels":"Lincoln(B-person) looks(O) much(O) as(O) it(O) did(O) during(O) the(O) Lincoln(B-event) County(I-event) War(I-event) ((O) 1878-1881(O) )(O) when(O) its(O) single(O) street(O) was(O) peopled(O) with(O) characters(O) like(O) Billy(B-person) the(I-person) Kid(I-person) ,(O) John(B-person) Chisum(I-person) and(O) Lawrence(B-person) Murphy(I-person) .(O)"}}
{"id":"37","dataset":"crossner_science","split":"dev","label_list":["academic journal","scientist","university","person","enzyme","protein","discipline","event","chemical compound","theory","country","organization","award","location","chemical element","astronomical object"],"instance":{"id":"37","words":["British","observers","allegedly","exclaimed",",","Maxwell","should","have","seen","this","!","Of","the","eleven","diplômes","d","'honneur",",","seven","went","to","non-French","exhibitors",",","including","Werner","Siemens",",","Thomas","Edison",",","Alexander","Graham","Bell","and","William","Thomson","."],"labels":["O","O","O","O","O","B-person","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","I-scientist","I-scientist","O","B-scientist","I-scientist","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: academic journal, scientist, university, person, enzyme, protein, discipline, event, chemical compound, theory, country, organization, award, location, chemical element, astronomical object and O.\nSentence: British observers allegedly exclaimed , Maxwell should have seen this ! Of the eleven diplômes d 'honneur , seven went to non-French exhibitors , including Werner Siemens , Thomas Edison , Alexander Graham Bell and William Thomson .","prompt_labels":"British(O) observers(O) allegedly(O) exclaimed(O) ,(O) Maxwell(B-person) should(O) have(O) seen(O) this(O) !(O) Of(O) the(O) eleven(O) diplômes(O) d(O) 'honneur(O) ,(O) seven(O) went(O) to(O) non-French(O) exhibitors(O) ,(O) including(O) Werner(B-scientist) Siemens(I-scientist) ,(O) Thomas(B-scientist) Edison(I-scientist) ,(O) Alexander(B-scientist) Graham(I-scientist) Bell(I-scientist) and(O) William(B-scientist) Thomson(I-scientist) .(O)"}}
{"id":"38","dataset":"crossner_science","split":"dev","label_list":["scientist","astronomical object","university","country","chemical element","location","protein","award","event","person","discipline","academic journal","theory","chemical compound","enzyme","organization"],"instance":{"id":"38","words":["One","aspect",",","the","idea","of","modelling","atomic","behaviour","under","incident","electromagnetic","radiation","using","virtual","oscillators","at","the","absorption","and","emission","frequencies",",","rather","than","the","(","different",")","apparent","frequencies","of","the","Bohr","orbits",",","significantly","led","Max","Born",",","Werner","Heisenberg","and","Kramers","to","explore","mathematics","that","strongly","inspired","the","subsequent","development","of","matrix","mechanics",",","the","first","form","of","modern","quantum","mechanics","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","O","B-theory","I-theory","O","O","O","B-scientist","I-scientist","O","B-scientist","I-scientist","O","B-scientist","O","O","B-discipline","O","O","O","O","O","O","O","B-discipline","I-discipline","O","O","O","O","O","O","B-discipline","I-discipline","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: scientist, astronomical object, university, country, chemical element, location, protein, award, event, person, discipline, academic journal, theory, chemical compound, enzyme, organization and O.\nSentence: One aspect , the idea of modelling atomic behaviour under incident electromagnetic radiation using virtual oscillators at the absorption and emission frequencies , rather than the ( different ) apparent frequencies of the Bohr orbits , significantly led Max Born , Werner Heisenberg and Kramers to explore mathematics that strongly inspired the subsequent development of matrix mechanics , the first form of modern quantum mechanics .","prompt_labels":"One(O) aspect(O) ,(O) the(O) idea(O) of(O) modelling(O) atomic(O) behaviour(O) under(O) incident(O) electromagnetic(O) radiation(O) using(O) virtual(O) oscillators(O) at(O) the(O) absorption(O) and(O) emission(O) frequencies(O) ,(O) rather(O) than(O) the(O) ((O) different(O) )(O) apparent(O) frequencies(O) of(O) the(O) Bohr(B-theory) orbits(I-theory) ,(O) significantly(O) led(O) Max(B-scientist) Born(I-scientist) ,(O) Werner(B-scientist) Heisenberg(I-scientist) and(O) Kramers(B-scientist) to(O) explore(O) mathematics(B-discipline) that(O) strongly(O) inspired(O) the(O) subsequent(O) development(O) of(O) matrix(B-discipline) mechanics(I-discipline) ,(O) the(O) first(O) form(O) of(O) modern(O) quantum(B-discipline) mechanics(I-discipline) .(O)"}}
{"id":"39","dataset":"crossner_science","split":"dev","label_list":["chemical compound","enzyme","protein","university","location","award","event","scientist","theory","academic journal","astronomical object","country","organization","chemical element","discipline","person"],"instance":{"id":"39","words":["The","team","that","she","manages","has","specially","studied","the","role","of","Proinsulin","/","insulin","in","the","development","of","the","central","nervous","system","."],"labels":["O","O","O","O","O","O","O","O","O","O","O","B-protein","O","B-protein","O","O","O","O","O","O","O","O","O"],"instruction_inputs":"Please analyze the sentence provided, identifying the type of entity for each word on a token-by-token basis.\nOutput format is: word_1(label_1), word_2(label_2), ...\nWe'll use the BIO-format to label the entities, where:\n1. B- (Begin) indicates the start of a named entity.\n2. I- (Inside) is used for words within a named entity but are not the first word.\n3. O (Outside) denotes words that are not part of a named entity.\n\nUse the specific entity tags: chemical compound, enzyme, protein, university, location, award, event, scientist, theory, academic journal, astronomical object, country, organization, chemical element, discipline, person and O.\nSentence: The team that she manages has specially studied the role of Proinsulin / insulin in the development of the central nervous system .","prompt_labels":"The(O) team(O) that(O) she(O) manages(O) has(O) specially(O) studied(O) the(O) role(O) of(O) Proinsulin(B-protein) /(O) insulin(B-protein) in(O) the(O) development(O) of(O) the(O) central(O) nervous(O) system(O) .(O)"}}
