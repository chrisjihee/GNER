(GNER) ~/proj/GNER git:[main]
bash setup-env.sh

Looking for: ['python=3.11']

conda-forge/linux-64                                        Using cache
conda-forge/noarch                                          Using cache
Transaction

  Prefix: /raid/chrisjihee/miniforge3/envs/GNER

  Updating specs:

   - python=3.11


  Package               Version  Build               Channel           Size
─────────────────────────────────────────────────────────────────────────────
  Install:
─────────────────────────────────────────────────────────────────────────────

  + _libgcc_mutex           0.1  conda_forge         conda-forge     Cached
  + ld_impl_linux-64       2.43  h712a8e2_2          conda-forge     Cached
  + ca-certificates   2024.8.30  hbcca054_0          conda-forge     Cached
  + libgomp              14.2.0  h77fa898_1          conda-forge     Cached
  + _openmp_mutex           4.5  2_gnu               conda-forge     Cached
  + libgcc               14.2.0  h77fa898_1          conda-forge     Cached
  + libzlib               1.3.1  hb9d3cd8_2          conda-forge     Cached
  + libexpat              2.6.4  h5888daf_0          conda-forge     Cached
  + libgcc-ng            14.2.0  h69a702a_1          conda-forge     Cached
  + openssl               3.3.2  hb9d3cd8_0          conda-forge     Cached
  + libsqlite            3.47.0  hadc24fc_1          conda-forge     Cached
  + tk                   8.6.13  noxft_h4845f30_101  conda-forge     Cached
  + libxcrypt            4.4.36  hd590300_1          conda-forge     Cached
  + libffi                3.4.2  h7f98852_5          conda-forge     Cached
  + bzip2                 1.0.8  h4bc722e_7          conda-forge     Cached
  + ncurses                 6.5  he02047a_1          conda-forge     Cached
  + libuuid              2.38.1  h0b41bf4_0          conda-forge     Cached
  + libnsl                2.0.1  hd590300_0          conda-forge     Cached
  + xz                    5.2.6  h166bdaf_0          conda-forge     Cached
  + readline                8.2  h8228510_1          conda-forge     Cached
  + tzdata                2024b  hc8b5060_0          conda-forge     Cached
  + python              3.11.10  hc5c86c4_3_cpython  conda-forge     Cached
  + wheel                0.44.0  pyhd8ed1ab_0        conda-forge     Cached
  + setuptools           75.3.0  pyhd8ed1ab_0        conda-forge     Cached
  + pip                  24.3.1  pyh8b19718_0        conda-forge     Cached

  Summary:

  Install: 25 packages

  Total download: 0 B

─────────────────────────────────────────────────────────────────────────────



Downloading and Extracting Packages:

Preparing transaction: done
Verifying transaction: done
Executing transaction: done

To activate this environment, use

     $ mamba activate GNER

To deactivate an active environment, use

     $ mamba deactivate

Run 'mamba init' to be able to run mamba activate/deactivate
and start a new shell session. Or use conda to activate/deactivate.


Looking for: ['cuda-libraries=11.8', 'cuda-libraries-dev=11.8', 'cuda-cudart=11.8', 'cuda-cudart-dev=11.8', 'cuda-nvrtc=11.8', 'cuda-nvrtc-dev=11.8', 'cuda-driver-dev=11.8', 'cuda-nvcc=11.8', 'cuda-cccl=11.8', 'cuda-runtime=11.8', 'cuda-version=12.4', 'libcusparse=11', 'libcusparse-dev=11', 'libcublas=11', 'libcublas-dev=11']

nvidia/linux-64                                             Using cache
nvidia/noarch                                               Using cache
pytorch/linux-64                                            Using cache
pytorch/noarch                                              Using cache
conda-forge/linux-64                                        Using cache
conda-forge/noarch                                          Using cache

Pinned packages:
  - python 3.11.*


Transaction

  Prefix: /raid/chrisjihee/miniforge3/envs/GNER

  Updating specs:

   - cuda-libraries=11.8
   - cuda-libraries-dev=11.8
   - cuda-cudart=11.8
   - cuda-cudart-dev=11.8
   - cuda-nvrtc=11.8
   - cuda-nvrtc-dev=11.8
   - cuda-driver-dev=11.8
   - cuda-nvcc=11.8
   - cuda-cccl=11.8
   - cuda-runtime=11.8
   - cuda-version=12.4
   - libcusparse=11
   - libcusparse-dev=11
   - libcublas=11
   - libcublas-dev=11
   - ca-certificates
   - openssl


  Package                  Version  Build       Channel           Size
────────────────────────────────────────────────────────────────────────
  Install:
────────────────────────────────────────────────────────────────────────

  + cuda-cudart            11.8.89  0           nvidia          Cached
  + cuda-nvrtc             11.8.89  0           nvidia          Cached
  + cuda-driver-dev        11.8.89  0           nvidia          Cached
  + cuda-nvcc              11.8.89  0           nvidia          Cached
  + cuda-cccl              11.8.89  0           nvidia          Cached
  + libcusparse          11.7.5.86  0           nvidia          Cached
  + libcublas            11.11.3.6  0           nvidia          Cached
  + cuda-profiler-api     12.4.127  0           nvidia          Cached
  + libcusolver           11.6.1.9  0           nvidia          Cached
  + libcufft              11.2.1.3  0           nvidia          Cached
  + libcufile              1.9.1.3  0           nvidia          Cached
  + libcurand           10.3.5.147  0           nvidia          Cached
  + libnpp               12.2.5.30  0           nvidia          Cached
  + libnvjpeg           12.3.1.117  0           nvidia          Cached
  + cuda-nvrtc-dev         11.8.89  0           nvidia          Cached
  + cuda-cudart-dev        11.8.89  0           nvidia          Cached
  + libcusparse-dev      11.7.5.86  0           nvidia          Cached
  + libcublas-dev        11.11.3.6  0           nvidia          Cached
  + libcusolver-dev       11.6.1.9  0           nvidia          Cached
  + libcufft-dev          11.2.1.3  0           nvidia          Cached
  + libcufile-dev          1.9.1.3  0           nvidia          Cached
  + libcurand-dev       10.3.5.147  0           nvidia          Cached
  + libnpp-dev           12.2.5.30  0           nvidia          Cached
  + libnvjpeg-dev       12.3.1.117  0           nvidia          Cached
  + cuda-libraries          11.8.0  0           nvidia          Cached
  + cuda-libraries-dev      11.8.0  0           nvidia          Cached
  + cuda-runtime            11.8.0  0           nvidia          Cached
  + cuda-version              12.4  h3060b56_3  conda-forge     Cached

  Summary:

  Install: 28 packages

  Total download: 0 B

────────────────────────────────────────────────────────────────────────



Downloading and Extracting Packages:

Preparing transaction: done
Verifying transaction: done
Executing transaction: done
Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu118
Collecting nltk (from -r requirements.txt (line 2))
  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)
Collecting numpy<2.0.0 (from -r requirements.txt (line 3))
  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)
Collecting datasets (from -r requirements.txt (line 4))
  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)
Collecting protobuf (from -r requirements.txt (line 5))
  Using cached protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)
Collecting sentencepiece (from -r requirements.txt (line 6))
  Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Collecting torch==2.4.0 (from -r requirements.txt (line 10))
  Downloading https://download.pytorch.org/whl/cu118/torch-2.4.0%2Bcu118-cp311-cp311-linux_x86_64.whl (857.8 MB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 857.8/857.8 MB 21.1 MB/s eta 0:00:00
Collecting deepspeed<0.13.2 (from -r requirements.txt (line 11))
  Using cached deepspeed-0.13.1-py3-none-any.whl
Collecting accelerate<1.0.0 (from -r requirements.txt (line 12))
  Using cached accelerate-0.34.2-py3-none-any.whl.metadata (19 kB)
Collecting transformers<4.39.0 (from -r requirements.txt (line 13))
  Using cached transformers-4.38.2-py3-none-any.whl.metadata (130 kB)
Collecting filelock (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)
Collecting typing-extensions>=4.8.0 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)
Collecting sympy (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)
Collecting jinja2 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)
Collecting fsspec (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)
Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu11==11.8.89 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu11==11.8.87 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu11==9.1.0.70 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)
Collecting nvidia-cublas-cu11==11.11.3.6 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu11==10.3.0.86 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu11==11.4.1.48 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu11==11.7.5.86 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-nccl-cu11==2.20.5 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.20.5-py3-none-manylinux2014_x86_64.whl (142.9 MB)
Collecting nvidia-nvtx-cu11==11.8.86 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)
Collecting triton==3.0.0 (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached https://download.pytorch.org/whl/triton-3.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)
Collecting click (from nltk->-r requirements.txt (line 2))
  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)
Collecting joblib (from nltk->-r requirements.txt (line 2))
  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)
Collecting regex>=2021.8.3 (from nltk->-r requirements.txt (line 2))
  Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)
Collecting tqdm (from nltk->-r requirements.txt (line 2))
  Using cached tqdm-4.67.0-py3-none-any.whl.metadata (57 kB)
Collecting pyarrow>=15.0.0 (from datasets->-r requirements.txt (line 4))
  Using cached pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)
Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 4))
  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)
Collecting pandas (from datasets->-r requirements.txt (line 4))
  Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)
Collecting requests>=2.32.2 (from datasets->-r requirements.txt (line 4))
  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)
Collecting xxhash (from datasets->-r requirements.txt (line 4))
  Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)
Collecting multiprocess<0.70.17 (from datasets->-r requirements.txt (line 4))
  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)
Collecting fsspec (from torch==2.4.0->-r requirements.txt (line 10))
  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)
Collecting aiohttp (from datasets->-r requirements.txt (line 4))
  Using cached aiohttp-3.10.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)
Collecting huggingface-hub>=0.23.0 (from datasets->-r requirements.txt (line 4))
  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)
Collecting packaging (from datasets->-r requirements.txt (line 4))
  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)
Collecting pyyaml>=5.1 (from datasets->-r requirements.txt (line 4))
  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)
Collecting hjson (from deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)
Collecting ninja (from deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)
Collecting psutil (from deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)
Collecting py-cpuinfo (from deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)
Collecting pydantic (from deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)
Collecting pynvml (from deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached pynvml-11.5.3-py3-none-any.whl.metadata (8.8 kB)
Collecting safetensors>=0.4.3 (from accelerate<1.0.0->-r requirements.txt (line 12))
  Using cached safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)
Collecting tokenizers<0.19,>=0.14 (from transformers<4.39.0->-r requirements.txt (line 13))
  Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)
Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->-r requirements.txt (line 4))
  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)
Collecting aiosignal>=1.1.2 (from aiohttp->datasets->-r requirements.txt (line 4))
  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)
Collecting attrs>=17.3.0 (from aiohttp->datasets->-r requirements.txt (line 4))
  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)
Collecting frozenlist>=1.1.1 (from aiohttp->datasets->-r requirements.txt (line 4))
  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)
Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->-r requirements.txt (line 4))
  Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)
Collecting yarl<2.0,>=1.12.0 (from aiohttp->datasets->-r requirements.txt (line 4))
  Using cached yarl-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (64 kB)
Collecting charset-normalizer<4,>=2 (from requests>=2.32.2->datasets->-r requirements.txt (line 4))
  Using cached charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)
Collecting idna<4,>=2.5 (from requests>=2.32.2->datasets->-r requirements.txt (line 4))
  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)
Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets->-r requirements.txt (line 4))
  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets->-r requirements.txt (line 4))
  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.0->-r requirements.txt (line 10))
  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)
Collecting python-dateutil>=2.8.2 (from pandas->datasets->-r requirements.txt (line 4))
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)
Collecting pytz>=2020.1 (from pandas->datasets->-r requirements.txt (line 4))
  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)
Collecting tzdata>=2022.7 (from pandas->datasets->-r requirements.txt (line 4))
  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting annotated-types>=0.6.0 (from pydantic->deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)
Collecting pydantic-core==2.23.4 (from pydantic->deepspeed<0.13.2->-r requirements.txt (line 11))
  Using cached pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)
Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.0->-r requirements.txt (line 10))
  Using cached https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)
Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->datasets->-r requirements.txt (line 4))
  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)
Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp->datasets->-r requirements.txt (line 4))
  Using cached propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Using cached nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux2014_x86_64.whl (417.9 MB)
Using cached nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux2014_x86_64.whl (13.1 MB)
Using cached nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (23.2 MB)
Using cached nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux2014_x86_64.whl (875 kB)
Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)
Using cached nvidia_curand_cu11-10.3.0.86-py3-none-manylinux2014_x86_64.whl (58.1 MB)
Using cached nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux2014_x86_64.whl (128.2 MB)
Using cached nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux2014_x86_64.whl (204.1 MB)
Using cached nvidia_nvtx_cu11-11.8.86-py3-none-manylinux2014_x86_64.whl (99 kB)
Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)
Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)
Using cached datasets-3.1.0-py3-none-any.whl (480 kB)
Using cached protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)
Using cached sentencepiece-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
Using cached accelerate-0.34.2-py3-none-any.whl (324 kB)
Using cached transformers-4.38.2-py3-none-any.whl (8.5 MB)
Using cached dill-0.3.8-py3-none-any.whl (116 kB)
Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)
Using cached aiohttp-3.10.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
Using cached huggingface_hub-0.26.2-py3-none-any.whl (447 kB)
Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)
Using cached packaging-24.2-py3-none-any.whl (65 kB)
Using cached pyarrow-18.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.0 MB)
Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)
Using cached regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)
Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Using cached safetensors-0.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)
Using cached tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)
Using cached tqdm-4.67.0-py3-none-any.whl (78 kB)
Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)
Using cached click-8.1.7-py3-none-any.whl (97 kB)
Using cached filelock-3.16.1-py3-none-any.whl (16 kB)
Using cached hjson-3.1.0-py3-none-any.whl (54 kB)
Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)
Using cached joblib-1.4.2-py3-none-any.whl (301 kB)
Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)
Using cached ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)
Using cached pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)
Using cached psutil-6.1.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)
Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)
Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)
Using cached pydantic_core-2.23.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)
Using cached pynvml-11.5.3-py3-none-any.whl (53 kB)
Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)
Using cached xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)
Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)
Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Using cached attrs-24.2.0-py3-none-any.whl (63 kB)
Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)
Using cached charset_normalizer-3.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)
Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)
Using cached idna-3.10-py3-none-any.whl (70 kB)
Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)
Using cached multidict-6.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)
Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)
Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)
Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)
Using cached yarl-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)
Using cached propcache-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (236 kB)
Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
Installing collected packages: sentencepiece, pytz, py-cpuinfo, ninja, mpmath, hjson, xxhash, urllib3, tzdata, typing-extensions, tqdm, sympy, six, safetensors, regex, pyyaml, pynvml, pyarrow, psutil, protobuf, propcache, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, multidict, MarkupSafe, joblib, idna, fsspec, frozenlist, filelock, dill, click, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, triton, requests, python-dateutil, pydantic-core, nvidia-cusolver-cu11, nvidia-cudnn-cu11, nltk, multiprocess, jinja2, aiosignal, torch, pydantic, pandas, huggingface-hub, aiohttp, tokenizers, deepspeed, accelerate, transformers, datasets
Successfully installed MarkupSafe-3.0.2 accelerate-0.34.2 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 annotated-types-0.7.0 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 click-8.1.7 datasets-3.1.0 deepspeed-0.13.1 dill-0.3.8 filelock-3.16.1 frozenlist-1.5.0 fsspec-2024.9.0 hjson-3.1.0 huggingface-hub-0.26.2 idna-3.10 jinja2-3.1.4 joblib-1.4.2 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 ninja-1.11.1.1 nltk-3.9.1 numpy-1.26.4 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.20.5 nvidia-nvtx-cu11-11.8.86 packaging-24.2 pandas-2.2.3 propcache-0.2.0 protobuf-5.28.3 psutil-6.1.0 py-cpuinfo-9.0.0 pyarrow-18.0.0 pydantic-2.9.2 pydantic-core-2.23.4 pynvml-11.5.3 python-dateutil-2.9.0.post0 pytz-2024.2 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.3 safetensors-0.4.5 sentencepiece-0.2.0 six-1.16.0 sympy-1.13.3 tokenizers-0.15.2 torch-2.4.0+cu118 tqdm-4.67.0 transformers-4.38.2 triton-3.0.0 typing-extensions-4.12.2 tzdata-2024.2 urllib3-2.2.3 xxhash-3.5.0 yarl-1.17.1
# packages in environment at /raid/chrisjihee/miniforge3/envs/GNER:
#
# Name                    Version                   Build  Channel
cuda-cccl                 11.8.89                       0    nvidia
cuda-cudart               11.8.89                       0    nvidia
cuda-cudart-dev           11.8.89                       0    nvidia
cuda-driver-dev           11.8.89                       0    nvidia
cuda-libraries            11.8.0                        0    nvidia
cuda-libraries-dev        11.8.0                        0    nvidia
cuda-nvcc                 11.8.89                       0    nvidia
cuda-nvrtc                11.8.89                       0    nvidia
cuda-nvrtc-dev            11.8.89                       0    nvidia
cuda-profiler-api         12.4.127                      0    nvidia
cuda-runtime              11.8.0                        0    nvidia
cuda-version              12.4                 h3060b56_3    conda-forge
nvidia-cuda-cupti-cu11    11.8.87                  pypi_0    pypi
nvidia-cuda-nvrtc-cu11    11.8.89                  pypi_0    pypi
nvidia-cuda-runtime-cu11  11.8.89                  pypi_0    pypi
# packages in environment at /raid/chrisjihee/miniforge3/envs/GNER:
#
# Name                    Version                   Build  Channel
libcublas                 11.11.3.6                     0    nvidia
libcublas-dev             11.11.3.6                     0    nvidia
libcufft                  11.2.1.3                      0    nvidia
libcufft-dev              11.2.1.3                      0    nvidia
libcufile                 1.9.1.3                       0    nvidia
libcufile-dev             1.9.1.3                       0    nvidia
libcurand                 10.3.5.147                    0    nvidia
libcurand-dev             10.3.5.147                    0    nvidia
libcusolver               11.6.1.9                      0    nvidia
libcusolver-dev           11.6.1.9                      0    nvidia
libcusparse               11.7.5.86                     0    nvidia
libcusparse-dev           11.7.5.86                     0    nvidia
[2024-11-09 01:19:14,617] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @autocast_custom_fwd
/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @autocast_custom_bwd
Traceback (most recent call last):
  File "/raid/chrisjihee/miniforge3/envs/GNER/bin/ds_report", line 3, in <module>
    from deepspeed.env_report import cli_main
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/__init__.py", line 22, in <module>
    from . import module_inject
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/module_inject/__init__.py", line 6, in <module>
    from .replace_module import replace_transformer_layer, revert_transformer_layer, ReplaceWithTensorSlicing, GroupQuantizer, generic_injection
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/module_inject/replace_module.py", line 607, in <module>
    from ..pipe import PipelineModule
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/pipe/__init__.py", line 6, in <module>
    from ..runtime.pipe import PipelineModule, LayerSpec, TiedLayerSpec
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/pipe/__init__.py", line 6, in <module>
    from .module import PipelineModule, LayerSpec, TiedLayerSpec
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/pipe/module.py", line 19, in <module>
    from ..activation_checkpointing import checkpointing
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 26, in <module>
    from deepspeed.runtime.config import DeepSpeedConfig
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/config.py", line 41, in <module>
    from ..elasticity import (
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/elasticity/__init__.py", line 10, in <module>
    from .elastic_agent import DSElasticAgent
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/elasticity/elastic_agent.py", line 9, in <module>
    from torch.distributed.elastic.agent.server.api import log, _get_socket_with_port
ImportError: cannot import name 'log' from 'torch.distributed.elastic.agent.server.api' (/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py)
++ shuf -i25000-30000 -n1
+ port=27145
+ MODEL_NAME_OR_PATH=yahma/llama-7b-hf
+ DATA_DIR=data
+ TRAIN_JSON_DIR=data/pile-ner.json
+ DATA_CONFIG_DIR=configs/dataset_configs/task_adaptation_configs
+ INSTRUCTION_FILE=configs/instruction_configs/instruction.json
+ OUTPUT_DIR=output/llama-7b-task-adaptation
+ DEEPSPEED_CONFIG=configs/deepspeed_configs/deepspeed_zero2_llama.json
+ RUN_NAME=llama-7B-experiment
+ deepspeed --include=localhost:0,1,2,3,4,5,6,7 --master_port 27145 src/run.py --bf16 True --tf32 True --do_train --do_predict --predict_with_generate --model_name_or_path yahma/llama-7b-hf --data_dir data --preprocessing_num_workers 12 --metric_for_best_model eval_average_f1 --greater_is_better True --train_json_dir data/pile-ner.json --data_config_dir configs/dataset_configs/task_adaptation_configs --instruction_file configs/instruction_configs/instruction.json --output_dir output/llama-7b-task-adaptation --per_device_train_batch_size 1 --per_device_eval_batch_size 4 --gradient_accumulation_steps 32 --gradient_checkpointing True --learning_rate 2e-05 --weight_decay 0. --warmup_ratio 0.04 --num_train_epochs 0.1 --lr_scheduler_type cosine --deepspeed configs/deepspeed_configs/deepspeed_zero2_llama.json --run_name llama-7B-experiment --max_source_length 640 --max_target_length 640 --generation_max_length 1280 --overwrite_output_dir --overwrite_cache --logging_strategy steps --logging_steps 5 --save_strategy steps --save_steps 10 --seed 1234
[2024-11-09 01:19:17,093] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/zero/linear.py:47: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.
  @autocast_custom_fwd
/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/zero/linear.py:66: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.
  @autocast_custom_bwd
Traceback (most recent call last):
  File "/raid/chrisjihee/miniforge3/envs/GNER/bin/deepspeed", line 3, in <module>
    from deepspeed.launcher.runner import main
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/__init__.py", line 22, in <module>
    from . import module_inject
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/module_inject/__init__.py", line 6, in <module>
    from .replace_module import replace_transformer_layer, revert_transformer_layer, ReplaceWithTensorSlicing, GroupQuantizer, generic_injection
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/module_inject/replace_module.py", line 607, in <module>
    from ..pipe import PipelineModule
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/pipe/__init__.py", line 6, in <module>
    from ..runtime.pipe import PipelineModule, LayerSpec, TiedLayerSpec
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/pipe/__init__.py", line 6, in <module>
    from .module import PipelineModule, LayerSpec, TiedLayerSpec
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/pipe/module.py", line 19, in <module>
    from ..activation_checkpointing import checkpointing
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/activation_checkpointing/checkpointing.py", line 26, in <module>
    from deepspeed.runtime.config import DeepSpeedConfig
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/runtime/config.py", line 41, in <module>
    from ..elasticity import (
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/elasticity/__init__.py", line 10, in <module>
    from .elastic_agent import DSElasticAgent
  File "/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/deepspeed/elasticity/elastic_agent.py", line 9, in <module>
    from torch.distributed.elastic.agent.server.api import log, _get_socket_with_port
ImportError: cannot import name 'log' from 'torch.distributed.elastic.agent.server.api' (/raid/chrisjihee/miniforge3/envs/GNER/lib/python3.11/site-packages/torch/distributed/elastic/agent/server/api.py)